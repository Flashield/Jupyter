{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets_PATH = '~/OneDrive/ProjectSpace/Jupyter/datasets/'\n",
    "TrainSets_filename = 'TrainSet.csv'\n",
    "TestSets_filename = 'TestSet.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TrainSet_Raw = pd.read_csv(Datasets_PATH+TrainSets_filename,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Y', 'COL_004', 'COL_007', 'COL_012', 'COL_025', 'COL_046',\n",
       "       'COL_048', 'COL_051', 'COL_052', 'COL_148', 'COL_150', 'COL_153',\n",
       "       'COL_154', 'COL_157', 'COL_158', 'COL_161', 'COL_163', 'COL_166',\n",
       "       'COL_167', 'COL_168', 'COL_175', 'COL_178', 'COL_180', 'COL_181',\n",
       "       'COL_183', 'COL_198', 'COL_202', 'COL_207', 'COL_214', 'COL_225',\n",
       "       'COL_226', 'COL_227', 'AGE', 'KD_ACTIVE', 'KD_XY', 'KD_STATUS',\n",
       "       'FEE_BUS', 'BANDWIDTH_IN', 'DUR60_USED', 'CNT_USED_DAY', 'DATE_USED',\n",
       "       'AREA_TYPE', 'IS_QF', 'JTTF', 'IS_TV', 'DURATION60_TV', 'LOGIN_CNT',\n",
       "       'TV_ZZ', 'TV_ZZ_3', 'JT_ZH', 'JT_FH', 'YX_MON', 'YX_MON_3', 'IS_4G',\n",
       "       'IS_5G', 'TOUSU_SUM', 'TOUSU_NUM', 'IS_TOUSU_TV', 'IS_TOUSU_KD', 'ARPU',\n",
       "       'ARPU_3', 'GPRS_BHD', 'RWY_BHD', 'VOI_BHD', 'YWKD', 'TOWN_TYPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['COL_109', 'SEX', 'KD_TYPE', 'ZC_TYPE', 'ZHICHA_2', 'TOUSU_TYPE'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数值类数据\n",
    "TrainSet_Raw.columns[TrainSet_Raw.dtypes != 'object']\n",
    "# 非数值类数据\n",
    "TrainSet_Raw.columns[TrainSet_Raw.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COL_109 5 ['中' '高' '未知' '一般' '低']\n",
      "SEX 3 ['女' '男' nan]\n",
      "KD_TYPE 3 ['fttb' 'ftth' nan]\n",
      "ZC_TYPE 32 [nan 'OTT机顶盒无改有' 'WIFI弱连接' 'OTT机顶盒无改有,WIFI弱连接,光猫托管' 'OTT机顶盒无改有,光猫托管'\n",
      " 'OTT机顶盒无改有,OTT严重卡顿' 'OTT机顶盒无改有,WIFI弱连接' '光猫托管' '光猫弱光' 'OTT机顶盒无改有,光猫弱光'\n",
      " '质差自购路由器' 'WIFI弱连接,光猫弱光,光猫托管' 'OTT严重卡顿' 'OTT机顶盒无改有,质差自购路由器'\n",
      " 'OTT机顶盒无改有,OTT严重卡顿,光猫弱光' 'OTT机顶盒无改有,OTT严重卡顿,WIFI弱连接'\n",
      " 'OTT机顶盒无改有,OTT严重卡顿,质差自购路由器' 'OTT机顶盒无改有,光猫弱光,质差自购路由器'\n",
      " 'OTT机顶盒无改有,光猫托管,质差自购路由器' 'WIFI弱连接,质差自购路由器'\n",
      " 'OTT机顶盒无改有,OTT严重卡顿,WIFI弱连接,光猫托管' 'OTT机顶盒无改有,WIFI弱连接,光猫弱光' 'WIFI弱连接,光猫托管'\n",
      " 'WIFI弱连接,光猫弱光' '光猫弱光,质差自购路由器' 'OTT机顶盒无改有,OTT严重卡顿,光猫托管' 'OTT严重卡顿,WIFI弱连接'\n",
      " 'OTT机顶盒无改有,WIFI弱连接,质差自购路由器' '光猫弱光,光猫托管' '光猫托管,质差自购路由器'\n",
      " 'WIFI弱连接,光猫托管,质差自购路由器' 'OTT机顶盒无改有,光猫弱光,光猫托管']\n",
      "ZHICHA_2 3 [nan '电视严重卡顿' 'ONU弱光']\n",
      "TOUSU_TYPE 9 [nan '售后服务' '功能使用' '功能使用,售后服务' '费用质疑' '办理规范' '功能使用,营销宣传' '营销宣传' '业务规则']\n"
     ]
    }
   ],
   "source": [
    "# 非数值类数据分析\n",
    "for idx_object in TrainSet_Raw.columns[TrainSet_Raw.dtypes == 'object']:\n",
    "    print(idx_object, len(TrainSet_Raw[idx_object].unique()), TrainSet_Raw[idx_object].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除无用数据\n",
    "TrainSet_Raw.drop(['ZC_TYPE'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理分类数据，使用Onehot码\n",
    "TrainSet_Raw = TrainSet_Raw.merge(pd.get_dummies(TrainSet_Raw[['COL_109', 'SEX', 'KD_TYPE', 'ZHICHA_2', 'TOUSU_TYPE']]),\n",
    "                        left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet_Raw.drop(['COL_109', 'SEX', 'KD_TYPE', 'ZHICHA_2', 'TOUSU_TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值(用0填充)\n",
    "TrainSet_Raw.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = TrainSet_Raw.drop(['id','Y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = TrainSet_Raw['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分训练、测试数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_raw, y_train_raw, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理测试集数据（此部分在拆分数据前已处理，无需再次处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除无用数据\n",
    "X_test.drop(['ZC_TYPE'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理分类数据，使用Onehot码\n",
    "X_test = X_test.merge(pd.get_dummies(X_test[['COL_109', 'SEX', 'KD_TYPE', 'ZHICHA_2', 'TOUSU_TYPE']]),\n",
    "                        left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(['COL_109', 'SEX', 'KD_TYPE', 'ZHICHA_2', 'TOUSU_TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5115556842534272"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)\n",
    "tree_pred = tree_reg.predict(X_test)\n",
    "tree_msle = mean_squared_log_error(tree_pred, y_test)\n",
    "tree_rmsle = np.sqrt(tree_msle)\n",
    "tree_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5173426412235282"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 十折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "scores = cross_val_score(tree_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "\n",
    "tree_rmsle_scores = np.sqrt(-scores)\n",
    "tree_rmsle_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)\n",
    "forest_pred = forest_reg.predict(X_test)\n",
    "forest_msle = mean_squared_log_error(forest_pred, y_test)\n",
    "forest_rmsle = np.sqrt(forest_msle)\n",
    "forest_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 十折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "scores = cross_val_score(forest_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "\n",
    "forest_rmsle_scores = np.sqrt(-scores)\n",
    "forest_rmsle_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_reg = AdaBoostRegressor()\n",
    "ada_reg.fit(X_train, y_train)\n",
    "ada_pred = ada_reg.predict(X_test)\n",
    "ada_msle = mean_squared_log_error(ada_pred, y_test)\n",
    "ada_rmsle = np.sqrt(ada_msle)\n",
    "ada_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 十折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ada_reg = AdaBoostRegressor()\n",
    "scores = cross_val_score(ada_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "\n",
    "ada_rmsle_scores = np.sqrt(-scores)\n",
    "ada_rmsle_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "grad_reg = GradientBoostingRegressor()\n",
    "grad_reg.fit(X_train, y_train)\n",
    "grad_pred = grad_reg.predict(X_test)\n",
    "grad_msle = mean_squared_log_error(grad_pred, y_test)\n",
    "grad_rmsle = np.sqrt(grad_msle)\n",
    "grad_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 十折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "grad_reg = GradientBoostingRegressor()\n",
    "scores = cross_val_score(grad_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_log_error\", cv=10)\n",
    "\n",
    "grad_rmsle_scores = np.sqrt(-scores)\n",
    "grad_rmsle_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归自动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择模型训练（回归）\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 归一化\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train_scale = scaler.transform(X_train)  \n",
    "# X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              Scoring              |                                                                                                                 Function                                                                                                                  |             Comment              |\n",
    "| --------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- |\n",
    "| **Classification**                |                                                                                                                                                                                                                                           |                                  |\n",
    "| ‘accuracy’                        | [`metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score \"sklearn.metrics.accuracy_score\")                                                         |                                  |\n",
    "| ‘balanced_accuracy’               | [`metrics.balanced_accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score \"sklearn.metrics.balanced_accuracy_score\")                     |                                  |\n",
    "| ‘average_precision’               | [`metrics.average_precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score \"sklearn.metrics.average_precision_score\")                     |                                  |\n",
    "| ‘neg\\_brier\\_score’               | [`metrics.brier_score_loss`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss \"sklearn.metrics.brier_score_loss\")                                                 |                                  |\n",
    "| ‘f1’                              | [`metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\")                                                                                 | for binary targets               |\n",
    "| ‘f1_micro’                        | [`metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\")                                                                                 | micro-averaged                   |\n",
    "| ‘f1_macro’                        | [`metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\")                                                                                 | macro-averaged                   |\n",
    "| ‘f1_weighted’                     | [`metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\")                                                                                 | weighted average                 |\n",
    "| ‘f1_samples’                      | [`metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score \"sklearn.metrics.f1_score\")                                                                                 | by multilabel sample             |\n",
    "| ‘neg\\_log\\_loss’                  | [`metrics.log_loss`] | requires `predict_proba` support |\n",
    "| ‘precision’ etc.                  | [`metrics.precision_score`]                   | suffixes apply as with ‘f1’      |\n",
    "| ‘recall’ etc.                     | [`metrics.recall_score`]                                | suffixes apply as with ‘f1’      |\n",
    "| ‘jaccard’ etc.                    | [`metrics.jaccard_score`]                              | suffixes apply as with ‘f1’      |\n",
    "| ‘roc_auc’                         | [`metrics.roc_auc_score`]                                                       |                                  |\n",
    "| ‘roc\\_auc\\_ovr’                   | [`metrics.roc_auc_score`]                                     |                                  |\n",
    "| ‘roc\\_auc\\_ovo’                   | [`metrics.roc_auc_score`]                                                           |                                  |\n",
    "| ‘roc\\_auc\\_ovr_weighted’          | [`metrics.roc_auc_score`]                                                            |                                  |\n",
    "| ‘roc\\_auc\\_ovo_weighted’          | [`metrics.roc_auc_score`]                                                            |                                  |\n",
    "| **Clustering**                    |                                                                                                                                                                                                                                           |                                  |\n",
    "| ‘adjusted\\_mutual\\_info_score’    | [`metrics.adjusted_mutual_info_score`]         |                                  |\n",
    "| ‘adjusted\\_rand\\_score’           | [`metrics.adjusted_rand_score`]     |                                  |\n",
    "| ‘completeness_score’              | [`metrics.completeness_score`]                                       |                                  |\n",
    "| ‘fowlkes\\_mallows\\_score’         | [`metrics.fowlkes_mallows_score`]                                |\n",
    "| ‘homogeneity_score’               | [`metrics.homogeneity_score`]             |                                  |\n",
    "| ‘mutual\\_info\\_score’             | [`metrics.mutual_info_score`]                                          |                                  |\n",
    "| ‘normalized\\_mutual\\_info_score’  | [`metrics.normalized_mutual_info_score`] |                                  |\n",
    "| ‘v\\_measure\\_score’               | [`metrics.v_measure_score`]                  |                                  |\n",
    "| **Regression**                    |                                                                                                                                                                                                                                           |                                  |\n",
    "| ‘explained_variance’              | [`metrics.explained_variance_score`]                 |                                  |\n",
    "| ‘max_error’                       | [`metrics.max_error`]                                                                     |                                  |\n",
    "| ‘neg\\_mean\\_absolute_error’       | [`metrics.mean_absolute_error`]    |                                  |\n",
    "| ‘neg\\_mean\\_squared_error’        | [`metrics.mean_squared_error`]        |                                  |\n",
    "| ‘neg\\_root\\_mean\\_squared\\_error’ | [`metrics.mean_squared_error`]        |                                  |\n",
    "| ‘neg\\_mean\\_squared\\_log\\_error’  | [`metrics.mean_squared_log_error`]                         |\n",
    "| ‘neg\\_median\\_absolute_error’     | [`metrics.median_absolute_error`]                           |                                  |\n",
    "| ‘r2’                              | [`metrics.r2_score`]                                                                             |                                  |\n",
    "| ‘neg\\_mean\\_poisson_deviance’     | [`metrics.mean_poisson_deviance`]                            |                                  |\n",
    "| ‘neg\\_mean\\_gamma_deviance’       | [`metrics.mean_gamma_deviance`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor() neg_mean_squared_log_error 0.3545367534878658\n",
      "AdaBoostRegressor() neg_mean_squared_log_error 0.355019535165337\n",
      "RandomForestRegressor() neg_mean_squared_log_error 0.3557691178056485\n",
      "SVR() neg_mean_squared_log_error 0.3780034502920132\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mean Squared Logarithmic Error cannot be used when targets contain negative values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 560, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 607, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n    score = scorer._score(cached_call, estimator,\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 212, in _score\n    return self._sign * self._score_func(y_true, y_pred,\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n    return f(**kwargs)\n  File \"/home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 334, in mean_squared_log_error\n    raise ValueError(\"Mean Squared Logarithmic Error cannot be used when \"\nValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0948c5115fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      SGDRegressor(), KNeighborsRegressor(), GaussianProcessRegressor(), MLPRegressor(), XGBRegressor()]:\n\u001b[1;32m      5\u001b[0m     \u001b[0mregresor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_select\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     reg_score = cross_val_score(regresor, X_train, y_train,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                scoring=score_metric, cv=10, n_jobs=-1)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mean Squared Logarithmic Error cannot be used when targets contain negative values."
     ]
    }
   ],
   "source": [
    "score_metric = 'neg_mean_squared_log_error'\n",
    "# 回归训练 \n",
    "for model_select in [GradientBoostingRegressor(), AdaBoostRegressor(), RandomForestRegressor(), SVR(), \n",
    "                     SGDRegressor(), KNeighborsRegressor(), GaussianProcessRegressor(), MLPRegressor(), XGBRegressor()]:\n",
    "    regresor = model_select\n",
    "    reg_score = cross_val_score(regresor, X_train, y_train,\n",
    "                               scoring=score_metric, cv=10, n_jobs=-1)\n",
    "    \n",
    "    reg_rmsle_scores = np.sqrt(-reg_score)\n",
    "    print(str(regresor), score_metric, reg_rmsle_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingRegressor() neg_mean_squared_log_error 0.352358110906292\n",
    "AdaBoostRegressor() neg_mean_squared_log_error 0.352789060016812\n",
    "RandomForestRegressor() neg_mean_squared_log_error 0.3536608862052085\n",
    "SVR() neg_mean_squared_log_error 0.37536296946841224\n",
    "KNeighborsRegressor() neg_mean_squared_log_error 0.37127147932634175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类自动预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择模型训练（分类）\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier() make_scorer(cohen_kappa_score) 0.0020048118677434166\n",
      "AdaBoostClassifier() make_scorer(cohen_kappa_score) 0.0011272477961544402\n",
      "RandomForestClassifier() make_scorer(cohen_kappa_score) 0.0014933170482912539\n",
      "SVC() make_scorer(cohen_kappa_score) 0.0\n",
      "SGDClassifier() make_scorer(cohen_kappa_score) 0.0030668196029185026\n",
      "KNeighborsClassifier() make_scorer(cohen_kappa_score) -0.0008495999976736335\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1f76e5e4660e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                      SGDClassifier(), KNeighborsClassifier(), GaussianProcessClassifier(), MLPClassifier(), XGBClassifier()]:\n\u001b[1;32m     11\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_select\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     clf_score = cross_val_score(clf, X_train, y_train,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                scoring=score_metric, cv=10, n_jobs=-1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/jupyter/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11), SIGSEGV(-11)}"
     ]
    }
   ],
   "source": [
    "# 评价标准\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "score_metric = make_scorer(cohen_kappa_score)\n",
    "# score_metric = 'f1'\n",
    "#from sklearn.metrics import f1_score\n",
    "#score_metric = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# 分类训练 \n",
    "for model_select in [GradientBoostingClassifier(), AdaBoostClassifier(), RandomForestClassifier(), SVC(), \n",
    "                     SGDClassifier(), KNeighborsClassifier(), GaussianProcessClassifier(), MLPClassifier(), XGBClassifier()]:\n",
    "    clf = model_select\n",
    "    clf_score = cross_val_score(clf, X_train, y_train,\n",
    "                               scoring=score_metric, cv=10, n_jobs=-1)\n",
    "    \n",
    "    clf_f1_scores = clf_score\n",
    "    print(str(clf), str(score_metric), clf_f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier() make_scorer(f1_score, average=weighted) 0.27770921004003346\n",
    "AdaBoostClassifier() make_scorer(f1_score, average=weighted) 0.276852844875935\n",
    "RandomForestClassifier() make_scorer(f1_score, average=weighted) 0.28406589909762425\n",
    "SVC() make_scorer(f1_score, average=weighted) 0.27656356005292493\n",
    "SGDClassifier() make_scorer(f1_score, average=weighted) 0.14433238655778674\n",
    "KNeighborsClassifier() make_scorer(f1_score, average=weighted) 0.2780129419725555\n",
    "MLPClassifier() make_scorer(f1_score, average=weighted) 0.1779162425669787\n",
    "XGBClassifier make_scorer(f1_score, average=weighted) 0.29400521520758044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "xgb_msle = mean_squared_log_error(xgb_pred, y_test)\n",
    "xgb_rmsle = np.sqrt(xgb_msle)\n",
    "xgb_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_reg = AdaBoostRegressor(n_estimators=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=80)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_boost_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada_boost_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_msle = mean_squared_log_error(y_pred, y_test)\n",
    "ada_boost_rmsle = np.sqrt(ada_boost_msle)\n",
    "ada_boost_rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredSet_Raw = pd.read_csv(Datasets_PATH+TestSets_filename, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除无用数据\n",
    "X_pred = PredSet_Raw.drop(['ZC_TYPE','id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理分类数据，使用Onehot码\n",
    "X_pred = X_pred.merge(pd.get_dummies(X_pred[['COL_109', 'SEX', 'KD_TYPE', 'ZHICHA_2', 'TOUSU_TYPE']]),\n",
    "                        left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred.drop(['COL_109', 'SEX', 'KD_TYPE', 'ZHICHA_2', 'TOUSU_TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值\n",
    "X_pred.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COL_004', 'COL_007', 'COL_012', 'COL_025', 'COL_046', 'COL_048',\n",
       "       'COL_051', 'COL_052', 'COL_148', 'COL_150', 'COL_153', 'COL_154',\n",
       "       'COL_157', 'COL_158', 'COL_161', 'COL_163', 'COL_166', 'COL_167',\n",
       "       'COL_168', 'COL_175', 'COL_178', 'COL_180', 'COL_181', 'COL_183',\n",
       "       'COL_198', 'COL_202', 'COL_207', 'COL_214', 'COL_225', 'COL_226',\n",
       "       'COL_227', 'AGE', 'KD_ACTIVE', 'KD_XY', 'KD_STATUS', 'FEE_BUS',\n",
       "       'BANDWIDTH_IN', 'DUR60_USED', 'CNT_USED_DAY', 'DATE_USED', 'AREA_TYPE',\n",
       "       'IS_QF', 'JTTF', 'IS_TV', 'DURATION60_TV', 'LOGIN_CNT', 'TV_ZZ',\n",
       "       'TV_ZZ_3', 'JT_ZH', 'JT_FH', 'YX_MON', 'YX_MON_3', 'IS_4G', 'IS_5G',\n",
       "       'TOUSU_SUM', 'TOUSU_NUM', 'IS_TOUSU_TV', 'IS_TOUSU_KD', 'ARPU',\n",
       "       'ARPU_3', 'GPRS_BHD', 'RWY_BHD', 'VOI_BHD', 'YWKD', 'TOWN_TYPE',\n",
       "       'COL_109_一般', 'COL_109_中', 'COL_109_低', 'COL_109_未知', 'COL_109_高',\n",
       "       'SEX_女', 'SEX_男', 'KD_TYPE_fttb', 'KD_TYPE_ftth', 'ZHICHA_2_ONU弱光',\n",
       "       'ZHICHA_2_电视严重卡顿', 'TOUSU_TYPE_业务规则', 'TOUSU_TYPE_办理规范',\n",
       "       'TOUSU_TYPE_功能使用', 'TOUSU_TYPE_功能使用,售后服务', 'TOUSU_TYPE_功能使用,营销宣传',\n",
       "       'TOUSU_TYPE_售后服务', 'TOUSU_TYPE_营销宣传', 'TOUSU_TYPE_费用质疑'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['COL_004', 'COL_007', 'COL_012', 'COL_025', 'COL_046', 'COL_048',\n",
       "       'COL_051', 'COL_052', 'COL_148', 'COL_150', 'COL_153', 'COL_154',\n",
       "       'COL_157', 'COL_158', 'COL_161', 'COL_163', 'COL_166', 'COL_167',\n",
       "       'COL_168', 'COL_175', 'COL_178', 'COL_180', 'COL_181', 'COL_183',\n",
       "       'COL_198', 'COL_202', 'COL_207', 'COL_214', 'COL_225', 'COL_226',\n",
       "       'COL_227', 'AGE', 'KD_ACTIVE', 'KD_XY', 'KD_STATUS', 'FEE_BUS',\n",
       "       'BANDWIDTH_IN', 'DUR60_USED', 'CNT_USED_DAY', 'DATE_USED', 'AREA_TYPE',\n",
       "       'IS_QF', 'JTTF', 'IS_TV', 'DURATION60_TV', 'LOGIN_CNT', 'TV_ZZ',\n",
       "       'TV_ZZ_3', 'JT_ZH', 'JT_FH', 'YX_MON', 'YX_MON_3', 'IS_4G', 'IS_5G',\n",
       "       'TOUSU_SUM', 'TOUSU_NUM', 'IS_TOUSU_TV', 'IS_TOUSU_KD', 'ARPU',\n",
       "       'ARPU_3', 'GPRS_BHD', 'RWY_BHD', 'VOI_BHD', 'YWKD', 'TOWN_TYPE',\n",
       "       'COL_109_一般', 'COL_109_中', 'COL_109_低', 'COL_109_未知', 'COL_109_高',\n",
       "       'SEX_女', 'SEX_男', 'KD_TYPE_fttb', 'KD_TYPE_ftth', 'ZHICHA_2_ONU弱光',\n",
       "       'ZHICHA_2_电视严重卡顿', 'TOUSU_TYPE_业务规则', 'TOUSU_TYPE_办理规范',\n",
       "       'TOUSU_TYPE_功能使用', 'TOUSU_TYPE_功能使用,售后服务', 'TOUSU_TYPE_功能使用,营销宣传',\n",
       "       'TOUSU_TYPE_售后服务', 'TOUSU_TYPE_营销宣传', 'TOUSU_TYPE_费用质疑'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集和测试集变换后的字段变换情况\n",
    "X_pred.columns\n",
    "X_train.columns\n",
    "set(X_pred.columns) - set(X_train.columns)\n",
    "set(X_train.columns) - set(X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COL_109_低\n",
      "TOUSU_TYPE_功能使用,营销宣传\n",
      "COL_109_一般\n",
      "TOUSU_TYPE_办理规范,业务规则\n"
     ]
    }
   ],
   "source": [
    "# 增加缺失的数据列\n",
    "for miss_columns in set(X_train.columns) - set(X_pred.columns):\n",
    "    print(miss_columns)\n",
    "    X_pred[miss_columns] = 0\n",
    "    \n",
    "# 去除增加的数据列\n",
    "for add_columns in set(X_pred.columns) - set(X_train.columns):\n",
    "    print(add_columns)\n",
    "    X_pred.drop(add_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集按预测集的列进行排序\n",
    "X_pred = X_pred[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rlt = ada_boost_reg.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.70420893, 7.26138538, 6.74061773, ..., 7.8664626 , 7.21688187,\n",
       "       7.21688187])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.704209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.261385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.740618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.704209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.704209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3996</td>\n",
       "      <td>7.704209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3997</td>\n",
       "      <td>7.216882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3998</td>\n",
       "      <td>7.866463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3999</td>\n",
       "      <td>7.216882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4000</td>\n",
       "      <td>7.216882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  pred_result\n",
       "0        1     7.704209\n",
       "1        2     7.261385\n",
       "2        3     6.740618\n",
       "3        4     7.704209\n",
       "4        5     7.704209\n",
       "...    ...          ...\n",
       "3995  3996     7.704209\n",
       "3996  3997     7.216882\n",
       "3997  3998     7.866463\n",
       "3998  3999     7.216882\n",
       "3999  4000     7.216882\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并结果\n",
    "PredSet_Raw['pred_result']=y_pred_rlt\n",
    "PredSet_Raw[['id','pred_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据结果\n",
    "#PredSet_Raw[['id','pred_result']].to_csv('test_ada_rlt.csv', index=False, header=False)\n",
    "PredSet_Raw[['id','pred_result']].to_csv('test_ada_rlt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数调优\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid=[{'learning_rate': [0.5, 1, 1.5],\n",
       "                          'loss': ['linear', 'exponential'],\n",
       "                          'n_estimators': [10, 50, 80, 100]}],\n",
       "             scoring='neg_mean_squared_log_error')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [10,50,80,100], 'loss': ['linear', 'exponential'], 'learning_rate':[0.5, 1, 1.5]},\n",
    "]\n",
    "\n",
    "ada_reg = AdaBoostRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(ada_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_log_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(learning_rate=0.5, n_estimators=10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.57086375, 7.57086375, 7.39737991, ..., 7.86355082, 7.45162636,\n",
       "       7.39413745])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred.to_csv('datasets/Export_pred.csv',encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
