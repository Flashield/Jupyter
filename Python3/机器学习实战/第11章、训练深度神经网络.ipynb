{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=55):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_no = '0' # or '1'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_no\n",
    "\n",
    "# 定义TensorFlow配置\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# 配置GPU内存分配方式，按需增长，很关键\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# 配置可使用的显存比例\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# 在创建session的时候把config作为参数传进去\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第10章介绍了人工神经网络，并且训练了第一个深度神经网络。但其实它是一个很浅层的DNN，只有两个隐藏层。当需要处理一个复杂问题时，比如要在高分辨率的图片中检测数百种形状的对象，该怎么办呢？可能需要训练一个更深层的DNN，比如说10层，每一层都含有数百个神经元，通过数十万个链接相连。这并不是公园里的一条步道：\n",
    "\n",
    "* 首先，可能会遇到很诡异的梯度消失问题（或者相关的梯度爆炸问题），它们会影响深度神经网络，从而导致低层训练困难。\n",
    "* 其次，对于这么庞大的一个网络，训练速度会非常慢。\n",
    "* 第三，一个有数百万参数的模型会很容易出现过度拟合训练集的风险。\n",
    "\n",
    "在本章，会回顾每一个问题，并且介绍科学解决方法。会从梯度消失问题开始，探索这类问题目前最流行的解决方案。接着会研究一下相较平坦梯度下降能够在训练大模型时做到明显提速的各种优化器。最后，浏览一下几个流行的针对大型神经网络的正则化技术。\n",
    "\n",
    "有了这些工具，就能够训练比较深的网络：欢迎来到深度学习！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度消失/爆炸问题\n",
    "\n",
    "正如在第10章中讨论的，反向传播算法是从输出层反向作用到输入层，在过程中传播误差梯度。一旦算法根据网络的参数计算出成本函数的梯度，就会根据梯度下降步骤利用这些梯度来修正每一个参数。\n",
    "\n",
    "不幸的是，梯度经常会随着算法进展到更低层时变得越来越小。导致的结果是，梯度下降在更低层网络连接权值更新方面基本没有改变，而且训练不会收敛到好的结果。这称为`梯度消失`问题。在一些例子中会发生相反的现象：梯度会越来越大，导致很多层的权值疯狂增大，使得算法发散。这就是`梯度爆炸`问题，它经常出现在循环神经网络中（参见第14章）。简单来讲，深度神经网络受制于不稳定梯度；不同层可能会以完全不同的速度学习。\n",
    "\n",
    "尽管证实这个不幸的表现经历了相当长一段时间（这也是深度神经网络在很长一段时间内几乎被遗弃的原因之一），直到2010年左右在梯度消失问题的研究方面才有了重大的突破。Xavier Glorot和Yoshua Bengio [1] 在论文“Understanding the Difficulty of Training Deep Feedforward Neural Networks”（ http://goo.gl/1rhAef ）中提到几个假设，包括流行的逻辑S激活函数和当时最流行的权重初始化技术的混合，即用均值为0、方差为1的正态分布进行随机初始化。简而言之，利用这种激活函数和初始化方式，他们发现每一层输出方差都比输入方差大很多。在这个网络里，每层都会出现方差增加，直到激活函数最高层饱和。如果逻辑函数的均值变成0.5，这个现象就会变得比较糟（均值为0的双曲正切函数比逻辑函数在深层网络中表现会稍好一些）。\n",
    "\n",
    "观察逻辑激活函数（见图11-1），会发现当输入变大（正或负），函数在0或1饱和，导数无限靠近0。也就是当反向传播起作用时，实际上并没有梯度通过网络反向作用，同时在反向传播到顶层的过程中几乎没有梯度被稀释，所以基本上没有给低层留下什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "#save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图11-1：逻辑激活函数饱和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier初始化和He初始化\n",
    "\n",
    "在Glorot和Bengio的论文中针对这个问题提出了一个很有效的缓和办法。需要让信号在两个方向都正确流动：当预测的时候要保持正向，在反向传播梯度时保持反方向。我们并不希望信号消亡，同样也不希望它们爆炸或者稀释。为了让信号正确流动，作者提出需要保持每一层的输入和输出的方差一致， [2] 并且需要在反向流动过某一层时，前后的方差也要一致（如果对数学细节感兴趣可以查阅论文）。事实上，这是很难保证的，除非一层有相同数量的输入和输出连接，当然他们也提出了一种很好的折中方案：连接权重必须按照公式11-1进行随机初始化，其中$n _{inputs}$ 和$n_{outputs}$ 是权重被初始化层的输入和输出连接数（也称为扇入和扇出）。这种初始化的方法称为Xavier初始化（以作者的名字命名），有时也称为Glorot初始化。\n",
    "\n",
    "公式11-1：Xavier初始化（当使用逻辑激活函数时）\n",
    "\n",
    "均值为0和标准差$\\sigma = \\sqrt{\\frac{2}{n_{inputs}+n_{outputs}}}$的正态分布，或者一个在$-r$和$+r$之间的标准分布，其中$r = \\sqrt{\\frac{6}{n_{inputs}+n_{outputs}}}$\n",
    "\n",
    "当输入连接数和输出连接数大体一致时，你可以得到一个简单的等式（比如：$\\sigma = \\frac{1}{\\sqrt {n_{inputs}}}$或者$r = \\frac{\\sqrt 3}{\\sqrt {n_{inputs}}}$）。在第10章 [3] 用过这个简易方法。\n",
    "\n",
    "利用Xavier初始化方法可以显著提高训练速度，它是众多带领深度学习取得现如今成功的方法之一。近期的一些论文 [4] 为不同的激活函数提供了类似的方法，见表11-1。ReLU激活函数的初始化方法（以及它的变种，包括简称的ELU激活）有时称为He初始化（以作者的姓氏命名）。\n",
    "\n",
    "表11-1：每种激活函数的初始化参数\n",
    "\n",
    "|激活函数|均匀分别 -r, r|正态分布|\n",
    "|:--:|:--:|:--:|\n",
    "|逻辑函数|$r = \\sqrt{\\frac{6}{n_{inputs}+n_{outputs}}}$|$\\sigma = \\sqrt{\\frac{2}{n_{inputs}+n_{outputs}}}$|\n",
    "|双曲正切函数|$r = \\sqrt[4]{\\frac{6}{n_{inputs}+n_{outputs}}}$|$\\sigma = \\sqrt[4]{\\frac{2}{n_{inputs}+n_{outputs}}}$|\n",
    "|ReLU（及变种）|$r = \\sqrt[\\sqrt2]{\\frac{6}{n_{inputs}+n_{outputs}}}$|$\\sigma = \\sqrt[\\sqrt2]{\\frac{2}{n_{inputs}+n_{outputs}}}$|\n",
    "\n",
    "`fully_connected()`函数（第10章已介绍）默认用Xavier初始化（用均匀分布）。你可以用下面的方法通过使用`variance_scaling_initializer()`函数将其变成He函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-da109dac52d3>:2: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> He初始化只考虑了扇入，没有像Xavier初始化一样取扇入和扇出的平均值。这也是`variance_scaling_initializer()`函数里默认设置的，但是可以通过修改参数`mode=\"FAN_AVG\"`来调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非饱和激活函数\n",
    "\n",
    "Glorot和Bengio在2010年的论文中提到一个观点，梯度消失/爆炸问题一部分的原因是选错了激活函数。在那之前很多人一直有这样的假设：如果大自然在生物神经元里都使用了S激活函数，那么这个函数一定是一个绝佳的选择。但结果却表明其他的激活函数在深度神经网络中表现得更好一些，特别是在ReLU激活函数中，出现这种结果最主要的原因是它并不稀释正值（同时也因为计算速度很快）。\n",
    "\n",
    "然而，ReLU激活函数并不是完美的。它会出现dying ReLU问题：在训练过程中，一些神经元实际上已经死了，即它们只输出0。在一些案例中，可能会发现网络中有一半神经元都死了，特别是当用了一个比较大的训练速度时。在训练过程中，如果神经元的权重更新到神经元输入的总权重是负值时，这个神经元就会开始输出0。当这种情况发生时，除非ReLu函数的梯度为0并且输入为负，否则这个神经元就不会再重新开始工作。\n",
    "\n",
    "要解决这个问题，可能需要使用ReLU函数的变种，比如leaky ReLU（带泄漏线性整流函数）。这个函数定义为：$LeakyReLU_\\alpha(z) = \\max(\\alpha z, z)$（见图11-2）。超参数$\\alpha$表示函数“泄漏”程度：它是函数中$z<0$时的坡度，一般会设置为0.01。这个小坡度可以保证leaky ReLU不会死；它可以进入一个很长的昏迷期，但最后还是有机会醒过来。一篇近期的论文（ https://goo.gl/B1xhKn ） [5] 中对比了几个ReLU激活函数的变种，其中一个结论就是带泄漏变种总是优于严格的ReLU激活函数。实际上，设置$\\alpha=0.2$（大泄漏）得到的结果会比$\\alpha=0.01$（小泄漏）好。同时，论文中也评估了RReLU（带泄漏随机ReLU），即在训练过程中$\\alpha$是在给定区间里的一个随机值，在测试过程中固定在一个平均值。它的表现也很不错，可以作为一个正则（降低了训练集过度拟合的风险）。最后，他们还评估了PReLU（参数线性整流），其中$\\alpha$在训练中可以进行学习（不作为超函数，而是在反向传播过程中的参数）。这个函数在大的图片数据集的情况下会比ReLU效果更好，但是在小的数据集时会有训练集过度拟合的风险。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "#save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图11-2：Leaky ReLU（带泄漏线性整流函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.96 Validation accuracy: 0.9028\n",
      "5 Batch accuracy: 0.92 Validation accuracy: 0.949\n",
      "10 Batch accuracy: 0.96 Validation accuracy: 0.9644\n",
      "15 Batch accuracy: 0.98 Validation accuracy: 0.9696\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9726\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.976\n",
      "30 Batch accuracy: 0.98 Validation accuracy: 0.9782\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，在Djork-ArnéClevert等人 [6] 2015年发表的一篇论文（ http://goo.gl/Sdl2P7 ）中提出了一个新的激活函数，称为ELU（加速线性单元），在他们的测试中，它的表现优于ReLU的所有变种：训练时间减小，神经网络在测试集的表现也更好。图11-3和公式11-2给出了这个函数的定义。\n",
    "\n",
    "$$\n",
    "ELU_\\alpha(z) = \\begin{cases}\n",
    "    \\alpha(\\exp(z) - 1) & (z < 0) \\\\\n",
    "    z                   & (z \\ge0)\n",
    "\\end{cases} \\tag{11-2} \\label{11-2}\n",
    "$$\n",
    "公式11-2：ELU激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAELCAYAAADECQ0AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAimElEQVR4nO3deXxU1d3H8c+PsAsCgiIKirhQcSlV6uOGpu5a17rVBYtWsW4FC1pFfZ5aKda6YUVR1JaKuOMu7jLFIkVBoRgEZLGAIIswQCAsSc7zx5mQkAxZJ3PmZr7v1+u+mMyZufc3Jzdf7pw5c6855xARkehqFLoAERGpGwW5iEjEKchFRCJOQS4iEnEKchGRiFOQi4hEnIJcRCTiFOQiIhGnIJc6MbNRZvZWA9pOIzN73Mx+MDNnZrn1vc1KaknLa05sq52ZLTOzvdOxvZoys5fMbGDoOjKV6Zud6WNmo4BfJWma7Jw7PNHewTl3+naeHwO+cs5dX+7+vsBw51yrlBZcvW23we9H8Shtp5Ltnw68AuQC84FVzrnN9bnNxHZjlHvd6XrNiW3di9/3Lq/vbSXZ9jHAIOBQYDfgcufcqHKPOQj4J7CXc25NumvMdI1DF5CFPgT6lLuv3oOivqTrjyqNf7z7AEudc5+maXvbla7XbGYtgSuBM9KxvSRaAV8BTyeWCpxzM8xsPnAp8Egaa4sEDa2k3ybn3PflllX1vVEzO8XMPjGz1Wa2yszeM7P9y7SbmQ00s2/MbJOZLTazuxNto4BjgesSww3OzLqWtJnZW2bWL/HWPKfcdp81szeqU0d1tlNmPc3MbFhimxvN7N9mdnSZ9piZPWpmQ81spZktN7P7zGy7+3xi+w8CeyS2/W2ZdQ0v/9iSeqqzrdr0b01fc21fN3Aa4ICJSfrkUDP7yMwKzGyumR1jZheYWYXH1pZzbpxzbrBz7mWguJKHvgFclKrtNiQK8uyxAzAMOAw/bLAGeNPMmibahwJ3AHcDBwDnA4sSbf2BScDfgU6JpaStxEtAG+DEkjvMrBVwFvBMNeuoznZK/AW4ELgC+AkwA3jXzDqVecwlQCFwJHA9MCDxnO3pD/wRWJzY9k8reWx5VW2rrv0L1XvN1amlvN7AVFdunNXMfgp8AowHDgb+DdwJ3JZ4LZR7/GAzy69i6V1JHVX5DDjMzFrUYR0Nk3NOS5oWYBT+Dyy/3HJPmfa3Knl+DD8WXv7+vkB+DWvZASgCjsa/td0I/KYW295aM35seXSZtkvxQd28OnXUYDs74IejLivTngPMA4aUWc+kcuv4AHiyin4ZBHxb1WsvV0+l26pt/9b0Ndf2dQOvAf9Icv8E4IUyP5+W+F2N3856dsIPTVW2tKii//OBvttpOxj/zmHvmuzr2bBojDz9JgD9yt0Xr++Nmp+NcBfwP8DO+HdjjYA98AHRDPiojpt5BviHmbV0zm3AHxmOdc5trGYd1bU30IQyQwHOuSIzmwT0KPO4/5R73hJglxpspyYq21YP6t6/1X3NVdWSTAtgWdk7zGxX/JH6z8rcvRn/u6pwNJ6oZxVQn8OEBYl/dURejoI8/TY45+bW8rlr8cMX5bXFH/lW5i38kMHVwHf4dwYzgaaVPamG3k6s9ywz+wg4ATg5zXWUHR7YkqStNsOJxYCVu69JuZ9Tta3aKD/1rKa1rATalbuv5POTKWXu6w7Mds79K9lKzGwwMLjyUjnVOfdJFY/Znp0S/66o5fMbLAV5tMwGTjMzc4n3mgmHJNqSMrP2wI+Aa51z4xP3HULp7/9rYBNwPPDNdlazGf9Wfrucc5vM7CX8kXgH4Hv8W/3q1lGt7eCHEzYDRyVuk/iQ9Qjg2SqeWxsr8OPWZf0Y+Laaz09F/9bna/4SPzxXVlv8fwBFiW21xo+Nf1/Jeh4DXqxiW9/VqkLvQOA759yyKh+ZZRTk6dcs8ba1rCLnXMlRxo5m1rNce9w59y0wAv/h1cNm9gR+3PU0/Cf5Z1ayzdX4o66rzGwRsDtwL/5oGOfcOjN7CLjbzDbhh3/aA4c650Yk1vEt/oOmrvhxzFXOuWQzDJ7BDyHsBTxX7jGV1lHd7Tjn1pvZCOAeM1sJLABuBDoCj1bSD7X1MTDMzM7E/4d5NdCFagZ5bfu33Drq8zW/l1hve+fcD4n7puHfhdxqZmPwv6elwD5mtq9zrsJ/SLUdWkl8KL5P4sdG+FlDPfG/+4VlHto7UauUF3qQPpsW/IdXLsmyuIr2l8us46f4nXkZfjhlMnB2NbZ9HH6u7sbEvydT5oMl/B/QLfgvwWzGz5r4U5nn74efWbEhUVPXMjW/VeZxhg8lBxxcizqqu51m+Nkvy/BHu/8m8YFpoj1GJR8eVtJPyT7sbIKfu7wysdxJxQ87K91Wbfq3pq+5jq97EnBdufsG49+NbATG4IdfJgIrUvx3kUvy/X5Umcc0x+/vh4f+O87ERd/sFBHM7BTgIaCHc64odD3lmdl1wFnOuZNC15KJNI9cRHDOvYt/19E5dC3bsQW4IXQRmUpH5CIiEacjchGRiFOQi4hEXJDphx06dHBdu3YNsemt1q9fzw477BC0hkyhvvBmz55NUVERPXqU/6JkdsrU/aKwEGbNgk2boF076Nat/reZKX0xderUlc65ncvfHyTIu3btypQpU6p+YD2KxWLk5uYGrSFTqC+83Nxc4vF48H0zU2TifrF5M5x8sg/xQw6BTz6Bli3rf7uZ0hdm9t9k92toRUQiwTm44QaIxaBTJ3j99fSEeBQoyEUkEh5+GEaOhObN4bXXoHOmTpQMQEEuIhnvvffgxhv97b/9DQ47LGw9mabOQW5mzc3sMzObbmZ5ZnZnKgoTEQH/weaFF0JxMdx+O1ykawRVkIoPOzcBxznn8s2sCfAvM3vHOffvFKxbRLLYqlVwxhmwZg384hdwpw4Tk6pzkDv/1dD8xI9NEou+LioidbJlC5x/PsydCz17wtNPQyMNBieVkumHifMiT8WfivIR59zkJI/pR+LKOB07diQWi6Vi07WWn58fvIZMob7w4vE4RUVF6ouE0PvFgw/uy8cf7067dpu59dapfP75pmC1hO6LKqX4dJRt8RdqPbCyxx166KEutPHjx4cuIWOoL7xjjz3W/fjHPw5dRsYIuV8MH+4cONesmXOTJgUrY6tM+RsBprgkmZrSNyrOuXgiyE9J5XpFJHt88AH07+9vP/UUHH542HqiIBWzVnY2s7aJ2y2AE4FZdV2viGSfOXPgggugqAhuvRUuuSR0RdGQijHyTvgrp+fg/2N40Tn3VgrWKyJZZPVqP0MlHoezz4YhQ0JXFB2pmLXyH+AnKahFRLJUYaE/Ep8zBw4+GEaP1gyVmlBXiUhwN94IH34Iu+wCb7wBrVqFrihaFOQiEtRjj8Hw4dC0Kbz6Kuy5Z+iKokdBLiLBfPwxXH+9v/3EE3DkkWHriSoFuYgE8c03cN55fobKzTfDZZeFrii6FOQiknbxuJ+hUjJTZejQ0BVFm4JcRNKqsNCfzXD2bDjoIBgzBnJyQlcVbQpyEUmrQYPg/fehQwc/Q6V169AVRZ+CXETS5okn4KGHoEkTP0Ml8DXYGwwFuYikRSwG117rbz/+OBx9dNByGhQFuYjUu3nz4Nxz/fj4wIFw+eWhK2pYFOQiUq/WrPEzU1atgp//HO65J3RFDY+CXETqTVGRv8bm11/DAQfAs89qhkp9UJCLSL256SZ45x1o397PUNlxx9AVNUwKchGpF089BQ8+CI0bwyuvQLduoStquBTkIpJyEybANdf42yNGwDHHhK2noVOQi0hKLVjgZ6hs2QIDBsCVV4auqOFTkItIyqxd62eorFwJp5wC994buqLsoCAXkZQoKoKLL4a8PNh/f3j+eT8+LvVPQS4iKXHLLfD227DTTvDmm9CmTeiKsoeCXETqbNQouO8+fwQ+dizsvXfoirKLglxE6mTiRLj6an/7kUcgNzdoOVlJQS4itfbtt3DOObB5M9xwA/TrF7qi7KQgF5FaWbcOzjwTVqyAk06CBx4IXVH2UpCLSI0VF8Oll8KMGdC9O7zwgmaohKQgF5EaGzzYnzulXTs/Q6Vt29AVZTcFuYjUyNNP+1PR5uTAyy/DvvuGrkgU5CJSbZMmwVVX+dsPPwzHHRe2HvEU5CJSLQsXwtln+xkq111XelIsCU9BLiJVys/3M1SWL4fjj/enp5XMoSAXkUoVF0OfPjB9uh8Pf+klaNIkdFVSloJcRCp1xx3w2mt+Zsqbb/qZKpJZ6hzkZtbFzMab2UwzyzOz/qkoTETCGzMGhg71M1RefNHPGZfMk4oj8kJgoHOuB3A4cJ2Z9UjBekUkoJkzW/PrX/vbw4bBiScGLUcqUecgd84tdc59kbi9Dvga2L2u6xWRcBYtgttvP4hNm+A3v/GzVCRzpXSM3My6Aj8BJqdyvSKSPuvXw1lnwerVTfnZz+CvfwWz0FVJZVJ2dgQzawWMBQY459Ymae8H9APo2LEjsVgsVZuulfz8/OA1ZAr1hRePxykqKsrqviguhjvvPIAvv9yZTp3W07//l0ycWBi6rOAy/W8kJUFuZk3wIT7GOfdKssc450YCIwF69erlcgOftDgWixG6hkyhvvDatm1LPB7P6r743/+FCRNgxx3h7rvzOOuso0OXlBEy/W+kzkFuZgY8BXztnNOJLEUi6vnn4a67oFEjfzbD5s03hC5JqikVY+RHAX2A48xsWmI5LQXrFZE0+ewzuPxyf/uBB+CUU8LWIzVT5yNy59y/AH0UIhJR333nz6GycaM/IdZvfxu6IqkpfbNTJItt2OBnqCxdCsceC8OHa4ZKFCnIRbKUc344ZepU6NbNn1u8adPQVUltKMhFstQf/+i/dt+6tb/aT4cOoSuS2lKQi2Shl16CP/zBz1B5/nk44IDQFUldKMhFsszUqfCrX/nb994Lp2mOWeQpyEWyyJIl/gIRBQVwxRVw442hK5JUUJCLZImCAj/NcMkS6N0bRozQDJWGQkEukgWc80fgn38OXbvC2LGaodKQKMhFssCf/uQ/1GzVyl/lZ+edQ1ckqaQgF2ngxo71l2szg+eegwMPDF2RpJqCXKQB+/JLuOwyf/uee+D008PWI/VDQS7SQC1d6meobNjgpxsOGhS6IqkvCnKRBmjjRjjnHFi8GI46Ch5/XDNUGjIFuUgD4xxceSVMngx77gmvvALNmoWuSuqTglykgfnzn2HMGNhhB38OlV12CV2R1DcFuUgD8tprMHiwH0YZMwYOPjh0RZIOCnKRBmL6dLj0Un976FB/nnHJDgpykQZg2TI44wxYvx769IHf/z50RZJOCnKRiCuZobJoERx+OIwcqRkq2UZBLhJhzkG/fjBpEnTp4sfImzcPXZWkm4JcJMLuvRdGj4aWLf0MlY4dQ1ckISjIRSLqjTfgllv87WeegZ49g5YjASnIRSJoxgy45BI/tDJkiB8jl+ylIBeJmOXL/QyV/Hy4+GI/b1yym4JcJEI2bYJf/AL++1847DB48knNUBEFuUhkOAe/+Q1MnAidO/sZKi1ahK5KMoGCXCQi7r8fRo3y4f3669CpU+iKJFMoyEUi4O234eab/e3Ro+GQQ8LWI5lFQS6S4fLy4KKL/NDKH/8I554buiLJNApykQy2cqWfobJuHVx4Idx+e+iKJBMpyEUy1ObN/uh7wQLo1Qv+/nfNUJHkUhLkZvY3M1tuZl+lYn0i2c45uPZamDABdtvNf7ipGSqyPak6Ih8FnJKidYlkvWHD4KmnSmeo7LZb6Iokk6UkyJ1zE4BVqViXSLZ7553SK96PGuWHVUQqozFykQwycyb88pdQXAz/939wwQWhK5IoaJyuDZlZP6AfQMeOHYnFYunadFL5+fnBa8gU6gsvHo9TVFQUrC/WrGnMtdceytq1LTj22OUcc8xMQv5atF+UyvS+SFuQO+dGAiMBevXq5XJzc9O16aRisRiha8gU6guvbdu2xOPxIH2xeTOcfDIsWeK/7DNu3C60bLlL2usoS/tFqUzvCw2tiATmHNxwA8Ri/mv3r7/uLxQhUl2pmn74HDAJ6G5mi83s16lYr0g2ePhhf53N5s39ibA6dw5dkURNSoZWnHMXpWI9Itnmvffgxhv97b/9zZ+aVqSmNLQiEsisWf5r98XF/qv3F+lwSGpJQS4SwKpV/hwqa9b4C0XceWfoiiTKFOQiabZlC5x/Psyd6y+Y/PTT0Eh/iVIH2n1E0qx/f/j4Y+jYEd54A3bYIXRFEnUKcpE0euQRGDECmjXzM1S6dAldkTQECnKRNPngA380Dv6EWIcfHrYeaTgU5CJpMGeOP29KURHceitccknoiqQhUZCL1LPVq/0MlXgczj4bhgwJXZE0NApykXq0ZYs/Ep8zBw4+2F84WTNUJNW0S4nUo9/9Dj78EHbZxc9QadUqdEXSECnIRerJY4/B8OHQtCm8+irsuWfoiqShUpCL1IOPP4brr/e3n3gCjjwybD3SsCnIRVLsm2/gvPP8DJWbb4bLLgtdkTR0CnKRFIrH/QyVkpkqQ4eGrkiygYJcJEUKC/3ZDGfPhoMOgjFjICcndFWSDRTkIikycCC8/z7svLOfodK6deiKJFsoyEVSYORI+OtfoUkTeOUV6No1dEWSTRTkInU0fjxcd52/PXIkHH102Hok+yjIRepg7lw/Q6WwEAYNgr59Q1ck2UhBLlJLa9bAmWf6q/2cfjr8+c+hK5JspSAXqYXCQvjlL+Hrr+GAAzRDRcJSkIvUwk03wbvvQocO8OabsOOOoSuSbKYgF6mhJ5+EYcNKZ6jstVfoiiTbKchFauCf/4RrrvG3H3sMevcOW48IKMhFqm3+fDj3XD8+/rvfwRVXhK5IxFOQi1TD2rX+3Ck//ACnngp/+UvoikRKKchFqlBUBBddBDNnwv77w3PPaYaKZBYFuUgVbr4Zxo2DnXbyM1TatAldkci2FOQilXjqKXjgAWjcGMaOhb33Dl2RSEUKcpHtmDChdIbKo49Cbm7QckS2S0EuksSCBX6GypYt0L8/XHVV6IpEtk9BLlJOyQyVlSvh5JPhvvtCVyRSuZQEuZmdYmazzWyumd2SinWKhOAcXHwx5OXBj34EL7zgx8dFMlmdd1EzywEeAU4EFgOfm9kbzrmZdV23SLotXdqC//xHM1QkWlJxrHEYMNc5Nx/AzJ4HzgK2G+SzZ88mN/AnR/F4nLZt2watIVOoL7zPPptGQQFALl26wJVXhq4oLO0XpTK9L1IR5LsDi8r8vBj4n/IPMrN+QD+AJk2aEI/HU7Dp2isqKgpeQ6ZQX8D69Y0TIQ6dO28ANpPlXaL9ooxM74u0jf4550YCIwF69erlpkyZkq5NJxWLxYK/K8gU2d4XeXkll2fLpUOHTSxaNCl0SRkh2/eLsjKlL8ws6f2p+LDzO6BLmZ87J+4TyXiLF8Mpp0A8Du3bw267FYQuSaTGUnFE/jmwr5nthQ/wXwIXp2C9IvVq9Wof4osXw1FHQaNGfuqhSNTU+YjcOVcIXA+8B3wNvOicy6vrekXqU36+nyuel+dPhPXGGz7IRaIoJWPkzrlxwLhUrEukvq1fDz//OUycCJ07+0u27bRT6KpEak/HIJJV1q/3V7yfMAF23x3Gj4c99ghdlUjdKMgla5QMp8Ri0KmTD/F99gldlUjd6cvHkhVWrvTDKZ99Brvu6kN8331DVyWSGjoilwZv4UI/T/yzz2DPPf0FlLt3D12VSOooyKVBy8vzUwtnz4aDDoJPP4X99gtdlUhqKcilwXrrLTjiCD9P/Oij/Qecu+0WuiqR1FOQS4PjnL/K/Zlnwrp1cOGF8P77kMHnPBKpEwW5NCj5+dCnD/z+9z7QhwzxV71v0SJ0ZSL1R7NWpMGYMQMuuABmzYIddoDRo+Gcc0JXJVL/dEQukeccPPkkHHaYD/EePfwMFYW4ZAsFuUTa99/7wL7qKti4Ea64Aj7/3Ie5SLZQkEtkvfACHHggvP467LgjPP00PPUUtGwZujKR9NIYuUTOwoXQvz+89pr/+cQT/dCKzpki2UpH5BIZW7b4aYX77+9DvFUreOwxeO89hbhkNx2RS8ZzDsaNg5tugq+/9vedfz488IA/Da1ItlOQS0b74gsYNMif5Apg771h+HB/ZR8R8TS0Ihlpxgx/1H3ooT7E27XzR+B5eQpxkfJ0RC4ZZdo0+NOf4OWX/c/NmsH118Ntt/kwF5GKFOQSXFERvP02PPigv+gD+AC/+mr/VXud6EqkcgpyCWbdOhg1Ch56CObN8/e1bg1XXunHxRXgItWjIJe0cs6fTvbvf/fDJ+vX+/u7doXf/hZ+/Wv/5R4RqT4FuaTFggXwzDP+CHz+/NL7e/f2X+45+2zIyQlVnUi0Kcil3syZ44+6x4710whLdO4Ml10GffvqupkiqaAgl5QpLITJk+Hdd/03L7/6qrStVSt/Bfu+feH443X0LZJKCnKpk4UL4YMPfHh/8AGsWVPa1qaNv0rPuefCSSfp4g4i9UVBLtXmnL+I8Sef+A8sJ0zwQV7Wvvv6L+yceqo/8m7aNEytItlEQS5JOecvWjxlSukydSr88MO2j2vbFo45xof3ySdDt25ByhXJagpyYePGRnzxhf/6+8yZMH26D+3lyys+tmNHH9wly4EHQiOd6EEkKAV5ltiyBRYt8lP/5s+HuXP9mQTz8uDbb3vjXMXntGsHvXptu3TpAmbpr19Etk9B3kDk58N338GSJX5ZuLA0tOfP9yFeVJT8uTk5ju7djR494IAD/HLoobDXXgptkShQkGeo4mKIx/2Y9MqV2y4rVsDSpT6wS8J73brK12fmj6a7dfPLXnv5CzQccAB8990nnHDCsWl5XSKSenUKcjM7H/gDsD9wmHNuSiqKirqiIigogA0bfMCuXeun5VX175o1pcH9ww8+zKureXN/bpLdd/f/du5cGtrdusGee/oTUSWzbFmScRURiYy6HpF/BfwCeDwFtdRIcbEPzJKlsLDiz1u2wObNyZcpU3Zi9erKH1OyFBSUBvOGDVXf3rw5Na+xTRvo0KHi0r49dOq0bXC3bathEJFsVacgd859DWA1TJAvv5xNq1a5OMfWD9latryAVq2uZcuWDaxcedrWtpIlJ6cvZn0pLFxJcfF5SdZ6DXAhsAjok6R9IHAGMBu4Okn77cAJwDRgQJL2ocCRwKfA4CTtw4CewIfAEBo18rM5Gjf232Lcf//H2XXX7qxb9ybffHM/OTmlbY0bw6BBo9lnny58/vkLvPLKCJo02TaYR416mQ4dOjBq1ChGjRpVYevjxo2jZcuWPProo7z44osV2mOJ88Ped999vPXWW9u0FRQUMHnyZADuuusuPvroo23a27dvz9ixYwG49dZbmTRp0jbtnTt35plnngFgwIABTJs2bZv2/fbbj5EjRwLQr18/5syZs017z549GTZsGACXXnopixcv3qb9iCOO4O677wbg3HPP5YdycyCPP/547rjjDgBOPfVUCgoKtmk//fTTGTRoEAC5ubmUd8EFF3DttddSXFzM3LlzKzymb9++9O3bl5UrV3LeeRX3vWuuuYYLL7yQRYsW0adPxX1v4MCBnHHGGcyePZurr664791+++2ccMIJTJs2jQEDBlRoHzp0KEceeSSffvopgwdX3PeGDRtGz549+fDDDxkyZEiF9scff5zu3bvz5ptvcv/991doHz16NF26dOGFF15gxIgRW++Px+O0bduWl1+uv32vRYsWvPPOO0B273sbNmzgtNNOq9Be1b5XIm1j5GbWD+jnf2q19ax3JQoKKs5RLmt7www+7BxNmhTRtOkWYAsbNzrAYebD1MzRrl0B7dqtobBwLUuWFAIu0ebb99nnBzp1WkJ+/jK++moTZi7RBo0aOXr3XkjXru1YsWI+48evp1Ejt3XdjRo5rrhiGj/6UT55edN5/vl4hTpvuGEye+yxlE8/nUE8XrG9detJODePtWvz2LChYvvEiRNp06YNs2bNSvr8CRMm0Lx5c+bMmZO0veSPad68eRXac3JytrYvWLCgQntxcfHW9oULF1Zob9Kkydb2xYsXV2hfsmTJ1vYlS5ZUaF+8ePHW9mXLllVoX7hw4db2FStWsHbt2m3aFyxYsLV91apVbNq0aZv2efPmbW1P1jdz5swhFosRj8dxzlV4zKxZs4jFYqxZsybp8/Py8ojFYixfvjxp+4wZM2jdunXSvgOYPn06jRs3Zu7cuUnbv/jiCzZv3sxXX32VtH3KlCnE43GmT5+etH3y5MksXbqUGTOS73uTJk1i3rx55OXlbdNeVFREPB6v132voKAgEvtefn5+ve57GzduTNpe1b5XwlyyeWdlH2D2IbBrkqbbnHOvJx4TAwZVd4y8R49e7tlnp5CTQ6VLyRFrsqWuc5djsVjS/yGzkfrCy83NJR6PVziqy1baL0plSl+Y2VTnXK/y91d5RO6cOyHVxbRsCT17pnqtIiLZSd/JExGJuDoFuZmdY2aLgSOAt83svdSUJSIi1VXXWSuvAq+mqBYREakFDa2IiEScglxEJOIU5CIiEacgFxGJOAW5iEjEKchFRCJOQS4iEnEKchGRiFOQi4hEnIJcRCTiFOQiIhGnIBcRiTgFuYhIxCnIRUQiTkEuIhJxCnIRkYhTkIuIRJyCXEQk4hTkIiIRpyAXEYk4BbmISMQpyEVEIk5BLiIScQpyEZGIU5CLiEScglxEJOIU5CIiEacgFxGJOAW5iEjEKchFRCJOQS4iEnF1CnIzu9fMZpnZf8zsVTNrm6K6RESkmup6RP4BcKBz7mBgDnBr3UsSEZGaqFOQO+fed84VJn78N9C57iWJiEhNpHKM/ArgnRSuT0REqqFxVQ8wsw+BXZM03eacez3xmNuAQmBMJevpB/QD6NixI7FYrDb1pkx+fn7wGjKF+sKLx+MUFRWpLxK0X5TK9L4w51zdVmDWF7gaON45t6E6z+nVq5ebMmVKnbZbV7FYjNzc3KA1ZAr1hZebm0s8HmfatGmhS8kI2i9KZUpfmNlU51yv8vdXeURexUpPAW4Gjq1uiIuISGrVdYx8ONAa+MDMppnZYymoSUREaqBOR+TOuX1SVYiIiNSOvtkpIhJxCnIRkYhTkIuIRFydpx/WaqNmK4D/pn3D2+oArAxcQ6ZQX5RSX5RSX5TKlL7Y0zm3c/k7gwR5JjCzKcnmY2Yj9UUp9UUp9UWpTO8LDa2IiEScglxEJOKyOchHhi4gg6gvSqkvSqkvSmV0X2TtGLmISEORzUfkIiINgoIcMLOBZubMrEPoWkLRZfv8SeDMbLaZzTWzW0LXE4qZdTGz8WY208zyzKx/6JpCM7McM/vSzN4KXUsyWR/kZtYFOAlYGLqWwLL6sn1mlgM8ApwK9AAuMrMeYasKphAY6JzrARwOXJfFfVGiP/B16CK2J+uDHHgQfyrerP6wQJft4zBgrnNuvnNuM/A8cFbgmoJwzi11zn2RuL0OH2C7h60qHDPrDPwceDJ0LduT1UFuZmcB3znnpoeuJcNk42X7dgcWlfl5MVkcXiXMrCvwE2By4FJCGoY/2CsOXMd21ek0tlFQ2aXqgMH4YZWskKrL9kl2MLNWwFhggHNubeh6QjCz04HlzrmpZpYbuJztavBB7pw7Idn9ZnYQsBcw3czADyV8YWaHOee+T2OJabO9viiRuGzf6fjL9mXbUNN3QJcyP3dO3JeVzKwJPsTHOOdeCV1PQEcBZ5rZaUBzYEcze8Y5d2nguraheeQJZvYt0Ms5lwknxkm7xGX7HsBftm9F6HrSzcwa4z/kPR4f4J8DFzvn8oIWFoD5I5t/AKuccwMCl5MxEkfkg5xzpwcupYKsHiOXbWT1ZfsSH/ReD7yH/3DvxWwM8YSjgD7AcYl9YVriiFQylI7IRUQiTkfkIiIRpyAXEYk4BbmISMQpyEVEIk5BLiIScQpyEZGIU5CLiEScglxEJOL+HzT4EGQ7Iqm1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z,alpha=1), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "#save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图11-3：ELU激活函数\n",
    "\n",
    "ELU激活函数和ReLU函数很像，只是有几个明显的不同：\n",
    "\n",
    "* 当$z<0$时它的值为负，从而允许单元的平均输出接近0。这样就可以如之前讨论的一样，缓和梯度消失问题。超参数$\\alpha$是指当$z$是一个极大的负数时，ELU函数接近的那个值。通常被设置为1，当然如果需要也可以改变它，与其他超参数的操作是一样的。\n",
    "\n",
    "* 第二，对于$z<0$有一个非零的梯度，这样就可以避免单元消失的问题。\n",
    "\n",
    "* 第三，这个函数整体很平滑，包括在$z=0$附近，这样就可以提高梯度下降，因为在$z=0$的左右两边都没有抖动。\n",
    "\n",
    "ELU激活函数的一个主要缺陷是计算速度比ReLU和它的变种慢（因为使用了指数函数），但是在训练过程中，可以通过更快的收敛速度来弥补。然而，测试中，ELU网络时间慢于ReLU网络。\n",
    "\n",
    "> 那么在深度神经网络的隐藏层到底应该使用哪一种激活函数呢？尽管里程会不一样，通常来说`ELU函数`>`leaky ReLU函数（和它的变种）`>`ReLU函数`>`tanh函数`>`逻辑函数`。如果更关心运行时的性能，那你可以选择`leaky ReLU函数`，而不是ELU函数。如果不想改变别的超参数，就只使用建议$\\alpha$的默认值（leaky ReLU函数是0.01，ELU函数是1）。如果有多余的时间和计算能力，可以使用交叉验证去评估别的激活函数，特别是如果网络过度拟合，可以使用RReLU函数，又或者是针对大的训练集使用PReLU函数。\n",
    "\n",
    "TensorFlow给你提供了一个`elu()`函数来构建神经网络，当调用`fully_connected()`(使用dense，前面讲过)函数时，可以很简单地设置`activation_fn`参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow没有leaky ReLU函数的预定义函数，但是也可以很简单地定义为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量归一化\n",
    "\n",
    "尽管使用了He初始化加ELU（或者ReLU的任一种变种）可以很明显地在训练初期降低梯度消失/爆炸问题，但还是不能保证在训练过程中不会再出现这些问题。\n",
    "\n",
    "在一篇发表于2015的论文（ https://goo.gl/gA4GSP ） [7] 中，Sergey Ioffe和Christian Szegedy提出了一个叫作`批量归一化`（BN）的技术，用它来解决梯度消失/爆炸问题，而且每一层的输入分散问题在训练过程中更普遍，前层变量的改变（称为内部协变量转变问题）也是一样。\n",
    "\n",
    "该技术包括在每一层激活函数之前在模型里加一个操作，`简单零中心化`和`归一化输入`，之后再通过每层的两个新参数（一个为了缩放，另一个为了移动）缩放和移动结果。换句话说，这个操作让模型学会了最佳规模和每层输入的平均值。\n",
    "\n",
    "为了零中心化和归一化输入，算法需要评估输入的平均值和标准方差。现在对于小批量（因此得名“批量归一化”）是通过评估输入的平均值和标准方差来这么做的。整个操作见公式11-3。\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "1. & \\mu_B = \\frac{1}{m_B}\\sum_{i=1}^{m_B}x^{(i)} \\\\\n",
    "2. &\\sigma_B^2=\\frac{1}{m_B}\\sum_{i=1}^{m_B}(x^{(i)}-\\mu_B)^2 \\\\\n",
    "3. &\\hat x^{(i)} = \\frac{x^{(i)}-\\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}} \\\\\n",
    "4. &z^{(i)} = \\gamma x^{(i)}+\\beta\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "公式11-3：批量归一化算法\n",
    "\n",
    "- $\\mu_B$是经验平均值，评估整个小批量$B$。\n",
    "\n",
    "- $\\sigma_B$是经验标准方差，评估整个小批量。\n",
    "\n",
    "- $m_B$是小批量的实例数。\n",
    "\n",
    "- $\\hat x^{(i)}$ 零中心化和归一化输入。\n",
    "\n",
    "- $\\gamma$是层缩放参数。\n",
    "\n",
    "- $\\beta$是层移动（偏移）参数。\n",
    "\n",
    "- $\\epsilon$是一个小的数字，为了避免除以0（标准化$10^{-3}$ ）。它被称为平滑项。\n",
    "\n",
    "- $z^{(i)}$ 是BN操作的输出：它是输入的缩放和移动版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在测试期间，没有小批量数据来计算经验平均值和标准方差，所以可简单地用整个训练集的平均值和标准方差来代替。在训练过程中可以用变动平均值有效地计算出来。所以，整体来看，4个参数是为每一批量归一化层来学习的：$\\gamma$（缩放），$\\beta$（偏移），$\\mu$（平均值）和$\\sigma$（标准方差）。\n",
    "\n",
    "作者提出的这个技术考虑了他们实验过的所有深度神经网络。梯度消失问题被有效改善，主要原因是他们使用了饱和激活函数（比如tanh）和逻辑激活函数。网络对于权重初始化也没有那么敏感。它们可以使用更高的学习速率，从而有效地加快整个学习过程。值得指出的是，他们提到“在应用到一个先进图片识别的模型时，批量归一化达到了相同的精度，同时还将训练步骤减少为原来的1/14，以显著的成绩击败了原始模型。[…]利用组合的批量归一化网络，我们在ImageNet上目前已经发表过的最佳结果的基础上又做了改进：达到了4.9%top-5的验证错误（4.8%的测试错误），超过了人类评估者的精度。”最终，像一个在持续给予的福利一样，批量归一化同时还可以进行正则化，降低其他正则化技术的需求（比如退出，本章后面会提到）。\n",
    "\n",
    "但是，批量归一化的确也给模型增加了一些复杂度（尽管因为有第一隐藏层而不用考虑归一化输入数据的需求，但是提供这个需求的却是批量归一化）。另外，还存在一个运行时的代价：神经网络的预测速度变慢，原因是每一层有很多其他需要进行的计算。所以如果需要快速预测，可能需要在进行批量归一化之前先检查一下ELU+He初始化的表现如何。\n",
    "\n",
    "> 你会发现一开始当梯度下降在每一层搜索最佳缩放和偏移量时，训练速度会非常慢，但是一旦找到一个合适的值，训练速度就会迅速提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用TensorFlow来实现批量归一化\n",
    "\n",
    "TensorFlow提供了一个`batch_normalization()`函数来中心化和归一化输入，但是必须自己计算均值和标准方差（在训练中基于一个小批量的数据或者就像刚才讨论的用整个数据集进行测试），然后把它们作为参数传给这个方法，而且必须自己确定缩放和偏移参数（并把它们传给这个方法）。这是可行的，但并不一定是最易行的方式。不过，可以用`batch_norm()`函数，它提供了所有的参数。可以直接调用，或者告诉`fully_connected()`[现在应该是`dense()`]函数去调用它，如以下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-451f5a26a556>:15: batch_normalization (from tensorflow.python.keras.legacy_tf_layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一起看一下上述代码。第一行非常清楚，只要定义了`is_training`(改为`training`)占位符，无所谓是True还是False。它负责告诉`batch_norm()`函数是使用当前小批量的均值和标准方差（训练中），还是使用运行平均值（测试中）。\n",
    "\n",
    "接着定义了bn_params，它是会传给`batch_norm()`函数的参数集合，当然也包括`training`。算法用到了指数衰减来计算运行平均值，这也是需要衰变参数的原因。给一个新值$v$，运行平均值$\\hat v$会通过公式$\\hat v \\leftarrow \\hat v \\times decay + v \\times (1-decay)$来更新(decay改为momentum)。一个好的衰变值会非常接近1，比如0.9、0.99、0.999（对越大的数据集和越小的批量，需要的9越多）。最后，如果希望`batch_norm()`(实际为`batch_normalization`)函数在训练中（即当`is_training=True`时）一结束批量归一化就更新运行平均值，就需要将`updates_collections`设置成None。如果不设置这些参数，在默认情况下，TensorFlow只将更新运行平均值的操作添加到必须运行的操作集合中。\n",
    "\n",
    "最后，用第10章中提过的方法，通过调用`fully_connected()`(更改为使用`dense()`)函数来创建层，但是这一次我们在调用激活函数前通过调用`batch_norm()`函数（通过参数nb_params）来进行输入归一化。\n",
    "\n",
    "> 注意默认情况下，`batch_norm()`只中心化、归一化和对输入进行偏移操作，但是并不缩放（即$\\gamma$固定为1）。这样对没有激活函数或者用ReLU激活函数的层是有效果的，但是对于其他的激活函数，你需要设置\"scale\"，即将bn_params设置为True。\n",
    "\n",
    "你可能已经注意到，定义前三层是重复的，因为有几个参数是相同的。为了避免一直重复同样的参数，你可以用`arg_scope()`方法构造一个参数范围：第一个参数是一个函数列表，其他参数会自动传给这些函数。最后三行预测代码可以修改成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这种小例子中，它的表现可能没有以前好，但是如果有10层并且设置了激活函数、初始化、归一化等，代码可读性就会大有改善。\n",
    "\n",
    "构造阶段剩下的部分和第10章中一致：定义成本函数；构建优化器，让它最小化成本函数；定义评估操作；创建Saver，等等。\n",
    "\n",
    "实施过程基本一致，只有一处不同。无论何时你运行一个依赖于`batch_norm`层的操作，都需要设置`training`占位符为True或者False："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.899\n",
      "1 Validation accuracy: 0.92\n",
      "2 Validation accuracy: 0.9316\n",
      "3 Validation accuracy: 0.9384\n",
      "4 Validation accuracy: 0.9462\n",
      "5 Validation accuracy: 0.9512\n",
      "6 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9572\n",
      "8 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.971\n",
      "20 Validation accuracy: 0.97\n",
      "21 Validation accuracy: 0.9716\n",
      "22 Validation accuracy: 0.9712\n",
      "23 Validation accuracy: 0.9708\n",
      "24 Validation accuracy: 0.9718\n",
      "25 Validation accuracy: 0.9738\n",
      "26 Validation accuracy: 0.974\n",
      "27 Validation accuracy: 0.9742\n",
      "28 Validation accuracy: 0.9736\n",
      "29 Validation accuracy: 0.9736\n",
      "30 Validation accuracy: 0.976\n",
      "31 Validation accuracy: 0.975\n",
      "32 Validation accuracy: 0.9752\n",
      "33 Validation accuracy: 0.976\n",
      "34 Validation accuracy: 0.9754\n",
      "35 Validation accuracy: 0.9762\n",
      "36 Validation accuracy: 0.9758\n",
      "37 Validation accuracy: 0.9774\n",
      "38 Validation accuracy: 0.9778\n",
      "39 Validation accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if epoch % 10 == 9:\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是这样！在这个小例子中只有两层，不像批量归一化有那么显著的影响，但是对于深层网络会有非常明显的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9604\n",
      "19 Validation accuracy: 0.971\n",
      "29 Validation accuracy: 0.9748\n",
      "39 Validation accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度剪裁\n",
    "\n",
    "一个流行的减轻梯度爆炸问题的技术是在反向传播的过程中简单地裁剪梯度，从而保证不会超过阈值（这个对于循环神经网络非常有效，详见第14章）。这种技术叫作`梯度剪裁`（ http://goo.gl/dRDAaf ） [8] 一般情况下，大家倾向批量归一化，但是仍然有必要了解梯度剪裁以及如何使用它。\n",
    "\n",
    "在TensorFlow里，优化器的`minimize()`函数同时负责计算和应用梯度，所以必须先调用优化器的`compute_gradients()`方法，然后调用`clip_by_value()`方法创建一个剪裁梯度的操作，最后再调用`apply_gradients()`方法来应用裁剪后的梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下，需要在每一个训练步骤中都跑一次`training_op`。它会计算梯度，在-1.0和1.0之间剪裁，然后应用。阈值是可以调整的超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9436\n",
      "19 Validation accuracy: 0.9614\n",
      "29 Validation accuracy: 0.9672\n",
      "39 Validation accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs+1):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if epoch % 10 == 9:\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] “Understanding the Difficulty of Training Deep Feedforward Neural Networks”，X.Glorot和Y Bengio（2010）。\n",
    "\n",
    "[2] 有一个类似的例子：如果你把麦克风放大器的旋钮调到非常接近0，人们就不会听到你的声音，同样如果你把它调到非常接近最大值，你的声音也会饱和，大家也听不清你在说什么。现在想象有一连串这样的放大器：它们需要设置好，保证在最后的时候你的声音可以清晰洪亮地传出来。那你的声音就必须保证每经过一个放大器它的输出都和输入有同样的振幅。\n",
    "\n",
    "[3] 这种简化方法其实很早就已经提出来了——比如，在1998年的《Neural Networks：Tricks of the Trade》一书中就有提过，作者是Genevieve Orr和Klaus-Robert Müller（由Springer出版）。\n",
    "\n",
    "[4] “Delving Deep into Rectifiers：Surpassing Human-Level Performance on ImageNet Classification”，K.He等人（2015）。\n",
    "\n",
    "[5] “Empirical Evaluation of Rectified Activations in Convolution Network”，B.Xu等人（2015）。\n",
    "\n",
    "[6] “Fast and Accurate Deep Network Learning by Exponential Linear Units（ELUs）”，D.Clevert、T.Unterthiner和S.Hochreiter（2015）。\n",
    "\n",
    "[7] “Batch Normalization：Accelerating Deep Network Training by Reducing Internal Covariate Shift”，S.Ioffe和C.Szegedy（2015）。\n",
    "\n",
    "[8] “On the difficulty of training recurrent neural networks”，R.Pascanu等人（2013）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重用预训练图层\n",
    "\n",
    "从头开始训练一个非常庞大的DNN并不明智。大多时候你应该试着去找一个能处理相似问题的已有的神经网络，然后重用它的低层网络，这叫作迁移学习。这不仅能极大地提升训练速度，也很大程度地减少训练数据。\n",
    "\n",
    "举例来说，假设已经有了一个训练好的DNN用来将图片分成100个类别，包括动物、植物、车辆和各种各样更多的类别。如果你需要训练一个DNN使之能够根据不同的交通工具来分类，因为训练任务和已有的那个十分类似，所以应该试着重用已有的部分网络（见图11-4）。\n",
    "\n",
    "![图11-4：重用预训练图层](images/VNote/20210112171503853_30764.png)\n",
    "\n",
    "图11-4：重用预训练图层\n",
    "\n",
    "> 如果新任务的输入图片和已有任务的输入图片尺寸不一致，就需要添加一个预处理过程来使图片尺寸满足已有任务的输入需求。一般来说，迁移学习只适用于新旧任务的输入有着相似的低层特征的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重用TensorFlow模型\n",
    "\n",
    "如果原有模型是用TensorFlow训练的，你可以轻松地还原该模型并在新任务中接着训练它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./models/my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/filename/input\n",
      "save/filename\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.093108286671858&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.13093073666095734\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.13093073666095734\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden3/MatMul&quot;\\n  input: &quot;hidden3/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden3/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden4/MatMul&quot;\\n  input: &quot;hidden4/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden4/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden5/MatMul&quot;\\n  input: &quot;hidden5/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden5/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.3162277638912201\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.3162277638912201\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value/Minimum&quot;\\n  input: &quot;clip_by_value/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_1/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_1/Minimum&quot;\\n  input: &quot;clip_by_value_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_2/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_2/Minimum&quot;\\n  input: &quot;clip_by_value_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_3/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_3/Minimum&quot;\\n  input: &quot;clip_by_value_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_4/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_4/Minimum&quot;\\n  input: &quot;clip_by_value_4/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_5/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_5/Minimum&quot;\\n  input: &quot;clip_by_value_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_6/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_6/Minimum&quot;\\n  input: &quot;clip_by_value_6/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_7/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_7/Minimum&quot;\\n  input: &quot;clip_by_value_7/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_8/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_8/Minimum&quot;\\n  input: &quot;clip_by_value_8/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_9/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_9/Minimum&quot;\\n  input: &quot;clip_by_value_9/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_10/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_10/Minimum&quot;\\n  input: &quot;clip_by_value_10/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_11/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_11/Minimum&quot;\\n  input: &quot;clip_by_value_11/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2&quot;\\n  op: &quot;InTopKV2&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  input: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/in_top_k/InTopKV2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden3/bias/Assign&quot;\\n  input: &quot;^hidden3/kernel/Assign&quot;\\n  input: &quot;^hidden4/bias/Assign&quot;\\n  input: &quot;^hidden4/kernel/Assign&quot;\\n  input: &quot;^hidden5/bias/Assign&quot;\\n  input: &quot;^hidden5/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/filename/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/filename&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;hidden3/bias&quot;\\n        string_val: &quot;hidden3/kernel&quot;\\n        string_val: &quot;hidden4/bias&quot;\\n        string_val: &quot;hidden4/kernel&quot;\\n        string_val: &quot;hidden5/bias&quot;\\n        string_val: &quot;hidden5/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;hidden3/bias&quot;\\n        string_val: &quot;hidden3/kernel&quot;\\n        string_val: &quot;hidden4/bias&quot;\\n        string_val: &quot;hidden4/kernel&quot;\\n        string_val: &quot;hidden5/bias&quot;\\n        string_val: &quot;hidden5/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;save/RestoreV2:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;save/RestoreV2:5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;save/RestoreV2:6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;save/RestoreV2:7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;save/RestoreV2:8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;save/RestoreV2:9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2:10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2:11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.093108286671858&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "    # continue training the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例代码中的增加内容：\n",
    "Alternatively, if you have access to the Python code that built the original graph, you can use it instead of `import_meta_graph()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n",
      "9 Validation accuracy: 0.9716\n",
      "19 Validation accuracy: 0.9732\n",
      "29 Validation accuracy: 0.9732\n",
      "39 Validation accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you will want to reuse only the lower layers. If you are using `import_meta_graph()` it will load the whole graph, but you can simply ignore the parts you do not need. In this example, we add a new 4th hidden layer on top of the pretrained 3rd layer (ignoring the old 4th hidden layer). We also build a new output layer, the loss for this new output, and a new optimizer to minimize it. We also need another saver to save the whole graph (containing both the entire old graph plus the new operations), and an initialization operation to initialize all the new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # new layer\n",
    "n_outputs = 10  # new layer\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./models/my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n",
      "9 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9718\n",
      "29 Validation accuracy: 0.9722\n",
      "39 Validation accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./models/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而，通常我们只想要重用原有模型的一部分（我们马上就会讨论这种状况），一种简单的解决方案就是配置Saver使之在还原原模型时只还原所有参数的一个子集。举例来说，下面的代码就只还原了隐藏层1、隐藏层2和隐藏层3："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you must create one `Saver` to restore the pretrained model (giving it the list of variables to restore, or else it will complain that the graphs don't match), and another `Saver` to save the new model, once it is trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n",
      "9 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9726\n",
      "29 Validation accuracy: 0.972\n",
      "39 Validation accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                            # not shown in the book\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # not shown\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})        # not shown\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})     # not shown\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)                   # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们建立了新模型，确保它复制了原有模型的隐藏层1到隐藏层3。同时创建了一个节点来初始化所有参数。之后获取到一个用`trainable=true`配置（默认配置）创建的参数列表，并用正则表达式`\"hidden[123]\"`来做筛选（即：最后得到的就是隐藏层1到隐藏层3的所有可训练参数）。之后创建了一个字典来存放每个参数在原有模型和新模型里的名字映射（通常会保持原名不变）。接下来创建一个Saver用来还原那些参数，创建另一个Saver来存储整个新模型，而不是只有层1到层3。之后开启一个会话，并初始化新模型的所有参数，然后将层1到层3的参数从已有模型中重建。最后，在新任务中训练新模型并存储它。\n",
    "\n",
    "> 任务越类似，我们就可以重用越多的层（从低层开始）。对于特别相似的任务，可以试着将所有隐藏层都保留，只替换外层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重用其他框架的模型\n",
    "\n",
    "如果已有模型是用其他框架训练出来的，就需要手动加载所有的权重（例如如果用Theano训练的话，就用Theano代码加载），然后将它们赋给适当的参数。这个过程会变得相当冗长乏味。举例来说，下面的代码展示了如何从其他框架训练出的模型来复制其第一个隐藏层的权重和偏移量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the assignment nodes for the hidden1 variables\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # not shown in the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach (initially used in the book) would be to create dedicated assignment nodes and dedicated placeholders. This is more verbose and less efficient, but you may find this more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the variables of layer hidden1\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):  # root scope\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "\n",
    "# Create dedicated placeholders and assignment nodes\n",
    "original_weights = tf.placeholder(tf.float32, shape=(n_inputs, n_hidden1))\n",
    "original_biases = tf.placeholder(tf.float32, shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights, original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights, feed_dict={original_weights: original_w})\n",
    "    sess.run(assign_hidden1_biases, feed_dict={original_biases: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also get a handle on the variables using `get_collection()` and specifying the `scope`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could use the graph's `get_tensor_by_name()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 冻结低层\n",
    "\n",
    "第一个DNN的低层可能已经学会了检测图像中的低级特征，这对于两个图像分类任务都是有用的，因此可以直接重用这些图层。训练新的DNN时，通常来讲“冻结”权重是一个比较好的方法：如果低层权重被固定，那么高层的权重就比较容易训练（因为不需要学习一个运动的目标）。为了在训练中冻结低层，最简单的办法就是给优化器列出要训练的变量列表，除去低层的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):                                         # not shown in the book\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     # not shown\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三行是获得所有在隐藏层3和隐藏层4及输出层的可训练变量。排除了在隐藏层1和隐藏层2的变量。下一步我们把这个可训练变量的受限列表传给优化器的`minimize()`函数。层1和层2现在被冻结了：它们在训练过程中不会抖动（通常被称为冻结层）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n",
      "9 Validation accuracy: 0.9648\n",
      "19 Validation accuracy: 0.9678\n",
      "29 Validation accuracy: 0.9686\n",
      "39 Validation accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n",
      "9 Validation accuracy: 0.9648\n",
      "19 Validation accuracy: 0.9678\n",
      "29 Validation accuracy: 0.9686\n",
      "39 Validation accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缓存冻结层\n",
    "\n",
    "因为冻结层不会变化，所以就有可能将每一个训练实例的最高冻结层的输出缓存起来。由于训练会轮询整个数据集很多次，所以将获得巨大的速度提升，因为只需要在一个训练实例中遍历一次冻结层（而不是每个全数据集一次）。举个例子，可以第一次在低层跑完整个训练集（假设有足够的RAM）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen & cached\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后在训练中，要做的不是构建批量的训练实例，而是批量构建隐藏层2的输出，并且将它们喂给训练操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n",
      "9 Validation accuracy: 0.9648\n",
      "19 Validation accuracy: 0.9678\n",
      "29 Validation accuracy: 0.9686\n",
      "39 Validation accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) # not shown in the book\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, # not shown\n",
    "                                                y: y_valid})             # not shown\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一行运行的是之前定义好的训练操作（冻结层1和层2），然后把隐藏层2（对应批量目标）的批量输出传给它。因为把隐藏层2的输出传给TensorFlow，所以它不用尝试去评估它（或者它依赖的其他节点）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整、丢弃或替换高层\n",
    "\n",
    "原始模型的输出层经常会被替换，因为对于新的任务基本没有用，甚至没办法提供正确的输出个数。\n",
    "\n",
    "同样，原始模型的高隐藏层没有低层用处多，因为对于新任务最有效的高级特性可能和原始任务中最有效的那些特性差别很大。需要找到正确的层数来重用。\n",
    "\n",
    "首先尝试冻结所有的复制层，然后训练模型观察效果。接着尝试解冻一到两个顶部的隐藏层，用反向传播进行调整来观察是否有改善。训练数据越多，越能解冻更多的层。\n",
    "\n",
    "如果一直不能获得好的效果，而且训练数据很少，那就尝试丢弃最高的一层或多层，然后重新冻结剩下的隐藏层。可以一直迭代直到找到正确的重用层数。如果有很多训练数据，可以尝试替换顶部的隐藏层而不是丢弃它们，甚至可以添加一些隐藏层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型动物园\n",
    "\n",
    "在哪里可以找到一个训练好的类似神经网络来完成一个想要解决的任务呢？首选当然是自己已有的模型目录。这是一个很好的方式，可以保存所有的模型，方便你整理，也方便你日后随时调用。另一个选择就是在模型动物园（Model Zoo）里搜索。很多人针对各种任务训练了很多机器学习的模型，并且很慷慨地公开这些预训练的模型。\n",
    "\n",
    "TensorFlow在 https://github.com/tensorflow/models 上公开了自己的模型动物园。特别需要指出的是，这个模型动物园包含了先进图片识别的网络，比如VGG、Inception和ResNet（见第13章，同时查看models/slim目录），包括代码、预训练模型，以及下载流行图片数据集的工具。\n",
    "\n",
    "另一个流行的模型动物园是Caffe模型动物园（ https://goo.gl/XI02X3 ）。其中也包括很多计算机视觉模型（比如：LeNet、AlexNet、ZFNet、GoogLeNet、VGGNet和inception），也都在各种数据集（比如ImageNet、Places Database、CIFAR10等）上经过训练。Saumitro Dasgupta写了一个转换器，可以在 https://github.com/ethereon/caffe-tensorflow 找到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 无监督的预训练\n",
    "\n",
    "假设要完成一个没有太多标记训练数据的复杂任务，并且没有找到在近似任务上训练过的模型。不要失去希望！首先，肯定需要努力去收集更多的标记过的训练数据，但是如果这个代价很高或者很难，仍然可以运行无监督的预训练（见图11-5）。也就是说，如果有一堆未标记的训练数据，那可以逐层训练它们，从最低层开始，然后向上，利用一种非监督特性检测算法比如受限玻尔兹曼机（RBM，见附录E）或者自动编码器（见第15章）。每一层都是基于提前训练好的图层（除去被冻结的训练层）的输出进行训练。一旦所有层都用这个方式训练过之后，就可以用监督学习的方式（即反向传播）来微调网络。\n",
    "\n",
    "这是一个冗长且无趣的过程，但是通常情况下效果都不错；事实上，正是这个Geoffrey Hinton和他的团队在2006使用的技术让神经网络复苏，并且取得了深度学习的成功。直到2010年，无监督的预训练（通常使用RBM）都是深度网络的基准，只有在梯度消失问题得到缓解之后，用反向传播来训练DNN才变得越来越普遍。然而，在面对复杂任务处理、没有相似模型可重用、有极少标记过的训练数据但是却有很多未标记的训练数据的情况下，无监督的预处理（现在通常使用自动编码器而不是RBM）仍然是一个非常不错的选择。 [1]\n",
    "\n",
    "![图11-5：无监督的预训练](images/VNote/20210113113145872_32450.png)\n",
    "\n",
    "图11-5：无监督的预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 辅助任务中的预训练\n",
    "\n",
    "最后一个选择是在辅助任务中训练第一个神经网络，可以轻松获得或者生成标记过的训练数据，然后重用该网络的低层来实现你的实际任务。第一个神经网络的低层会学习可能被第二个神经网络重用的特征检测器。\n",
    "\n",
    "举个例子，如果想构建一个人脸识别系统，但是只有每个人的几张照片，很明显没办法训练一个好的分类器。收集每个人成百上千张照片根本不可行。但是，可以在网上收集很多随机的人像照片，用它们可以训练第一个神经网络来检测两张不同的照片是否属于相同的人。这个网络将学习优质的人脸特征检测器，然后重用这个网络的低层，这样就可以用很少的训练数据训练出一个优质的人脸分类器。\n",
    "\n",
    "通常情况下，收集未标记训练示例会廉价很多，但是标记它们却很贵。针对这种情况，常用的技术是将所有示例都标记为“好”，然后通过破坏好的训练示例来生成新的训练实例，并把那些被破坏的实例标记为“坏”。接着就可以训练第一个神经网络来区分好的实例和坏的实例。举个例子，可以下载数百万条句子，标记它们为“好”，然后随机修改每一句中的一个单词，并标记这些修改后的句子为“坏”。如果一个神经网络可以识别出“The dog sleeps”是好，“The dog they”是坏，那么它可能已经学会不少语言了。重用这个网络的低层可能有助于很多语言处理任务。\n",
    "\n",
    "另一种方法是训练第一个神经网络，让它输出每一个训练实例的得分，然后利用成本函数，确保每一个好的实例的得分都比坏的实例的得分至少高一些。我们称其为`最大边界学习`。\n",
    "\n",
    "[1] 另一种方式是针对你可以很方便找到大量标记的训练数据运行一个监督任务，然后使用之前提到的迁移学习。举个例子，如果想训练一个模型来识别出图片中你的朋友，可以在网上下载成千上万张脸，然后训练一个分类器来检测两张脸是否一致，之后用这个分类器来对比新图片和每一张你朋友的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速优化器\n",
    "\n",
    "训练一个很大的深度神经网络可能相当慢。到目前为止，已经了解了四种方法来提高训练速度（并且实现一个更好的解决方案）：在连接权重上应用一个良好的初始化策略，使用一个良好的激活函数，使用批量归一化，以及重用部分预处理网络。另一种明显提高训练速度的方法是使用快速优化器，而不是常规的梯度下降优化器。本节会给出最流行的几种：Momentum（动量优化），NAG（Nesterov梯度加速），AdaGrad，RMSProp，以及Adam优化。\n",
    "\n",
    "扰乱警报：本节的结论是几乎一直需要使用Adam优化， [1] 所以如果你不关心它的工作原理，那么就只需要简单地用AdamOptimizer替换GradientDescent Optimizer然后跳到下一节就可以了！仅仅是这么简单的一个改变，训练速度就会明显提高好几倍。然而，的确可以调节（加上学习速率）Adam优化的三个超参数；默认值一般表现良好，但是如果需要对它们进行微调，了解每一个值具体是什么还是很有帮助的。Adam优化集合了其他几种优化算法的想法，所以有必要先看看其他算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum优化\n",
    "\n",
    "想象一个保龄球在光滑表面滚下一个平缓的斜坡：最开始会很慢，但是会迅速恢复动力，直到达到最终速度（假设有一定摩擦力或空气阻力）。这是Momentum优化的一个很简单的想法，由Boris Polyak在1964年提出（ https://goo.gl/FlSE8c ）。 [2] 相比之下，常规梯度下降会沿着斜坡采用常规的小步前进的方式，所以会花比较长的时间才能到达底部。\n",
    "\n",
    "回顾一下之前的内容，梯度下降是直接从权重$\\theta$中减去成本函数$J(\\theta)$的梯度（$\\nabla_\\theta J(\\theta)$ ）乘以学习速率$\\eta$。公式是：$\\theta \\rightarrow \\theta-\\eta \\nabla_\\theta J(\\theta)$ 。它不关心之前的梯度是多少。如果本地梯度很少，它就会走得很慢。\n",
    "\n",
    "Momentum优化关注以前的梯度是多少：每一个迭代，会给momentum矢量$m$加本地梯度（乘以学习速率$\\eta$），同时权重要减去momentum矢量（见公式11-4）。换句话说，梯度被当作加速度来使用，而不是速度。为了模拟某种摩擦机制并防止动量（momentum）增长过大，该算法引入了一个新的超参数$\\beta$，简称为动量，其必须设置在0（高摩擦）和1（无摩擦）之间。一个标准动量值为0.9。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. & m \\leftarrow \\beta m + \\eta \\nabla_\\theta J(\\theta) \\\\\n",
    "2. &  \\theta \\leftarrow \\theta - m\n",
    "\\end{aligned}  \\tag{11-4} \\label{11-4}\n",
    "$$\n",
    "公式11-4：Momentum算法\n",
    "\n",
    "可以很容易地验证当梯度保持一个常量，最终速度（即权重变化的最大值）就等于梯度乘以学习速率$\\eta$乘以$1/(1-\\beta)$。举个例子，如果$\\beta=0.9$，那么最终速度等于10倍梯度乘以学习速率，所以Momentum优化最终会比梯度下降快10倍！这样就使得Momentum优化从平台逃离比梯度下降快得多。值得一提的是，在第4章中看到当输入的尺寸很特别时，成本函数看起来会像一个细长的碗（见图4-7）。梯度下降在陡坡下降得非常快，但是在山谷中下降得很慢。相比较而言，Momentum优化会以越来越快的速度滑向谷底直到到达谷底（最佳）。在不使用批量归一化的深度神经网络中，高层最终常会产生不同尺寸的输入，因此使用Momentum优化会很有帮助，同时还会帮助跨过局部最优。\n",
    "\n",
    "> 由于有动量，优化器可能会超调一点，然后返回，再超调，来回振荡多次后，最后稳定在最小值。这也是系统中要有一些摩擦的原因之一：它可以帮助摆脱振荡，从而加速收敛。\n",
    "\n",
    "在TensorFlow中实现Momentum优化非常简单：只需用MomentumOptimizer替换GradientDescentOptimizer，然后等着结果即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum优化的一个缺点是增加了一个超参数来微调。然而一般情况下，动量值为0.9的表现都比梯度下降好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov梯度加速\n",
    "\n",
    "Yurii Nesterov在1983年提出了一个Momentum优化的小的变体（ https://goo.gl/V011vD ）， [3] 几乎总快过Vanilla Momentum优化。Nesterov Momentum优化，或者Nesterov梯度加速（NAG），是用来衡量成本函数的梯度的，不是在本地而是动量方向稍向前一点的位置（见公式11-5）。与Vanilla Momentum优化唯一的不同就是用$\\theta+\\beta m$来测量梯度，而不是$\\theta$。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. & m \\leftarrow \\beta m + \\eta \\nabla_\\theta J(\\theta+\\beta m) \\\\\n",
    "2. &  \\theta \\leftarrow \\theta - m\n",
    "\\end{aligned}  \\tag{11-5} \\label{11-5}\n",
    "$$\n",
    "\n",
    "公式11-5：Nesterov梯度加速算法\n",
    "\n",
    "这个小调整有效是因为在通常情况下，动量矢量会指向正确的方向（即最优方向），所以在该方向相对远的地方使用梯度会比在原有地方更准确一些，正如图11-6所示（其中$\\nabla_1$表示在起始点$\\theta$用成本函数测量的梯度，$\\nabla_2$表示在点$\\theta+\\beta m$的梯度）。正如所见，Nesterov更接近最优值。过一阵之后，这些小的改进叠加在一起，于是NAG就比常规Momentum优化明显增速很多。再者，注意到当动量把权重推过山谷时，$\\nabla_1$会跨过山谷并且推向更远，然而$\\nabla_2$却往谷底的方向退回了一些。这有助于降低振荡，从而更快收敛。\n",
    "\n",
    "![图11-6：常规Momentum优化对比Nesterov Momentum优化](images/VNote/20210113160917748_28558.png)\n",
    "\n",
    "图11-6：常规Momentum优化对比Nesterov Momentum优化\n",
    "\n",
    "对比Momentum优化，NAG几乎总能提高训练速度。要使用NGA，在创建Momentum Optimizer时只需简单地设置`use_nesterov=True`即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad\n",
    "\n",
    "重新考虑一下细长碗的问题：梯度下降开始很快就走下最陡的斜坡，之后慢慢移动到谷底。如果算法可以早点检测到，并且修正方向往全局最优偏移一些就好了。\n",
    "\n",
    "AdaGrad算法（ http://goo.gl/4Tyd4j ） [4] 通过沿着最陡尺寸缩小梯度向量来实现这一点（见公式11-6）。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. & s \\leftarrow s + \\nabla_\\theta J(\\theta)  \\otimes \\nabla_\\theta J(\\theta)\\\\\n",
    "2. &  \\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s+\\epsilon}\n",
    "\\end{aligned}  \\tag{11-6} \\label{11-6}\n",
    "$$\n",
    "公式11-6：AdaGrad算法\n",
    "\n",
    "\n",
    "第一步将梯度的平方累积到向量$s$中（$\\otimes$表示矩阵乘法）。这个向量化表等于给向量$s$中每一个元素$s_i$ 进行$s_i \\leftarrow s_i + (\\frac{\\partial}{\\partial\\theta_i J(\\theta)})^2$运算；换句话说，对于参数$\\theta_i$ ，每个$s_i$ 累积成本函数偏导数的平方。如果成本函数沿着第$i$个尺寸陡峭，那么$s_i$会在每一个迭代中越来越大。\n",
    "\n",
    "第二步与梯度下降基本一致，但是有一个最大的区别：梯度向量按比例$\\sqrt{s+\\epsilon}$缩小（$\\oslash$表示矩阵除法，$\\epsilon$是避免除以0的平滑项，通常设置为$10^{-10}$ ）。这个向量化表等于对于所有参数$\\theta_i$ 进行$\\theta_i \\leftarrow \\theta_i - \\eta \\cfrac{\\cfrac{\\partial}{\\partial\\theta_i J(\\theta)}}{\\sqrt{s_i+\\epsilon}}$运算（同步）。\n",
    "\n",
    "简而言之，这个算法衰减了学习速率，但是对于陡度尺寸而言，它比使用较缓斜率的尺寸要快得多。这称为`适应性学习速率`。它有助于将所得到的更新更直接地指向全局最优（见图11-7）。另一个附加的好处是只需对学习速率超参数$\\eta$做很少的调整。\n",
    "\n",
    "![图11-7：AdaGrad对比梯度下降](images/VNote/20210113164840743_28485.png)\n",
    "\n",
    "图11-7：AdaGrad对比梯度下降\n",
    "\n",
    "> AdaGrad对于简单的二次问题一般表现都不错，但是在训练神经网络时却经常很早就停滞了。学习速率缩小得很多，在到达全局最优前算法就停止了。所以尽管TensorFlow有AdagradOptimizer，也不要用它来训练深度神经网络（但是，对于类似线性回归这样的简单任务可能是有效的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "\n",
    "AdaGrad降速太快而且没办法收敛到全局最优，RMSProp算法 [5] 却通过仅累积最近迭代中的梯度（而非从训练开始的所有梯度）解决了这个问题。它通过在第一步使用指数衰减来实现这个操作（见公式11-7）。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. & s \\leftarrow \\beta s + (1-\\beta)\\nabla_\\theta J(\\theta)  \\otimes \\nabla_\\theta J(\\theta)\\\\\n",
    "2. &  \\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s+\\epsilon}\n",
    "\\end{aligned}  \\tag{11-7} \\label{11-7}\n",
    "$$\n",
    "公式11-7：RMSProp算法\n",
    "\n",
    "衰减率$\\beta$通常设置为0.9。没错，这又是一个新的超参数，但是这个默认值一般表现都比较好，所以基本不需要做任何微调。\n",
    "\n",
    "正如所期待的，TensorFlow有`RMSPropOptimizer`类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除去非常简单的问题，这个优化器的表现几乎全都优于AdaGrad。同时表现也基本都优于Momentum优化和NAG。事实上，在Adam优化出现之前，它是众多研究者所推荐的优化算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam优化\n",
    "\n",
    "Adam（ https://goo.gl/Un8Axa ）， [6] 代表了自适应力矩估计，集合了Momentum优化和RMSProp的想法：类似Momentum优化，它会跟踪过去梯度的指数衰减平均值，同时也类似RMSProp，它会跟踪过去梯度平方的指数衰减平均值（见公式11-8）。 [7]\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. & m \\leftarrow \\beta_1 m + (1 - \\beta_1) \\nabla_\\theta J(\\theta) \\\\\n",
    "2. & s \\leftarrow \\beta_2 s + (1 - \\beta_2) \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta) \\\\\n",
    "3. & m \\leftarrow \\frac{m}{1-\\beta_1^T} \\\\\n",
    "4. & s \\leftarrow \\frac{s}{1-\\beta_2^T} \\\\\n",
    "5. & \\theta \\leftarrow \\theta - \\eta m \\oslash \\sqrt{s + \\epsilon}\n",
    "\\end{aligned}  \\tag{11-8} \\label{11-8}\n",
    "$$\n",
    "公式11-8：Adam算法\n",
    "\n",
    "* $T$表示迭代数（从1开始）。\n",
    "\n",
    "如果只看步骤1、步骤2和步骤5，你会发现Adam同Momentum优化以及RMSProp非常类似。唯一的不同是步骤1计算的是指数衰减的平均值而不是指数衰减的总和，但是除了常数因子以外，它们都是相等的（衰减平均值是$1-\\beta_1$ 倍的衰减总和）。步骤3和步骤4是一种技术的细节：因为$m$和$s$初始化都为0，它们会在训练开始时相对0有一点偏移量，所以这两个步骤在训练开始时有助于提高$m$和$s$。\n",
    "\n",
    "动量衰减超参数$\\beta_1$ 通常被初始化为0.9，缩放衰减超参数通常被初始化为0.999。与之前一样，平滑项$\\epsilon$通常会设置为一个很小的数字，比如$10^{-8}$ 。这些是TensorFlow的AdamOptimizer类的默认值，可以使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上，因为Adam是一个自适应学习速率算法（与AdaGrad以及RMSProp类似），它需要对学习速率超参数$\\eta$进行微调。可以一直使用默认值$\\eta=0.001$，这样使得Adam比梯度下降更容易使用。\n",
    "\n",
    "> 目前讨论过的所有优化技术都依赖于一阶偏导数（Jacobians）。优化文献包含基于二阶偏导数（Hessians）的算法。不幸的是，这些算法都非常难应用到深度神经网络，原因是每层输出都有$n^2$ Hessians（其中$n$是参数个数），而不是每次只有$n$ Jacobians。因为DNN通常有数万个参数，所以二阶优化算法一般不会在内存里适用，而且即使运行，计算Hessians也会非常慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练稀疏模型\n",
    "\n",
    "所有提到的优化算法都是制作密集模型，意味着大部分参数都是非零的。如果需要在运行时有一个超速模型，或者如果你需要它占用更少的内存，最终可能需要一个稀疏模型。\n",
    "\n",
    "实现这个目的的一个小方法是像往常一样训练模型，然后摆脱掉小的权重（将其设置为0）。\n",
    "\n",
    "另一种方法是在训练中应用强1正则化，因为它可以促使优化器尽可能地将权重归零（如第4章讨论的Lasso回归）。\n",
    "\n",
    "然而，在某些例子中这些技术可能会无效。最后一个方法是应用对偶平均，通常称为FTRL（Fllow The Regularized Leader），这是Yurii Nesterov（ https://goo.gl/xSQD4C ） [8] 提出的一个技术。当使用$\\ell_1$正则化时，这种技术会导出一个非常稀疏的模型。TensorFlow在FTRLOptimizer类中实现了一个名为FTRL-Proximal（ https://goo.gl/bxme2B ） [9] 的FTRL变体。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习速率调度\n",
    "\n",
    "要找到一个良好的学习速率会比较麻烦。如果你把它设置得太高，训练可能会产生分歧（如第4章讨论的）。如果设置得太低，训练可能需要花很长的时间才能收敛到最优解。如果设置得相对高一些，可能最开始运行得很快，但是最后一直在最优解附近摆动不停下来（除非你使用适应性学习速率优化算法，比如AdaGrad、RMSProp或者Adam，但即使这样也需要时间来稳定）。如果计算机预算有限，你可能必须在训练正确收敛之前停下来，从而生成次优解（见图11-8）。\n",
    "\n",
    "\n",
    "![图11-8：不同学习速率的学习曲线](images/VNote/20210113191216819_2290.png)\n",
    "图11-8：不同学习速率的学习曲线\n",
    "\n",
    "可能会通过使用各种学习速率，对比学习曲线在几个数据集内多次训练网络，从而得到一个非常良好的学习速率。理想的学习速率学习速度非常快，并且会收敛到良好的解决方案。\n",
    "\n",
    "然而相比一个固定的学习速率，可以做得更好：如果以一个高学习速率开始，然后一旦它停止快速过程就降低速率，那么会获得一个比最优固定学习速率更快速的方案。有很多不同的策略在训练过程中监督学习速率。这些策略称为学习计划（我们在第4章简单介绍过这个概念），最常用的有：\n",
    "\n",
    "* 预定分段常数学习速率\n",
    "\n",
    "举个例子，最开始设置学习速率$\\eta_0 =0.1$，在50个数据集之后设置$\\eta_0 =0.01$。尽管这个方法效果不错，但是需要搞清楚正确的学习速率和何时使用。\n",
    "\n",
    "* 性能调度\n",
    "\n",
    "每N个步骤进行测量来验证错误（比如早起停止），然后当错误停止出现时，将学习速率降低到$1/\\lambda$。\n",
    "\n",
    "* 指数调度\n",
    "\n",
    "将学习速率设置为迭代数t的函数：$\\eta(t)=\\eta_0 10^{-t/r}$ 。这个效果很好，但是需要微调$\\eta_0$ 和$r$。学习速率每$r$步下降10。\n",
    "\n",
    "* 功率调度\n",
    "\n",
    "设置学习速率为$\\eta(t)=\\eta_0(1+t/r)^{-c}$。超参数$c$通常设置为1。这个与指数调度类似，但是学习速率降低得非常慢。\n",
    "\n",
    "Andrew Senior等人在2013年的一篇论文（ http://goo.gl/Hu6Zyq ） [10] 中对比了运用Momentum优化训练深度神经网络进行语音识别的一些最受欢迎的学习计划的表现。作者总结，在这样的设置下，性能调度和指数调度表现都很好，但是他们更推荐指数调度，因为它更容易实现，容易微调，而且收敛到最优解的速度稍快一些。\n",
    "\n",
    "用TensorFlow实现学习计划非常直接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       # not shown in the book\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置完超参数值后，创建一个不可训练变量`global_step`（初始化为0）来跟踪当前训练的迭代数。然后用TensorFlow的`exponential_decay()`函数定义一个指数衰减学习速率（其中$\\eta_0 =0.1$，$r=10000$）。接着，构建一个使用该衰减学习速率的优化器（本例使用了`MomentumOptimizer`）。最后，通过调用优化器的`minimize()`方法构建训练操作；因为给它传入了`global_step`变量，所以它会自增。\n",
    "\n",
    "因为AdaGrad、RMSProp和Adam优化在训练中自动降低了学习速率，所以不需要额外加入学习计划。对于其他的优化算法，使用指数衰减或性能调度可以很有效地提高收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9836\n",
      "19 Validation accuracy: 0.9836\n",
      "29 Validation accuracy: 0.9838\n",
      "39 Validation accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 至少就现在来讲：研究进展很快，特别是针对优化领域。请确保在每一个TensorFlow新版本发布的时候查看一下最新和最好的优化器。\n",
    "\n",
    "[2] “Some methods of speeding up the convergence of iteration methods”，B.Polyak（1964）。\n",
    "\n",
    "[3] “A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence O（1/k2）”，Yurii Nesterov（1983）。\n",
    "\n",
    "[4] “Adaptive Subgradient Methods for Online Learning and Stochastic Optimization”，J.Duchi等人（2011）。\n",
    "\n",
    "[5] 这个算法是Tijmen Tieleman和Geoffrey Hinton在2012年提出的，并且由Geoffrey Hinton在他的针对神经网络的Coursera课程上发表（幻灯片地址：http://goo.gl/RsQeis ；视频地址： https://goo.gl/XUbIyJ ）。 有趣的是，因为作者并没有在任何论文中提到这个算法，所以研究者经常在他们的论文中以“讲座6的第29张幻灯片”的方式进行引用。\n",
    "\n",
    "[6] “Adam：A Method for Stochastic Optimization”，D.Kingma和J.Ba（2015）。\n",
    "\n",
    "[7] 这些是梯度均值和（非中心）方差的估值。均值被称为第一力矩，方差被称为第二力矩，从而有了算法的名字。\n",
    "\n",
    "[8] “Primal-Dual Subgradient Methods for Convex Problems”，Yurii Nesterov（2005）。\n",
    "\n",
    "[9] “Ad Click Prediction：a View from the Trenches”，H.McMahan等人（2013）。\n",
    "\n",
    "[10] “An Empirical Study of Learning Rates in Deep Neural Networks for Speech Recognition”，A.Senior等人（2013）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过正则化避免过度拟合\n",
    "\n",
    "用四个参数我可以适应一头大象，用五个参数我可以让它摆动躯干。\n",
    "\n",
    "——John von Neumann，Enrico Fermi在Nature 427中引用\n",
    "\n",
    "深度神经网络通常有数万个参数，有时甚至过亿。因为有大量参数，网络具有相当的自由度，可以使用各种恶意复杂的数据集。但是这种极大的灵活性也意味着它容易过度拟合训练集。\n",
    "\n",
    "拥有数亿的参数可以适应整个动物园。本节中会给出集中神经网络中最受欢迎的正则化技术，以及用TensorFlow怎样实现：提前停止，$\\ell_1$和$\\ell_2$正则化、dropout、最大范数正则化和数据扩充。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提前停止\n",
    "\n",
    "要避免过度拟合训练集，有一个解决方案是提前停止（在第4章介绍过）：当验证集的性能开始下降时停止训练。\n",
    "\n",
    "用TensorFlow实现提前停止的一种方法是定期对验证集进行模型评估（比如：每50步），同时如果表现好于前一个“优胜者”快照就将此“优胜者”快照保存起来。在保存最后一张“优胜者”快照的时候计算步数，当步数达到某些限制（比如：2000步）时停止训练。然后恢复最后一张“优胜者”快照。\n",
    "\n",
    "尽管在练习中提前停止表现得很好，但通常你还是可以通过结合其他正则化技术来获得更高的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\ell_1$和$\\ell_2$正则化\n",
    "\n",
    "与第4章中简单的线性模型一样，可以使用$\\ell_1$和$\\ell_2$正则化来约束一个神经网络的连接权重（但通常不是其偏差）。\n",
    "\n",
    "用TensorFlow实现的一个方式是简单地将适当的正则项加在成本函数中。举个例子，假设只有一个隐藏层，权重为weight1，一个输出层，权重为weight2，然后可以这样使用$\\ell_1$正则化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001 # l1 regularization hyperparameter\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而，如果层数多，这个方法就不是很有效。幸运的是，TensorFlow提供了一个更好的方案。许多构建变量的函数（比如`get_variable()`和`fully_connected()`）在构建每一个变量（比如`weights_regularizer`）时可以接受一个参数`*_regularizer`。可以传递任何把权重作为参数并且返回相应的正则化损失的函数。函数`l1_regularizer()`、`l2_regularizer()`和`l1_l2_regularizer()`返回这些函数。下面的代码把它们放在一起："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9064\n",
      "19 Validation accuracy: 0.9062\n",
      "29 Validation accuracy: 0.9018\n",
      "39 Validation accuracy: 0.9054\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    #kernel_regularizer=tf.contrib.layers.l1_regularizer(scale),\n",
    "    kernel_regularizer = tf.keras.regularizers.l1(scale))\n",
    "\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个代码构建了一个有两个隐藏层和一个输出层的神经网络，同时也在图中构建了节点来计算对应每一层权重的 正则化损失。TensorFlow自动将这些节点加到一个包含所有正则化损失的特殊连接中。只需要将这些正则化损失加到你整体的损失中即可，类似这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):                                     # not shown in the book\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  # not shown\n",
    "        labels=y, logits=logits)                                # not shown\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   # not shown\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 不要忘记将正则化损失加到整体损失中，不然就会被直接忽略掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9214\n",
      "19 Validation accuracy: 0.9206\n",
      "29 Validation accuracy: 0.918\n",
      "39 Validation accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "最受欢迎的深度神经网络正则化技术无疑是dropout。它是由G.E.Hinton在2012年提出的（ https://goo.gl/PMjVnG ） [1] ，Nitish Srivastava等人在之后的一篇论文（ http://goo.gl/DNKZo1 ） [2] 中进行了更细致的解释，并且证明有很高的成功率：即使是最先进的神经网络在加了dropout之后也能提高1%～2%的正确性。这看上去可能不是很多，但是当一个模型已经有95%的正确性，提高2%就意味着降低了将近40%的错误率（从5%的误差到差不多3%）。\n",
    "\n",
    "这是一个很简单的算法：每一个训练步骤，每一个神经元（包括输入神经元，不包括输出神经元）都有一个会被暂时“丢弃”的可能性$p$，意思是在这次训练步骤中它会被完全忽略，但是到下一步的时候就会被激活（见图11-9）。超参数$p$被称为`丢弃率`，通常设置为50%。在训练之后，神经元不会再被丢弃。原理就是这样。\n",
    "\n",
    "![图11-9：dropout正则化](images/VNote/20210114151910505_22674.png)\n",
    "\n",
    "图11-9：dropout正则化\n",
    "\n",
    "最开始这种相当暴力的方法可以起作用也是非常令人震惊的。如果员工每天早上通过扔硬币来决定去不去上班，这样的公司会越来越好吗？好吧，谁知道呢，说不定会呢！公司很明显是要去适应它的组织，而不是依赖某一个人去填充咖啡机或者去做其他关键的任务，所以这些专业知识必须分散到好几个人身上。员工需要学习和许多同事一些协作，而不仅是其中几个人。公司的适应性会越来越好。如果有一个人离开，也不会有太大的影响。现在还不清楚这个想法对于公司是不是真正奏效，但是对于神经网络的确是有用的。训练有dropout的神经元不能和周围的神经元共适应；它们必须让自己尽可能有用。它们也不能过分依赖几个输入神经元；它们必须关注每一个输入神经元。它们最后会变得对于输入的轻微变化不那么敏感。最终，会获得一个更好地泛化了的健壮的网络。\n",
    "\n",
    "再者，理解dropout的强大是因为注意到在每一个训练步骤都会创建一个独立的神经网络。因为每一个神经元都可能出现或不出现，所以就会有总共$2^N$ 个可能的网络（其中N是可丢弃神经元的个数）。这是一个很大的数字，几乎不可能对一个神经网络采样两次。一旦已经运行了10000个训练步骤，那实际上就已经训练了10000个不同的神经网络（每一个网络都有一个训练实例）。这些神经网络很明显不是独立的，因为它们共享很多它们的权重，但是它们还是不同的。所得到的神经网络可以看作是这些较小的神经网络的平均集合。\n",
    "\n",
    "这里提到一个很小但是很重要的技术细节。假设p=50，在测试期间，一个神经元将会被连接到训练期间输入神经元（平均）的两倍。为了弥补这个情况，需要在训练之后给每一个神经元的输入连接权重乘以0.5。如果不这样做，每一个神经元就会得到一个总输入信号，大概是之前训练网络的两倍，而且性能不会表现得特别好。更通俗来讲，需要在训练结束后给每一个输入连接权重乘以保持可能性（1-p）。或者，可以在训练过程中给每一个神经元的输出除以保持可能性（这些可选方案不完全一致，但是它们的效果都一样好）。\n",
    "\n",
    "要用TensorFlow实现dropout，可以直接在输入层和每一个隐藏层的输出调用`dropout()`函数。在训练中，这个函数会随机丢弃一些项（把它们设置为0），并且给剩下的项除以保持可能性。在训练结束后，这个函数什么也不做。下面是一个针对三层神经网络应用dropout正则化的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "#X_drop = tf.keras.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9742\n",
      "29 Validation accuracy: 0.975\n",
      "39 Validation accuracy: 0.9768\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 想在tensorflow.contrib.layers调用`dropout()`，而不是tensorflow.nn。在不训练的时候，对想调用的第一个关掉（no-op），但是第二个不关。\n",
    "\n",
    "当然，与之前批量归一化类似，需要在训练时设置`training`为True，在测试时设置`training`为False。\n",
    "\n",
    "如果发现模型过度拟合，可以提高dropout速率（即降低`keep_prob`超参数）。相反，如果模型不拟合训练集，需要降低dropout速率（即提高`keep_prob`超参数）。同样针对大层可以帮助提高dropout速率，针对小层可以降低。\n",
    "\n",
    "dropout确实收敛变慢，但是如果微调合适，它通常都会得到一个更好的模型。所以这个结果是值得付出多一些时间和代价的。\n",
    "\n",
    "> Dropconnect是dropout的一个变体，它随机丢弃掉独立连接，而不是整个神经元。通常情况下，dropout表现得更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大范数正则化\n",
    "\n",
    "另一种神经网络比较流行的正则化技术叫作`最大范数正则化`：对每一个神经元，包含一个传入连接权重w满足$||w||_2 \\leq r$，其中$r$是最大范数超参数，$||\\cdot||_2$ 是$\\ell_2$范数。\n",
    "\n",
    "通常这样来满足这个约束，在每一次训练步骤后计算$||w||_2$ ，同时如果需要会剪裁 。\n",
    "\n",
    "降低$r$会增加正则化数目，同时帮助减少过度拟合。最大范数正则化可以同时帮助缓解梯度消失/爆炸问题（如果不使用批量归一化）。\n",
    "\n",
    "TensorFlow没有提供现成的最大范数正则化器，但是实现起来也不难。下面的代码构建了一个节点clip_weights，该节点会沿着第二个轴削减weights变量，从而使每一个行向量的最大范数为1.0："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以按照下面的方法在每一个训练步骤之后进行操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9826\n",
      "19 Validation accuracy: 0.984\n",
      "29 Validation accuracy: 0.9852\n",
      "39 Validation accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              # not shown in the book\n",
    "    init.run()                                                          # not shown\n",
    "    for epoch in range(n_epochs):                                       # not shown\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # not shown\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        # not shown\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})   # not shown\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", acc_valid)                 # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")               # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold = 1.0\n",
    "\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "\n",
    "clip_weights = tf.assign(weights, clipped_weights)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    [...]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        [...]\n",
    "\n",
    "        for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "            clip_weights.eval()\n",
    "如果你不知道如何获得每一层的weights变量。你可以像下面这样调用一个可变范围：\n",
    "\n",
    "hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\")\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"hidden1\", reuse=True):\n",
    "\n",
    "    weights1 = tf.get_variable(\"weights\")\n",
    "同样，你也可以调用根变量范围：\n",
    "\n",
    "hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\")\n",
    "\n",
    "hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\")\n",
    "\n",
    "[...]\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):  # root scope\n",
    "\n",
    "    weights1 = tf.get_variable(\"hidden1/weights\")\n",
    "\n",
    "    weights2 = tf.get_variable(\"hidden2/weights\")\n",
    "如果你不知道某个变量的名字，可以调用TensorBoard去查询或者调用global_variables（）函数打印出所有的变量名：\n",
    "\n",
    "for variable in tf.global_variables():\n",
    "\n",
    "    print(variable.name)\n",
    "尽管之前的方法效果不错，但是还是有点烦琐。一个简洁的方法是构建一个`max_norm_regularizer()`函数，像之前的`l1_regularizer()`函数一样使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数返回一个参数化`max_norm()`函数，可以像其他正则化器一样使用它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大范数正则化不需要将正则化损失项加入整体损失函数，所以`max_norm()`方法返回None。但是仍然需要在每一个训练步骤之后返回`clip_weights`操作，这样才可以获取它的句柄。这就是为什么`max_norm()`函数要添加`clip_weights`节点到最大范数剪裁操作集合里。需要调用这些剪裁操作并在每一个训练步骤之后返回它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9804\n",
      "19 Validation accuracy: 0.9848\n",
      "29 Validation accuracy: 0.9838\n",
      "39 Validation accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # not shown\n",
    "        if (epoch % 10 == 9):\n",
    "            print(epoch, \"Validation accuracy:\", acc_valid)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")             # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码整洁多了，是吧？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据扩充\n",
    "\n",
    "最后一个正则化技术是数据扩充，包括从已有实例构建新的训练实例，人为提高训练集大小。因为会减少过度拟合，所以它是一种正则化技术。棘手的是构建一个切实可用的训练实例；理想情况下，人是没办法区分哪个实例建好了，哪个没有建好。而且，简单地增加白噪声也没有用；进行的修改应该是可学习的（白噪声不可学习）。\n",
    "\n",
    "举个例子，如果你的模型要区分蘑菇的照片，你可简单地移动、旋转和改变每张在训练集中的照片的大小，同时把这些改变后的照片添加进训练集中（见图11-10）。这就迫使模型要兼容照片中蘑菇的位置、方向和大小。如果你希望模型对光的敏感度也增加，那你可以类似地生成许多具有各种对比度的照片。假设蘑菇是对称的，你也可以水平翻转照片。通过混合各种变换，你可以很快地增加你的训练集。\n",
    "\n",
    "![图11-10：用现有实例来生成新的训练实例](images/VNote/20210114163158865_11629.png)\n",
    "\n",
    "图11-10：用现有实例来生成新的训练实例\n",
    "\n",
    "一般偏向在训练过程中快速生成训练实例，而不是浪费存储空间和网络带宽。TensorFlow提供了多种图片处理操作，比如转置（偏移）、旋转、调整大小、翻转和裁剪，同时还有调整亮度、对比度、饱和度和色调（详见API文档）。这样就可以轻松地实现图像数据集的数据扩充。\n",
    "\n",
    "> 另外一种训练深度神经网络的有效技术是添加跳过连接（跳过连接就是把层输入加到高层的输出上）。会在第13章讨论到深度残留网络时再展开讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] “Improving neural networks by preventing co-adaptation of feature detectors”，G.Hinton等人（2012）。\n",
    "\n",
    "[2] “Dropout：A Simple Way to Prevent Neural Networks from Overfitting”，N.Srivastava等人（2014）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实用指南\n",
    "\n",
    "在这一章里，介绍了很多技术，可能会搞不清到底应该用哪一个。表11-2中的配置在大多数情况下都是有用的。\n",
    "\n",
    "|                        |                     |\n",
    "| ---------------------- | ------------------- |\n",
    "| Initialization         | He initialization   |\n",
    "| Activation Function    | ELU                 |\n",
    "| Normalization          | Batch Normalization |\n",
    "| Regularization         | dropout             |\n",
    "| Optimizer              | Adam                |\n",
    "| Learning rate schedule | None                |\n",
    "\n",
    "表11-2：默认DNN配置\n",
    "\n",
    "当然，如果能够找到解决类似问题的方法，应该尝试重用部分预训练的神经网络。\n",
    "\n",
    "这个默认配置可能需要调整：\n",
    "\n",
    "- 如果找不到良好的学习速率（之前收敛太慢，所以你想提高训练速率，现在收敛变快了，但是网络正确性却是次优的），那你可以尝试添加一个类似指数衰减的学习计划。\n",
    "\n",
    "- 如果你的训练集有点小，你可以使用数据扩充。\n",
    "\n",
    "- 如果你需要一个稀疏模型，你可以在混合中加一些$\\ell_1$正则化（并且在训练之后选择权重为0）。如果你想要再稀疏一些的模型，你可以尝试用FTRL代替Adam优化，并且搭配$\\ell_1$正则化。\n",
    "\n",
    "- 如果你在运行时需要一个快速闪电模型，你可能需要丢弃批量归一化，同时可能需要用leaky ReLU代替ELU激活函数。有一个稀疏模型可能也会有帮助。\n",
    "\n",
    "有了这些准则，你就可以开始训练一个深度网络了——好吧，如果你很有耐心，那就对了！如果你只有一台设备，你可能需要等上几天甚至几个月才能完成训练。在下一章，我们会讨论怎么使用分布式TensorFlow来在许多服务器和GPU上训练和运行模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习\n",
    "\n",
    "1.只要使用He初始化随机进行选择，就可以将所有权重初始化为相同的值吗？\n",
    "\n",
    "不能\n",
    "\n",
    "标准答案：\n",
    "不，所有权重需要独立处理，它们不可以初始化为统一值。随机取样权重一个重要的目的是破坏对称性：如果所有的权重具有相同的初始值，即使该值不为0，对称性也无法被破坏（即一层中所有神经元都是一样的），并且反向传播将无法破坏它。具体来说，这就意味着一层中所有神经元始终保持相同的权重。就像每层只有一个神经元，而且要慢得多。这样的配置是无法收敛到一个好的解决方案的。\n",
    "\n",
    "2.将偏移项初始化为0可以吗？\n",
    "\n",
    "没问题。\n",
    "\n",
    "标准答案：\n",
    "当然可以设置为0。有些人喜欢像初始化权重一样处理偏差项，这样也是可以的，没有太大的区别。\n",
    "\n",
    "3.给出ELU相比ReLU的3个优点。\n",
    "\n",
    "标准答案：\n",
    "- 它可以使用负值，所以相比使用ReLU激活方程（从不输出负值），某一给定层的神经元输出平均值理论上更容易接近0。这样有助于缓解梯度消失问题。\n",
    "\n",
    "- 它总是有一个非零的导数，可以避免影响ReLU单元的单元消失问题。\n",
    "\n",
    "- 它在任何地方都是平滑的，而在$z=0$时，ReLU的梯度突然从0跳至1。这个突然的变化会引起在$z=0$附近摆动，从而可以缓解梯度下降。\n",
    "\n",
    "4.在什么情况下你会依次使用下列这些激活函数：ELU、leaky ReLU（以及它的变体）、ReLU、tanh、逻辑激活函数和softmax？\n",
    "\n",
    "标准答案：\n",
    "ELU激活函数是一个不错的默认选择。如果对神经网络的速度要求很高，可以用leaky ReLU的一个变种（即使用默认超参数值的leaky ReLU）。这是因为ReLU激活函数简单方便，所以很多人会将其作为首选，即使输出表现会被ELU和leaky ReLU超过。但是，某些情况下，ReLU激活函数的精确输出能力是有用的（见第15章）。如果你需要输出一个介于-1和1之间的数，tanh在输出层会比较有效，但是现在在隐藏层的使用频度并不高。在你需要评估可能性（比如二进制分类）时，逻辑激活函数在输出层比较有效，但是同样在隐藏层中很少使用（也有例外，比如，变分自动编码器的编码层，见第15章）。最后softmax激活函数在输出层输出互相排斥类的概率是有效的，但是除了（或者曾经）隐藏层以外基本不使用。\n",
    "\n",
    "5.使用Momentum Optimizer时，如果你将动量超参数设置的离1特别近（比如0.99999），那么会发生什么？\n",
    "\n",
    "标准答案：\n",
    "如果使用MomentumOptimizer时，将动量超参数设置得太接近1（比如：0.99999），算法就会提速很高，偏向全局最小值，但是接着会经过最小值。之后就会慢慢降速回落，再加速，再超调，循环往复。这种方式在收敛前会振荡好几次，所以总体来说，收敛速度会比用小动量慢。\n",
    "\n",
    "6.给出三种沟通稀疏模型的方法。\n",
    "\n",
    "标准答案：\n",
    "一种实现稀疏模型的方法（即大多数权重等于0）是正常训练一个模型，然后将小权重设置为0。为了更稀疏，可以在训练过程中应用$\\ell_1$正则化，这样可以促使优化器更加稀疏。第三种方式是使用TensorFlow的FTRLOptimizer类将$\\ell_1$正则化和对偶平均相结合。\n",
    "\n",
    "7.dropout会减慢训练速度吗？是否减慢推理（即对新实例进行预测）？\n",
    "\n",
    "会。不会减少预测的速度。\n",
    "\n",
    "是的，dropout会减慢训练速度，一般降为原速度的一半。但是，因为只是在训练期间使用所以对于预测没有影响。\n",
    "\n",
    "8.深度学习。\n",
    "\n",
    "a.用每100个神经元5个隐藏层，He初始化和ELU激活函数构建一个DNN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5 # 只能在数字0～4之间\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.用Adam优化和提前停止，尝试在MNIST上进行训练，但只能在数字0～4之间，因为在下一个练习中我们会用迁移学习来对5～9进行训练。你需要一个有5个神经元的softmax输出层，而且要一直保持定期保存检查点，然后要保存最后的模型以便之后重用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[y_train < 5]\n",
    "y_train1 = y_train[y_train < 5]\n",
    "X_valid1 = X_valid[y_valid < 5]\n",
    "y_valid1 = y_valid[y_valid < 5]\n",
    "X_test1 = X_test[y_test < 5]\n",
    "y_test1 = y_test[y_test < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.099841\tBest loss: 0.099841\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.125081\tBest loss: 0.099841\tAccuracy: 96.99%\n",
      "2\tValidation loss: 0.121770\tBest loss: 0.099841\tAccuracy: 97.11%\n",
      "3\tValidation loss: 0.595908\tBest loss: 0.099841\tAccuracy: 91.71%\n",
      "4\tValidation loss: 0.150809\tBest loss: 0.099841\tAccuracy: 97.30%\n",
      "5\tValidation loss: 0.152884\tBest loss: 0.099841\tAccuracy: 96.68%\n",
      "6\tValidation loss: 0.104155\tBest loss: 0.099841\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.121703\tBest loss: 0.099841\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.264582\tBest loss: 0.099841\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.166940\tBest loss: 0.099841\tAccuracy: 97.69%\n",
      "10\tValidation loss: 0.570540\tBest loss: 0.099841\tAccuracy: 78.46%\n",
      "11\tValidation loss: 0.405632\tBest loss: 0.099841\tAccuracy: 79.28%\n",
      "12\tValidation loss: 0.383561\tBest loss: 0.099841\tAccuracy: 79.52%\n",
      "13\tValidation loss: 0.566053\tBest loss: 0.099841\tAccuracy: 79.24%\n",
      "14\tValidation loss: 0.492089\tBest loss: 0.099841\tAccuracy: 83.97%\n",
      "15\tValidation loss: 0.153096\tBest loss: 0.099841\tAccuracy: 96.99%\n",
      "16\tValidation loss: 0.140076\tBest loss: 0.099841\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.118811\tBest loss: 0.099841\tAccuracy: 97.26%\n",
      "18\tValidation loss: 0.149795\tBest loss: 0.099841\tAccuracy: 97.69%\n",
      "19\tValidation loss: 0.264599\tBest loss: 0.099841\tAccuracy: 96.29%\n",
      "20\tValidation loss: 0.182754\tBest loss: 0.099841\tAccuracy: 96.79%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 98.13%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./models/my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.用交叉验证调整超参数，观察你可以实现的精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    if epoch % 10 == 0:\n",
    "                        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                            epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.099841\tBest loss: 0.099841\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.125081\tBest loss: 0.099841\tAccuracy: 96.99%\n",
      "2\tValidation loss: 0.121770\tBest loss: 0.099841\tAccuracy: 97.11%\n",
      "3\tValidation loss: 0.595908\tBest loss: 0.099841\tAccuracy: 91.71%\n",
      "4\tValidation loss: 0.150809\tBest loss: 0.099841\tAccuracy: 97.30%\n",
      "5\tValidation loss: 0.152884\tBest loss: 0.099841\tAccuracy: 96.68%\n",
      "6\tValidation loss: 0.104155\tBest loss: 0.099841\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.121703\tBest loss: 0.099841\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.264582\tBest loss: 0.099841\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.166940\tBest loss: 0.099841\tAccuracy: 97.69%\n",
      "10\tValidation loss: 0.570540\tBest loss: 0.099841\tAccuracy: 78.46%\n",
      "11\tValidation loss: 0.405632\tBest loss: 0.099841\tAccuracy: 79.28%\n",
      "12\tValidation loss: 0.383561\tBest loss: 0.099841\tAccuracy: 79.52%\n",
      "13\tValidation loss: 0.566053\tBest loss: 0.099841\tAccuracy: 79.24%\n",
      "14\tValidation loss: 0.492089\tBest loss: 0.099841\tAccuracy: 83.97%\n",
      "15\tValidation loss: 0.153096\tBest loss: 0.099841\tAccuracy: 96.99%\n",
      "16\tValidation loss: 0.140076\tBest loss: 0.099841\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.118811\tBest loss: 0.099841\tAccuracy: 97.26%\n",
      "18\tValidation loss: 0.149795\tBest loss: 0.099841\tAccuracy: 97.69%\n",
      "19\tValidation loss: 0.264599\tBest loss: 0.099841\tAccuracy: 96.29%\n",
      "20\tValidation loss: 0.182754\tBest loss: 0.099841\tAccuracy: 96.79%\n",
      "21\tValidation loss: 0.189755\tBest loss: 0.099841\tAccuracy: 97.89%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(random_state=55)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(random_state=55)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dnn_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2b61609ed65a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dnn_clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=50, activation=<function elu at 0x7fabf3fc68b0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.123453\tBest loss: 0.123453\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.137429\tBest loss: 0.123453\tAccuracy: 97.54%\n",
      "2\tValidation loss: 0.079596\tBest loss: 0.079596\tAccuracy: 98.48%\n",
      "3\tValidation loss: 0.093554\tBest loss: 0.079596\tAccuracy: 97.62%\n",
      "4\tValidation loss: 0.083259\tBest loss: 0.079596\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.108235\tBest loss: 0.079596\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.380997\tBest loss: 0.079596\tAccuracy: 96.01%\n",
      "7\tValidation loss: 0.096875\tBest loss: 0.079596\tAccuracy: 97.38%\n",
      "8\tValidation loss: 0.105657\tBest loss: 0.079596\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.078764\tBest loss: 0.078764\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.129176\tBest loss: 0.078764\tAccuracy: 96.36%\n",
      "11\tValidation loss: 0.082618\tBest loss: 0.078764\tAccuracy: 97.77%\n",
      "12\tValidation loss: 0.093501\tBest loss: 0.078764\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.084058\tBest loss: 0.078764\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.075091\tBest loss: 0.075091\tAccuracy: 98.36%\n",
      "15\tValidation loss: 0.067472\tBest loss: 0.067472\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.066557\tBest loss: 0.066557\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.108691\tBest loss: 0.066557\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.088059\tBest loss: 0.066557\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.102842\tBest loss: 0.066557\tAccuracy: 97.85%\n",
      "20\tValidation loss: 0.081251\tBest loss: 0.066557\tAccuracy: 98.05%\n",
      "21\tValidation loss: 1.619562\tBest loss: 0.066557\tAccuracy: 92.73%\n",
      "22\tValidation loss: 0.517590\tBest loss: 0.066557\tAccuracy: 88.00%\n",
      "23\tValidation loss: 0.251080\tBest loss: 0.066557\tAccuracy: 96.68%\n",
      "24\tValidation loss: 0.283214\tBest loss: 0.066557\tAccuracy: 95.23%\n",
      "25\tValidation loss: 0.217977\tBest loss: 0.066557\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.142656\tBest loss: 0.066557\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.119148\tBest loss: 0.066557\tAccuracy: 97.50%\n",
      "28\tValidation loss: 0.185710\tBest loss: 0.066557\tAccuracy: 98.16%\n",
      "29\tValidation loss: 0.239803\tBest loss: 0.066557\tAccuracy: 98.08%\n",
      "30\tValidation loss: 0.117731\tBest loss: 0.066557\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.212586\tBest loss: 0.066557\tAccuracy: 96.17%\n",
      "32\tValidation loss: 0.170890\tBest loss: 0.066557\tAccuracy: 98.28%\n",
      "33\tValidation loss: 0.087348\tBest loss: 0.066557\tAccuracy: 98.51%\n",
      "34\tValidation loss: 0.143095\tBest loss: 0.066557\tAccuracy: 96.99%\n",
      "35\tValidation loss: 0.145984\tBest loss: 0.066557\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.106117\tBest loss: 0.066557\tAccuracy: 98.59%\n",
      "37\tValidation loss: 0.105207\tBest loss: 0.066557\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=50, activation=<function elu at 0x7fabf3fc68b0>, total=  41.6s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=50, activation=<function elu at 0x7fabf3fc68b0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   41.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.145525\tBest loss: 0.145525\tAccuracy: 95.27%\n",
      "1\tValidation loss: 0.161296\tBest loss: 0.145525\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.211413\tBest loss: 0.145525\tAccuracy: 96.44%\n",
      "3\tValidation loss: 0.062123\tBest loss: 0.062123\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.071108\tBest loss: 0.062123\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.056673\tBest loss: 0.056673\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.123913\tBest loss: 0.056673\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.060419\tBest loss: 0.056673\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.050332\tBest loss: 0.050332\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.108432\tBest loss: 0.050332\tAccuracy: 97.22%\n",
      "10\tValidation loss: 0.383225\tBest loss: 0.050332\tAccuracy: 97.85%\n",
      "11\tValidation loss: 0.070471\tBest loss: 0.050332\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.126568\tBest loss: 0.050332\tAccuracy: 97.19%\n",
      "13\tValidation loss: 0.129941\tBest loss: 0.050332\tAccuracy: 97.30%\n",
      "14\tValidation loss: 0.081489\tBest loss: 0.050332\tAccuracy: 97.77%\n",
      "15\tValidation loss: 0.061782\tBest loss: 0.050332\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.125028\tBest loss: 0.050332\tAccuracy: 97.85%\n",
      "17\tValidation loss: 0.103779\tBest loss: 0.050332\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.089454\tBest loss: 0.050332\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.186167\tBest loss: 0.050332\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.084238\tBest loss: 0.050332\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.183453\tBest loss: 0.050332\tAccuracy: 98.05%\n",
      "22\tValidation loss: 0.121920\tBest loss: 0.050332\tAccuracy: 97.69%\n",
      "23\tValidation loss: 0.152173\tBest loss: 0.050332\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.164084\tBest loss: 0.050332\tAccuracy: 97.46%\n",
      "25\tValidation loss: 0.183684\tBest loss: 0.050332\tAccuracy: 98.28%\n",
      "26\tValidation loss: 0.125795\tBest loss: 0.050332\tAccuracy: 98.48%\n",
      "27\tValidation loss: 0.215608\tBest loss: 0.050332\tAccuracy: 92.89%\n",
      "28\tValidation loss: 0.158657\tBest loss: 0.050332\tAccuracy: 98.36%\n",
      "29\tValidation loss: 0.173679\tBest loss: 0.050332\tAccuracy: 98.36%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=50, activation=<function elu at 0x7fabf3fc68b0>, total=  32.5s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=50, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.118597\tBest loss: 0.118597\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.085719\tBest loss: 0.085719\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.108942\tBest loss: 0.085719\tAccuracy: 97.07%\n",
      "3\tValidation loss: 0.070235\tBest loss: 0.070235\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.074961\tBest loss: 0.070235\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.057031\tBest loss: 0.057031\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.076153\tBest loss: 0.057031\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.093682\tBest loss: 0.057031\tAccuracy: 98.01%\n",
      "8\tValidation loss: 0.079466\tBest loss: 0.057031\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.061932\tBest loss: 0.057031\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.094878\tBest loss: 0.057031\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.849959\tBest loss: 0.057031\tAccuracy: 92.22%\n",
      "12\tValidation loss: 0.234171\tBest loss: 0.057031\tAccuracy: 94.10%\n",
      "13\tValidation loss: 0.164473\tBest loss: 0.057031\tAccuracy: 95.90%\n",
      "14\tValidation loss: 0.159469\tBest loss: 0.057031\tAccuracy: 96.25%\n",
      "15\tValidation loss: 0.146082\tBest loss: 0.057031\tAccuracy: 97.22%\n",
      "16\tValidation loss: 0.183117\tBest loss: 0.057031\tAccuracy: 95.86%\n",
      "17\tValidation loss: 0.136893\tBest loss: 0.057031\tAccuracy: 97.38%\n",
      "18\tValidation loss: 0.201239\tBest loss: 0.057031\tAccuracy: 95.93%\n",
      "19\tValidation loss: 0.139830\tBest loss: 0.057031\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.159927\tBest loss: 0.057031\tAccuracy: 96.95%\n",
      "21\tValidation loss: 0.109798\tBest loss: 0.057031\tAccuracy: 97.97%\n",
      "22\tValidation loss: 0.133688\tBest loss: 0.057031\tAccuracy: 97.58%\n",
      "23\tValidation loss: 0.113412\tBest loss: 0.057031\tAccuracy: 97.93%\n",
      "24\tValidation loss: 0.189887\tBest loss: 0.057031\tAccuracy: 97.62%\n",
      "25\tValidation loss: 0.413450\tBest loss: 0.057031\tAccuracy: 77.91%\n",
      "26\tValidation loss: 0.173342\tBest loss: 0.057031\tAccuracy: 96.60%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=50, activation=<function elu at 0x7fabf3fc68b0>, total=  29.3s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.131107\tBest loss: 0.131107\tAccuracy: 97.46%\n",
      "1\tValidation loss: 0.191175\tBest loss: 0.131107\tAccuracy: 96.79%\n",
      "2\tValidation loss: 0.128475\tBest loss: 0.128475\tAccuracy: 96.52%\n",
      "3\tValidation loss: 0.140016\tBest loss: 0.128475\tAccuracy: 96.48%\n",
      "4\tValidation loss: 0.131654\tBest loss: 0.128475\tAccuracy: 96.83%\n",
      "5\tValidation loss: 0.076936\tBest loss: 0.076936\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.105317\tBest loss: 0.076936\tAccuracy: 97.19%\n",
      "7\tValidation loss: 0.060817\tBest loss: 0.060817\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.100671\tBest loss: 0.060817\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.149736\tBest loss: 0.060817\tAccuracy: 96.95%\n",
      "10\tValidation loss: 11.682391\tBest loss: 0.060817\tAccuracy: 93.04%\n",
      "11\tValidation loss: 3.077834\tBest loss: 0.060817\tAccuracy: 94.57%\n",
      "12\tValidation loss: 1.927301\tBest loss: 0.060817\tAccuracy: 96.60%\n",
      "13\tValidation loss: 1.706506\tBest loss: 0.060817\tAccuracy: 96.25%\n",
      "14\tValidation loss: 1.053795\tBest loss: 0.060817\tAccuracy: 97.03%\n",
      "15\tValidation loss: 0.979255\tBest loss: 0.060817\tAccuracy: 96.56%\n",
      "16\tValidation loss: 0.724413\tBest loss: 0.060817\tAccuracy: 97.11%\n",
      "17\tValidation loss: 0.931146\tBest loss: 0.060817\tAccuracy: 96.56%\n",
      "18\tValidation loss: 1.056952\tBest loss: 0.060817\tAccuracy: 97.50%\n",
      "19\tValidation loss: 0.936452\tBest loss: 0.060817\tAccuracy: 97.77%\n",
      "20\tValidation loss: 2.130321\tBest loss: 0.060817\tAccuracy: 96.76%\n",
      "21\tValidation loss: 1.140606\tBest loss: 0.060817\tAccuracy: 97.22%\n",
      "22\tValidation loss: 0.744886\tBest loss: 0.060817\tAccuracy: 97.46%\n",
      "23\tValidation loss: 2.808657\tBest loss: 0.060817\tAccuracy: 92.57%\n",
      "24\tValidation loss: 0.866992\tBest loss: 0.060817\tAccuracy: 98.20%\n",
      "25\tValidation loss: 15.449409\tBest loss: 0.060817\tAccuracy: 96.44%\n",
      "26\tValidation loss: 4.180077\tBest loss: 0.060817\tAccuracy: 96.60%\n",
      "27\tValidation loss: 2.326020\tBest loss: 0.060817\tAccuracy: 97.38%\n",
      "28\tValidation loss: 2.792715\tBest loss: 0.060817\tAccuracy: 97.50%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  48.4s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 4.465487\tBest loss: 4.465487\tAccuracy: 64.31%\n",
      "1\tValidation loss: 0.131243\tBest loss: 0.131243\tAccuracy: 96.56%\n",
      "2\tValidation loss: 0.115502\tBest loss: 0.115502\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.242306\tBest loss: 0.115502\tAccuracy: 89.99%\n",
      "4\tValidation loss: 0.068341\tBest loss: 0.068341\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.115808\tBest loss: 0.068341\tAccuracy: 98.01%\n",
      "6\tValidation loss: 0.091976\tBest loss: 0.068341\tAccuracy: 98.16%\n",
      "7\tValidation loss: 5.620898\tBest loss: 0.068341\tAccuracy: 92.46%\n",
      "8\tValidation loss: 4.816486\tBest loss: 0.068341\tAccuracy: 94.53%\n",
      "9\tValidation loss: 1.290395\tBest loss: 0.068341\tAccuracy: 96.60%\n",
      "10\tValidation loss: 0.988818\tBest loss: 0.068341\tAccuracy: 97.15%\n",
      "11\tValidation loss: 0.957061\tBest loss: 0.068341\tAccuracy: 97.46%\n",
      "12\tValidation loss: 0.611840\tBest loss: 0.068341\tAccuracy: 97.50%\n",
      "13\tValidation loss: 0.514348\tBest loss: 0.068341\tAccuracy: 97.93%\n",
      "14\tValidation loss: 2.516892\tBest loss: 0.068341\tAccuracy: 96.76%\n",
      "15\tValidation loss: 1.419088\tBest loss: 0.068341\tAccuracy: 95.58%\n",
      "16\tValidation loss: 0.943293\tBest loss: 0.068341\tAccuracy: 97.50%\n",
      "17\tValidation loss: 0.413419\tBest loss: 0.068341\tAccuracy: 97.77%\n",
      "18\tValidation loss: 0.770427\tBest loss: 0.068341\tAccuracy: 97.54%\n",
      "19\tValidation loss: 0.379536\tBest loss: 0.068341\tAccuracy: 97.81%\n",
      "20\tValidation loss: 0.719980\tBest loss: 0.068341\tAccuracy: 97.93%\n",
      "21\tValidation loss: 0.490434\tBest loss: 0.068341\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.688748\tBest loss: 0.068341\tAccuracy: 98.28%\n",
      "23\tValidation loss: 14.778851\tBest loss: 0.068341\tAccuracy: 96.95%\n",
      "24\tValidation loss: 7.349813\tBest loss: 0.068341\tAccuracy: 97.26%\n",
      "25\tValidation loss: 7.991042\tBest loss: 0.068341\tAccuracy: 96.13%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  43.6s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.261667\tBest loss: 0.261667\tAccuracy: 96.17%\n",
      "1\tValidation loss: 0.365626\tBest loss: 0.261667\tAccuracy: 95.39%\n",
      "2\tValidation loss: 0.119331\tBest loss: 0.119331\tAccuracy: 96.33%\n",
      "3\tValidation loss: 0.105975\tBest loss: 0.105975\tAccuracy: 97.22%\n",
      "4\tValidation loss: 0.105952\tBest loss: 0.105952\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.142767\tBest loss: 0.105952\tAccuracy: 97.73%\n",
      "6\tValidation loss: 0.138737\tBest loss: 0.105952\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.104744\tBest loss: 0.104744\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.132493\tBest loss: 0.104744\tAccuracy: 97.65%\n",
      "9\tValidation loss: 0.086466\tBest loss: 0.086466\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.091315\tBest loss: 0.086466\tAccuracy: 97.97%\n",
      "11\tValidation loss: 138.022156\tBest loss: 0.086466\tAccuracy: 89.01%\n",
      "12\tValidation loss: 12.396344\tBest loss: 0.086466\tAccuracy: 95.39%\n",
      "13\tValidation loss: 1.565362\tBest loss: 0.086466\tAccuracy: 97.50%\n",
      "14\tValidation loss: 1.577765\tBest loss: 0.086466\tAccuracy: 97.19%\n",
      "15\tValidation loss: 2.580718\tBest loss: 0.086466\tAccuracy: 94.37%\n",
      "16\tValidation loss: 0.852908\tBest loss: 0.086466\tAccuracy: 97.85%\n",
      "17\tValidation loss: 0.650447\tBest loss: 0.086466\tAccuracy: 97.69%\n",
      "18\tValidation loss: 0.701522\tBest loss: 0.086466\tAccuracy: 97.81%\n",
      "19\tValidation loss: 1.259207\tBest loss: 0.086466\tAccuracy: 97.85%\n",
      "20\tValidation loss: 0.693268\tBest loss: 0.086466\tAccuracy: 97.50%\n",
      "21\tValidation loss: 2.041111\tBest loss: 0.086466\tAccuracy: 97.11%\n",
      "22\tValidation loss: 2.404849\tBest loss: 0.086466\tAccuracy: 96.40%\n",
      "23\tValidation loss: 5.776481\tBest loss: 0.086466\tAccuracy: 96.72%\n",
      "24\tValidation loss: 0.968566\tBest loss: 0.086466\tAccuracy: 97.62%\n",
      "25\tValidation loss: 0.633163\tBest loss: 0.086466\tAccuracy: 97.62%\n",
      "26\tValidation loss: 0.622029\tBest loss: 0.086466\tAccuracy: 97.93%\n",
      "27\tValidation loss: 289.944824\tBest loss: 0.086466\tAccuracy: 88.86%\n",
      "28\tValidation loss: 18.105047\tBest loss: 0.086466\tAccuracy: 97.34%\n",
      "29\tValidation loss: 8.697256\tBest loss: 0.086466\tAccuracy: 97.65%\n",
      "30\tValidation loss: 9.289116\tBest loss: 0.086466\tAccuracy: 97.73%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  51.6s\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.091157\tBest loss: 0.091157\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.106128\tBest loss: 0.091157\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.078496\tBest loss: 0.078496\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.068367\tBest loss: 0.068367\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.089872\tBest loss: 0.068367\tAccuracy: 97.89%\n",
      "5\tValidation loss: 8.597051\tBest loss: 0.068367\tAccuracy: 91.52%\n",
      "6\tValidation loss: 0.197936\tBest loss: 0.068367\tAccuracy: 96.52%\n",
      "7\tValidation loss: 0.126447\tBest loss: 0.068367\tAccuracy: 97.46%\n",
      "8\tValidation loss: 0.125577\tBest loss: 0.068367\tAccuracy: 97.77%\n",
      "9\tValidation loss: 0.111811\tBest loss: 0.068367\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.105744\tBest loss: 0.068367\tAccuracy: 97.97%\n",
      "11\tValidation loss: 0.133348\tBest loss: 0.068367\tAccuracy: 97.81%\n",
      "12\tValidation loss: 0.096224\tBest loss: 0.068367\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.108703\tBest loss: 0.068367\tAccuracy: 98.24%\n",
      "14\tValidation loss: 0.088535\tBest loss: 0.068367\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.146301\tBest loss: 0.068367\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.199781\tBest loss: 0.068367\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.106763\tBest loss: 0.068367\tAccuracy: 97.93%\n",
      "18\tValidation loss: 0.167916\tBest loss: 0.068367\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.275498\tBest loss: 0.068367\tAccuracy: 97.65%\n",
      "20\tValidation loss: 0.081630\tBest loss: 0.068367\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.064913\tBest loss: 0.064913\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.075854\tBest loss: 0.064913\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.106958\tBest loss: 0.064913\tAccuracy: 98.44%\n",
      "24\tValidation loss: 0.127025\tBest loss: 0.064913\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.577362\tBest loss: 0.064913\tAccuracy: 98.28%\n",
      "26\tValidation loss: 104.673889\tBest loss: 0.064913\tAccuracy: 78.93%\n",
      "27\tValidation loss: 1.271660\tBest loss: 0.064913\tAccuracy: 96.13%\n",
      "28\tValidation loss: 0.627451\tBest loss: 0.064913\tAccuracy: 96.13%\n",
      "29\tValidation loss: 0.372024\tBest loss: 0.064913\tAccuracy: 97.93%\n",
      "30\tValidation loss: 0.412105\tBest loss: 0.064913\tAccuracy: 97.93%\n",
      "31\tValidation loss: 0.366941\tBest loss: 0.064913\tAccuracy: 98.24%\n",
      "32\tValidation loss: 0.435766\tBest loss: 0.064913\tAccuracy: 98.08%\n",
      "33\tValidation loss: 0.485056\tBest loss: 0.064913\tAccuracy: 98.16%\n",
      "34\tValidation loss: 0.840143\tBest loss: 0.064913\tAccuracy: 96.95%\n",
      "35\tValidation loss: 0.560297\tBest loss: 0.064913\tAccuracy: 97.93%\n",
      "36\tValidation loss: 0.673853\tBest loss: 0.064913\tAccuracy: 98.05%\n",
      "37\tValidation loss: 0.441491\tBest loss: 0.064913\tAccuracy: 98.20%\n",
      "38\tValidation loss: 0.692263\tBest loss: 0.064913\tAccuracy: 98.08%\n",
      "39\tValidation loss: 0.957765\tBest loss: 0.064913\tAccuracy: 98.12%\n",
      "40\tValidation loss: 0.759438\tBest loss: 0.064913\tAccuracy: 98.05%\n",
      "41\tValidation loss: 0.621607\tBest loss: 0.064913\tAccuracy: 97.54%\n",
      "42\tValidation loss: 0.531900\tBest loss: 0.064913\tAccuracy: 98.32%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  44.3s\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.116617\tBest loss: 0.116617\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.097788\tBest loss: 0.097788\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.070389\tBest loss: 0.070389\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.382754\tBest loss: 0.070389\tAccuracy: 96.91%\n",
      "4\tValidation loss: 0.212201\tBest loss: 0.070389\tAccuracy: 96.44%\n",
      "5\tValidation loss: 0.146730\tBest loss: 0.070389\tAccuracy: 97.03%\n",
      "6\tValidation loss: 0.095813\tBest loss: 0.070389\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.091280\tBest loss: 0.070389\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.096786\tBest loss: 0.070389\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.084009\tBest loss: 0.070389\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.090863\tBest loss: 0.070389\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.101170\tBest loss: 0.070389\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.109535\tBest loss: 0.070389\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.101131\tBest loss: 0.070389\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.100016\tBest loss: 0.070389\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.104175\tBest loss: 0.070389\tAccuracy: 98.05%\n",
      "16\tValidation loss: 0.112210\tBest loss: 0.070389\tAccuracy: 98.12%\n",
      "17\tValidation loss: 0.104853\tBest loss: 0.070389\tAccuracy: 98.44%\n",
      "18\tValidation loss: 0.097223\tBest loss: 0.070389\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.217046\tBest loss: 0.070389\tAccuracy: 97.73%\n",
      "20\tValidation loss: 0.069734\tBest loss: 0.069734\tAccuracy: 98.87%\n",
      "21\tValidation loss: 45.519024\tBest loss: 0.069734\tAccuracy: 83.85%\n",
      "22\tValidation loss: 0.813879\tBest loss: 0.069734\tAccuracy: 96.09%\n",
      "23\tValidation loss: 0.547231\tBest loss: 0.069734\tAccuracy: 96.60%\n",
      "24\tValidation loss: 0.367509\tBest loss: 0.069734\tAccuracy: 96.91%\n",
      "25\tValidation loss: 0.375710\tBest loss: 0.069734\tAccuracy: 97.54%\n",
      "26\tValidation loss: 0.314572\tBest loss: 0.069734\tAccuracy: 97.58%\n",
      "27\tValidation loss: 0.277234\tBest loss: 0.069734\tAccuracy: 97.50%\n",
      "28\tValidation loss: 0.301366\tBest loss: 0.069734\tAccuracy: 97.38%\n",
      "29\tValidation loss: 0.212960\tBest loss: 0.069734\tAccuracy: 98.05%\n",
      "30\tValidation loss: 0.245578\tBest loss: 0.069734\tAccuracy: 97.58%\n",
      "31\tValidation loss: 0.250039\tBest loss: 0.069734\tAccuracy: 97.81%\n",
      "32\tValidation loss: 0.214612\tBest loss: 0.069734\tAccuracy: 97.89%\n",
      "33\tValidation loss: 0.249334\tBest loss: 0.069734\tAccuracy: 97.69%\n",
      "34\tValidation loss: 0.200174\tBest loss: 0.069734\tAccuracy: 97.62%\n",
      "35\tValidation loss: 0.196744\tBest loss: 0.069734\tAccuracy: 98.05%\n",
      "36\tValidation loss: 0.166948\tBest loss: 0.069734\tAccuracy: 98.12%\n",
      "37\tValidation loss: 0.200894\tBest loss: 0.069734\tAccuracy: 97.97%\n",
      "38\tValidation loss: 0.206452\tBest loss: 0.069734\tAccuracy: 97.89%\n",
      "39\tValidation loss: 0.321734\tBest loss: 0.069734\tAccuracy: 97.42%\n",
      "40\tValidation loss: 0.247501\tBest loss: 0.069734\tAccuracy: 98.16%\n",
      "41\tValidation loss: 0.593923\tBest loss: 0.069734\tAccuracy: 97.46%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  43.4s\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.098789\tBest loss: 0.098789\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.126124\tBest loss: 0.098789\tAccuracy: 96.72%\n",
      "2\tValidation loss: 0.085551\tBest loss: 0.085551\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.094654\tBest loss: 0.085551\tAccuracy: 97.73%\n",
      "4\tValidation loss: 1.561197\tBest loss: 0.085551\tAccuracy: 85.34%\n",
      "5\tValidation loss: 0.120090\tBest loss: 0.085551\tAccuracy: 97.26%\n",
      "6\tValidation loss: 0.095446\tBest loss: 0.085551\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.084230\tBest loss: 0.084230\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.084123\tBest loss: 0.084123\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.078470\tBest loss: 0.078470\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.077014\tBest loss: 0.077014\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.082343\tBest loss: 0.077014\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.083149\tBest loss: 0.077014\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.072646\tBest loss: 0.072646\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.118898\tBest loss: 0.072646\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.075427\tBest loss: 0.072646\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.116697\tBest loss: 0.072646\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.140461\tBest loss: 0.072646\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.138956\tBest loss: 0.072646\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.181114\tBest loss: 0.072646\tAccuracy: 98.55%\n",
      "20\tValidation loss: 0.104901\tBest loss: 0.072646\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.168128\tBest loss: 0.072646\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.209571\tBest loss: 0.072646\tAccuracy: 98.59%\n",
      "23\tValidation loss: 0.388101\tBest loss: 0.072646\tAccuracy: 97.62%\n",
      "24\tValidation loss: 2.166394\tBest loss: 0.072646\tAccuracy: 97.62%\n",
      "25\tValidation loss: 0.988758\tBest loss: 0.072646\tAccuracy: 97.69%\n",
      "26\tValidation loss: 0.925433\tBest loss: 0.072646\tAccuracy: 97.50%\n",
      "27\tValidation loss: 4.651396\tBest loss: 0.072646\tAccuracy: 97.73%\n",
      "28\tValidation loss: 2.120401\tBest loss: 0.072646\tAccuracy: 98.01%\n",
      "29\tValidation loss: 2.197124\tBest loss: 0.072646\tAccuracy: 98.20%\n",
      "30\tValidation loss: 2.333372\tBest loss: 0.072646\tAccuracy: 97.07%\n",
      "31\tValidation loss: 1.404378\tBest loss: 0.072646\tAccuracy: 98.28%\n",
      "32\tValidation loss: 1.633857\tBest loss: 0.072646\tAccuracy: 97.89%\n",
      "33\tValidation loss: 2.470412\tBest loss: 0.072646\tAccuracy: 97.42%\n",
      "34\tValidation loss: 1.290296\tBest loss: 0.072646\tAccuracy: 98.08%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  37.1s\n",
      "[CV] n_neurons=120, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.134216\tBest loss: 0.134216\tAccuracy: 96.25%\n",
      "1\tValidation loss: 0.347775\tBest loss: 0.134216\tAccuracy: 94.61%\n",
      "2\tValidation loss: 0.146653\tBest loss: 0.134216\tAccuracy: 95.74%\n",
      "3\tValidation loss: 741.667297\tBest loss: 0.134216\tAccuracy: 90.11%\n",
      "4\tValidation loss: 2.171752\tBest loss: 0.134216\tAccuracy: 93.67%\n",
      "5\tValidation loss: 1.318957\tBest loss: 0.134216\tAccuracy: 87.61%\n",
      "6\tValidation loss: 3.622188\tBest loss: 0.134216\tAccuracy: 93.59%\n",
      "7\tValidation loss: 12.580092\tBest loss: 0.134216\tAccuracy: 94.88%\n",
      "8\tValidation loss: 20.378441\tBest loss: 0.134216\tAccuracy: 94.84%\n",
      "9\tValidation loss: 8.183147\tBest loss: 0.134216\tAccuracy: 93.75%\n",
      "10\tValidation loss: 25.644531\tBest loss: 0.134216\tAccuracy: 94.84%\n",
      "11\tValidation loss: 63.337318\tBest loss: 0.134216\tAccuracy: 95.00%\n",
      "12\tValidation loss: 163.955811\tBest loss: 0.134216\tAccuracy: 95.97%\n",
      "13\tValidation loss: 17.377836\tBest loss: 0.134216\tAccuracy: 65.56%\n",
      "14\tValidation loss: 18.232279\tBest loss: 0.134216\tAccuracy: 74.00%\n",
      "15\tValidation loss: 0.625094\tBest loss: 0.134216\tAccuracy: 91.44%\n",
      "16\tValidation loss: 0.722329\tBest loss: 0.134216\tAccuracy: 93.47%\n",
      "17\tValidation loss: 0.400707\tBest loss: 0.134216\tAccuracy: 95.15%\n",
      "18\tValidation loss: 0.319667\tBest loss: 0.134216\tAccuracy: 96.01%\n",
      "19\tValidation loss: 0.474196\tBest loss: 0.134216\tAccuracy: 92.81%\n",
      "20\tValidation loss: 0.195008\tBest loss: 0.134216\tAccuracy: 95.90%\n",
      "21\tValidation loss: 0.240506\tBest loss: 0.134216\tAccuracy: 96.60%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  37.0s\n",
      "[CV] n_neurons=120, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 30.101730\tBest loss: 30.101730\tAccuracy: 61.69%\n",
      "1\tValidation loss: 0.262341\tBest loss: 0.262341\tAccuracy: 93.51%\n",
      "2\tValidation loss: 0.136372\tBest loss: 0.136372\tAccuracy: 96.29%\n",
      "3\tValidation loss: 0.119134\tBest loss: 0.119134\tAccuracy: 96.40%\n",
      "4\tValidation loss: 0.100003\tBest loss: 0.100003\tAccuracy: 97.26%\n",
      "5\tValidation loss: 0.106847\tBest loss: 0.100003\tAccuracy: 97.15%\n",
      "6\tValidation loss: 0.121162\tBest loss: 0.100003\tAccuracy: 96.76%\n",
      "7\tValidation loss: 0.155274\tBest loss: 0.100003\tAccuracy: 96.99%\n",
      "8\tValidation loss: 0.230405\tBest loss: 0.100003\tAccuracy: 94.76%\n",
      "9\tValidation loss: 107.054031\tBest loss: 0.100003\tAccuracy: 52.19%\n",
      "10\tValidation loss: 4.843631\tBest loss: 0.100003\tAccuracy: 86.55%\n",
      "11\tValidation loss: 1.441188\tBest loss: 0.100003\tAccuracy: 92.38%\n",
      "12\tValidation loss: 1.144372\tBest loss: 0.100003\tAccuracy: 95.19%\n",
      "13\tValidation loss: 6.623359\tBest loss: 0.100003\tAccuracy: 75.65%\n",
      "14\tValidation loss: 1.103149\tBest loss: 0.100003\tAccuracy: 94.33%\n",
      "15\tValidation loss: 0.898571\tBest loss: 0.100003\tAccuracy: 90.97%\n",
      "16\tValidation loss: 1.254411\tBest loss: 0.100003\tAccuracy: 94.02%\n",
      "17\tValidation loss: 0.528345\tBest loss: 0.100003\tAccuracy: 96.33%\n",
      "18\tValidation loss: 0.749332\tBest loss: 0.100003\tAccuracy: 94.80%\n",
      "19\tValidation loss: 16.719315\tBest loss: 0.100003\tAccuracy: 96.33%\n",
      "20\tValidation loss: 2.678282\tBest loss: 0.100003\tAccuracy: 89.87%\n",
      "21\tValidation loss: 0.694574\tBest loss: 0.100003\tAccuracy: 94.92%\n",
      "22\tValidation loss: 0.497457\tBest loss: 0.100003\tAccuracy: 95.90%\n",
      "23\tValidation loss: 0.597400\tBest loss: 0.100003\tAccuracy: 93.82%\n",
      "24\tValidation loss: 0.561802\tBest loss: 0.100003\tAccuracy: 95.35%\n",
      "25\tValidation loss: 3.202964\tBest loss: 0.100003\tAccuracy: 94.21%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  43.5s\n",
      "[CV] n_neurons=120, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.157702\tBest loss: 0.157702\tAccuracy: 97.34%\n",
      "1\tValidation loss: 0.221887\tBest loss: 0.157702\tAccuracy: 93.86%\n",
      "2\tValidation loss: 0.155644\tBest loss: 0.155644\tAccuracy: 97.07%\n",
      "3\tValidation loss: 0.273646\tBest loss: 0.155644\tAccuracy: 96.79%\n",
      "4\tValidation loss: 31.042618\tBest loss: 0.155644\tAccuracy: 89.80%\n",
      "5\tValidation loss: 3.973302\tBest loss: 0.155644\tAccuracy: 93.78%\n",
      "6\tValidation loss: 3.631186\tBest loss: 0.155644\tAccuracy: 95.27%\n",
      "7\tValidation loss: 3.262103\tBest loss: 0.155644\tAccuracy: 94.02%\n",
      "8\tValidation loss: 1.764944\tBest loss: 0.155644\tAccuracy: 94.06%\n",
      "9\tValidation loss: 2.203955\tBest loss: 0.155644\tAccuracy: 95.54%\n",
      "10\tValidation loss: 1.608128\tBest loss: 0.155644\tAccuracy: 94.02%\n",
      "11\tValidation loss: 2.711451\tBest loss: 0.155644\tAccuracy: 93.71%\n",
      "12\tValidation loss: 1.784793\tBest loss: 0.155644\tAccuracy: 92.96%\n",
      "13\tValidation loss: 0.857834\tBest loss: 0.155644\tAccuracy: 95.35%\n",
      "14\tValidation loss: 8.322471\tBest loss: 0.155644\tAccuracy: 93.86%\n",
      "15\tValidation loss: 3.230947\tBest loss: 0.155644\tAccuracy: 96.36%\n",
      "16\tValidation loss: 6.600493\tBest loss: 0.155644\tAccuracy: 89.64%\n",
      "17\tValidation loss: 1.831391\tBest loss: 0.155644\tAccuracy: 95.54%\n",
      "18\tValidation loss: 1.890464\tBest loss: 0.155644\tAccuracy: 95.47%\n",
      "19\tValidation loss: 4.344527\tBest loss: 0.155644\tAccuracy: 96.60%\n",
      "20\tValidation loss: 1.479504\tBest loss: 0.155644\tAccuracy: 96.21%\n",
      "21\tValidation loss: 1.296151\tBest loss: 0.155644\tAccuracy: 95.66%\n",
      "22\tValidation loss: 3.480944\tBest loss: 0.155644\tAccuracy: 89.01%\n",
      "23\tValidation loss: 0.786069\tBest loss: 0.155644\tAccuracy: 96.76%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  39.7s\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=50, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.459693\tBest loss: 0.459693\tAccuracy: 88.23%\n",
      "1\tValidation loss: 0.545413\tBest loss: 0.459693\tAccuracy: 80.18%\n",
      "2\tValidation loss: 0.393347\tBest loss: 0.393347\tAccuracy: 87.69%\n",
      "3\tValidation loss: 0.656838\tBest loss: 0.393347\tAccuracy: 76.04%\n",
      "4\tValidation loss: 0.442058\tBest loss: 0.393347\tAccuracy: 84.40%\n",
      "5\tValidation loss: 0.433347\tBest loss: 0.393347\tAccuracy: 89.68%\n",
      "6\tValidation loss: 0.361114\tBest loss: 0.361114\tAccuracy: 91.36%\n",
      "7\tValidation loss: 0.491873\tBest loss: 0.361114\tAccuracy: 89.09%\n",
      "8\tValidation loss: 0.372395\tBest loss: 0.361114\tAccuracy: 90.38%\n",
      "9\tValidation loss: 0.419601\tBest loss: 0.361114\tAccuracy: 87.65%\n",
      "10\tValidation loss: 0.458956\tBest loss: 0.361114\tAccuracy: 90.58%\n",
      "11\tValidation loss: 0.404960\tBest loss: 0.361114\tAccuracy: 88.94%\n",
      "12\tValidation loss: 0.482642\tBest loss: 0.361114\tAccuracy: 86.00%\n",
      "13\tValidation loss: 0.404926\tBest loss: 0.361114\tAccuracy: 90.34%\n",
      "14\tValidation loss: 0.501162\tBest loss: 0.361114\tAccuracy: 89.99%\n",
      "15\tValidation loss: 0.366049\tBest loss: 0.361114\tAccuracy: 92.10%\n",
      "16\tValidation loss: 0.467261\tBest loss: 0.361114\tAccuracy: 91.67%\n",
      "17\tValidation loss: 0.484856\tBest loss: 0.361114\tAccuracy: 88.12%\n",
      "18\tValidation loss: 0.413869\tBest loss: 0.361114\tAccuracy: 91.36%\n",
      "19\tValidation loss: 0.490588\tBest loss: 0.361114\tAccuracy: 88.19%\n",
      "20\tValidation loss: 1.673590\tBest loss: 0.361114\tAccuracy: 18.73%\n",
      "21\tValidation loss: 1.627013\tBest loss: 0.361114\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.671432\tBest loss: 0.361114\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.637906\tBest loss: 0.361114\tAccuracy: 19.27%\n",
      "24\tValidation loss: 1.617717\tBest loss: 0.361114\tAccuracy: 19.08%\n",
      "25\tValidation loss: 1.631815\tBest loss: 0.361114\tAccuracy: 19.08%\n",
      "26\tValidation loss: 1.619158\tBest loss: 0.361114\tAccuracy: 22.01%\n",
      "27\tValidation loss: 1.620914\tBest loss: 0.361114\tAccuracy: 18.73%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=50, activation=<function relu at 0x7fabf3f8d0d0>, total=  19.1s\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=50, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.623208\tBest loss: 1.623208\tAccuracy: 18.73%\n",
      "1\tValidation loss: 1.614153\tBest loss: 1.614153\tAccuracy: 22.01%\n",
      "2\tValidation loss: 1.619950\tBest loss: 1.614153\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.618476\tBest loss: 1.614153\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.624645\tBest loss: 1.614153\tAccuracy: 19.27%\n",
      "5\tValidation loss: 1.611681\tBest loss: 1.611681\tAccuracy: 19.08%\n",
      "6\tValidation loss: 1.614071\tBest loss: 1.611681\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.619169\tBest loss: 1.611681\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.616542\tBest loss: 1.611681\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.611340\tBest loss: 1.611340\tAccuracy: 22.01%\n",
      "10\tValidation loss: 1.614291\tBest loss: 1.611340\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.612337\tBest loss: 1.611340\tAccuracy: 19.27%\n",
      "12\tValidation loss: 1.612157\tBest loss: 1.611340\tAccuracy: 18.73%\n",
      "13\tValidation loss: 1.614677\tBest loss: 1.611340\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.609513\tBest loss: 1.609513\tAccuracy: 20.91%\n",
      "15\tValidation loss: 1.611920\tBest loss: 1.609513\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.617774\tBest loss: 1.609513\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.613517\tBest loss: 1.609513\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.621384\tBest loss: 1.609513\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.616646\tBest loss: 1.609513\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.621742\tBest loss: 1.609513\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.617912\tBest loss: 1.609513\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.614912\tBest loss: 1.609513\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.610154\tBest loss: 1.609513\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.609388\tBest loss: 1.609388\tAccuracy: 19.27%\n",
      "25\tValidation loss: 1.619918\tBest loss: 1.609388\tAccuracy: 18.73%\n",
      "26\tValidation loss: 1.611506\tBest loss: 1.609388\tAccuracy: 18.73%\n",
      "27\tValidation loss: 1.608956\tBest loss: 1.608956\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.615347\tBest loss: 1.608956\tAccuracy: 22.01%\n",
      "29\tValidation loss: 1.634744\tBest loss: 1.608956\tAccuracy: 19.27%\n",
      "30\tValidation loss: 1.611764\tBest loss: 1.608956\tAccuracy: 19.27%\n",
      "31\tValidation loss: 1.612068\tBest loss: 1.608956\tAccuracy: 22.01%\n",
      "32\tValidation loss: 1.610579\tBest loss: 1.608956\tAccuracy: 20.91%\n",
      "33\tValidation loss: 1.609687\tBest loss: 1.608956\tAccuracy: 20.91%\n",
      "34\tValidation loss: 1.612856\tBest loss: 1.608956\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.616472\tBest loss: 1.608956\tAccuracy: 18.73%\n",
      "36\tValidation loss: 1.611885\tBest loss: 1.608956\tAccuracy: 20.91%\n",
      "37\tValidation loss: 1.611673\tBest loss: 1.608956\tAccuracy: 19.27%\n",
      "38\tValidation loss: 1.624596\tBest loss: 1.608956\tAccuracy: 18.73%\n",
      "39\tValidation loss: 1.615364\tBest loss: 1.608956\tAccuracy: 20.91%\n",
      "40\tValidation loss: 1.615840\tBest loss: 1.608956\tAccuracy: 18.73%\n",
      "41\tValidation loss: 1.622003\tBest loss: 1.608956\tAccuracy: 19.27%\n",
      "42\tValidation loss: 1.611831\tBest loss: 1.608956\tAccuracy: 18.73%\n",
      "43\tValidation loss: 1.611038\tBest loss: 1.608956\tAccuracy: 22.01%\n",
      "44\tValidation loss: 1.616547\tBest loss: 1.608956\tAccuracy: 19.27%\n",
      "45\tValidation loss: 1.625214\tBest loss: 1.608956\tAccuracy: 22.01%\n",
      "46\tValidation loss: 1.608584\tBest loss: 1.608584\tAccuracy: 20.91%\n",
      "47\tValidation loss: 1.618341\tBest loss: 1.608584\tAccuracy: 19.08%\n",
      "48\tValidation loss: 1.620455\tBest loss: 1.608584\tAccuracy: 18.73%\n",
      "49\tValidation loss: 1.610196\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "50\tValidation loss: 1.619402\tBest loss: 1.608584\tAccuracy: 18.73%\n",
      "51\tValidation loss: 1.613973\tBest loss: 1.608584\tAccuracy: 19.08%\n",
      "52\tValidation loss: 1.613271\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "53\tValidation loss: 1.617819\tBest loss: 1.608584\tAccuracy: 19.27%\n",
      "54\tValidation loss: 1.624898\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "55\tValidation loss: 1.616033\tBest loss: 1.608584\tAccuracy: 19.27%\n",
      "56\tValidation loss: 1.610243\tBest loss: 1.608584\tAccuracy: 20.91%\n",
      "57\tValidation loss: 1.609276\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "58\tValidation loss: 1.612623\tBest loss: 1.608584\tAccuracy: 19.08%\n",
      "59\tValidation loss: 1.615735\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "60\tValidation loss: 1.615275\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "61\tValidation loss: 1.616961\tBest loss: 1.608584\tAccuracy: 19.08%\n",
      "62\tValidation loss: 1.629731\tBest loss: 1.608584\tAccuracy: 19.08%\n",
      "63\tValidation loss: 1.620248\tBest loss: 1.608584\tAccuracy: 19.27%\n",
      "64\tValidation loss: 1.613057\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "65\tValidation loss: 1.614872\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "66\tValidation loss: 1.615389\tBest loss: 1.608584\tAccuracy: 22.01%\n",
      "67\tValidation loss: 1.612209\tBest loss: 1.608584\tAccuracy: 18.73%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=50, activation=<function relu at 0x7fabf3f8d0d0>, total=  46.5s\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=50, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.617238\tBest loss: 1.617238\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.615992\tBest loss: 1.615992\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.620881\tBest loss: 1.615992\tAccuracy: 18.73%\n",
      "3\tValidation loss: 1.612879\tBest loss: 1.612879\tAccuracy: 19.08%\n",
      "4\tValidation loss: 1.617509\tBest loss: 1.612879\tAccuracy: 19.27%\n",
      "5\tValidation loss: 1.613965\tBest loss: 1.612879\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.620927\tBest loss: 1.612879\tAccuracy: 18.73%\n",
      "7\tValidation loss: 1.609950\tBest loss: 1.609950\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.622812\tBest loss: 1.609950\tAccuracy: 18.73%\n",
      "9\tValidation loss: 1.616541\tBest loss: 1.609950\tAccuracy: 18.73%\n",
      "10\tValidation loss: 1.612618\tBest loss: 1.609950\tAccuracy: 19.27%\n",
      "11\tValidation loss: 1.617171\tBest loss: 1.609950\tAccuracy: 19.27%\n",
      "12\tValidation loss: 1.608377\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "13\tValidation loss: 1.615217\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.611617\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.614430\tBest loss: 1.608377\tAccuracy: 20.91%\n",
      "16\tValidation loss: 1.610052\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.614070\tBest loss: 1.608377\tAccuracy: 18.73%\n",
      "18\tValidation loss: 1.612618\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.620225\tBest loss: 1.608377\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.627005\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.614668\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.610135\tBest loss: 1.608377\tAccuracy: 20.91%\n",
      "23\tValidation loss: 1.609188\tBest loss: 1.608377\tAccuracy: 20.91%\n",
      "24\tValidation loss: 1.614686\tBest loss: 1.608377\tAccuracy: 20.91%\n",
      "25\tValidation loss: 1.610745\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.613990\tBest loss: 1.608377\tAccuracy: 18.73%\n",
      "27\tValidation loss: 1.614191\tBest loss: 1.608377\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.616814\tBest loss: 1.608377\tAccuracy: 19.27%\n",
      "29\tValidation loss: 1.619090\tBest loss: 1.608377\tAccuracy: 19.08%\n",
      "30\tValidation loss: 1.609816\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "31\tValidation loss: 1.621396\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "32\tValidation loss: 1.610468\tBest loss: 1.608377\tAccuracy: 20.91%\n",
      "33\tValidation loss: 1.608480\tBest loss: 1.608377\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=50, activation=<function relu at 0x7fabf3f8d0d0>, total=  23.6s\n",
      "[CV] n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.126205\tBest loss: 0.126205\tAccuracy: 96.17%\n",
      "1\tValidation loss: 0.091681\tBest loss: 0.091681\tAccuracy: 96.87%\n",
      "2\tValidation loss: 0.070782\tBest loss: 0.070782\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.066458\tBest loss: 0.066458\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.067296\tBest loss: 0.066458\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.066386\tBest loss: 0.066386\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.056864\tBest loss: 0.056864\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.050751\tBest loss: 0.050751\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.052060\tBest loss: 0.050751\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.068949\tBest loss: 0.050751\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.050962\tBest loss: 0.050751\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.060787\tBest loss: 0.050751\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.059236\tBest loss: 0.050751\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.078135\tBest loss: 0.050751\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.057346\tBest loss: 0.050751\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.093241\tBest loss: 0.050751\tAccuracy: 98.01%\n",
      "16\tValidation loss: 0.091454\tBest loss: 0.050751\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.059941\tBest loss: 0.050751\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.075359\tBest loss: 0.050751\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.070229\tBest loss: 0.050751\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.080219\tBest loss: 0.050751\tAccuracy: 98.87%\n",
      "21\tValidation loss: 0.072307\tBest loss: 0.050751\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.075091\tBest loss: 0.050751\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.090637\tBest loss: 0.050751\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.080208\tBest loss: 0.050751\tAccuracy: 98.51%\n",
      "25\tValidation loss: 0.066243\tBest loss: 0.050751\tAccuracy: 98.20%\n",
      "26\tValidation loss: 0.068142\tBest loss: 0.050751\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.074096\tBest loss: 0.050751\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.070409\tBest loss: 0.050751\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  24.4s\n",
      "[CV] n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.139234\tBest loss: 0.139234\tAccuracy: 96.29%\n",
      "1\tValidation loss: 0.087561\tBest loss: 0.087561\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.082107\tBest loss: 0.082107\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.076230\tBest loss: 0.076230\tAccuracy: 97.85%\n",
      "4\tValidation loss: 0.088248\tBest loss: 0.076230\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.056412\tBest loss: 0.056412\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.057953\tBest loss: 0.056412\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.050621\tBest loss: 0.050621\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.086241\tBest loss: 0.050621\tAccuracy: 97.50%\n",
      "9\tValidation loss: 0.061727\tBest loss: 0.050621\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.059888\tBest loss: 0.050621\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.051647\tBest loss: 0.050621\tAccuracy: 98.87%\n",
      "12\tValidation loss: 0.078006\tBest loss: 0.050621\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.071216\tBest loss: 0.050621\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.074821\tBest loss: 0.050621\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.066308\tBest loss: 0.050621\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.080265\tBest loss: 0.050621\tAccuracy: 98.32%\n",
      "17\tValidation loss: 0.086860\tBest loss: 0.050621\tAccuracy: 98.48%\n",
      "18\tValidation loss: 25425.449219\tBest loss: 0.050621\tAccuracy: 18.65%\n",
      "19\tValidation loss: 526.930664\tBest loss: 0.050621\tAccuracy: 63.72%\n",
      "20\tValidation loss: 177.254379\tBest loss: 0.050621\tAccuracy: 83.27%\n",
      "21\tValidation loss: 44.779739\tBest loss: 0.050621\tAccuracy: 90.93%\n",
      "22\tValidation loss: 35.320065\tBest loss: 0.050621\tAccuracy: 90.27%\n",
      "23\tValidation loss: 24.959980\tBest loss: 0.050621\tAccuracy: 91.63%\n",
      "24\tValidation loss: 43.924797\tBest loss: 0.050621\tAccuracy: 88.35%\n",
      "25\tValidation loss: 22.060131\tBest loss: 0.050621\tAccuracy: 93.35%\n",
      "26\tValidation loss: 15.668738\tBest loss: 0.050621\tAccuracy: 93.32%\n",
      "27\tValidation loss: 18.876961\tBest loss: 0.050621\tAccuracy: 92.22%\n",
      "28\tValidation loss: 18.038647\tBest loss: 0.050621\tAccuracy: 93.16%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  24.6s\n",
      "[CV] n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 0.184368\tBest loss: 0.184368\tAccuracy: 94.06%\n",
      "1\tValidation loss: 0.104057\tBest loss: 0.104057\tAccuracy: 96.68%\n",
      "2\tValidation loss: 0.090203\tBest loss: 0.090203\tAccuracy: 97.15%\n",
      "3\tValidation loss: 0.077827\tBest loss: 0.077827\tAccuracy: 97.65%\n",
      "4\tValidation loss: 0.066369\tBest loss: 0.066369\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.062666\tBest loss: 0.062666\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.062681\tBest loss: 0.062666\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.056204\tBest loss: 0.056204\tAccuracy: 98.32%\n",
      "8\tValidation loss: 0.072592\tBest loss: 0.056204\tAccuracy: 98.32%\n",
      "9\tValidation loss: 0.073336\tBest loss: 0.056204\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.083906\tBest loss: 0.056204\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.075477\tBest loss: 0.056204\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.052874\tBest loss: 0.052874\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.053650\tBest loss: 0.052874\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.071734\tBest loss: 0.052874\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.066120\tBest loss: 0.052874\tAccuracy: 98.48%\n",
      "16\tValidation loss: 0.061721\tBest loss: 0.052874\tAccuracy: 98.71%\n",
      "17\tValidation loss: 0.063897\tBest loss: 0.052874\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.086296\tBest loss: 0.052874\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.057226\tBest loss: 0.052874\tAccuracy: 98.83%\n",
      "20\tValidation loss: 0.074814\tBest loss: 0.052874\tAccuracy: 98.67%\n",
      "21\tValidation loss: 0.101697\tBest loss: 0.052874\tAccuracy: 97.89%\n",
      "22\tValidation loss: 0.092812\tBest loss: 0.052874\tAccuracy: 98.16%\n",
      "23\tValidation loss: 0.062481\tBest loss: 0.052874\tAccuracy: 98.51%\n",
      "24\tValidation loss: 0.081224\tBest loss: 0.052874\tAccuracy: 98.63%\n",
      "25\tValidation loss: 0.087916\tBest loss: 0.052874\tAccuracy: 98.32%\n",
      "26\tValidation loss: 0.107320\tBest loss: 0.052874\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.069607\tBest loss: 0.052874\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.093255\tBest loss: 0.052874\tAccuracy: 98.51%\n",
      "29\tValidation loss: 0.122819\tBest loss: 0.052874\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.070909\tBest loss: 0.052874\tAccuracy: 98.59%\n",
      "31\tValidation loss: 0.068646\tBest loss: 0.052874\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.115664\tBest loss: 0.052874\tAccuracy: 98.48%\n",
      "33\tValidation loss: 0.084043\tBest loss: 0.052874\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  28.4s\n",
      "[CV] n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.108403\tBest loss: 0.108403\tAccuracy: 96.36%\n",
      "1\tValidation loss: 0.086366\tBest loss: 0.086366\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.076900\tBest loss: 0.076900\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.062330\tBest loss: 0.062330\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.082421\tBest loss: 0.062330\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.076450\tBest loss: 0.062330\tAccuracy: 97.89%\n",
      "6\tValidation loss: 0.072050\tBest loss: 0.062330\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.052813\tBest loss: 0.052813\tAccuracy: 98.32%\n",
      "8\tValidation loss: 0.053998\tBest loss: 0.052813\tAccuracy: 98.32%\n",
      "9\tValidation loss: 0.065216\tBest loss: 0.052813\tAccuracy: 98.16%\n",
      "10\tValidation loss: 0.075427\tBest loss: 0.052813\tAccuracy: 98.48%\n",
      "11\tValidation loss: 0.088130\tBest loss: 0.052813\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.098185\tBest loss: 0.052813\tAccuracy: 97.69%\n",
      "13\tValidation loss: 0.066700\tBest loss: 0.052813\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.092166\tBest loss: 0.052813\tAccuracy: 97.81%\n",
      "15\tValidation loss: 0.118054\tBest loss: 0.052813\tAccuracy: 97.97%\n",
      "16\tValidation loss: 0.109334\tBest loss: 0.052813\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.149479\tBest loss: 0.052813\tAccuracy: 98.08%\n",
      "18\tValidation loss: 0.089530\tBest loss: 0.052813\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.151854\tBest loss: 0.052813\tAccuracy: 97.93%\n",
      "20\tValidation loss: 0.569448\tBest loss: 0.052813\tAccuracy: 91.91%\n",
      "21\tValidation loss: 194.470428\tBest loss: 0.052813\tAccuracy: 54.89%\n",
      "22\tValidation loss: 2250.733887\tBest loss: 0.052813\tAccuracy: 69.35%\n",
      "23\tValidation loss: 3.374303\tBest loss: 0.052813\tAccuracy: 93.12%\n",
      "24\tValidation loss: 3.404442\tBest loss: 0.052813\tAccuracy: 95.74%\n",
      "25\tValidation loss: 3.483240\tBest loss: 0.052813\tAccuracy: 88.12%\n",
      "26\tValidation loss: 1.373518\tBest loss: 0.052813\tAccuracy: 95.78%\n",
      "27\tValidation loss: 0.724716\tBest loss: 0.052813\tAccuracy: 95.97%\n",
      "28\tValidation loss: 0.648946\tBest loss: 0.052813\tAccuracy: 96.09%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  24.3s\n",
      "[CV] n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.105680\tBest loss: 0.105680\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.098326\tBest loss: 0.098326\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.074249\tBest loss: 0.074249\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.081250\tBest loss: 0.074249\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.065311\tBest loss: 0.065311\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.068933\tBest loss: 0.065311\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.061958\tBest loss: 0.061958\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.131519\tBest loss: 0.061958\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.082848\tBest loss: 0.061958\tAccuracy: 98.40%\n",
      "9\tValidation loss: 0.062399\tBest loss: 0.061958\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.327805\tBest loss: 0.061958\tAccuracy: 84.48%\n",
      "11\tValidation loss: 2.015241\tBest loss: 0.061958\tAccuracy: 68.45%\n",
      "12\tValidation loss: 0.535959\tBest loss: 0.061958\tAccuracy: 88.98%\n",
      "13\tValidation loss: 0.160127\tBest loss: 0.061958\tAccuracy: 95.78%\n",
      "14\tValidation loss: 0.107592\tBest loss: 0.061958\tAccuracy: 97.07%\n",
      "15\tValidation loss: 0.101724\tBest loss: 0.061958\tAccuracy: 97.46%\n",
      "16\tValidation loss: 0.103336\tBest loss: 0.061958\tAccuracy: 97.46%\n",
      "17\tValidation loss: 0.100275\tBest loss: 0.061958\tAccuracy: 97.65%\n",
      "18\tValidation loss: 0.090099\tBest loss: 0.061958\tAccuracy: 97.93%\n",
      "19\tValidation loss: 0.091591\tBest loss: 0.061958\tAccuracy: 97.89%\n",
      "20\tValidation loss: 0.103006\tBest loss: 0.061958\tAccuracy: 98.05%\n",
      "21\tValidation loss: 0.091122\tBest loss: 0.061958\tAccuracy: 98.12%\n",
      "22\tValidation loss: 0.098237\tBest loss: 0.061958\tAccuracy: 97.77%\n",
      "23\tValidation loss: 0.091414\tBest loss: 0.061958\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.092153\tBest loss: 0.061958\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.091840\tBest loss: 0.061958\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.128990\tBest loss: 0.061958\tAccuracy: 97.73%\n",
      "27\tValidation loss: 0.087029\tBest loss: 0.061958\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  24.3s\n",
      "[CV] n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.125503\tBest loss: 0.125503\tAccuracy: 96.48%\n",
      "1\tValidation loss: 0.094856\tBest loss: 0.094856\tAccuracy: 97.15%\n",
      "2\tValidation loss: 0.075498\tBest loss: 0.075498\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.064130\tBest loss: 0.064130\tAccuracy: 98.16%\n",
      "4\tValidation loss: 0.096975\tBest loss: 0.064130\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.075385\tBest loss: 0.064130\tAccuracy: 97.65%\n",
      "6\tValidation loss: 0.076262\tBest loss: 0.064130\tAccuracy: 97.97%\n",
      "7\tValidation loss: 0.086948\tBest loss: 0.064130\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.081642\tBest loss: 0.064130\tAccuracy: 98.05%\n",
      "9\tValidation loss: 0.074731\tBest loss: 0.064130\tAccuracy: 98.20%\n",
      "10\tValidation loss: 0.076778\tBest loss: 0.064130\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.069395\tBest loss: 0.064130\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.075723\tBest loss: 0.064130\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.059826\tBest loss: 0.059826\tAccuracy: 98.40%\n",
      "14\tValidation loss: 0.088678\tBest loss: 0.059826\tAccuracy: 97.97%\n",
      "15\tValidation loss: 0.088924\tBest loss: 0.059826\tAccuracy: 98.28%\n",
      "16\tValidation loss: 0.065854\tBest loss: 0.059826\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.311894\tBest loss: 0.059826\tAccuracy: 94.49%\n",
      "18\tValidation loss: 7.964506\tBest loss: 0.059826\tAccuracy: 63.17%\n",
      "19\tValidation loss: 4.631244\tBest loss: 0.059826\tAccuracy: 88.43%\n",
      "20\tValidation loss: 6.303285\tBest loss: 0.059826\tAccuracy: 85.85%\n",
      "21\tValidation loss: 2.126986\tBest loss: 0.059826\tAccuracy: 91.28%\n",
      "22\tValidation loss: 0.602656\tBest loss: 0.059826\tAccuracy: 94.02%\n",
      "23\tValidation loss: 0.450756\tBest loss: 0.059826\tAccuracy: 94.53%\n",
      "24\tValidation loss: 0.549729\tBest loss: 0.059826\tAccuracy: 94.68%\n",
      "25\tValidation loss: 0.346439\tBest loss: 0.059826\tAccuracy: 94.61%\n",
      "26\tValidation loss: 0.279400\tBest loss: 0.059826\tAccuracy: 94.84%\n",
      "27\tValidation loss: 0.208249\tBest loss: 0.059826\tAccuracy: 96.44%\n",
      "28\tValidation loss: 0.244430\tBest loss: 0.059826\tAccuracy: 96.09%\n",
      "29\tValidation loss: 0.198774\tBest loss: 0.059826\tAccuracy: 95.93%\n",
      "30\tValidation loss: 0.201134\tBest loss: 0.059826\tAccuracy: 95.74%\n",
      "31\tValidation loss: 0.195181\tBest loss: 0.059826\tAccuracy: 95.74%\n",
      "32\tValidation loss: 0.151131\tBest loss: 0.059826\tAccuracy: 96.99%\n",
      "33\tValidation loss: 0.182134\tBest loss: 0.059826\tAccuracy: 96.17%\n",
      "34\tValidation loss: 0.172979\tBest loss: 0.059826\tAccuracy: 96.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  29.3s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.081345\tBest loss: 0.081345\tAccuracy: 97.77%\n",
      "1\tValidation loss: 0.064474\tBest loss: 0.064474\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.062443\tBest loss: 0.062443\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.062517\tBest loss: 0.062443\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.087268\tBest loss: 0.062443\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.073424\tBest loss: 0.062443\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.065747\tBest loss: 0.062443\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.066029\tBest loss: 0.062443\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.056359\tBest loss: 0.056359\tAccuracy: 98.75%\n",
      "9\tValidation loss: 0.071779\tBest loss: 0.056359\tAccuracy: 98.12%\n",
      "10\tValidation loss: 0.142267\tBest loss: 0.056359\tAccuracy: 97.50%\n",
      "11\tValidation loss: 0.082772\tBest loss: 0.056359\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.078447\tBest loss: 0.056359\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.069253\tBest loss: 0.056359\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.672387\tBest loss: 0.056359\tAccuracy: 97.69%\n",
      "15\tValidation loss: 0.403143\tBest loss: 0.056359\tAccuracy: 79.01%\n",
      "16\tValidation loss: 0.082668\tBest loss: 0.056359\tAccuracy: 97.81%\n",
      "17\tValidation loss: 0.078408\tBest loss: 0.056359\tAccuracy: 97.93%\n",
      "18\tValidation loss: 0.092242\tBest loss: 0.056359\tAccuracy: 97.77%\n",
      "19\tValidation loss: 0.085666\tBest loss: 0.056359\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.058862\tBest loss: 0.056359\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.054916\tBest loss: 0.054916\tAccuracy: 98.55%\n",
      "22\tValidation loss: 0.074204\tBest loss: 0.054916\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.063056\tBest loss: 0.054916\tAccuracy: 98.36%\n",
      "24\tValidation loss: 0.062962\tBest loss: 0.054916\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.094512\tBest loss: 0.054916\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.105927\tBest loss: 0.054916\tAccuracy: 97.93%\n",
      "27\tValidation loss: 0.063197\tBest loss: 0.054916\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.102685\tBest loss: 0.054916\tAccuracy: 98.51%\n",
      "29\tValidation loss: 0.153728\tBest loss: 0.054916\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.236391\tBest loss: 0.054916\tAccuracy: 96.21%\n",
      "31\tValidation loss: 0.102558\tBest loss: 0.054916\tAccuracy: 97.89%\n",
      "32\tValidation loss: 0.055335\tBest loss: 0.054916\tAccuracy: 98.79%\n",
      "33\tValidation loss: 0.057180\tBest loss: 0.054916\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.062226\tBest loss: 0.054916\tAccuracy: 98.51%\n",
      "35\tValidation loss: 0.071719\tBest loss: 0.054916\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.114023\tBest loss: 0.054916\tAccuracy: 98.91%\n",
      "37\tValidation loss: 0.071942\tBest loss: 0.054916\tAccuracy: 98.98%\n",
      "38\tValidation loss: 0.074848\tBest loss: 0.054916\tAccuracy: 99.06%\n",
      "39\tValidation loss: 0.217970\tBest loss: 0.054916\tAccuracy: 96.36%\n",
      "40\tValidation loss: 0.298836\tBest loss: 0.054916\tAccuracy: 98.20%\n",
      "41\tValidation loss: 0.090221\tBest loss: 0.054916\tAccuracy: 98.51%\n",
      "42\tValidation loss: 0.070215\tBest loss: 0.054916\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  36.9s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.094804\tBest loss: 0.094804\tAccuracy: 96.99%\n",
      "1\tValidation loss: 0.071936\tBest loss: 0.071936\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.051613\tBest loss: 0.051613\tAccuracy: 98.44%\n",
      "3\tValidation loss: 0.086276\tBest loss: 0.051613\tAccuracy: 98.12%\n",
      "4\tValidation loss: 0.059730\tBest loss: 0.051613\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.056558\tBest loss: 0.051613\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.080384\tBest loss: 0.051613\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.061468\tBest loss: 0.051613\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.447285\tBest loss: 0.051613\tAccuracy: 92.34%\n",
      "9\tValidation loss: 0.065108\tBest loss: 0.051613\tAccuracy: 98.24%\n",
      "10\tValidation loss: 0.060712\tBest loss: 0.051613\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.048634\tBest loss: 0.048634\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.067768\tBest loss: 0.048634\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.078457\tBest loss: 0.048634\tAccuracy: 98.16%\n",
      "14\tValidation loss: 0.090262\tBest loss: 0.048634\tAccuracy: 98.36%\n",
      "15\tValidation loss: 0.049333\tBest loss: 0.048634\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.054130\tBest loss: 0.048634\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.071754\tBest loss: 0.048634\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.157052\tBest loss: 0.048634\tAccuracy: 97.73%\n",
      "19\tValidation loss: 0.106576\tBest loss: 0.048634\tAccuracy: 96.76%\n",
      "20\tValidation loss: 0.051344\tBest loss: 0.048634\tAccuracy: 98.63%\n",
      "21\tValidation loss: 0.059270\tBest loss: 0.048634\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.093478\tBest loss: 0.048634\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.056242\tBest loss: 0.048634\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.356309\tBest loss: 0.048634\tAccuracy: 96.52%\n",
      "25\tValidation loss: 0.442798\tBest loss: 0.048634\tAccuracy: 98.12%\n",
      "26\tValidation loss: 0.086899\tBest loss: 0.048634\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.100477\tBest loss: 0.048634\tAccuracy: 98.28%\n",
      "28\tValidation loss: 0.080719\tBest loss: 0.048634\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.085765\tBest loss: 0.048634\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.093902\tBest loss: 0.048634\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.112064\tBest loss: 0.048634\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.114972\tBest loss: 0.048634\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  28.4s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.079187\tBest loss: 0.079187\tAccuracy: 98.08%\n",
      "1\tValidation loss: 0.106598\tBest loss: 0.079187\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.071120\tBest loss: 0.071120\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.061931\tBest loss: 0.061931\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.083724\tBest loss: 0.061931\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.062614\tBest loss: 0.061931\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.054386\tBest loss: 0.054386\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.079323\tBest loss: 0.054386\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.160091\tBest loss: 0.054386\tAccuracy: 96.76%\n",
      "9\tValidation loss: 0.074834\tBest loss: 0.054386\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.070214\tBest loss: 0.054386\tAccuracy: 98.32%\n",
      "11\tValidation loss: 0.064195\tBest loss: 0.054386\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.077788\tBest loss: 0.054386\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.060244\tBest loss: 0.054386\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.074647\tBest loss: 0.054386\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.080342\tBest loss: 0.054386\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.197305\tBest loss: 0.054386\tAccuracy: 95.90%\n",
      "17\tValidation loss: 0.068026\tBest loss: 0.054386\tAccuracy: 98.36%\n",
      "18\tValidation loss: 0.074467\tBest loss: 0.054386\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.079895\tBest loss: 0.054386\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.067465\tBest loss: 0.054386\tAccuracy: 98.67%\n",
      "21\tValidation loss: 0.062887\tBest loss: 0.054386\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.099575\tBest loss: 0.054386\tAccuracy: 98.40%\n",
      "23\tValidation loss: 0.065639\tBest loss: 0.054386\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.082675\tBest loss: 0.054386\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.095142\tBest loss: 0.054386\tAccuracy: 98.59%\n",
      "26\tValidation loss: 1.066762\tBest loss: 0.054386\tAccuracy: 95.47%\n",
      "27\tValidation loss: 0.127848\tBest loss: 0.054386\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  24.9s\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 342.898773\tBest loss: 342.898773\tAccuracy: 21.11%\n",
      "1\tValidation loss: 14.975940\tBest loss: 14.975940\tAccuracy: 73.61%\n",
      "2\tValidation loss: 26.025242\tBest loss: 14.975940\tAccuracy: 66.97%\n",
      "3\tValidation loss: 9.378650\tBest loss: 9.378650\tAccuracy: 72.67%\n",
      "4\tValidation loss: 3.636983\tBest loss: 3.636983\tAccuracy: 88.66%\n",
      "5\tValidation loss: 3.592813\tBest loss: 3.592813\tAccuracy: 87.72%\n",
      "6\tValidation loss: 1294.233765\tBest loss: 3.592813\tAccuracy: 41.59%\n",
      "7\tValidation loss: 540.895691\tBest loss: 3.592813\tAccuracy: 45.97%\n",
      "8\tValidation loss: 487.226440\tBest loss: 3.592813\tAccuracy: 44.80%\n",
      "9\tValidation loss: 407.268158\tBest loss: 3.592813\tAccuracy: 62.55%\n",
      "10\tValidation loss: 312.733368\tBest loss: 3.592813\tAccuracy: 74.20%\n",
      "11\tValidation loss: 175.494659\tBest loss: 3.592813\tAccuracy: 79.16%\n",
      "12\tValidation loss: 180.185226\tBest loss: 3.592813\tAccuracy: 85.34%\n",
      "13\tValidation loss: 108.086563\tBest loss: 3.592813\tAccuracy: 89.76%\n",
      "14\tValidation loss: 143.286880\tBest loss: 3.592813\tAccuracy: 84.32%\n",
      "15\tValidation loss: 647.817383\tBest loss: 3.592813\tAccuracy: 66.61%\n",
      "16\tValidation loss: 92.637115\tBest loss: 3.592813\tAccuracy: 90.07%\n",
      "17\tValidation loss: 408.202057\tBest loss: 3.592813\tAccuracy: 75.57%\n",
      "18\tValidation loss: 105.152245\tBest loss: 3.592813\tAccuracy: 90.81%\n",
      "19\tValidation loss: 196.894943\tBest loss: 3.592813\tAccuracy: 85.73%\n",
      "20\tValidation loss: 94.237198\tBest loss: 3.592813\tAccuracy: 95.07%\n",
      "21\tValidation loss: 6128.302246\tBest loss: 3.592813\tAccuracy: 43.43%\n",
      "22\tValidation loss: 1714.891724\tBest loss: 3.592813\tAccuracy: 37.41%\n",
      "23\tValidation loss: 2815.394775\tBest loss: 3.592813\tAccuracy: 39.64%\n",
      "24\tValidation loss: 794.430420\tBest loss: 3.592813\tAccuracy: 59.30%\n",
      "25\tValidation loss: 2827.257324\tBest loss: 3.592813\tAccuracy: 41.36%\n",
      "26\tValidation loss: 944.803040\tBest loss: 3.592813\tAccuracy: 59.15%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  39.8s\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 1.166245\tBest loss: 1.166245\tAccuracy: 52.23%\n",
      "1\tValidation loss: 0.784497\tBest loss: 0.784497\tAccuracy: 67.01%\n",
      "2\tValidation loss: 1.138009\tBest loss: 0.784497\tAccuracy: 51.95%\n",
      "3\tValidation loss: 0.587460\tBest loss: 0.587460\tAccuracy: 79.01%\n",
      "4\tValidation loss: 0.343693\tBest loss: 0.343693\tAccuracy: 89.17%\n",
      "5\tValidation loss: 0.366008\tBest loss: 0.343693\tAccuracy: 89.05%\n",
      "6\tValidation loss: 0.255877\tBest loss: 0.255877\tAccuracy: 92.22%\n",
      "7\tValidation loss: 0.199902\tBest loss: 0.199902\tAccuracy: 94.21%\n",
      "8\tValidation loss: 8.331534\tBest loss: 0.199902\tAccuracy: 57.58%\n",
      "9\tValidation loss: 217.106766\tBest loss: 0.199902\tAccuracy: 49.34%\n",
      "10\tValidation loss: 95.518837\tBest loss: 0.199902\tAccuracy: 52.03%\n",
      "11\tValidation loss: 59.366150\tBest loss: 0.199902\tAccuracy: 65.75%\n",
      "12\tValidation loss: 46.881187\tBest loss: 0.199902\tAccuracy: 79.32%\n",
      "13\tValidation loss: 34.501423\tBest loss: 0.199902\tAccuracy: 85.77%\n",
      "14\tValidation loss: 32.578556\tBest loss: 0.199902\tAccuracy: 89.68%\n",
      "15\tValidation loss: 55.726490\tBest loss: 0.199902\tAccuracy: 65.17%\n",
      "16\tValidation loss: 31.831463\tBest loss: 0.199902\tAccuracy: 91.95%\n",
      "17\tValidation loss: 3160.749512\tBest loss: 0.199902\tAccuracy: 30.10%\n",
      "18\tValidation loss: 111.987358\tBest loss: 0.199902\tAccuracy: 58.91%\n",
      "19\tValidation loss: 42.659061\tBest loss: 0.199902\tAccuracy: 73.61%\n",
      "20\tValidation loss: 69.772621\tBest loss: 0.199902\tAccuracy: 65.72%\n",
      "21\tValidation loss: 41.497143\tBest loss: 0.199902\tAccuracy: 66.03%\n",
      "22\tValidation loss: 48.111866\tBest loss: 0.199902\tAccuracy: 76.94%\n",
      "23\tValidation loss: 22.904156\tBest loss: 0.199902\tAccuracy: 88.04%\n",
      "24\tValidation loss: 41.393959\tBest loss: 0.199902\tAccuracy: 81.31%\n",
      "25\tValidation loss: 41.531090\tBest loss: 0.199902\tAccuracy: 78.54%\n",
      "26\tValidation loss: 592.125061\tBest loss: 0.199902\tAccuracy: 67.08%\n",
      "27\tValidation loss: 5260.030273\tBest loss: 0.199902\tAccuracy: 80.10%\n",
      "28\tValidation loss: 185.121338\tBest loss: 0.199902\tAccuracy: 61.92%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  42.8s\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 13.559899\tBest loss: 13.559899\tAccuracy: 46.87%\n",
      "1\tValidation loss: 1.063763\tBest loss: 1.063763\tAccuracy: 80.38%\n",
      "2\tValidation loss: 1.557092\tBest loss: 1.063763\tAccuracy: 74.43%\n",
      "3\tValidation loss: 0.517077\tBest loss: 0.517077\tAccuracy: 86.32%\n",
      "4\tValidation loss: 0.783337\tBest loss: 0.517077\tAccuracy: 84.99%\n",
      "5\tValidation loss: 0.415956\tBest loss: 0.415956\tAccuracy: 89.41%\n",
      "6\tValidation loss: 3763.288818\tBest loss: 0.415956\tAccuracy: 25.88%\n",
      "7\tValidation loss: 140.648743\tBest loss: 0.415956\tAccuracy: 22.67%\n",
      "8\tValidation loss: 83.034325\tBest loss: 0.415956\tAccuracy: 36.59%\n",
      "9\tValidation loss: 35.671562\tBest loss: 0.415956\tAccuracy: 42.42%\n",
      "10\tValidation loss: 48.829296\tBest loss: 0.415956\tAccuracy: 38.58%\n",
      "11\tValidation loss: 13.875469\tBest loss: 0.415956\tAccuracy: 56.92%\n",
      "12\tValidation loss: 39.223171\tBest loss: 0.415956\tAccuracy: 45.70%\n",
      "13\tValidation loss: 37.743416\tBest loss: 0.415956\tAccuracy: 52.42%\n",
      "14\tValidation loss: 30.807207\tBest loss: 0.415956\tAccuracy: 53.71%\n",
      "15\tValidation loss: 40.640320\tBest loss: 0.415956\tAccuracy: 63.80%\n",
      "16\tValidation loss: 18.008698\tBest loss: 0.415956\tAccuracy: 63.76%\n",
      "17\tValidation loss: 7.808444\tBest loss: 0.415956\tAccuracy: 82.21%\n",
      "18\tValidation loss: 28.876148\tBest loss: 0.415956\tAccuracy: 56.02%\n",
      "19\tValidation loss: 61.737556\tBest loss: 0.415956\tAccuracy: 66.73%\n",
      "20\tValidation loss: 8.973001\tBest loss: 0.415956\tAccuracy: 82.76%\n",
      "21\tValidation loss: 630.611572\tBest loss: 0.415956\tAccuracy: 42.14%\n",
      "22\tValidation loss: 1543.618042\tBest loss: 0.415956\tAccuracy: 29.28%\n",
      "23\tValidation loss: 326.138947\tBest loss: 0.415956\tAccuracy: 66.58%\n",
      "24\tValidation loss: 294.646545\tBest loss: 0.415956\tAccuracy: 59.58%\n",
      "25\tValidation loss: 161.854263\tBest loss: 0.415956\tAccuracy: 74.98%\n",
      "26\tValidation loss: 106.399055\tBest loss: 0.415956\tAccuracy: 89.33%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  39.6s\n",
      "[CV] n_neurons=100, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.126268\tBest loss: 0.126268\tAccuracy: 96.83%\n",
      "1\tValidation loss: 0.286520\tBest loss: 0.126268\tAccuracy: 92.06%\n",
      "2\tValidation loss: 0.351336\tBest loss: 0.126268\tAccuracy: 93.47%\n",
      "3\tValidation loss: 0.203563\tBest loss: 0.126268\tAccuracy: 95.58%\n",
      "4\tValidation loss: 0.147281\tBest loss: 0.126268\tAccuracy: 95.82%\n",
      "5\tValidation loss: 0.136270\tBest loss: 0.126268\tAccuracy: 96.52%\n",
      "6\tValidation loss: 0.121248\tBest loss: 0.121248\tAccuracy: 96.99%\n",
      "7\tValidation loss: 0.113899\tBest loss: 0.113899\tAccuracy: 97.15%\n",
      "8\tValidation loss: 0.134411\tBest loss: 0.113899\tAccuracy: 96.99%\n",
      "9\tValidation loss: 0.150059\tBest loss: 0.113899\tAccuracy: 96.05%\n",
      "10\tValidation loss: 6.770463\tBest loss: 0.113899\tAccuracy: 83.07%\n",
      "11\tValidation loss: 0.985611\tBest loss: 0.113899\tAccuracy: 91.09%\n",
      "12\tValidation loss: 0.547309\tBest loss: 0.113899\tAccuracy: 95.11%\n",
      "13\tValidation loss: 0.515634\tBest loss: 0.113899\tAccuracy: 94.21%\n",
      "14\tValidation loss: 0.303312\tBest loss: 0.113899\tAccuracy: 95.27%\n",
      "15\tValidation loss: 0.280819\tBest loss: 0.113899\tAccuracy: 95.39%\n",
      "16\tValidation loss: 0.254211\tBest loss: 0.113899\tAccuracy: 95.90%\n",
      "17\tValidation loss: 0.337404\tBest loss: 0.113899\tAccuracy: 92.96%\n",
      "18\tValidation loss: 4.143568\tBest loss: 0.113899\tAccuracy: 77.33%\n",
      "19\tValidation loss: 1.515469\tBest loss: 0.113899\tAccuracy: 84.28%\n",
      "20\tValidation loss: 1.315704\tBest loss: 0.113899\tAccuracy: 87.57%\n",
      "21\tValidation loss: 0.849770\tBest loss: 0.113899\tAccuracy: 93.55%\n",
      "22\tValidation loss: 0.619826\tBest loss: 0.113899\tAccuracy: 94.14%\n",
      "23\tValidation loss: 1.430531\tBest loss: 0.113899\tAccuracy: 88.55%\n",
      "24\tValidation loss: 0.821360\tBest loss: 0.113899\tAccuracy: 88.98%\n",
      "25\tValidation loss: 1.271863\tBest loss: 0.113899\tAccuracy: 79.63%\n",
      "26\tValidation loss: 1.143992\tBest loss: 0.113899\tAccuracy: 90.93%\n",
      "27\tValidation loss: 0.831617\tBest loss: 0.113899\tAccuracy: 88.04%\n",
      "28\tValidation loss: 0.419153\tBest loss: 0.113899\tAccuracy: 93.82%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  45.2s\n",
      "[CV] n_neurons=100, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.150780\tBest loss: 0.150780\tAccuracy: 95.90%\n",
      "1\tValidation loss: 0.188890\tBest loss: 0.150780\tAccuracy: 95.50%\n",
      "2\tValidation loss: 0.124442\tBest loss: 0.124442\tAccuracy: 97.11%\n",
      "3\tValidation loss: 9.365659\tBest loss: 0.124442\tAccuracy: 94.10%\n",
      "4\tValidation loss: 2.093612\tBest loss: 0.124442\tAccuracy: 94.57%\n",
      "5\tValidation loss: 0.948742\tBest loss: 0.124442\tAccuracy: 95.04%\n",
      "6\tValidation loss: 0.628021\tBest loss: 0.124442\tAccuracy: 96.25%\n",
      "7\tValidation loss: 0.457692\tBest loss: 0.124442\tAccuracy: 97.22%\n",
      "8\tValidation loss: 12.305743\tBest loss: 0.124442\tAccuracy: 73.89%\n",
      "9\tValidation loss: 0.761999\tBest loss: 0.124442\tAccuracy: 94.37%\n",
      "10\tValidation loss: 0.458347\tBest loss: 0.124442\tAccuracy: 96.36%\n",
      "11\tValidation loss: 0.460609\tBest loss: 0.124442\tAccuracy: 96.17%\n",
      "12\tValidation loss: 0.283371\tBest loss: 0.124442\tAccuracy: 96.87%\n",
      "13\tValidation loss: 0.578980\tBest loss: 0.124442\tAccuracy: 93.20%\n",
      "14\tValidation loss: 20.656242\tBest loss: 0.124442\tAccuracy: 68.80%\n",
      "15\tValidation loss: 3.248576\tBest loss: 0.124442\tAccuracy: 89.48%\n",
      "16\tValidation loss: 2.022366\tBest loss: 0.124442\tAccuracy: 93.00%\n",
      "17\tValidation loss: 1.545720\tBest loss: 0.124442\tAccuracy: 96.09%\n",
      "18\tValidation loss: 1.471255\tBest loss: 0.124442\tAccuracy: 94.72%\n",
      "19\tValidation loss: 1.986211\tBest loss: 0.124442\tAccuracy: 91.71%\n",
      "20\tValidation loss: 0.842611\tBest loss: 0.124442\tAccuracy: 96.52%\n",
      "21\tValidation loss: 19.758417\tBest loss: 0.124442\tAccuracy: 88.04%\n",
      "22\tValidation loss: 7.163049\tBest loss: 0.124442\tAccuracy: 95.31%\n",
      "23\tValidation loss: 3.369863\tBest loss: 0.124442\tAccuracy: 94.33%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  37.2s\n",
      "[CV] n_neurons=100, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.837499\tBest loss: 0.837499\tAccuracy: 73.96%\n",
      "1\tValidation loss: 0.127835\tBest loss: 0.127835\tAccuracy: 96.64%\n",
      "2\tValidation loss: 0.242088\tBest loss: 0.127835\tAccuracy: 94.02%\n",
      "3\tValidation loss: 0.182517\tBest loss: 0.127835\tAccuracy: 95.54%\n",
      "4\tValidation loss: 1.217267\tBest loss: 0.127835\tAccuracy: 88.58%\n",
      "5\tValidation loss: 0.640052\tBest loss: 0.127835\tAccuracy: 90.93%\n",
      "6\tValidation loss: 0.530857\tBest loss: 0.127835\tAccuracy: 90.66%\n",
      "7\tValidation loss: 0.862076\tBest loss: 0.127835\tAccuracy: 89.80%\n",
      "8\tValidation loss: 1.048406\tBest loss: 0.127835\tAccuracy: 91.24%\n",
      "9\tValidation loss: 0.465062\tBest loss: 0.127835\tAccuracy: 94.96%\n",
      "10\tValidation loss: 0.298423\tBest loss: 0.127835\tAccuracy: 96.05%\n",
      "11\tValidation loss: 0.280296\tBest loss: 0.127835\tAccuracy: 95.86%\n",
      "12\tValidation loss: 0.271280\tBest loss: 0.127835\tAccuracy: 95.74%\n",
      "13\tValidation loss: 0.213155\tBest loss: 0.127835\tAccuracy: 95.43%\n",
      "14\tValidation loss: 0.240120\tBest loss: 0.127835\tAccuracy: 96.33%\n",
      "15\tValidation loss: 0.316589\tBest loss: 0.127835\tAccuracy: 91.99%\n",
      "16\tValidation loss: 26.774935\tBest loss: 0.127835\tAccuracy: 56.41%\n",
      "17\tValidation loss: 7.561440\tBest loss: 0.127835\tAccuracy: 51.88%\n",
      "18\tValidation loss: 1.237472\tBest loss: 0.127835\tAccuracy: 89.84%\n",
      "19\tValidation loss: 3.328918\tBest loss: 0.127835\tAccuracy: 77.25%\n",
      "20\tValidation loss: 1.220738\tBest loss: 0.127835\tAccuracy: 90.38%\n",
      "21\tValidation loss: 1.549902\tBest loss: 0.127835\tAccuracy: 81.47%\n",
      "22\tValidation loss: 2.757231\tBest loss: 0.127835\tAccuracy: 73.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total=  36.7s\n",
      "[CV] n_neurons=100, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 9.888402\tBest loss: 9.888402\tAccuracy: 88.31%\n",
      "1\tValidation loss: 1.649039\tBest loss: 1.649039\tAccuracy: 94.25%\n",
      "2\tValidation loss: 2.017454\tBest loss: 1.649039\tAccuracy: 92.65%\n",
      "3\tValidation loss: 1.045560\tBest loss: 1.045560\tAccuracy: 95.35%\n",
      "4\tValidation loss: 1.101786\tBest loss: 1.045560\tAccuracy: 96.21%\n",
      "5\tValidation loss: 0.994087\tBest loss: 0.994087\tAccuracy: 92.96%\n",
      "6\tValidation loss: 0.663314\tBest loss: 0.663314\tAccuracy: 96.95%\n",
      "7\tValidation loss: 0.543465\tBest loss: 0.543465\tAccuracy: 96.95%\n",
      "8\tValidation loss: 0.997873\tBest loss: 0.543465\tAccuracy: 95.23%\n",
      "9\tValidation loss: 0.506943\tBest loss: 0.506943\tAccuracy: 94.21%\n",
      "10\tValidation loss: 0.228496\tBest loss: 0.228496\tAccuracy: 97.38%\n",
      "11\tValidation loss: 0.296441\tBest loss: 0.228496\tAccuracy: 97.15%\n",
      "12\tValidation loss: 0.338447\tBest loss: 0.228496\tAccuracy: 96.13%\n",
      "13\tValidation loss: 7990815.500000\tBest loss: 0.228496\tAccuracy: 5.28%\n",
      "14\tValidation loss: 266093.187500\tBest loss: 0.228496\tAccuracy: 86.71%\n",
      "15\tValidation loss: 149728.578125\tBest loss: 0.228496\tAccuracy: 87.14%\n",
      "16\tValidation loss: 55204.117188\tBest loss: 0.228496\tAccuracy: 90.66%\n",
      "17\tValidation loss: 57413.992188\tBest loss: 0.228496\tAccuracy: 91.63%\n",
      "18\tValidation loss: 60039.757812\tBest loss: 0.228496\tAccuracy: 91.79%\n",
      "19\tValidation loss: 68642.820312\tBest loss: 0.228496\tAccuracy: 89.48%\n",
      "20\tValidation loss: 31025.601562\tBest loss: 0.228496\tAccuracy: 92.89%\n",
      "21\tValidation loss: 33219.097656\tBest loss: 0.228496\tAccuracy: 92.18%\n",
      "22\tValidation loss: 24765.304688\tBest loss: 0.228496\tAccuracy: 94.68%\n",
      "23\tValidation loss: 42418.433594\tBest loss: 0.228496\tAccuracy: 91.32%\n",
      "24\tValidation loss: 31560.125000\tBest loss: 0.228496\tAccuracy: 93.63%\n",
      "25\tValidation loss: 16535.224609\tBest loss: 0.228496\tAccuracy: 94.37%\n",
      "26\tValidation loss: 33350.871094\tBest loss: 0.228496\tAccuracy: 92.10%\n",
      "27\tValidation loss: 16367.040039\tBest loss: 0.228496\tAccuracy: 95.93%\n",
      "28\tValidation loss: 40055.570312\tBest loss: 0.228496\tAccuracy: 92.65%\n",
      "29\tValidation loss: 23475.828125\tBest loss: 0.228496\tAccuracy: 94.33%\n",
      "30\tValidation loss: 21980.763672\tBest loss: 0.228496\tAccuracy: 93.78%\n",
      "31\tValidation loss: 30622.968750\tBest loss: 0.228496\tAccuracy: 92.65%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  35.7s\n",
      "[CV] n_neurons=100, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 2.806394\tBest loss: 2.806394\tAccuracy: 94.29%\n",
      "1\tValidation loss: 3.719890\tBest loss: 2.806394\tAccuracy: 93.12%\n",
      "2\tValidation loss: 0.664001\tBest loss: 0.664001\tAccuracy: 94.96%\n",
      "3\tValidation loss: 0.280097\tBest loss: 0.280097\tAccuracy: 96.40%\n",
      "4\tValidation loss: 0.356251\tBest loss: 0.280097\tAccuracy: 94.68%\n",
      "5\tValidation loss: 0.384676\tBest loss: 0.280097\tAccuracy: 95.43%\n",
      "6\tValidation loss: 0.287277\tBest loss: 0.280097\tAccuracy: 96.87%\n",
      "7\tValidation loss: 0.463533\tBest loss: 0.280097\tAccuracy: 96.56%\n",
      "8\tValidation loss: 0.274633\tBest loss: 0.274633\tAccuracy: 96.56%\n",
      "9\tValidation loss: 0.180741\tBest loss: 0.180741\tAccuracy: 96.68%\n",
      "10\tValidation loss: 0.161447\tBest loss: 0.161447\tAccuracy: 96.52%\n",
      "11\tValidation loss: 0.176235\tBest loss: 0.161447\tAccuracy: 97.03%\n",
      "12\tValidation loss: 0.182066\tBest loss: 0.161447\tAccuracy: 96.91%\n",
      "13\tValidation loss: 0.197511\tBest loss: 0.161447\tAccuracy: 96.33%\n",
      "14\tValidation loss: 459801.812500\tBest loss: 0.161447\tAccuracy: 68.37%\n",
      "15\tValidation loss: 111695.671875\tBest loss: 0.161447\tAccuracy: 83.42%\n",
      "16\tValidation loss: 83303.593750\tBest loss: 0.161447\tAccuracy: 84.64%\n",
      "17\tValidation loss: 86472.593750\tBest loss: 0.161447\tAccuracy: 83.03%\n",
      "18\tValidation loss: 54368.113281\tBest loss: 0.161447\tAccuracy: 85.77%\n",
      "19\tValidation loss: 73889.273438\tBest loss: 0.161447\tAccuracy: 83.82%\n",
      "20\tValidation loss: 47375.378906\tBest loss: 0.161447\tAccuracy: 88.31%\n",
      "21\tValidation loss: 39311.597656\tBest loss: 0.161447\tAccuracy: 89.91%\n",
      "22\tValidation loss: 49889.234375\tBest loss: 0.161447\tAccuracy: 88.23%\n",
      "23\tValidation loss: 30244.437500\tBest loss: 0.161447\tAccuracy: 90.93%\n",
      "24\tValidation loss: 22657.339844\tBest loss: 0.161447\tAccuracy: 92.81%\n",
      "25\tValidation loss: 89571.718750\tBest loss: 0.161447\tAccuracy: 76.11%\n",
      "26\tValidation loss: 16102.515625\tBest loss: 0.161447\tAccuracy: 92.42%\n",
      "27\tValidation loss: 20202.494141\tBest loss: 0.161447\tAccuracy: 94.49%\n",
      "28\tValidation loss: 14464.374023\tBest loss: 0.161447\tAccuracy: 95.04%\n",
      "29\tValidation loss: 21100.855469\tBest loss: 0.161447\tAccuracy: 91.75%\n",
      "30\tValidation loss: 15455.586914\tBest loss: 0.161447\tAccuracy: 94.64%\n",
      "31\tValidation loss: 19039.867188\tBest loss: 0.161447\tAccuracy: 94.37%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  36.1s\n",
      "[CV] n_neurons=100, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550> \n",
      "0\tValidation loss: 4305.487793\tBest loss: 4305.487793\tAccuracy: 74.16%\n",
      "1\tValidation loss: 119.239250\tBest loss: 119.239250\tAccuracy: 93.04%\n",
      "2\tValidation loss: 47.502037\tBest loss: 47.502037\tAccuracy: 95.66%\n",
      "3\tValidation loss: 39.380650\tBest loss: 39.380650\tAccuracy: 95.86%\n",
      "4\tValidation loss: 48.493393\tBest loss: 39.380650\tAccuracy: 95.35%\n",
      "5\tValidation loss: 51.066261\tBest loss: 39.380650\tAccuracy: 96.52%\n",
      "6\tValidation loss: 56.486141\tBest loss: 39.380650\tAccuracy: 96.44%\n",
      "7\tValidation loss: 47.037800\tBest loss: 39.380650\tAccuracy: 95.66%\n",
      "8\tValidation loss: 56.202049\tBest loss: 39.380650\tAccuracy: 95.50%\n",
      "9\tValidation loss: 55.655750\tBest loss: 39.380650\tAccuracy: 94.18%\n",
      "10\tValidation loss: 55.019894\tBest loss: 39.380650\tAccuracy: 96.72%\n",
      "11\tValidation loss: 55.039360\tBest loss: 39.380650\tAccuracy: 96.91%\n",
      "12\tValidation loss: 67.959480\tBest loss: 39.380650\tAccuracy: 95.15%\n",
      "13\tValidation loss: 59.573261\tBest loss: 39.380650\tAccuracy: 96.64%\n",
      "14\tValidation loss: 62.756138\tBest loss: 39.380650\tAccuracy: 96.25%\n",
      "15\tValidation loss: 71.839966\tBest loss: 39.380650\tAccuracy: 97.11%\n",
      "16\tValidation loss: 109870744.000000\tBest loss: 39.380650\tAccuracy: 20.09%\n",
      "17\tValidation loss: 79790.109375\tBest loss: 39.380650\tAccuracy: 89.25%\n",
      "18\tValidation loss: 37183.207031\tBest loss: 39.380650\tAccuracy: 88.39%\n",
      "19\tValidation loss: 21825.777344\tBest loss: 39.380650\tAccuracy: 93.59%\n",
      "20\tValidation loss: 34529.882812\tBest loss: 39.380650\tAccuracy: 91.99%\n",
      "21\tValidation loss: 24350.943359\tBest loss: 39.380650\tAccuracy: 91.09%\n",
      "22\tValidation loss: 19080.677734\tBest loss: 39.380650\tAccuracy: 91.63%\n",
      "23\tValidation loss: 16220.206055\tBest loss: 39.380650\tAccuracy: 94.92%\n",
      "24\tValidation loss: 11176.070312\tBest loss: 39.380650\tAccuracy: 94.80%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fab10620550>, total=  28.3s\n",
      "[CV] n_neurons=30, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 4.911894\tBest loss: 4.911894\tAccuracy: 49.34%\n",
      "1\tValidation loss: 2.081449\tBest loss: 2.081449\tAccuracy: 39.64%\n",
      "2\tValidation loss: 1.150561\tBest loss: 1.150561\tAccuracy: 54.53%\n",
      "3\tValidation loss: 3.205347\tBest loss: 1.150561\tAccuracy: 44.02%\n",
      "4\tValidation loss: 125.713928\tBest loss: 1.150561\tAccuracy: 33.50%\n",
      "5\tValidation loss: 16.592855\tBest loss: 1.150561\tAccuracy: 64.54%\n",
      "6\tValidation loss: 8.053742\tBest loss: 1.150561\tAccuracy: 69.78%\n",
      "7\tValidation loss: 7.295758\tBest loss: 1.150561\tAccuracy: 74.39%\n",
      "8\tValidation loss: 110.197563\tBest loss: 1.150561\tAccuracy: 43.20%\n",
      "9\tValidation loss: 9.224699\tBest loss: 1.150561\tAccuracy: 55.86%\n",
      "10\tValidation loss: 7134.346191\tBest loss: 1.150561\tAccuracy: 59.85%\n",
      "11\tValidation loss: 58.229294\tBest loss: 1.150561\tAccuracy: 68.02%\n",
      "12\tValidation loss: 109.032188\tBest loss: 1.150561\tAccuracy: 54.89%\n",
      "13\tValidation loss: 31.927702\tBest loss: 1.150561\tAccuracy: 70.09%\n",
      "14\tValidation loss: 14.625759\tBest loss: 1.150561\tAccuracy: 79.67%\n",
      "15\tValidation loss: 17.624975\tBest loss: 1.150561\tAccuracy: 80.41%\n",
      "16\tValidation loss: 36.003300\tBest loss: 1.150561\tAccuracy: 57.27%\n",
      "17\tValidation loss: 9.034760\tBest loss: 1.150561\tAccuracy: 81.86%\n",
      "18\tValidation loss: 12879.911133\tBest loss: 1.150561\tAccuracy: 21.15%\n",
      "19\tValidation loss: 114.400131\tBest loss: 1.150561\tAccuracy: 52.03%\n",
      "20\tValidation loss: 45.964314\tBest loss: 1.150561\tAccuracy: 77.72%\n",
      "21\tValidation loss: 34.075916\tBest loss: 1.150561\tAccuracy: 85.26%\n",
      "22\tValidation loss: 225.976624\tBest loss: 1.150561\tAccuracy: 57.51%\n",
      "23\tValidation loss: 53.778122\tBest loss: 1.150561\tAccuracy: 82.88%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total= 1.5min\n",
      "[CV] n_neurons=30, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 1.052109\tBest loss: 1.052109\tAccuracy: 69.59%\n",
      "1\tValidation loss: 3.835639\tBest loss: 1.052109\tAccuracy: 58.91%\n",
      "2\tValidation loss: 1.086544\tBest loss: 1.052109\tAccuracy: 74.78%\n",
      "3\tValidation loss: 64.827774\tBest loss: 1.052109\tAccuracy: 19.08%\n",
      "4\tValidation loss: 21.921228\tBest loss: 1.052109\tAccuracy: 27.48%\n",
      "5\tValidation loss: 9.296166\tBest loss: 1.052109\tAccuracy: 49.18%\n",
      "6\tValidation loss: 27.393332\tBest loss: 1.052109\tAccuracy: 65.21%\n",
      "7\tValidation loss: 7.728739\tBest loss: 1.052109\tAccuracy: 64.97%\n",
      "8\tValidation loss: 31.140629\tBest loss: 1.052109\tAccuracy: 41.32%\n",
      "9\tValidation loss: 45.394707\tBest loss: 1.052109\tAccuracy: 50.00%\n",
      "10\tValidation loss: 30.917973\tBest loss: 1.052109\tAccuracy: 54.22%\n",
      "11\tValidation loss: 786.548645\tBest loss: 1.052109\tAccuracy: 38.74%\n",
      "12\tValidation loss: 125.523125\tBest loss: 1.052109\tAccuracy: 54.34%\n",
      "13\tValidation loss: 148.145981\tBest loss: 1.052109\tAccuracy: 55.04%\n",
      "14\tValidation loss: 17.741545\tBest loss: 1.052109\tAccuracy: 67.63%\n",
      "15\tValidation loss: 32.323311\tBest loss: 1.052109\tAccuracy: 65.91%\n",
      "16\tValidation loss: 9.162329\tBest loss: 1.052109\tAccuracy: 73.06%\n",
      "17\tValidation loss: 27.727707\tBest loss: 1.052109\tAccuracy: 70.41%\n",
      "18\tValidation loss: 8.235812\tBest loss: 1.052109\tAccuracy: 85.03%\n",
      "19\tValidation loss: 50.252491\tBest loss: 1.052109\tAccuracy: 57.62%\n",
      "20\tValidation loss: 14.018728\tBest loss: 1.052109\tAccuracy: 71.42%\n",
      "21\tValidation loss: 13.645252\tBest loss: 1.052109\tAccuracy: 77.13%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total= 1.3min\n",
      "[CV] n_neurons=30, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0> \n",
      "0\tValidation loss: 0.710556\tBest loss: 0.710556\tAccuracy: 72.60%\n",
      "1\tValidation loss: 0.407146\tBest loss: 0.407146\tAccuracy: 86.94%\n",
      "2\tValidation loss: 3.918616\tBest loss: 0.407146\tAccuracy: 32.06%\n",
      "3\tValidation loss: 28.389767\tBest loss: 0.407146\tAccuracy: 24.08%\n",
      "4\tValidation loss: 2.130080\tBest loss: 0.407146\tAccuracy: 43.08%\n",
      "5\tValidation loss: 2.367158\tBest loss: 0.407146\tAccuracy: 29.79%\n",
      "6\tValidation loss: 1.239322\tBest loss: 0.407146\tAccuracy: 54.18%\n",
      "7\tValidation loss: 9.072826\tBest loss: 0.407146\tAccuracy: 40.42%\n",
      "8\tValidation loss: 21.638655\tBest loss: 0.407146\tAccuracy: 21.70%\n",
      "9\tValidation loss: 13.099324\tBest loss: 0.407146\tAccuracy: 27.72%\n",
      "10\tValidation loss: 6.235466\tBest loss: 0.407146\tAccuracy: 37.72%\n",
      "11\tValidation loss: 312.856567\tBest loss: 0.407146\tAccuracy: 57.31%\n",
      "12\tValidation loss: 2.967199\tBest loss: 0.407146\tAccuracy: 40.19%\n",
      "13\tValidation loss: 12.740979\tBest loss: 0.407146\tAccuracy: 36.51%\n",
      "14\tValidation loss: 17.811222\tBest loss: 0.407146\tAccuracy: 26.19%\n",
      "15\tValidation loss: 6.224379\tBest loss: 0.407146\tAccuracy: 31.47%\n",
      "16\tValidation loss: 8.802809\tBest loss: 0.407146\tAccuracy: 36.32%\n",
      "17\tValidation loss: 53.084343\tBest loss: 0.407146\tAccuracy: 19.35%\n",
      "18\tValidation loss: 14.562358\tBest loss: 0.407146\tAccuracy: 31.86%\n",
      "19\tValidation loss: 4.809194\tBest loss: 0.407146\tAccuracy: 37.80%\n",
      "20\tValidation loss: 148.247711\tBest loss: 0.407146\tAccuracy: 19.23%\n",
      "21\tValidation loss: 9.571218\tBest loss: 0.407146\tAccuracy: 34.13%\n",
      "22\tValidation loss: 7.705445\tBest loss: 0.407146\tAccuracy: 33.42%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fabac7af3a0>, total= 1.4min\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=100, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.118975\tBest loss: 0.118975\tAccuracy: 96.56%\n",
      "1\tValidation loss: 0.099888\tBest loss: 0.099888\tAccuracy: 96.91%\n",
      "2\tValidation loss: 0.081609\tBest loss: 0.081609\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.075163\tBest loss: 0.075163\tAccuracy: 97.50%\n",
      "4\tValidation loss: 0.111829\tBest loss: 0.075163\tAccuracy: 96.68%\n",
      "5\tValidation loss: 0.088632\tBest loss: 0.075163\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.094017\tBest loss: 0.075163\tAccuracy: 97.34%\n",
      "7\tValidation loss: 0.090220\tBest loss: 0.075163\tAccuracy: 96.95%\n",
      "8\tValidation loss: 0.092857\tBest loss: 0.075163\tAccuracy: 97.26%\n",
      "9\tValidation loss: 0.093601\tBest loss: 0.075163\tAccuracy: 97.58%\n",
      "10\tValidation loss: 0.086482\tBest loss: 0.075163\tAccuracy: 97.54%\n",
      "11\tValidation loss: 0.096142\tBest loss: 0.075163\tAccuracy: 97.62%\n",
      "12\tValidation loss: 0.155001\tBest loss: 0.075163\tAccuracy: 96.01%\n",
      "13\tValidation loss: 0.105256\tBest loss: 0.075163\tAccuracy: 97.54%\n",
      "14\tValidation loss: 0.089699\tBest loss: 0.075163\tAccuracy: 97.77%\n",
      "15\tValidation loss: 0.086384\tBest loss: 0.075163\tAccuracy: 97.50%\n",
      "16\tValidation loss: 0.102089\tBest loss: 0.075163\tAccuracy: 97.15%\n",
      "17\tValidation loss: 0.116403\tBest loss: 0.075163\tAccuracy: 96.95%\n",
      "18\tValidation loss: 0.100884\tBest loss: 0.075163\tAccuracy: 97.85%\n",
      "19\tValidation loss: 0.106496\tBest loss: 0.075163\tAccuracy: 97.19%\n",
      "20\tValidation loss: 0.095809\tBest loss: 0.075163\tAccuracy: 97.73%\n",
      "21\tValidation loss: 0.111266\tBest loss: 0.075163\tAccuracy: 97.46%\n",
      "22\tValidation loss: 0.102304\tBest loss: 0.075163\tAccuracy: 97.38%\n",
      "23\tValidation loss: 0.104918\tBest loss: 0.075163\tAccuracy: 97.30%\n",
      "24\tValidation loss: 0.129218\tBest loss: 0.075163\tAccuracy: 97.54%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=100, activation=<function elu at 0x7fabf3fc68b0>, total=  12.9s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=100, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.098779\tBest loss: 0.098779\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.109543\tBest loss: 0.098779\tAccuracy: 96.68%\n",
      "2\tValidation loss: 0.081535\tBest loss: 0.081535\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.064662\tBest loss: 0.064662\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.072918\tBest loss: 0.064662\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.075022\tBest loss: 0.064662\tAccuracy: 97.81%\n",
      "6\tValidation loss: 0.086962\tBest loss: 0.064662\tAccuracy: 97.58%\n",
      "7\tValidation loss: 0.082199\tBest loss: 0.064662\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.080151\tBest loss: 0.064662\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.068683\tBest loss: 0.064662\tAccuracy: 98.05%\n",
      "10\tValidation loss: 0.077983\tBest loss: 0.064662\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.088780\tBest loss: 0.064662\tAccuracy: 97.81%\n",
      "12\tValidation loss: 0.097938\tBest loss: 0.064662\tAccuracy: 97.69%\n",
      "13\tValidation loss: 0.098686\tBest loss: 0.064662\tAccuracy: 97.65%\n",
      "14\tValidation loss: 0.082210\tBest loss: 0.064662\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.080579\tBest loss: 0.064662\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.087160\tBest loss: 0.064662\tAccuracy: 97.62%\n",
      "17\tValidation loss: 0.086802\tBest loss: 0.064662\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.116303\tBest loss: 0.064662\tAccuracy: 97.65%\n",
      "19\tValidation loss: 0.091680\tBest loss: 0.064662\tAccuracy: 97.81%\n",
      "20\tValidation loss: 0.102302\tBest loss: 0.064662\tAccuracy: 97.93%\n",
      "21\tValidation loss: 0.134238\tBest loss: 0.064662\tAccuracy: 97.34%\n",
      "22\tValidation loss: 0.099459\tBest loss: 0.064662\tAccuracy: 97.89%\n",
      "23\tValidation loss: 0.097546\tBest loss: 0.064662\tAccuracy: 98.01%\n",
      "24\tValidation loss: 0.105445\tBest loss: 0.064662\tAccuracy: 97.85%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=100, activation=<function elu at 0x7fabf3fc68b0>, total=  12.9s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=100, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.102573\tBest loss: 0.102573\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.098937\tBest loss: 0.098937\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.087184\tBest loss: 0.087184\tAccuracy: 97.30%\n",
      "3\tValidation loss: 0.080003\tBest loss: 0.080003\tAccuracy: 97.58%\n",
      "4\tValidation loss: 0.071621\tBest loss: 0.071621\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.079962\tBest loss: 0.071621\tAccuracy: 97.62%\n",
      "6\tValidation loss: 0.086768\tBest loss: 0.071621\tAccuracy: 97.03%\n",
      "7\tValidation loss: 0.074595\tBest loss: 0.071621\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.109695\tBest loss: 0.071621\tAccuracy: 97.03%\n",
      "9\tValidation loss: 0.066605\tBest loss: 0.066605\tAccuracy: 98.05%\n",
      "10\tValidation loss: 0.072718\tBest loss: 0.066605\tAccuracy: 97.73%\n",
      "11\tValidation loss: 0.086633\tBest loss: 0.066605\tAccuracy: 97.65%\n",
      "12\tValidation loss: 0.078767\tBest loss: 0.066605\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.066690\tBest loss: 0.066605\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.090603\tBest loss: 0.066605\tAccuracy: 97.89%\n",
      "15\tValidation loss: 0.084673\tBest loss: 0.066605\tAccuracy: 97.81%\n",
      "16\tValidation loss: 0.073572\tBest loss: 0.066605\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.090467\tBest loss: 0.066605\tAccuracy: 97.62%\n",
      "18\tValidation loss: 0.079585\tBest loss: 0.066605\tAccuracy: 97.77%\n",
      "19\tValidation loss: 0.080595\tBest loss: 0.066605\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.103729\tBest loss: 0.066605\tAccuracy: 97.69%\n",
      "21\tValidation loss: 0.088435\tBest loss: 0.066605\tAccuracy: 97.77%\n",
      "22\tValidation loss: 0.067480\tBest loss: 0.066605\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.077503\tBest loss: 0.066605\tAccuracy: 97.85%\n",
      "24\tValidation loss: 0.090223\tBest loss: 0.066605\tAccuracy: 98.08%\n",
      "25\tValidation loss: 0.104699\tBest loss: 0.066605\tAccuracy: 97.50%\n",
      "26\tValidation loss: 0.091456\tBest loss: 0.066605\tAccuracy: 97.97%\n",
      "27\tValidation loss: 0.091696\tBest loss: 0.066605\tAccuracy: 97.93%\n",
      "28\tValidation loss: 0.073820\tBest loss: 0.066605\tAccuracy: 98.16%\n",
      "29\tValidation loss: 0.075964\tBest loss: 0.066605\tAccuracy: 98.16%\n",
      "30\tValidation loss: 0.077366\tBest loss: 0.066605\tAccuracy: 97.93%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=100, activation=<function elu at 0x7fabf3fc68b0>, total=  15.7s\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=10, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.611556\tBest loss: 1.611556\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.635437\tBest loss: 1.611556\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.635119\tBest loss: 1.611556\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.627702\tBest loss: 1.611556\tAccuracy: 18.73%\n",
      "4\tValidation loss: 1.620434\tBest loss: 1.611556\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.610206\tBest loss: 1.610206\tAccuracy: 19.08%\n",
      "6\tValidation loss: 1.617693\tBest loss: 1.610206\tAccuracy: 22.01%\n",
      "7\tValidation loss: 1.619608\tBest loss: 1.610206\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.638418\tBest loss: 1.610206\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.618620\tBest loss: 1.610206\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.641804\tBest loss: 1.610206\tAccuracy: 19.27%\n",
      "11\tValidation loss: 1.615162\tBest loss: 1.610206\tAccuracy: 20.91%\n",
      "12\tValidation loss: 1.612164\tBest loss: 1.610206\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.621821\tBest loss: 1.610206\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.621621\tBest loss: 1.610206\tAccuracy: 20.91%\n",
      "15\tValidation loss: 1.616235\tBest loss: 1.610206\tAccuracy: 19.27%\n",
      "16\tValidation loss: 1.639859\tBest loss: 1.610206\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.633260\tBest loss: 1.610206\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.634459\tBest loss: 1.610206\tAccuracy: 19.08%\n",
      "19\tValidation loss: 1.640391\tBest loss: 1.610206\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.620359\tBest loss: 1.610206\tAccuracy: 18.73%\n",
      "21\tValidation loss: 1.649628\tBest loss: 1.610206\tAccuracy: 19.08%\n",
      "22\tValidation loss: 1.637530\tBest loss: 1.610206\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.622783\tBest loss: 1.610206\tAccuracy: 19.27%\n",
      "24\tValidation loss: 1.615558\tBest loss: 1.610206\tAccuracy: 19.08%\n",
      "25\tValidation loss: 1.638159\tBest loss: 1.610206\tAccuracy: 19.27%\n",
      "26\tValidation loss: 1.616934\tBest loss: 1.610206\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=10, activation=<function relu at 0x7fabf3f8d0d0>, total= 2.3min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=10, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.613202\tBest loss: 1.613202\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.616420\tBest loss: 1.613202\tAccuracy: 18.73%\n",
      "2\tValidation loss: 1.620659\tBest loss: 1.613202\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.611295\tBest loss: 1.611295\tAccuracy: 20.91%\n",
      "4\tValidation loss: 1.625675\tBest loss: 1.611295\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.612059\tBest loss: 1.611295\tAccuracy: 19.08%\n",
      "6\tValidation loss: 1.625974\tBest loss: 1.611295\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.614816\tBest loss: 1.611295\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.627533\tBest loss: 1.611295\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.619027\tBest loss: 1.611295\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.624332\tBest loss: 1.611295\tAccuracy: 19.08%\n",
      "11\tValidation loss: 1.622442\tBest loss: 1.611295\tAccuracy: 20.91%\n",
      "12\tValidation loss: 1.619989\tBest loss: 1.611295\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.640651\tBest loss: 1.611295\tAccuracy: 18.73%\n",
      "14\tValidation loss: 1.618694\tBest loss: 1.611295\tAccuracy: 20.91%\n",
      "15\tValidation loss: 1.624425\tBest loss: 1.611295\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.641113\tBest loss: 1.611295\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.611041\tBest loss: 1.611041\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.624193\tBest loss: 1.611041\tAccuracy: 18.73%\n",
      "19\tValidation loss: 1.640716\tBest loss: 1.611041\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.626724\tBest loss: 1.611041\tAccuracy: 19.27%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=55), param_distribs, n_iter=50,\n",
    "                                cv=3, random_state=55, verbose=2, n_jobs=-1)\n",
    "rnd_search.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "\n",
    "# If you have Scikit-Learn 0.18 or earlier, you should upgrade, or use the fit_params argument:\n",
    "# fit_params = dict(X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "# rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "#                                 fit_params=fit_params, random_state=42, verbose=2)\n",
    "# rnd_search.fit(X_train1, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 50,\n",
       " 'learning_rate': 0.01,\n",
       " 'batch_size': 100,\n",
       " 'activation': <function __main__.leaky_relu.<locals>.parametrized_leaky_relu(z, name=None)>}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852111305701499"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_estimator_.save(\"./models/my_best_mnist_model_0_to_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.尝试添加批量归一化来对比学习曲线：是否比之前收敛得快？是否构建了一个更好的模型？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.086617\tBest loss: 0.086617\tAccuracy: 97.50%\n",
      "1\tValidation loss: 0.068906\tBest loss: 0.068906\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.048210\tBest loss: 0.048210\tAccuracy: 98.32%\n",
      "3\tValidation loss: 0.061887\tBest loss: 0.048210\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.051874\tBest loss: 0.048210\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.042459\tBest loss: 0.042459\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.043500\tBest loss: 0.042459\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.047271\tBest loss: 0.042459\tAccuracy: 98.71%\n",
      "8\tValidation loss: 0.044797\tBest loss: 0.042459\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.053848\tBest loss: 0.042459\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.060443\tBest loss: 0.042459\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.047712\tBest loss: 0.042459\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.040458\tBest loss: 0.040458\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.064702\tBest loss: 0.040458\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.052317\tBest loss: 0.040458\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.046847\tBest loss: 0.040458\tAccuracy: 99.10%\n",
      "16\tValidation loss: 0.039897\tBest loss: 0.039897\tAccuracy: 98.94%\n",
      "17\tValidation loss: 0.051915\tBest loss: 0.039897\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.064340\tBest loss: 0.039897\tAccuracy: 98.67%\n",
      "19\tValidation loss: 0.050496\tBest loss: 0.039897\tAccuracy: 99.02%\n",
      "20\tValidation loss: 0.046605\tBest loss: 0.039897\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.073093\tBest loss: 0.039897\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.086405\tBest loss: 0.039897\tAccuracy: 98.91%\n",
      "23\tValidation loss: 6.986340\tBest loss: 0.039897\tAccuracy: 89.72%\n",
      "24\tValidation loss: 0.644885\tBest loss: 0.039897\tAccuracy: 96.99%\n",
      "25\tValidation loss: 0.262678\tBest loss: 0.039897\tAccuracy: 97.07%\n",
      "26\tValidation loss: 0.244291\tBest loss: 0.039897\tAccuracy: 97.42%\n",
      "27\tValidation loss: 0.192820\tBest loss: 0.039897\tAccuracy: 97.50%\n",
      "28\tValidation loss: 0.168504\tBest loss: 0.039897\tAccuracy: 97.73%\n",
      "29\tValidation loss: 0.139454\tBest loss: 0.039897\tAccuracy: 98.20%\n",
      "30\tValidation loss: 0.119820\tBest loss: 0.039897\tAccuracy: 98.40%\n",
      "31\tValidation loss: 0.110364\tBest loss: 0.039897\tAccuracy: 98.36%\n",
      "32\tValidation loss: 0.102987\tBest loss: 0.039897\tAccuracy: 98.48%\n",
      "33\tValidation loss: 0.099688\tBest loss: 0.039897\tAccuracy: 98.44%\n",
      "34\tValidation loss: 0.114240\tBest loss: 0.039897\tAccuracy: 98.20%\n",
      "35\tValidation loss: 0.105393\tBest loss: 0.039897\tAccuracy: 98.32%\n",
      "36\tValidation loss: 0.100523\tBest loss: 0.039897\tAccuracy: 98.36%\n",
      "37\tValidation loss: 0.105026\tBest loss: 0.039897\tAccuracy: 98.36%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7c0a0670>,\n",
       "              batch_size=500, n_neurons=140, random_state=55)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                        n_neurons=140, random_state=55)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910488421871959"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.055476\tBest loss: 0.055476\tAccuracy: 98.51%\n",
      "1\tValidation loss: 0.044804\tBest loss: 0.044804\tAccuracy: 98.59%\n",
      "2\tValidation loss: 0.040734\tBest loss: 0.040734\tAccuracy: 98.67%\n",
      "3\tValidation loss: 0.033411\tBest loss: 0.033411\tAccuracy: 99.02%\n",
      "4\tValidation loss: 0.031255\tBest loss: 0.031255\tAccuracy: 99.02%\n",
      "5\tValidation loss: 0.041427\tBest loss: 0.031255\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.033339\tBest loss: 0.031255\tAccuracy: 99.22%\n",
      "7\tValidation loss: 0.042179\tBest loss: 0.031255\tAccuracy: 98.87%\n",
      "8\tValidation loss: 0.044984\tBest loss: 0.031255\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.034495\tBest loss: 0.031255\tAccuracy: 99.06%\n",
      "10\tValidation loss: 0.068000\tBest loss: 0.031255\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.043354\tBest loss: 0.031255\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.027831\tBest loss: 0.027831\tAccuracy: 99.30%\n",
      "13\tValidation loss: 0.041782\tBest loss: 0.027831\tAccuracy: 98.98%\n",
      "14\tValidation loss: 0.024408\tBest loss: 0.024408\tAccuracy: 99.41%\n",
      "15\tValidation loss: 0.044278\tBest loss: 0.024408\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.036365\tBest loss: 0.024408\tAccuracy: 99.14%\n",
      "17\tValidation loss: 0.029400\tBest loss: 0.024408\tAccuracy: 99.30%\n",
      "18\tValidation loss: 0.028659\tBest loss: 0.024408\tAccuracy: 99.26%\n",
      "19\tValidation loss: 0.044551\tBest loss: 0.024408\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.038819\tBest loss: 0.024408\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.024504\tBest loss: 0.024408\tAccuracy: 99.37%\n",
      "22\tValidation loss: 0.025126\tBest loss: 0.024408\tAccuracy: 99.49%\n",
      "23\tValidation loss: 0.034213\tBest loss: 0.024408\tAccuracy: 99.22%\n",
      "24\tValidation loss: 0.042332\tBest loss: 0.024408\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.050045\tBest loss: 0.024408\tAccuracy: 99.22%\n",
      "26\tValidation loss: 0.030678\tBest loss: 0.024408\tAccuracy: 99.45%\n",
      "27\tValidation loss: 0.053651\tBest loss: 0.024408\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.034615\tBest loss: 0.024408\tAccuracy: 99.18%\n",
      "29\tValidation loss: 0.048624\tBest loss: 0.024408\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.042129\tBest loss: 0.024408\tAccuracy: 99.10%\n",
      "31\tValidation loss: 0.026774\tBest loss: 0.024408\tAccuracy: 99.37%\n",
      "32\tValidation loss: 0.029187\tBest loss: 0.024408\tAccuracy: 99.34%\n",
      "33\tValidation loss: 0.034840\tBest loss: 0.024408\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.030862\tBest loss: 0.024408\tAccuracy: 99.30%\n",
      "35\tValidation loss: 0.039711\tBest loss: 0.024408\tAccuracy: 99.10%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7c0a0ca0>,\n",
       "              batch_norm_momentum=0.95, batch_size=500, n_neurons=90,\n",
       "              random_state=55)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_bn = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                           n_neurons=90, random_state=55,\n",
    "                           batch_norm_momentum=0.95)\n",
    "dnn_clf_bn.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935785172212492"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_bn.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] n_neurons=160, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.085469\tBest loss: 0.085469\tAccuracy: 97.46%\n",
      "1\tValidation loss: 0.077867\tBest loss: 0.077867\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.071089\tBest loss: 0.071089\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.062372\tBest loss: 0.062372\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.052644\tBest loss: 0.052644\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.068663\tBest loss: 0.052644\tAccuracy: 98.24%\n",
      "6\tValidation loss: 0.063452\tBest loss: 0.052644\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.069047\tBest loss: 0.052644\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.048476\tBest loss: 0.048476\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.044991\tBest loss: 0.044991\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.060642\tBest loss: 0.044991\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.065435\tBest loss: 0.044991\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.074897\tBest loss: 0.044991\tAccuracy: 98.44%\n",
      "13\tValidation loss: 0.092807\tBest loss: 0.044991\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.069866\tBest loss: 0.044991\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.051524\tBest loss: 0.044991\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.073304\tBest loss: 0.044991\tAccuracy: 98.40%\n",
      "17\tValidation loss: 0.059747\tBest loss: 0.044991\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.074099\tBest loss: 0.044991\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.132523\tBest loss: 0.044991\tAccuracy: 97.11%\n",
      "20\tValidation loss: 0.250143\tBest loss: 0.044991\tAccuracy: 96.05%\n",
      "21\tValidation loss: 0.097212\tBest loss: 0.044991\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.063130\tBest loss: 0.044991\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.036608\tBest loss: 0.036608\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.039754\tBest loss: 0.036608\tAccuracy: 99.18%\n",
      "25\tValidation loss: 0.059406\tBest loss: 0.036608\tAccuracy: 98.94%\n",
      "26\tValidation loss: 0.059030\tBest loss: 0.036608\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.047759\tBest loss: 0.036608\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.055971\tBest loss: 0.036608\tAccuracy: 99.18%\n",
      "29\tValidation loss: 0.070774\tBest loss: 0.036608\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.180232\tBest loss: 0.036608\tAccuracy: 98.08%\n",
      "31\tValidation loss: 0.154309\tBest loss: 0.036608\tAccuracy: 98.40%\n",
      "32\tValidation loss: 0.092871\tBest loss: 0.036608\tAccuracy: 98.48%\n",
      "33\tValidation loss: 0.075826\tBest loss: 0.036608\tAccuracy: 98.98%\n",
      "34\tValidation loss: 0.063070\tBest loss: 0.036608\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.065147\tBest loss: 0.036608\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.062772\tBest loss: 0.036608\tAccuracy: 99.06%\n",
      "37\tValidation loss: 0.062816\tBest loss: 0.036608\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.077371\tBest loss: 0.036608\tAccuracy: 99.22%\n",
      "39\tValidation loss: 0.066614\tBest loss: 0.036608\tAccuracy: 99.02%\n",
      "40\tValidation loss: 0.082086\tBest loss: 0.036608\tAccuracy: 99.18%\n",
      "41\tValidation loss: 0.091385\tBest loss: 0.036608\tAccuracy: 99.14%\n",
      "42\tValidation loss: 0.096971\tBest loss: 0.036608\tAccuracy: 98.75%\n",
      "43\tValidation loss: 0.153408\tBest loss: 0.036608\tAccuracy: 98.59%\n",
      "44\tValidation loss: 0.081992\tBest loss: 0.036608\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 2.2min\n",
      "[CV] n_neurons=160, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.096340\tBest loss: 0.096340\tAccuracy: 97.03%\n",
      "1\tValidation loss: 0.081872\tBest loss: 0.081872\tAccuracy: 97.26%\n",
      "2\tValidation loss: 0.053235\tBest loss: 0.053235\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.050510\tBest loss: 0.050510\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.054943\tBest loss: 0.050510\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.045834\tBest loss: 0.045834\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.057908\tBest loss: 0.045834\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.047251\tBest loss: 0.045834\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.076391\tBest loss: 0.045834\tAccuracy: 98.05%\n",
      "9\tValidation loss: 0.069281\tBest loss: 0.045834\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.050454\tBest loss: 0.045834\tAccuracy: 99.06%\n",
      "11\tValidation loss: 0.053654\tBest loss: 0.045834\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.061859\tBest loss: 0.045834\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.059091\tBest loss: 0.045834\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.084940\tBest loss: 0.045834\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.099396\tBest loss: 0.045834\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.051255\tBest loss: 0.045834\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.054685\tBest loss: 0.045834\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.041394\tBest loss: 0.041394\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.054287\tBest loss: 0.041394\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.056992\tBest loss: 0.041394\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.077446\tBest loss: 0.041394\tAccuracy: 98.28%\n",
      "22\tValidation loss: 0.068497\tBest loss: 0.041394\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.084537\tBest loss: 0.041394\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.098924\tBest loss: 0.041394\tAccuracy: 98.55%\n",
      "25\tValidation loss: 0.063427\tBest loss: 0.041394\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.071591\tBest loss: 0.041394\tAccuracy: 98.75%\n",
      "27\tValidation loss: 0.055328\tBest loss: 0.041394\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.057148\tBest loss: 0.041394\tAccuracy: 98.98%\n",
      "29\tValidation loss: 0.069962\tBest loss: 0.041394\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.060042\tBest loss: 0.041394\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.058480\tBest loss: 0.041394\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.054922\tBest loss: 0.041394\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.053145\tBest loss: 0.041394\tAccuracy: 99.10%\n",
      "34\tValidation loss: 0.042188\tBest loss: 0.041394\tAccuracy: 99.26%\n",
      "35\tValidation loss: 0.179092\tBest loss: 0.041394\tAccuracy: 98.24%\n",
      "36\tValidation loss: 0.109146\tBest loss: 0.041394\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.053421\tBest loss: 0.041394\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.075110\tBest loss: 0.041394\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.060907\tBest loss: 0.041394\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 2.0min\n",
      "[CV] n_neurons=160, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.087232\tBest loss: 0.087232\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.063461\tBest loss: 0.063461\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.058723\tBest loss: 0.058723\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.043017\tBest loss: 0.043017\tAccuracy: 98.75%\n",
      "4\tValidation loss: 0.045732\tBest loss: 0.043017\tAccuracy: 98.91%\n",
      "5\tValidation loss: 0.078997\tBest loss: 0.043017\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.054255\tBest loss: 0.043017\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.036762\tBest loss: 0.036762\tAccuracy: 99.14%\n",
      "8\tValidation loss: 0.085087\tBest loss: 0.036762\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.042255\tBest loss: 0.036762\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.053678\tBest loss: 0.036762\tAccuracy: 98.79%\n",
      "11\tValidation loss: 0.040961\tBest loss: 0.036762\tAccuracy: 98.98%\n",
      "12\tValidation loss: 0.056993\tBest loss: 0.036762\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.051248\tBest loss: 0.036762\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.045561\tBest loss: 0.036762\tAccuracy: 99.10%\n",
      "15\tValidation loss: 0.082198\tBest loss: 0.036762\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.041101\tBest loss: 0.036762\tAccuracy: 98.94%\n",
      "17\tValidation loss: 0.044065\tBest loss: 0.036762\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.042528\tBest loss: 0.036762\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.041951\tBest loss: 0.036762\tAccuracy: 99.10%\n",
      "20\tValidation loss: 0.064387\tBest loss: 0.036762\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.061588\tBest loss: 0.036762\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.054904\tBest loss: 0.036762\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.354672\tBest loss: 0.036762\tAccuracy: 96.33%\n",
      "24\tValidation loss: 0.093865\tBest loss: 0.036762\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.069843\tBest loss: 0.036762\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.048359\tBest loss: 0.036762\tAccuracy: 99.10%\n",
      "27\tValidation loss: 0.050515\tBest loss: 0.036762\tAccuracy: 99.02%\n",
      "28\tValidation loss: 0.065955\tBest loss: 0.036762\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 1.4min\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.99, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.099200\tBest loss: 0.099200\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.100488\tBest loss: 0.099200\tAccuracy: 96.91%\n",
      "2\tValidation loss: 0.067515\tBest loss: 0.067515\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.097338\tBest loss: 0.067515\tAccuracy: 97.26%\n",
      "4\tValidation loss: 0.065156\tBest loss: 0.065156\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.062425\tBest loss: 0.062425\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.063499\tBest loss: 0.062425\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.061674\tBest loss: 0.061674\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.053650\tBest loss: 0.053650\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.087161\tBest loss: 0.053650\tAccuracy: 97.38%\n",
      "10\tValidation loss: 0.067883\tBest loss: 0.053650\tAccuracy: 97.69%\n",
      "11\tValidation loss: 0.081597\tBest loss: 0.053650\tAccuracy: 97.38%\n",
      "12\tValidation loss: 0.061632\tBest loss: 0.053650\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.046355\tBest loss: 0.046355\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.047208\tBest loss: 0.046355\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.058150\tBest loss: 0.046355\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.046232\tBest loss: 0.046232\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.062269\tBest loss: 0.046232\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.050515\tBest loss: 0.046232\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.049446\tBest loss: 0.046232\tAccuracy: 98.55%\n",
      "20\tValidation loss: 0.047219\tBest loss: 0.046232\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.053891\tBest loss: 0.046232\tAccuracy: 98.20%\n",
      "22\tValidation loss: 0.079643\tBest loss: 0.046232\tAccuracy: 97.62%\n",
      "23\tValidation loss: 0.064231\tBest loss: 0.046232\tAccuracy: 97.89%\n",
      "24\tValidation loss: 0.038905\tBest loss: 0.038905\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.045736\tBest loss: 0.038905\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.042183\tBest loss: 0.038905\tAccuracy: 98.59%\n",
      "27\tValidation loss: 0.042830\tBest loss: 0.038905\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.077540\tBest loss: 0.038905\tAccuracy: 97.65%\n",
      "29\tValidation loss: 0.042103\tBest loss: 0.038905\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.047561\tBest loss: 0.038905\tAccuracy: 98.48%\n",
      "31\tValidation loss: 0.052432\tBest loss: 0.038905\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.045937\tBest loss: 0.038905\tAccuracy: 98.44%\n",
      "33\tValidation loss: 0.055182\tBest loss: 0.038905\tAccuracy: 98.36%\n",
      "34\tValidation loss: 0.053631\tBest loss: 0.038905\tAccuracy: 98.40%\n",
      "35\tValidation loss: 0.052916\tBest loss: 0.038905\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.052062\tBest loss: 0.038905\tAccuracy: 98.48%\n",
      "37\tValidation loss: 0.050895\tBest loss: 0.038905\tAccuracy: 98.55%\n",
      "38\tValidation loss: 0.060947\tBest loss: 0.038905\tAccuracy: 98.44%\n",
      "39\tValidation loss: 0.057688\tBest loss: 0.038905\tAccuracy: 98.51%\n",
      "40\tValidation loss: 0.051928\tBest loss: 0.038905\tAccuracy: 98.79%\n",
      "41\tValidation loss: 0.049416\tBest loss: 0.038905\tAccuracy: 98.83%\n",
      "42\tValidation loss: 0.053799\tBest loss: 0.038905\tAccuracy: 98.44%\n",
      "43\tValidation loss: 0.055086\tBest loss: 0.038905\tAccuracy: 98.79%\n",
      "44\tValidation loss: 0.051022\tBest loss: 0.038905\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.050353\tBest loss: 0.038905\tAccuracy: 98.51%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.99, activation=<function relu at 0x7fabf3f8d0d0>, total= 6.8min\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.99, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.093734\tBest loss: 0.093734\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.080455\tBest loss: 0.080455\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.079456\tBest loss: 0.079456\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.057791\tBest loss: 0.057791\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.065204\tBest loss: 0.057791\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.065218\tBest loss: 0.057791\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.060860\tBest loss: 0.057791\tAccuracy: 97.97%\n",
      "7\tValidation loss: 0.060048\tBest loss: 0.057791\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.084638\tBest loss: 0.057791\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.059884\tBest loss: 0.057791\tAccuracy: 98.20%\n",
      "10\tValidation loss: 0.049172\tBest loss: 0.049172\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.052644\tBest loss: 0.049172\tAccuracy: 98.24%\n",
      "12\tValidation loss: 0.045525\tBest loss: 0.045525\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.053256\tBest loss: 0.045525\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.054427\tBest loss: 0.045525\tAccuracy: 98.32%\n",
      "15\tValidation loss: 0.061249\tBest loss: 0.045525\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.048284\tBest loss: 0.045525\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.054299\tBest loss: 0.045525\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.059442\tBest loss: 0.045525\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.049667\tBest loss: 0.045525\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.046094\tBest loss: 0.045525\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.063062\tBest loss: 0.045525\tAccuracy: 97.93%\n",
      "22\tValidation loss: 0.037724\tBest loss: 0.037724\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.048321\tBest loss: 0.037724\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.043588\tBest loss: 0.037724\tAccuracy: 98.63%\n",
      "25\tValidation loss: 0.058470\tBest loss: 0.037724\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.050882\tBest loss: 0.037724\tAccuracy: 98.59%\n",
      "27\tValidation loss: 0.042954\tBest loss: 0.037724\tAccuracy: 98.55%\n",
      "28\tValidation loss: 0.045622\tBest loss: 0.037724\tAccuracy: 98.48%\n",
      "29\tValidation loss: 0.050646\tBest loss: 0.037724\tAccuracy: 98.63%\n",
      "30\tValidation loss: 0.052921\tBest loss: 0.037724\tAccuracy: 98.51%\n",
      "31\tValidation loss: 0.055702\tBest loss: 0.037724\tAccuracy: 98.36%\n",
      "32\tValidation loss: 0.061424\tBest loss: 0.037724\tAccuracy: 98.32%\n",
      "33\tValidation loss: 0.046522\tBest loss: 0.037724\tAccuracy: 98.40%\n",
      "34\tValidation loss: 0.052535\tBest loss: 0.037724\tAccuracy: 98.36%\n",
      "35\tValidation loss: 0.072976\tBest loss: 0.037724\tAccuracy: 98.24%\n",
      "36\tValidation loss: 0.049789\tBest loss: 0.037724\tAccuracy: 98.55%\n",
      "37\tValidation loss: 0.046559\tBest loss: 0.037724\tAccuracy: 98.59%\n",
      "38\tValidation loss: 0.045873\tBest loss: 0.037724\tAccuracy: 98.63%\n",
      "39\tValidation loss: 0.045776\tBest loss: 0.037724\tAccuracy: 98.79%\n",
      "40\tValidation loss: 0.052148\tBest loss: 0.037724\tAccuracy: 98.48%\n",
      "41\tValidation loss: 0.050181\tBest loss: 0.037724\tAccuracy: 98.67%\n",
      "42\tValidation loss: 0.059116\tBest loss: 0.037724\tAccuracy: 98.12%\n",
      "43\tValidation loss: 0.048442\tBest loss: 0.037724\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.99, activation=<function relu at 0x7fabf3f8d0d0>, total= 6.6min\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.99, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.137117\tBest loss: 0.137117\tAccuracy: 95.54%\n",
      "1\tValidation loss: 0.107617\tBest loss: 0.107617\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.079742\tBest loss: 0.079742\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.086574\tBest loss: 0.079742\tAccuracy: 97.65%\n",
      "4\tValidation loss: 0.068433\tBest loss: 0.068433\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.070994\tBest loss: 0.068433\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.051651\tBest loss: 0.051651\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.053086\tBest loss: 0.051651\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.053030\tBest loss: 0.051651\tAccuracy: 98.32%\n",
      "9\tValidation loss: 0.045499\tBest loss: 0.045499\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.055223\tBest loss: 0.045499\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.134430\tBest loss: 0.045499\tAccuracy: 95.62%\n",
      "12\tValidation loss: 0.042233\tBest loss: 0.042233\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.049579\tBest loss: 0.042233\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.051577\tBest loss: 0.042233\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.056152\tBest loss: 0.042233\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.049128\tBest loss: 0.042233\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.053579\tBest loss: 0.042233\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.041516\tBest loss: 0.041516\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.051711\tBest loss: 0.041516\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.042065\tBest loss: 0.041516\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.044756\tBest loss: 0.041516\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.041901\tBest loss: 0.041516\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.045707\tBest loss: 0.041516\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.032634\tBest loss: 0.032634\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.044583\tBest loss: 0.032634\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.035150\tBest loss: 0.032634\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.038038\tBest loss: 0.032634\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.040932\tBest loss: 0.032634\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.043135\tBest loss: 0.032634\tAccuracy: 98.83%\n",
      "30\tValidation loss: 0.039239\tBest loss: 0.032634\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.052126\tBest loss: 0.032634\tAccuracy: 98.59%\n",
      "32\tValidation loss: 0.048485\tBest loss: 0.032634\tAccuracy: 98.63%\n",
      "33\tValidation loss: 0.045341\tBest loss: 0.032634\tAccuracy: 98.67%\n",
      "34\tValidation loss: 0.071380\tBest loss: 0.032634\tAccuracy: 98.32%\n",
      "35\tValidation loss: 0.079536\tBest loss: 0.032634\tAccuracy: 97.69%\n",
      "36\tValidation loss: 0.038032\tBest loss: 0.032634\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.043204\tBest loss: 0.032634\tAccuracy: 98.91%\n",
      "38\tValidation loss: 0.049429\tBest loss: 0.032634\tAccuracy: 98.36%\n",
      "39\tValidation loss: 0.044613\tBest loss: 0.032634\tAccuracy: 98.71%\n",
      "40\tValidation loss: 0.052709\tBest loss: 0.032634\tAccuracy: 98.75%\n",
      "41\tValidation loss: 0.061507\tBest loss: 0.032634\tAccuracy: 98.12%\n",
      "42\tValidation loss: 0.055455\tBest loss: 0.032634\tAccuracy: 98.71%\n",
      "43\tValidation loss: 0.048473\tBest loss: 0.032634\tAccuracy: 98.79%\n",
      "44\tValidation loss: 0.053207\tBest loss: 0.032634\tAccuracy: 98.75%\n",
      "45\tValidation loss: 0.044056\tBest loss: 0.032634\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.99, activation=<function relu at 0x7fabf3f8d0d0>, total= 6.8min\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.082884\tBest loss: 0.082884\tAccuracy: 97.58%\n",
      "1\tValidation loss: 0.116024\tBest loss: 0.082884\tAccuracy: 96.91%\n",
      "2\tValidation loss: 0.069919\tBest loss: 0.069919\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.118099\tBest loss: 0.069919\tAccuracy: 96.60%\n",
      "4\tValidation loss: 0.054552\tBest loss: 0.054552\tAccuracy: 98.55%\n",
      "5\tValidation loss: 0.088536\tBest loss: 0.054552\tAccuracy: 97.85%\n",
      "6\tValidation loss: 0.068437\tBest loss: 0.054552\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.106170\tBest loss: 0.054552\tAccuracy: 97.58%\n",
      "8\tValidation loss: 0.048412\tBest loss: 0.048412\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.092448\tBest loss: 0.048412\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.095444\tBest loss: 0.048412\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.061413\tBest loss: 0.048412\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.058413\tBest loss: 0.048412\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.052187\tBest loss: 0.048412\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.385340\tBest loss: 0.048412\tAccuracy: 96.52%\n",
      "15\tValidation loss: 0.085689\tBest loss: 0.048412\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.046016\tBest loss: 0.046016\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.076760\tBest loss: 0.046016\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.129715\tBest loss: 0.046016\tAccuracy: 99.06%\n",
      "19\tValidation loss: 0.130179\tBest loss: 0.046016\tAccuracy: 98.28%\n",
      "20\tValidation loss: 0.062958\tBest loss: 0.046016\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.048937\tBest loss: 0.046016\tAccuracy: 99.22%\n",
      "22\tValidation loss: 0.046616\tBest loss: 0.046016\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.064986\tBest loss: 0.046016\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.057632\tBest loss: 0.046016\tAccuracy: 98.94%\n",
      "25\tValidation loss: 0.191549\tBest loss: 0.046016\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.076673\tBest loss: 0.046016\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.054863\tBest loss: 0.046016\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.054388\tBest loss: 0.046016\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.043131\tBest loss: 0.043131\tAccuracy: 99.14%\n",
      "30\tValidation loss: 0.184209\tBest loss: 0.043131\tAccuracy: 98.16%\n",
      "31\tValidation loss: 0.114208\tBest loss: 0.043131\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.061443\tBest loss: 0.043131\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.047874\tBest loss: 0.043131\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.038779\tBest loss: 0.038779\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.058317\tBest loss: 0.038779\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.072907\tBest loss: 0.038779\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.171316\tBest loss: 0.038779\tAccuracy: 98.16%\n",
      "38\tValidation loss: 0.119005\tBest loss: 0.038779\tAccuracy: 98.75%\n",
      "39\tValidation loss: 0.103485\tBest loss: 0.038779\tAccuracy: 98.79%\n",
      "40\tValidation loss: 0.093953\tBest loss: 0.038779\tAccuracy: 98.51%\n",
      "41\tValidation loss: 0.139187\tBest loss: 0.038779\tAccuracy: 98.59%\n",
      "42\tValidation loss: 0.276910\tBest loss: 0.038779\tAccuracy: 98.28%\n",
      "43\tValidation loss: 0.101011\tBest loss: 0.038779\tAccuracy: 98.91%\n",
      "44\tValidation loss: 0.076966\tBest loss: 0.038779\tAccuracy: 99.14%\n",
      "45\tValidation loss: 0.076787\tBest loss: 0.038779\tAccuracy: 99.26%\n",
      "46\tValidation loss: 0.067000\tBest loss: 0.038779\tAccuracy: 99.34%\n",
      "47\tValidation loss: 0.070710\tBest loss: 0.038779\tAccuracy: 99.14%\n",
      "48\tValidation loss: 0.082559\tBest loss: 0.038779\tAccuracy: 99.14%\n",
      "49\tValidation loss: 0.089058\tBest loss: 0.038779\tAccuracy: 98.75%\n",
      "50\tValidation loss: 0.141016\tBest loss: 0.038779\tAccuracy: 98.12%\n",
      "51\tValidation loss: 0.229424\tBest loss: 0.038779\tAccuracy: 98.08%\n",
      "52\tValidation loss: 0.096831\tBest loss: 0.038779\tAccuracy: 98.98%\n",
      "53\tValidation loss: 0.085464\tBest loss: 0.038779\tAccuracy: 98.94%\n",
      "54\tValidation loss: 0.062187\tBest loss: 0.038779\tAccuracy: 98.94%\n",
      "55\tValidation loss: 0.062001\tBest loss: 0.038779\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0>, total= 3.0min\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.102199\tBest loss: 0.102199\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.083803\tBest loss: 0.083803\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.063444\tBest loss: 0.063444\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.067046\tBest loss: 0.063444\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.090738\tBest loss: 0.063444\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.062874\tBest loss: 0.062874\tAccuracy: 98.24%\n",
      "6\tValidation loss: 0.066463\tBest loss: 0.062874\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.070409\tBest loss: 0.062874\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.057048\tBest loss: 0.057048\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.142558\tBest loss: 0.057048\tAccuracy: 96.83%\n",
      "10\tValidation loss: 0.068142\tBest loss: 0.057048\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.075357\tBest loss: 0.057048\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.066580\tBest loss: 0.057048\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.046413\tBest loss: 0.046413\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.051215\tBest loss: 0.046413\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.089359\tBest loss: 0.046413\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.239905\tBest loss: 0.046413\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.058248\tBest loss: 0.046413\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.037381\tBest loss: 0.037381\tAccuracy: 99.06%\n",
      "19\tValidation loss: 0.048597\tBest loss: 0.037381\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.053244\tBest loss: 0.037381\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.053030\tBest loss: 0.037381\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.058324\tBest loss: 0.037381\tAccuracy: 98.67%\n",
      "23\tValidation loss: 0.053787\tBest loss: 0.037381\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.081858\tBest loss: 0.037381\tAccuracy: 98.28%\n",
      "25\tValidation loss: 0.077440\tBest loss: 0.037381\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.064612\tBest loss: 0.037381\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.042033\tBest loss: 0.037381\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.047301\tBest loss: 0.037381\tAccuracy: 99.06%\n",
      "29\tValidation loss: 0.047919\tBest loss: 0.037381\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.060927\tBest loss: 0.037381\tAccuracy: 99.06%\n",
      "31\tValidation loss: 0.058305\tBest loss: 0.037381\tAccuracy: 99.06%\n",
      "32\tValidation loss: 0.052093\tBest loss: 0.037381\tAccuracy: 99.30%\n",
      "33\tValidation loss: 0.088109\tBest loss: 0.037381\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.048528\tBest loss: 0.037381\tAccuracy: 98.87%\n",
      "35\tValidation loss: 0.049181\tBest loss: 0.037381\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.062985\tBest loss: 0.037381\tAccuracy: 98.94%\n",
      "37\tValidation loss: 0.178078\tBest loss: 0.037381\tAccuracy: 98.28%\n",
      "38\tValidation loss: 0.149772\tBest loss: 0.037381\tAccuracy: 98.63%\n",
      "39\tValidation loss: 0.097308\tBest loss: 0.037381\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0>, total= 2.1min\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.115297\tBest loss: 0.115297\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.077355\tBest loss: 0.077355\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.071668\tBest loss: 0.071668\tAccuracy: 98.40%\n",
      "3\tValidation loss: 0.054684\tBest loss: 0.054684\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.077129\tBest loss: 0.054684\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.069832\tBest loss: 0.054684\tAccuracy: 98.24%\n",
      "6\tValidation loss: 0.053969\tBest loss: 0.053969\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.043289\tBest loss: 0.043289\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.085517\tBest loss: 0.043289\tAccuracy: 97.62%\n",
      "9\tValidation loss: 0.054724\tBest loss: 0.043289\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.074247\tBest loss: 0.043289\tAccuracy: 98.08%\n",
      "11\tValidation loss: 0.053367\tBest loss: 0.043289\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.097304\tBest loss: 0.043289\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.051182\tBest loss: 0.043289\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.260077\tBest loss: 0.043289\tAccuracy: 97.42%\n",
      "15\tValidation loss: 0.046521\tBest loss: 0.043289\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.035830\tBest loss: 0.035830\tAccuracy: 99.22%\n",
      "17\tValidation loss: 0.039099\tBest loss: 0.035830\tAccuracy: 99.10%\n",
      "18\tValidation loss: 0.040710\tBest loss: 0.035830\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.061293\tBest loss: 0.035830\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.053310\tBest loss: 0.035830\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.060056\tBest loss: 0.035830\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.061008\tBest loss: 0.035830\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.039766\tBest loss: 0.035830\tAccuracy: 99.18%\n",
      "24\tValidation loss: 0.055398\tBest loss: 0.035830\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.047977\tBest loss: 0.035830\tAccuracy: 98.91%\n",
      "26\tValidation loss: 0.066450\tBest loss: 0.035830\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.127914\tBest loss: 0.035830\tAccuracy: 98.55%\n",
      "28\tValidation loss: 0.042383\tBest loss: 0.035830\tAccuracy: 99.26%\n",
      "29\tValidation loss: 0.038121\tBest loss: 0.035830\tAccuracy: 99.10%\n",
      "30\tValidation loss: 0.062613\tBest loss: 0.035830\tAccuracy: 99.10%\n",
      "31\tValidation loss: 0.090017\tBest loss: 0.035830\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.067071\tBest loss: 0.035830\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.059183\tBest loss: 0.035830\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.046554\tBest loss: 0.035830\tAccuracy: 99.14%\n",
      "35\tValidation loss: 0.096529\tBest loss: 0.035830\tAccuracy: 98.59%\n",
      "36\tValidation loss: 0.076040\tBest loss: 0.035830\tAccuracy: 98.75%\n",
      "37\tValidation loss: 0.068729\tBest loss: 0.035830\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0>, total= 2.0min\n",
      "[CV] n_neurons=120, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 435.648590\tBest loss: 435.648590\tAccuracy: 80.14%\n",
      "1\tValidation loss: 68.625717\tBest loss: 68.625717\tAccuracy: 78.34%\n",
      "2\tValidation loss: 9.995888\tBest loss: 9.995888\tAccuracy: 91.75%\n",
      "3\tValidation loss: 5.809836\tBest loss: 5.809836\tAccuracy: 91.52%\n",
      "4\tValidation loss: 3.115245\tBest loss: 3.115245\tAccuracy: 93.32%\n",
      "5\tValidation loss: 3.828886\tBest loss: 3.115245\tAccuracy: 91.52%\n",
      "6\tValidation loss: 2.572032\tBest loss: 2.572032\tAccuracy: 92.26%\n",
      "7\tValidation loss: 3.370038\tBest loss: 2.572032\tAccuracy: 86.98%\n",
      "8\tValidation loss: 1.541477\tBest loss: 1.541477\tAccuracy: 93.04%\n",
      "9\tValidation loss: 1.385329\tBest loss: 1.385329\tAccuracy: 94.33%\n",
      "10\tValidation loss: 1.341470\tBest loss: 1.341470\tAccuracy: 94.37%\n",
      "11\tValidation loss: 1.220657\tBest loss: 1.220657\tAccuracy: 94.72%\n",
      "12\tValidation loss: 1.592568\tBest loss: 1.220657\tAccuracy: 93.82%\n",
      "13\tValidation loss: 1.372897\tBest loss: 1.220657\tAccuracy: 94.33%\n",
      "14\tValidation loss: 0.876101\tBest loss: 0.876101\tAccuracy: 95.58%\n",
      "15\tValidation loss: 0.641440\tBest loss: 0.641440\tAccuracy: 96.91%\n",
      "16\tValidation loss: 0.430316\tBest loss: 0.430316\tAccuracy: 97.89%\n",
      "17\tValidation loss: 0.460869\tBest loss: 0.430316\tAccuracy: 97.54%\n",
      "18\tValidation loss: 0.510722\tBest loss: 0.430316\tAccuracy: 97.69%\n",
      "19\tValidation loss: 0.472845\tBest loss: 0.430316\tAccuracy: 97.77%\n",
      "20\tValidation loss: 1.023941\tBest loss: 0.430316\tAccuracy: 95.19%\n",
      "21\tValidation loss: 0.490256\tBest loss: 0.430316\tAccuracy: 97.69%\n",
      "22\tValidation loss: 0.356282\tBest loss: 0.356282\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.555847\tBest loss: 0.356282\tAccuracy: 97.38%\n",
      "24\tValidation loss: 0.345566\tBest loss: 0.345566\tAccuracy: 98.28%\n",
      "25\tValidation loss: 0.465548\tBest loss: 0.345566\tAccuracy: 97.89%\n",
      "26\tValidation loss: 0.430789\tBest loss: 0.345566\tAccuracy: 97.30%\n",
      "27\tValidation loss: 0.238142\tBest loss: 0.238142\tAccuracy: 98.40%\n",
      "28\tValidation loss: 0.307413\tBest loss: 0.238142\tAccuracy: 98.36%\n",
      "29\tValidation loss: 0.316483\tBest loss: 0.238142\tAccuracy: 98.44%\n",
      "30\tValidation loss: 0.375739\tBest loss: 0.238142\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.354029\tBest loss: 0.238142\tAccuracy: 98.16%\n",
      "32\tValidation loss: 0.489329\tBest loss: 0.238142\tAccuracy: 97.93%\n",
      "33\tValidation loss: 0.411128\tBest loss: 0.238142\tAccuracy: 97.89%\n",
      "34\tValidation loss: 0.221008\tBest loss: 0.221008\tAccuracy: 98.71%\n",
      "35\tValidation loss: 0.287137\tBest loss: 0.221008\tAccuracy: 98.44%\n",
      "36\tValidation loss: 0.270150\tBest loss: 0.221008\tAccuracy: 98.51%\n",
      "37\tValidation loss: 0.258211\tBest loss: 0.221008\tAccuracy: 98.32%\n",
      "38\tValidation loss: 0.358053\tBest loss: 0.221008\tAccuracy: 97.73%\n",
      "39\tValidation loss: 0.321215\tBest loss: 0.221008\tAccuracy: 98.01%\n",
      "40\tValidation loss: 0.345602\tBest loss: 0.221008\tAccuracy: 97.42%\n",
      "41\tValidation loss: 0.249605\tBest loss: 0.221008\tAccuracy: 98.12%\n",
      "42\tValidation loss: 0.516001\tBest loss: 0.221008\tAccuracy: 97.26%\n",
      "43\tValidation loss: 0.337660\tBest loss: 0.221008\tAccuracy: 98.08%\n",
      "44\tValidation loss: 0.395505\tBest loss: 0.221008\tAccuracy: 97.81%\n",
      "45\tValidation loss: 0.327483\tBest loss: 0.221008\tAccuracy: 98.44%\n",
      "46\tValidation loss: 0.258588\tBest loss: 0.221008\tAccuracy: 98.44%\n",
      "47\tValidation loss: 0.239853\tBest loss: 0.221008\tAccuracy: 98.59%\n",
      "48\tValidation loss: 0.273610\tBest loss: 0.221008\tAccuracy: 98.44%\n",
      "49\tValidation loss: 0.361473\tBest loss: 0.221008\tAccuracy: 98.32%\n",
      "50\tValidation loss: 0.409859\tBest loss: 0.221008\tAccuracy: 97.97%\n",
      "51\tValidation loss: 0.368393\tBest loss: 0.221008\tAccuracy: 98.20%\n",
      "52\tValidation loss: 0.306976\tBest loss: 0.221008\tAccuracy: 98.44%\n",
      "53\tValidation loss: 0.295726\tBest loss: 0.221008\tAccuracy: 98.28%\n",
      "54\tValidation loss: 0.322922\tBest loss: 0.221008\tAccuracy: 98.36%\n",
      "55\tValidation loss: 0.202538\tBest loss: 0.202538\tAccuracy: 98.79%\n",
      "56\tValidation loss: 0.213313\tBest loss: 0.202538\tAccuracy: 98.63%\n",
      "57\tValidation loss: 0.286227\tBest loss: 0.202538\tAccuracy: 98.28%\n",
      "58\tValidation loss: 0.271839\tBest loss: 0.202538\tAccuracy: 98.24%\n",
      "59\tValidation loss: 0.264735\tBest loss: 0.202538\tAccuracy: 98.59%\n",
      "60\tValidation loss: 0.270408\tBest loss: 0.202538\tAccuracy: 98.24%\n",
      "61\tValidation loss: 0.210540\tBest loss: 0.202538\tAccuracy: 98.44%\n",
      "62\tValidation loss: 0.329598\tBest loss: 0.202538\tAccuracy: 97.85%\n",
      "63\tValidation loss: 0.362542\tBest loss: 0.202538\tAccuracy: 98.08%\n",
      "64\tValidation loss: 0.311721\tBest loss: 0.202538\tAccuracy: 98.24%\n",
      "65\tValidation loss: 0.240946\tBest loss: 0.202538\tAccuracy: 98.40%\n",
      "66\tValidation loss: 0.285802\tBest loss: 0.202538\tAccuracy: 98.44%\n",
      "67\tValidation loss: 0.339058\tBest loss: 0.202538\tAccuracy: 98.05%\n",
      "68\tValidation loss: 0.295564\tBest loss: 0.202538\tAccuracy: 98.05%\n",
      "69\tValidation loss: 0.281392\tBest loss: 0.202538\tAccuracy: 98.08%\n",
      "70\tValidation loss: 0.199802\tBest loss: 0.199802\tAccuracy: 98.71%\n",
      "71\tValidation loss: 0.310403\tBest loss: 0.199802\tAccuracy: 98.44%\n",
      "72\tValidation loss: 0.289723\tBest loss: 0.199802\tAccuracy: 98.05%\n",
      "73\tValidation loss: 0.531429\tBest loss: 0.199802\tAccuracy: 97.58%\n",
      "74\tValidation loss: 0.499215\tBest loss: 0.199802\tAccuracy: 97.69%\n",
      "75\tValidation loss: 0.409410\tBest loss: 0.199802\tAccuracy: 97.85%\n",
      "76\tValidation loss: 0.452393\tBest loss: 0.199802\tAccuracy: 97.81%\n",
      "77\tValidation loss: 0.265665\tBest loss: 0.199802\tAccuracy: 98.44%\n",
      "78\tValidation loss: 0.348590\tBest loss: 0.199802\tAccuracy: 98.20%\n",
      "79\tValidation loss: 0.270044\tBest loss: 0.199802\tAccuracy: 98.87%\n",
      "80\tValidation loss: 0.434323\tBest loss: 0.199802\tAccuracy: 97.42%\n",
      "81\tValidation loss: 0.272803\tBest loss: 0.199802\tAccuracy: 98.36%\n",
      "82\tValidation loss: 0.282598\tBest loss: 0.199802\tAccuracy: 98.48%\n",
      "83\tValidation loss: 0.436807\tBest loss: 0.199802\tAccuracy: 97.77%\n",
      "84\tValidation loss: 0.301665\tBest loss: 0.199802\tAccuracy: 98.32%\n",
      "85\tValidation loss: 0.240757\tBest loss: 0.199802\tAccuracy: 98.55%\n",
      "86\tValidation loss: 0.273210\tBest loss: 0.199802\tAccuracy: 98.55%\n",
      "87\tValidation loss: 0.264461\tBest loss: 0.199802\tAccuracy: 98.32%\n",
      "88\tValidation loss: 0.216351\tBest loss: 0.199802\tAccuracy: 98.55%\n",
      "89\tValidation loss: 0.529589\tBest loss: 0.199802\tAccuracy: 97.03%\n",
      "90\tValidation loss: 0.368288\tBest loss: 0.199802\tAccuracy: 98.16%\n",
      "91\tValidation loss: 0.314183\tBest loss: 0.199802\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 1.9min\n",
      "[CV] n_neurons=120, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 475.269836\tBest loss: 475.269836\tAccuracy: 84.71%\n",
      "1\tValidation loss: 69.239197\tBest loss: 69.239197\tAccuracy: 86.12%\n",
      "2\tValidation loss: 19.342642\tBest loss: 19.342642\tAccuracy: 89.13%\n",
      "3\tValidation loss: 8.158511\tBest loss: 8.158511\tAccuracy: 89.56%\n",
      "4\tValidation loss: 4.728618\tBest loss: 4.728618\tAccuracy: 90.85%\n",
      "5\tValidation loss: 2.038071\tBest loss: 2.038071\tAccuracy: 95.54%\n",
      "6\tValidation loss: 1.742099\tBest loss: 1.742099\tAccuracy: 95.54%\n",
      "7\tValidation loss: 0.889330\tBest loss: 0.889330\tAccuracy: 97.22%\n",
      "8\tValidation loss: 1.849344\tBest loss: 0.889330\tAccuracy: 94.25%\n",
      "9\tValidation loss: 1.339045\tBest loss: 0.889330\tAccuracy: 95.62%\n",
      "10\tValidation loss: 0.907359\tBest loss: 0.889330\tAccuracy: 96.79%\n",
      "11\tValidation loss: 0.750854\tBest loss: 0.750854\tAccuracy: 97.22%\n",
      "12\tValidation loss: 0.517941\tBest loss: 0.517941\tAccuracy: 97.65%\n",
      "13\tValidation loss: 0.567706\tBest loss: 0.517941\tAccuracy: 97.54%\n",
      "14\tValidation loss: 1.030679\tBest loss: 0.517941\tAccuracy: 96.25%\n",
      "15\tValidation loss: 0.685782\tBest loss: 0.517941\tAccuracy: 97.46%\n",
      "16\tValidation loss: 0.710730\tBest loss: 0.517941\tAccuracy: 97.42%\n",
      "17\tValidation loss: 0.721895\tBest loss: 0.517941\tAccuracy: 97.34%\n",
      "18\tValidation loss: 0.668540\tBest loss: 0.517941\tAccuracy: 96.87%\n",
      "19\tValidation loss: 0.492428\tBest loss: 0.492428\tAccuracy: 97.77%\n",
      "20\tValidation loss: 0.421824\tBest loss: 0.421824\tAccuracy: 97.81%\n",
      "21\tValidation loss: 0.402200\tBest loss: 0.402200\tAccuracy: 98.01%\n",
      "22\tValidation loss: 0.462846\tBest loss: 0.402200\tAccuracy: 97.50%\n",
      "23\tValidation loss: 0.619325\tBest loss: 0.402200\tAccuracy: 96.79%\n",
      "24\tValidation loss: 0.444361\tBest loss: 0.402200\tAccuracy: 98.16%\n",
      "25\tValidation loss: 0.412035\tBest loss: 0.402200\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.381911\tBest loss: 0.381911\tAccuracy: 97.97%\n",
      "27\tValidation loss: 0.283376\tBest loss: 0.283376\tAccuracy: 98.32%\n",
      "28\tValidation loss: 0.332030\tBest loss: 0.283376\tAccuracy: 98.28%\n",
      "29\tValidation loss: 0.389111\tBest loss: 0.283376\tAccuracy: 97.50%\n",
      "30\tValidation loss: 0.494335\tBest loss: 0.283376\tAccuracy: 97.34%\n",
      "31\tValidation loss: 0.237507\tBest loss: 0.237507\tAccuracy: 98.44%\n",
      "32\tValidation loss: 0.311995\tBest loss: 0.237507\tAccuracy: 97.97%\n",
      "33\tValidation loss: 0.268467\tBest loss: 0.237507\tAccuracy: 98.36%\n",
      "34\tValidation loss: 0.247248\tBest loss: 0.237507\tAccuracy: 98.36%\n",
      "35\tValidation loss: 0.355463\tBest loss: 0.237507\tAccuracy: 97.89%\n",
      "36\tValidation loss: 0.262782\tBest loss: 0.237507\tAccuracy: 97.97%\n",
      "37\tValidation loss: 0.272464\tBest loss: 0.237507\tAccuracy: 98.05%\n",
      "38\tValidation loss: 0.265433\tBest loss: 0.237507\tAccuracy: 98.40%\n",
      "39\tValidation loss: 0.276560\tBest loss: 0.237507\tAccuracy: 98.28%\n",
      "40\tValidation loss: 0.260641\tBest loss: 0.237507\tAccuracy: 98.44%\n",
      "41\tValidation loss: 0.188229\tBest loss: 0.188229\tAccuracy: 98.75%\n",
      "42\tValidation loss: 0.172017\tBest loss: 0.172017\tAccuracy: 98.98%\n",
      "43\tValidation loss: 0.166643\tBest loss: 0.166643\tAccuracy: 98.75%\n",
      "44\tValidation loss: 0.510973\tBest loss: 0.166643\tAccuracy: 97.11%\n",
      "45\tValidation loss: 0.227491\tBest loss: 0.166643\tAccuracy: 98.51%\n",
      "46\tValidation loss: 0.355165\tBest loss: 0.166643\tAccuracy: 97.65%\n",
      "47\tValidation loss: 0.240675\tBest loss: 0.166643\tAccuracy: 98.32%\n",
      "48\tValidation loss: 0.329049\tBest loss: 0.166643\tAccuracy: 97.81%\n",
      "49\tValidation loss: 0.408812\tBest loss: 0.166643\tAccuracy: 97.50%\n",
      "50\tValidation loss: 0.244049\tBest loss: 0.166643\tAccuracy: 98.44%\n",
      "51\tValidation loss: 0.199472\tBest loss: 0.166643\tAccuracy: 98.59%\n",
      "52\tValidation loss: 0.229254\tBest loss: 0.166643\tAccuracy: 98.36%\n",
      "53\tValidation loss: 0.220235\tBest loss: 0.166643\tAccuracy: 98.36%\n",
      "54\tValidation loss: 0.193924\tBest loss: 0.166643\tAccuracy: 98.59%\n",
      "55\tValidation loss: 0.158187\tBest loss: 0.158187\tAccuracy: 98.94%\n",
      "56\tValidation loss: 0.155056\tBest loss: 0.155056\tAccuracy: 98.75%\n",
      "57\tValidation loss: 0.171260\tBest loss: 0.155056\tAccuracy: 98.79%\n",
      "58\tValidation loss: 0.216897\tBest loss: 0.155056\tAccuracy: 98.67%\n",
      "59\tValidation loss: 0.186309\tBest loss: 0.155056\tAccuracy: 98.83%\n",
      "60\tValidation loss: 0.184083\tBest loss: 0.155056\tAccuracy: 98.59%\n",
      "61\tValidation loss: 0.145654\tBest loss: 0.145654\tAccuracy: 98.98%\n",
      "62\tValidation loss: 0.166285\tBest loss: 0.145654\tAccuracy: 98.63%\n",
      "63\tValidation loss: 0.226442\tBest loss: 0.145654\tAccuracy: 98.55%\n",
      "64\tValidation loss: 0.199007\tBest loss: 0.145654\tAccuracy: 98.87%\n",
      "65\tValidation loss: 0.267810\tBest loss: 0.145654\tAccuracy: 98.05%\n",
      "66\tValidation loss: 0.260982\tBest loss: 0.145654\tAccuracy: 98.40%\n",
      "67\tValidation loss: 0.235380\tBest loss: 0.145654\tAccuracy: 98.16%\n",
      "68\tValidation loss: 0.317844\tBest loss: 0.145654\tAccuracy: 98.24%\n",
      "69\tValidation loss: 0.246372\tBest loss: 0.145654\tAccuracy: 98.59%\n",
      "70\tValidation loss: 0.341836\tBest loss: 0.145654\tAccuracy: 98.12%\n",
      "71\tValidation loss: 0.254659\tBest loss: 0.145654\tAccuracy: 98.55%\n",
      "72\tValidation loss: 0.229769\tBest loss: 0.145654\tAccuracy: 98.36%\n",
      "73\tValidation loss: 0.267931\tBest loss: 0.145654\tAccuracy: 98.24%\n",
      "74\tValidation loss: 0.235572\tBest loss: 0.145654\tAccuracy: 98.75%\n",
      "75\tValidation loss: 0.210709\tBest loss: 0.145654\tAccuracy: 98.98%\n",
      "76\tValidation loss: 0.324441\tBest loss: 0.145654\tAccuracy: 98.28%\n",
      "77\tValidation loss: 0.269115\tBest loss: 0.145654\tAccuracy: 98.48%\n",
      "78\tValidation loss: 0.280131\tBest loss: 0.145654\tAccuracy: 98.28%\n",
      "79\tValidation loss: 0.258854\tBest loss: 0.145654\tAccuracy: 98.40%\n",
      "80\tValidation loss: 0.282692\tBest loss: 0.145654\tAccuracy: 98.24%\n",
      "81\tValidation loss: 0.239124\tBest loss: 0.145654\tAccuracy: 98.51%\n",
      "82\tValidation loss: 0.202306\tBest loss: 0.145654\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 1.7min\n",
      "[CV] n_neurons=120, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 896.878296\tBest loss: 896.878296\tAccuracy: 76.78%\n",
      "1\tValidation loss: 57.990746\tBest loss: 57.990746\tAccuracy: 87.29%\n",
      "2\tValidation loss: 14.138380\tBest loss: 14.138380\tAccuracy: 92.06%\n",
      "3\tValidation loss: 7.656734\tBest loss: 7.656734\tAccuracy: 91.91%\n",
      "4\tValidation loss: 3.339336\tBest loss: 3.339336\tAccuracy: 94.72%\n",
      "5\tValidation loss: 1.749746\tBest loss: 1.749746\tAccuracy: 95.86%\n",
      "6\tValidation loss: 1.133591\tBest loss: 1.133591\tAccuracy: 96.64%\n",
      "7\tValidation loss: 0.990493\tBest loss: 0.990493\tAccuracy: 96.83%\n",
      "8\tValidation loss: 0.886998\tBest loss: 0.886998\tAccuracy: 97.26%\n",
      "9\tValidation loss: 0.594736\tBest loss: 0.594736\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.739691\tBest loss: 0.594736\tAccuracy: 97.07%\n",
      "11\tValidation loss: 0.553575\tBest loss: 0.553575\tAccuracy: 97.62%\n",
      "12\tValidation loss: 0.668366\tBest loss: 0.553575\tAccuracy: 97.34%\n",
      "13\tValidation loss: 0.459563\tBest loss: 0.459563\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.498843\tBest loss: 0.459563\tAccuracy: 98.01%\n",
      "15\tValidation loss: 0.543907\tBest loss: 0.459563\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.449380\tBest loss: 0.449380\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.487981\tBest loss: 0.449380\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.376164\tBest loss: 0.376164\tAccuracy: 98.36%\n",
      "19\tValidation loss: 0.564057\tBest loss: 0.376164\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.613575\tBest loss: 0.376164\tAccuracy: 97.69%\n",
      "21\tValidation loss: 0.471493\tBest loss: 0.376164\tAccuracy: 98.16%\n",
      "22\tValidation loss: 0.423909\tBest loss: 0.376164\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.431799\tBest loss: 0.376164\tAccuracy: 98.05%\n",
      "24\tValidation loss: 0.447604\tBest loss: 0.376164\tAccuracy: 98.12%\n",
      "25\tValidation loss: 0.395976\tBest loss: 0.376164\tAccuracy: 98.20%\n",
      "26\tValidation loss: 0.364997\tBest loss: 0.364997\tAccuracy: 98.01%\n",
      "27\tValidation loss: 0.292758\tBest loss: 0.292758\tAccuracy: 98.63%\n",
      "28\tValidation loss: 0.415810\tBest loss: 0.292758\tAccuracy: 98.44%\n",
      "29\tValidation loss: 0.333459\tBest loss: 0.292758\tAccuracy: 98.44%\n",
      "30\tValidation loss: 0.333665\tBest loss: 0.292758\tAccuracy: 98.32%\n",
      "31\tValidation loss: 0.461702\tBest loss: 0.292758\tAccuracy: 97.93%\n",
      "32\tValidation loss: 0.429450\tBest loss: 0.292758\tAccuracy: 98.01%\n",
      "33\tValidation loss: 0.328172\tBest loss: 0.292758\tAccuracy: 97.93%\n",
      "34\tValidation loss: 0.340743\tBest loss: 0.292758\tAccuracy: 98.01%\n",
      "35\tValidation loss: 0.417007\tBest loss: 0.292758\tAccuracy: 97.77%\n",
      "36\tValidation loss: 0.390652\tBest loss: 0.292758\tAccuracy: 98.12%\n",
      "37\tValidation loss: 0.389654\tBest loss: 0.292758\tAccuracy: 98.16%\n",
      "38\tValidation loss: 0.324843\tBest loss: 0.292758\tAccuracy: 98.67%\n",
      "39\tValidation loss: 0.441108\tBest loss: 0.292758\tAccuracy: 98.08%\n",
      "40\tValidation loss: 0.383956\tBest loss: 0.292758\tAccuracy: 98.24%\n",
      "41\tValidation loss: 0.310190\tBest loss: 0.292758\tAccuracy: 98.51%\n",
      "42\tValidation loss: 0.324019\tBest loss: 0.292758\tAccuracy: 98.32%\n",
      "43\tValidation loss: 0.519788\tBest loss: 0.292758\tAccuracy: 97.46%\n",
      "44\tValidation loss: 0.348661\tBest loss: 0.292758\tAccuracy: 97.81%\n",
      "45\tValidation loss: 0.422631\tBest loss: 0.292758\tAccuracy: 97.77%\n",
      "46\tValidation loss: 0.323634\tBest loss: 0.292758\tAccuracy: 98.16%\n",
      "47\tValidation loss: 0.250850\tBest loss: 0.250850\tAccuracy: 98.12%\n",
      "48\tValidation loss: 0.345877\tBest loss: 0.250850\tAccuracy: 98.12%\n",
      "49\tValidation loss: 0.412505\tBest loss: 0.250850\tAccuracy: 98.08%\n",
      "50\tValidation loss: 0.482062\tBest loss: 0.250850\tAccuracy: 97.81%\n",
      "51\tValidation loss: 0.340532\tBest loss: 0.250850\tAccuracy: 98.12%\n",
      "52\tValidation loss: 0.252440\tBest loss: 0.250850\tAccuracy: 98.63%\n",
      "53\tValidation loss: 0.238046\tBest loss: 0.238046\tAccuracy: 98.59%\n",
      "54\tValidation loss: 0.238052\tBest loss: 0.238046\tAccuracy: 98.63%\n",
      "55\tValidation loss: 0.272948\tBest loss: 0.238046\tAccuracy: 98.40%\n",
      "56\tValidation loss: 0.243169\tBest loss: 0.238046\tAccuracy: 98.51%\n",
      "57\tValidation loss: 0.226295\tBest loss: 0.226295\tAccuracy: 98.67%\n",
      "58\tValidation loss: 0.237042\tBest loss: 0.226295\tAccuracy: 98.79%\n",
      "59\tValidation loss: 0.209215\tBest loss: 0.209215\tAccuracy: 98.51%\n",
      "60\tValidation loss: 0.265404\tBest loss: 0.209215\tAccuracy: 98.40%\n",
      "61\tValidation loss: 0.221822\tBest loss: 0.209215\tAccuracy: 98.83%\n",
      "62\tValidation loss: 0.210925\tBest loss: 0.209215\tAccuracy: 98.67%\n",
      "63\tValidation loss: 0.194283\tBest loss: 0.194283\tAccuracy: 98.51%\n",
      "64\tValidation loss: 0.171732\tBest loss: 0.171732\tAccuracy: 98.79%\n",
      "65\tValidation loss: 0.205795\tBest loss: 0.171732\tAccuracy: 98.79%\n",
      "66\tValidation loss: 0.200250\tBest loss: 0.171732\tAccuracy: 98.63%\n",
      "67\tValidation loss: 0.174919\tBest loss: 0.171732\tAccuracy: 98.75%\n",
      "68\tValidation loss: 0.207840\tBest loss: 0.171732\tAccuracy: 98.59%\n",
      "69\tValidation loss: 0.182028\tBest loss: 0.171732\tAccuracy: 98.75%\n",
      "70\tValidation loss: 0.149564\tBest loss: 0.149564\tAccuracy: 98.83%\n",
      "71\tValidation loss: 0.152596\tBest loss: 0.149564\tAccuracy: 98.71%\n",
      "72\tValidation loss: 0.177988\tBest loss: 0.149564\tAccuracy: 98.83%\n",
      "73\tValidation loss: 0.214623\tBest loss: 0.149564\tAccuracy: 98.75%\n",
      "74\tValidation loss: 0.239980\tBest loss: 0.149564\tAccuracy: 98.51%\n",
      "75\tValidation loss: 0.166893\tBest loss: 0.149564\tAccuracy: 98.67%\n",
      "76\tValidation loss: 0.236008\tBest loss: 0.149564\tAccuracy: 98.40%\n",
      "77\tValidation loss: 0.240443\tBest loss: 0.149564\tAccuracy: 98.44%\n",
      "78\tValidation loss: 0.694440\tBest loss: 0.149564\tAccuracy: 96.13%\n",
      "79\tValidation loss: 0.195699\tBest loss: 0.149564\tAccuracy: 98.67%\n",
      "80\tValidation loss: 0.312088\tBest loss: 0.149564\tAccuracy: 98.40%\n",
      "81\tValidation loss: 0.232563\tBest loss: 0.149564\tAccuracy: 98.83%\n",
      "82\tValidation loss: 0.209372\tBest loss: 0.149564\tAccuracy: 98.67%\n",
      "83\tValidation loss: 0.193849\tBest loss: 0.149564\tAccuracy: 98.59%\n",
      "84\tValidation loss: 0.312519\tBest loss: 0.149564\tAccuracy: 98.59%\n",
      "85\tValidation loss: 0.283596\tBest loss: 0.149564\tAccuracy: 98.48%\n",
      "86\tValidation loss: 0.243055\tBest loss: 0.149564\tAccuracy: 98.59%\n",
      "87\tValidation loss: 0.213102\tBest loss: 0.149564\tAccuracy: 98.59%\n",
      "88\tValidation loss: 0.308530\tBest loss: 0.149564\tAccuracy: 98.32%\n",
      "89\tValidation loss: 0.347477\tBest loss: 0.149564\tAccuracy: 98.08%\n",
      "90\tValidation loss: 0.243116\tBest loss: 0.149564\tAccuracy: 98.59%\n",
      "91\tValidation loss: 0.274533\tBest loss: 0.149564\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 1.8min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.065102\tBest loss: 0.065102\tAccuracy: 97.85%\n",
      "1\tValidation loss: 0.100740\tBest loss: 0.065102\tAccuracy: 96.87%\n",
      "2\tValidation loss: 0.070661\tBest loss: 0.065102\tAccuracy: 97.77%\n",
      "3\tValidation loss: 0.080312\tBest loss: 0.065102\tAccuracy: 97.34%\n",
      "4\tValidation loss: 0.043190\tBest loss: 0.043190\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.055462\tBest loss: 0.043190\tAccuracy: 98.24%\n",
      "6\tValidation loss: 0.062215\tBest loss: 0.043190\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.042212\tBest loss: 0.042212\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.060863\tBest loss: 0.042212\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.038400\tBest loss: 0.038400\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.038917\tBest loss: 0.038400\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.033142\tBest loss: 0.033142\tAccuracy: 98.98%\n",
      "12\tValidation loss: 0.033486\tBest loss: 0.033142\tAccuracy: 99.18%\n",
      "13\tValidation loss: 0.031796\tBest loss: 0.031796\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.037091\tBest loss: 0.031796\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.043838\tBest loss: 0.031796\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.030804\tBest loss: 0.030804\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.039749\tBest loss: 0.030804\tAccuracy: 98.94%\n",
      "18\tValidation loss: 0.037168\tBest loss: 0.030804\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.028816\tBest loss: 0.028816\tAccuracy: 99.14%\n",
      "20\tValidation loss: 0.037380\tBest loss: 0.028816\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.039598\tBest loss: 0.028816\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.031498\tBest loss: 0.028816\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.030512\tBest loss: 0.028816\tAccuracy: 99.22%\n",
      "24\tValidation loss: 0.039214\tBest loss: 0.028816\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.047516\tBest loss: 0.028816\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.049248\tBest loss: 0.028816\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.040191\tBest loss: 0.028816\tAccuracy: 98.87%\n",
      "28\tValidation loss: 0.045437\tBest loss: 0.028816\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.035211\tBest loss: 0.028816\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.035034\tBest loss: 0.028816\tAccuracy: 99.30%\n",
      "31\tValidation loss: 0.042287\tBest loss: 0.028816\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.053451\tBest loss: 0.028816\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.050305\tBest loss: 0.028816\tAccuracy: 98.79%\n",
      "34\tValidation loss: 0.051549\tBest loss: 0.028816\tAccuracy: 98.67%\n",
      "35\tValidation loss: 0.044888\tBest loss: 0.028816\tAccuracy: 98.79%\n",
      "36\tValidation loss: 0.048263\tBest loss: 0.028816\tAccuracy: 98.75%\n",
      "37\tValidation loss: 0.040466\tBest loss: 0.028816\tAccuracy: 98.71%\n",
      "38\tValidation loss: 0.037891\tBest loss: 0.028816\tAccuracy: 99.10%\n",
      "39\tValidation loss: 0.059189\tBest loss: 0.028816\tAccuracy: 98.55%\n",
      "40\tValidation loss: 0.050578\tBest loss: 0.028816\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 9.4min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.073496\tBest loss: 0.073496\tAccuracy: 97.58%\n",
      "1\tValidation loss: 0.070995\tBest loss: 0.070995\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.051647\tBest loss: 0.051647\tAccuracy: 98.67%\n",
      "3\tValidation loss: 0.072098\tBest loss: 0.051647\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.049456\tBest loss: 0.049456\tAccuracy: 98.40%\n",
      "5\tValidation loss: 0.053050\tBest loss: 0.049456\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.039422\tBest loss: 0.039422\tAccuracy: 98.83%\n",
      "7\tValidation loss: 0.060851\tBest loss: 0.039422\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.044259\tBest loss: 0.039422\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.041967\tBest loss: 0.039422\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.041765\tBest loss: 0.039422\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.046367\tBest loss: 0.039422\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.034484\tBest loss: 0.034484\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.034752\tBest loss: 0.034484\tAccuracy: 99.10%\n",
      "14\tValidation loss: 0.040734\tBest loss: 0.034484\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.045460\tBest loss: 0.034484\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.044813\tBest loss: 0.034484\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.042223\tBest loss: 0.034484\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.040905\tBest loss: 0.034484\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.045594\tBest loss: 0.034484\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.052898\tBest loss: 0.034484\tAccuracy: 98.51%\n",
      "21\tValidation loss: 0.037494\tBest loss: 0.034484\tAccuracy: 99.14%\n",
      "22\tValidation loss: 0.046753\tBest loss: 0.034484\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.039783\tBest loss: 0.034484\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.041991\tBest loss: 0.034484\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.043851\tBest loss: 0.034484\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.039575\tBest loss: 0.034484\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.053267\tBest loss: 0.034484\tAccuracy: 98.44%\n",
      "28\tValidation loss: 0.035472\tBest loss: 0.034484\tAccuracy: 98.98%\n",
      "29\tValidation loss: 0.039025\tBest loss: 0.034484\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.043942\tBest loss: 0.034484\tAccuracy: 98.71%\n",
      "31\tValidation loss: 0.033154\tBest loss: 0.033154\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.032336\tBest loss: 0.032336\tAccuracy: 99.10%\n",
      "33\tValidation loss: 0.040110\tBest loss: 0.032336\tAccuracy: 99.14%\n",
      "34\tValidation loss: 0.047131\tBest loss: 0.032336\tAccuracy: 99.02%\n",
      "35\tValidation loss: 0.053859\tBest loss: 0.032336\tAccuracy: 98.91%\n",
      "36\tValidation loss: 0.041117\tBest loss: 0.032336\tAccuracy: 99.06%\n",
      "37\tValidation loss: 0.049470\tBest loss: 0.032336\tAccuracy: 98.94%\n",
      "38\tValidation loss: 0.047910\tBest loss: 0.032336\tAccuracy: 98.75%\n",
      "39\tValidation loss: 0.045330\tBest loss: 0.032336\tAccuracy: 98.87%\n",
      "40\tValidation loss: 0.041417\tBest loss: 0.032336\tAccuracy: 99.14%\n",
      "41\tValidation loss: 0.032742\tBest loss: 0.032336\tAccuracy: 99.14%\n",
      "42\tValidation loss: 0.066310\tBest loss: 0.032336\tAccuracy: 98.36%\n",
      "43\tValidation loss: 0.041510\tBest loss: 0.032336\tAccuracy: 99.02%\n",
      "44\tValidation loss: 0.052193\tBest loss: 0.032336\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.052985\tBest loss: 0.032336\tAccuracy: 98.59%\n",
      "46\tValidation loss: 0.054898\tBest loss: 0.032336\tAccuracy: 98.55%\n",
      "47\tValidation loss: 0.029401\tBest loss: 0.029401\tAccuracy: 98.98%\n",
      "48\tValidation loss: 0.042237\tBest loss: 0.029401\tAccuracy: 98.71%\n",
      "49\tValidation loss: 0.044533\tBest loss: 0.029401\tAccuracy: 98.91%\n",
      "50\tValidation loss: 0.038213\tBest loss: 0.029401\tAccuracy: 99.10%\n",
      "51\tValidation loss: 0.038047\tBest loss: 0.029401\tAccuracy: 98.94%\n",
      "52\tValidation loss: 0.036273\tBest loss: 0.029401\tAccuracy: 98.83%\n",
      "53\tValidation loss: 0.040631\tBest loss: 0.029401\tAccuracy: 99.10%\n",
      "54\tValidation loss: 0.052044\tBest loss: 0.029401\tAccuracy: 98.75%\n",
      "55\tValidation loss: 0.047521\tBest loss: 0.029401\tAccuracy: 98.63%\n",
      "56\tValidation loss: 0.034869\tBest loss: 0.029401\tAccuracy: 99.26%\n",
      "57\tValidation loss: 0.045348\tBest loss: 0.029401\tAccuracy: 99.14%\n",
      "58\tValidation loss: 0.043411\tBest loss: 0.029401\tAccuracy: 98.94%\n",
      "59\tValidation loss: 0.046061\tBest loss: 0.029401\tAccuracy: 98.79%\n",
      "60\tValidation loss: 0.057937\tBest loss: 0.029401\tAccuracy: 98.83%\n",
      "61\tValidation loss: 0.046362\tBest loss: 0.029401\tAccuracy: 98.98%\n",
      "62\tValidation loss: 0.044587\tBest loss: 0.029401\tAccuracy: 98.91%\n",
      "63\tValidation loss: 0.044798\tBest loss: 0.029401\tAccuracy: 99.10%\n",
      "64\tValidation loss: 0.053060\tBest loss: 0.029401\tAccuracy: 98.91%\n",
      "65\tValidation loss: 0.041596\tBest loss: 0.029401\tAccuracy: 99.06%\n",
      "66\tValidation loss: 0.039636\tBest loss: 0.029401\tAccuracy: 99.02%\n",
      "67\tValidation loss: 0.036467\tBest loss: 0.029401\tAccuracy: 99.14%\n",
      "68\tValidation loss: 0.038940\tBest loss: 0.029401\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=15.8min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.122129\tBest loss: 0.122129\tAccuracy: 95.93%\n",
      "1\tValidation loss: 0.087950\tBest loss: 0.087950\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.073634\tBest loss: 0.073634\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.047501\tBest loss: 0.047501\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.048337\tBest loss: 0.047501\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.061864\tBest loss: 0.047501\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.037545\tBest loss: 0.037545\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.042291\tBest loss: 0.037545\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.053410\tBest loss: 0.037545\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.035238\tBest loss: 0.035238\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.034772\tBest loss: 0.034772\tAccuracy: 98.91%\n",
      "11\tValidation loss: 0.046401\tBest loss: 0.034772\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.026262\tBest loss: 0.026262\tAccuracy: 99.34%\n",
      "13\tValidation loss: 0.034257\tBest loss: 0.026262\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.051652\tBest loss: 0.026262\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.042228\tBest loss: 0.026262\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.036357\tBest loss: 0.026262\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.034998\tBest loss: 0.026262\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.035638\tBest loss: 0.026262\tAccuracy: 99.02%\n",
      "19\tValidation loss: 0.041885\tBest loss: 0.026262\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.039805\tBest loss: 0.026262\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.032528\tBest loss: 0.026262\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.029563\tBest loss: 0.026262\tAccuracy: 99.18%\n",
      "23\tValidation loss: 0.035480\tBest loss: 0.026262\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.032915\tBest loss: 0.026262\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.029286\tBest loss: 0.026262\tAccuracy: 99.30%\n",
      "26\tValidation loss: 0.033311\tBest loss: 0.026262\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.068211\tBest loss: 0.026262\tAccuracy: 98.20%\n",
      "28\tValidation loss: 0.035854\tBest loss: 0.026262\tAccuracy: 98.67%\n",
      "29\tValidation loss: 0.042054\tBest loss: 0.026262\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.032901\tBest loss: 0.026262\tAccuracy: 99.14%\n",
      "31\tValidation loss: 0.037778\tBest loss: 0.026262\tAccuracy: 99.06%\n",
      "32\tValidation loss: 0.028697\tBest loss: 0.026262\tAccuracy: 99.10%\n",
      "33\tValidation loss: 0.055447\tBest loss: 0.026262\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 7.8min\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.204512\tBest loss: 0.204512\tAccuracy: 94.84%\n",
      "1\tValidation loss: 0.201161\tBest loss: 0.201161\tAccuracy: 94.41%\n",
      "2\tValidation loss: 0.261532\tBest loss: 0.201161\tAccuracy: 90.93%\n",
      "3\tValidation loss: 0.410825\tBest loss: 0.201161\tAccuracy: 86.79%\n",
      "4\tValidation loss: 0.145938\tBest loss: 0.145938\tAccuracy: 95.74%\n",
      "5\tValidation loss: 0.144475\tBest loss: 0.144475\tAccuracy: 95.74%\n",
      "6\tValidation loss: 0.181928\tBest loss: 0.144475\tAccuracy: 94.14%\n",
      "7\tValidation loss: 0.188520\tBest loss: 0.144475\tAccuracy: 94.57%\n",
      "8\tValidation loss: 0.155418\tBest loss: 0.144475\tAccuracy: 95.31%\n",
      "9\tValidation loss: 0.147937\tBest loss: 0.144475\tAccuracy: 95.78%\n",
      "10\tValidation loss: 0.144032\tBest loss: 0.144032\tAccuracy: 95.58%\n",
      "11\tValidation loss: 0.161535\tBest loss: 0.144032\tAccuracy: 95.35%\n",
      "12\tValidation loss: 0.140776\tBest loss: 0.140776\tAccuracy: 95.70%\n",
      "13\tValidation loss: 0.137940\tBest loss: 0.137940\tAccuracy: 95.93%\n",
      "14\tValidation loss: 0.216781\tBest loss: 0.137940\tAccuracy: 93.75%\n",
      "15\tValidation loss: 0.178573\tBest loss: 0.137940\tAccuracy: 94.80%\n",
      "16\tValidation loss: 0.293346\tBest loss: 0.137940\tAccuracy: 91.20%\n",
      "17\tValidation loss: 0.172149\tBest loss: 0.137940\tAccuracy: 94.80%\n",
      "18\tValidation loss: 0.128116\tBest loss: 0.128116\tAccuracy: 96.25%\n",
      "19\tValidation loss: 0.293978\tBest loss: 0.128116\tAccuracy: 90.03%\n",
      "20\tValidation loss: 0.145500\tBest loss: 0.128116\tAccuracy: 95.70%\n",
      "21\tValidation loss: 0.186059\tBest loss: 0.128116\tAccuracy: 94.14%\n",
      "22\tValidation loss: 0.199822\tBest loss: 0.128116\tAccuracy: 94.33%\n",
      "23\tValidation loss: 0.176953\tBest loss: 0.128116\tAccuracy: 95.19%\n",
      "24\tValidation loss: 0.163286\tBest loss: 0.128116\tAccuracy: 95.39%\n",
      "25\tValidation loss: 0.223610\tBest loss: 0.128116\tAccuracy: 93.39%\n",
      "26\tValidation loss: 0.161352\tBest loss: 0.128116\tAccuracy: 94.88%\n",
      "27\tValidation loss: 0.447309\tBest loss: 0.128116\tAccuracy: 84.09%\n",
      "28\tValidation loss: 0.189530\tBest loss: 0.128116\tAccuracy: 95.19%\n",
      "29\tValidation loss: 0.176915\tBest loss: 0.128116\tAccuracy: 95.04%\n",
      "30\tValidation loss: 0.130783\tBest loss: 0.128116\tAccuracy: 96.48%\n",
      "31\tValidation loss: 0.243881\tBest loss: 0.128116\tAccuracy: 91.63%\n",
      "32\tValidation loss: 0.138958\tBest loss: 0.128116\tAccuracy: 95.82%\n",
      "33\tValidation loss: 0.128522\tBest loss: 0.128116\tAccuracy: 96.52%\n",
      "34\tValidation loss: 0.175015\tBest loss: 0.128116\tAccuracy: 95.07%\n",
      "35\tValidation loss: 0.293606\tBest loss: 0.128116\tAccuracy: 91.95%\n",
      "36\tValidation loss: 0.146548\tBest loss: 0.128116\tAccuracy: 95.39%\n",
      "37\tValidation loss: 0.166931\tBest loss: 0.128116\tAccuracy: 94.68%\n",
      "38\tValidation loss: 0.195621\tBest loss: 0.128116\tAccuracy: 93.51%\n",
      "39\tValidation loss: 0.146086\tBest loss: 0.128116\tAccuracy: 95.97%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0>, total= 5.4min\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.139064\tBest loss: 0.139064\tAccuracy: 95.82%\n",
      "1\tValidation loss: 0.130714\tBest loss: 0.130714\tAccuracy: 96.05%\n",
      "2\tValidation loss: 0.166676\tBest loss: 0.130714\tAccuracy: 95.43%\n",
      "3\tValidation loss: 0.343530\tBest loss: 0.130714\tAccuracy: 89.72%\n",
      "4\tValidation loss: 0.176062\tBest loss: 0.130714\tAccuracy: 94.45%\n",
      "5\tValidation loss: 0.108727\tBest loss: 0.108727\tAccuracy: 96.76%\n",
      "6\tValidation loss: 0.245646\tBest loss: 0.108727\tAccuracy: 93.39%\n",
      "7\tValidation loss: 0.122671\tBest loss: 0.108727\tAccuracy: 97.03%\n",
      "8\tValidation loss: 0.119500\tBest loss: 0.108727\tAccuracy: 95.90%\n",
      "9\tValidation loss: 0.144359\tBest loss: 0.108727\tAccuracy: 95.54%\n",
      "10\tValidation loss: 0.346972\tBest loss: 0.108727\tAccuracy: 91.28%\n",
      "11\tValidation loss: 0.103828\tBest loss: 0.103828\tAccuracy: 96.05%\n",
      "12\tValidation loss: 0.110782\tBest loss: 0.103828\tAccuracy: 96.40%\n",
      "13\tValidation loss: 0.127922\tBest loss: 0.103828\tAccuracy: 96.72%\n",
      "14\tValidation loss: 0.154767\tBest loss: 0.103828\tAccuracy: 95.62%\n",
      "15\tValidation loss: 0.124050\tBest loss: 0.103828\tAccuracy: 96.29%\n",
      "16\tValidation loss: 0.146136\tBest loss: 0.103828\tAccuracy: 96.21%\n",
      "17\tValidation loss: 0.186060\tBest loss: 0.103828\tAccuracy: 93.51%\n",
      "18\tValidation loss: 0.117889\tBest loss: 0.103828\tAccuracy: 96.64%\n",
      "19\tValidation loss: 0.119351\tBest loss: 0.103828\tAccuracy: 96.79%\n",
      "20\tValidation loss: 0.103884\tBest loss: 0.103828\tAccuracy: 96.99%\n",
      "21\tValidation loss: 0.130532\tBest loss: 0.103828\tAccuracy: 96.72%\n",
      "22\tValidation loss: 0.141424\tBest loss: 0.103828\tAccuracy: 97.07%\n",
      "23\tValidation loss: 0.482073\tBest loss: 0.103828\tAccuracy: 84.56%\n",
      "24\tValidation loss: 0.124634\tBest loss: 0.103828\tAccuracy: 97.22%\n",
      "25\tValidation loss: 0.122041\tBest loss: 0.103828\tAccuracy: 96.36%\n",
      "26\tValidation loss: 0.108852\tBest loss: 0.103828\tAccuracy: 96.95%\n",
      "27\tValidation loss: 0.120853\tBest loss: 0.103828\tAccuracy: 96.40%\n",
      "28\tValidation loss: 0.117456\tBest loss: 0.103828\tAccuracy: 96.95%\n",
      "29\tValidation loss: 0.108020\tBest loss: 0.103828\tAccuracy: 96.64%\n",
      "30\tValidation loss: 0.112001\tBest loss: 0.103828\tAccuracy: 96.83%\n",
      "31\tValidation loss: 0.098514\tBest loss: 0.098514\tAccuracy: 97.26%\n",
      "32\tValidation loss: 0.148232\tBest loss: 0.098514\tAccuracy: 95.74%\n",
      "33\tValidation loss: 0.181457\tBest loss: 0.098514\tAccuracy: 94.68%\n",
      "34\tValidation loss: 0.105991\tBest loss: 0.098514\tAccuracy: 97.11%\n",
      "35\tValidation loss: 0.178940\tBest loss: 0.098514\tAccuracy: 94.25%\n",
      "36\tValidation loss: 0.110583\tBest loss: 0.098514\tAccuracy: 97.34%\n",
      "37\tValidation loss: 0.116310\tBest loss: 0.098514\tAccuracy: 97.19%\n",
      "38\tValidation loss: 0.093372\tBest loss: 0.093372\tAccuracy: 97.46%\n",
      "39\tValidation loss: 0.120514\tBest loss: 0.093372\tAccuracy: 96.83%\n",
      "40\tValidation loss: 0.165009\tBest loss: 0.093372\tAccuracy: 95.90%\n",
      "41\tValidation loss: 0.090706\tBest loss: 0.090706\tAccuracy: 97.46%\n",
      "42\tValidation loss: 0.102351\tBest loss: 0.090706\tAccuracy: 96.87%\n",
      "43\tValidation loss: 0.119076\tBest loss: 0.090706\tAccuracy: 97.22%\n",
      "44\tValidation loss: 0.165759\tBest loss: 0.090706\tAccuracy: 95.50%\n",
      "45\tValidation loss: 0.119893\tBest loss: 0.090706\tAccuracy: 96.72%\n",
      "46\tValidation loss: 0.105195\tBest loss: 0.090706\tAccuracy: 96.99%\n",
      "47\tValidation loss: 0.123806\tBest loss: 0.090706\tAccuracy: 97.11%\n",
      "48\tValidation loss: 0.171556\tBest loss: 0.090706\tAccuracy: 95.39%\n",
      "49\tValidation loss: 0.128386\tBest loss: 0.090706\tAccuracy: 96.72%\n",
      "50\tValidation loss: 0.114296\tBest loss: 0.090706\tAccuracy: 96.95%\n",
      "51\tValidation loss: 0.151974\tBest loss: 0.090706\tAccuracy: 95.50%\n",
      "52\tValidation loss: 0.143885\tBest loss: 0.090706\tAccuracy: 96.64%\n",
      "53\tValidation loss: 0.090475\tBest loss: 0.090475\tAccuracy: 97.22%\n",
      "54\tValidation loss: 0.109226\tBest loss: 0.090475\tAccuracy: 97.30%\n",
      "55\tValidation loss: 0.234229\tBest loss: 0.090475\tAccuracy: 92.38%\n",
      "56\tValidation loss: 0.108682\tBest loss: 0.090475\tAccuracy: 97.26%\n",
      "57\tValidation loss: 0.160814\tBest loss: 0.090475\tAccuracy: 95.50%\n",
      "58\tValidation loss: 0.103116\tBest loss: 0.090475\tAccuracy: 97.34%\n",
      "59\tValidation loss: 0.160912\tBest loss: 0.090475\tAccuracy: 95.19%\n",
      "60\tValidation loss: 0.098361\tBest loss: 0.090475\tAccuracy: 97.42%\n",
      "61\tValidation loss: 0.279763\tBest loss: 0.090475\tAccuracy: 93.94%\n",
      "62\tValidation loss: 0.103966\tBest loss: 0.090475\tAccuracy: 96.91%\n",
      "63\tValidation loss: 0.099096\tBest loss: 0.090475\tAccuracy: 97.54%\n",
      "64\tValidation loss: 0.165905\tBest loss: 0.090475\tAccuracy: 94.92%\n",
      "65\tValidation loss: 0.110848\tBest loss: 0.090475\tAccuracy: 97.34%\n",
      "66\tValidation loss: 0.132825\tBest loss: 0.090475\tAccuracy: 97.07%\n",
      "67\tValidation loss: 0.114668\tBest loss: 0.090475\tAccuracy: 96.91%\n",
      "68\tValidation loss: 0.151258\tBest loss: 0.090475\tAccuracy: 95.47%\n",
      "69\tValidation loss: 0.140929\tBest loss: 0.090475\tAccuracy: 96.68%\n",
      "70\tValidation loss: 0.098621\tBest loss: 0.090475\tAccuracy: 97.19%\n",
      "71\tValidation loss: 0.098722\tBest loss: 0.090475\tAccuracy: 97.26%\n",
      "72\tValidation loss: 0.144056\tBest loss: 0.090475\tAccuracy: 96.29%\n",
      "73\tValidation loss: 0.122136\tBest loss: 0.090475\tAccuracy: 96.36%\n",
      "74\tValidation loss: 0.121017\tBest loss: 0.090475\tAccuracy: 97.15%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0>, total=10.1min\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.158797\tBest loss: 0.158797\tAccuracy: 95.15%\n",
      "1\tValidation loss: 0.198515\tBest loss: 0.158797\tAccuracy: 95.11%\n",
      "2\tValidation loss: 0.224225\tBest loss: 0.158797\tAccuracy: 93.63%\n",
      "3\tValidation loss: 0.168194\tBest loss: 0.158797\tAccuracy: 94.72%\n",
      "4\tValidation loss: 0.112871\tBest loss: 0.112871\tAccuracy: 96.99%\n",
      "5\tValidation loss: 0.231036\tBest loss: 0.112871\tAccuracy: 93.90%\n",
      "6\tValidation loss: 0.137876\tBest loss: 0.112871\tAccuracy: 96.64%\n",
      "7\tValidation loss: 0.125234\tBest loss: 0.112871\tAccuracy: 96.91%\n",
      "8\tValidation loss: 0.105355\tBest loss: 0.105355\tAccuracy: 97.07%\n",
      "9\tValidation loss: 0.106643\tBest loss: 0.105355\tAccuracy: 97.11%\n",
      "10\tValidation loss: 0.119509\tBest loss: 0.105355\tAccuracy: 96.91%\n",
      "11\tValidation loss: 0.135028\tBest loss: 0.105355\tAccuracy: 96.36%\n",
      "12\tValidation loss: 0.140067\tBest loss: 0.105355\tAccuracy: 96.13%\n",
      "13\tValidation loss: 0.147228\tBest loss: 0.105355\tAccuracy: 96.33%\n",
      "14\tValidation loss: 0.132619\tBest loss: 0.105355\tAccuracy: 96.44%\n",
      "15\tValidation loss: 0.131172\tBest loss: 0.105355\tAccuracy: 96.79%\n",
      "16\tValidation loss: 0.120042\tBest loss: 0.105355\tAccuracy: 97.03%\n",
      "17\tValidation loss: 0.111331\tBest loss: 0.105355\tAccuracy: 97.03%\n",
      "18\tValidation loss: 0.190535\tBest loss: 0.105355\tAccuracy: 94.37%\n",
      "19\tValidation loss: 0.144158\tBest loss: 0.105355\tAccuracy: 96.25%\n",
      "20\tValidation loss: 0.111022\tBest loss: 0.105355\tAccuracy: 96.95%\n",
      "21\tValidation loss: 0.099606\tBest loss: 0.099606\tAccuracy: 97.22%\n",
      "22\tValidation loss: 0.158936\tBest loss: 0.099606\tAccuracy: 96.17%\n",
      "23\tValidation loss: 0.118575\tBest loss: 0.099606\tAccuracy: 96.72%\n",
      "24\tValidation loss: 0.122965\tBest loss: 0.099606\tAccuracy: 96.40%\n",
      "25\tValidation loss: 0.142811\tBest loss: 0.099606\tAccuracy: 96.29%\n",
      "26\tValidation loss: 0.163597\tBest loss: 0.099606\tAccuracy: 96.01%\n",
      "27\tValidation loss: 0.179912\tBest loss: 0.099606\tAccuracy: 94.61%\n",
      "28\tValidation loss: 0.101359\tBest loss: 0.099606\tAccuracy: 97.07%\n",
      "29\tValidation loss: 0.146773\tBest loss: 0.099606\tAccuracy: 96.33%\n",
      "30\tValidation loss: 0.124305\tBest loss: 0.099606\tAccuracy: 96.83%\n",
      "31\tValidation loss: 0.114919\tBest loss: 0.099606\tAccuracy: 97.07%\n",
      "32\tValidation loss: 0.154329\tBest loss: 0.099606\tAccuracy: 95.78%\n",
      "33\tValidation loss: 0.103153\tBest loss: 0.099606\tAccuracy: 97.26%\n",
      "34\tValidation loss: 0.170108\tBest loss: 0.099606\tAccuracy: 95.58%\n",
      "35\tValidation loss: 0.143820\tBest loss: 0.099606\tAccuracy: 95.78%\n",
      "36\tValidation loss: 0.112717\tBest loss: 0.099606\tAccuracy: 97.07%\n",
      "37\tValidation loss: 0.106516\tBest loss: 0.099606\tAccuracy: 96.83%\n",
      "38\tValidation loss: 0.130444\tBest loss: 0.099606\tAccuracy: 96.33%\n",
      "39\tValidation loss: 0.133907\tBest loss: 0.099606\tAccuracy: 96.44%\n",
      "40\tValidation loss: 0.101736\tBest loss: 0.099606\tAccuracy: 97.34%\n",
      "41\tValidation loss: 0.152338\tBest loss: 0.099606\tAccuracy: 96.01%\n",
      "42\tValidation loss: 0.173842\tBest loss: 0.099606\tAccuracy: 94.33%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0>, total= 5.9min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.087426\tBest loss: 0.087426\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.129228\tBest loss: 0.087426\tAccuracy: 97.42%\n",
      "2\tValidation loss: 0.100146\tBest loss: 0.087426\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.087656\tBest loss: 0.087426\tAccuracy: 97.85%\n",
      "4\tValidation loss: 0.062474\tBest loss: 0.062474\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.077690\tBest loss: 0.062474\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.059787\tBest loss: 0.059787\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.067675\tBest loss: 0.059787\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.077972\tBest loss: 0.059787\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.288105\tBest loss: 0.059787\tAccuracy: 96.56%\n",
      "10\tValidation loss: 0.061609\tBest loss: 0.059787\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.068728\tBest loss: 0.059787\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.112142\tBest loss: 0.059787\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.088618\tBest loss: 0.059787\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.074686\tBest loss: 0.059787\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.170031\tBest loss: 0.059787\tAccuracy: 98.12%\n",
      "16\tValidation loss: 0.121924\tBest loss: 0.059787\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.067504\tBest loss: 0.059787\tAccuracy: 98.83%\n",
      "18\tValidation loss: 0.135653\tBest loss: 0.059787\tAccuracy: 98.24%\n",
      "19\tValidation loss: 0.298754\tBest loss: 0.059787\tAccuracy: 92.77%\n",
      "20\tValidation loss: 0.090294\tBest loss: 0.059787\tAccuracy: 98.87%\n",
      "21\tValidation loss: 0.072577\tBest loss: 0.059787\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.079353\tBest loss: 0.059787\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.063241\tBest loss: 0.059787\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.102821\tBest loss: 0.059787\tAccuracy: 98.63%\n",
      "25\tValidation loss: 0.135753\tBest loss: 0.059787\tAccuracy: 98.32%\n",
      "26\tValidation loss: 0.097503\tBest loss: 0.059787\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.103846\tBest loss: 0.059787\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.9min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.106303\tBest loss: 0.106303\tAccuracy: 96.64%\n",
      "1\tValidation loss: 0.183653\tBest loss: 0.106303\tAccuracy: 96.52%\n",
      "2\tValidation loss: 0.071317\tBest loss: 0.071317\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.053113\tBest loss: 0.053113\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.066713\tBest loss: 0.053113\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.054902\tBest loss: 0.053113\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.099851\tBest loss: 0.053113\tAccuracy: 97.85%\n",
      "7\tValidation loss: 0.065362\tBest loss: 0.053113\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.084694\tBest loss: 0.053113\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.052756\tBest loss: 0.052756\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.037662\tBest loss: 0.037662\tAccuracy: 98.98%\n",
      "11\tValidation loss: 0.117184\tBest loss: 0.037662\tAccuracy: 97.85%\n",
      "12\tValidation loss: 0.096275\tBest loss: 0.037662\tAccuracy: 98.44%\n",
      "13\tValidation loss: 0.064256\tBest loss: 0.037662\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.061061\tBest loss: 0.037662\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.087005\tBest loss: 0.037662\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.080730\tBest loss: 0.037662\tAccuracy: 97.97%\n",
      "17\tValidation loss: 0.056132\tBest loss: 0.037662\tAccuracy: 98.83%\n",
      "18\tValidation loss: 0.575317\tBest loss: 0.037662\tAccuracy: 96.99%\n",
      "19\tValidation loss: 0.063300\tBest loss: 0.037662\tAccuracy: 98.67%\n",
      "20\tValidation loss: 0.220175\tBest loss: 0.037662\tAccuracy: 97.73%\n",
      "21\tValidation loss: 0.113521\tBest loss: 0.037662\tAccuracy: 98.28%\n",
      "22\tValidation loss: 0.073073\tBest loss: 0.037662\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.083223\tBest loss: 0.037662\tAccuracy: 98.67%\n",
      "24\tValidation loss: 0.065343\tBest loss: 0.037662\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.067293\tBest loss: 0.037662\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.064842\tBest loss: 0.037662\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.099149\tBest loss: 0.037662\tAccuracy: 98.40%\n",
      "28\tValidation loss: 0.080037\tBest loss: 0.037662\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.079682\tBest loss: 0.037662\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.129061\tBest loss: 0.037662\tAccuracy: 98.28%\n",
      "31\tValidation loss: 0.095135\tBest loss: 0.037662\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.2min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.081653\tBest loss: 0.081653\tAccuracy: 97.85%\n",
      "1\tValidation loss: 0.092013\tBest loss: 0.081653\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.088576\tBest loss: 0.081653\tAccuracy: 97.26%\n",
      "3\tValidation loss: 0.069754\tBest loss: 0.069754\tAccuracy: 98.01%\n",
      "4\tValidation loss: 0.074148\tBest loss: 0.069754\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.075586\tBest loss: 0.069754\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.066053\tBest loss: 0.066053\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.062436\tBest loss: 0.062436\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.114205\tBest loss: 0.062436\tAccuracy: 97.19%\n",
      "9\tValidation loss: 0.073268\tBest loss: 0.062436\tAccuracy: 98.24%\n",
      "10\tValidation loss: 0.067670\tBest loss: 0.062436\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.041210\tBest loss: 0.041210\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.072305\tBest loss: 0.041210\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.053805\tBest loss: 0.041210\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.119332\tBest loss: 0.041210\tAccuracy: 98.24%\n",
      "15\tValidation loss: 0.053373\tBest loss: 0.041210\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.077139\tBest loss: 0.041210\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.074358\tBest loss: 0.041210\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.052891\tBest loss: 0.041210\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.061945\tBest loss: 0.041210\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.070345\tBest loss: 0.041210\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.109960\tBest loss: 0.041210\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.083048\tBest loss: 0.041210\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.069035\tBest loss: 0.041210\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.087026\tBest loss: 0.041210\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.178889\tBest loss: 0.041210\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.109636\tBest loss: 0.041210\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.067527\tBest loss: 0.041210\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.121031\tBest loss: 0.041210\tAccuracy: 98.20%\n",
      "29\tValidation loss: 0.109672\tBest loss: 0.041210\tAccuracy: 98.59%\n",
      "30\tValidation loss: 0.065866\tBest loss: 0.041210\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.070171\tBest loss: 0.041210\tAccuracy: 98.94%\n",
      "32\tValidation loss: 0.076365\tBest loss: 0.041210\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.2min\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.074100\tBest loss: 0.074100\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.075382\tBest loss: 0.074100\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.063091\tBest loss: 0.063091\tAccuracy: 98.32%\n",
      "3\tValidation loss: 0.076144\tBest loss: 0.063091\tAccuracy: 98.12%\n",
      "4\tValidation loss: 0.083678\tBest loss: 0.063091\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.076727\tBest loss: 0.063091\tAccuracy: 97.62%\n",
      "6\tValidation loss: 0.064152\tBest loss: 0.063091\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.046025\tBest loss: 0.046025\tAccuracy: 98.71%\n",
      "8\tValidation loss: 0.060517\tBest loss: 0.046025\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.061662\tBest loss: 0.046025\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.054650\tBest loss: 0.046025\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.055685\tBest loss: 0.046025\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.047440\tBest loss: 0.046025\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.063459\tBest loss: 0.046025\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.057919\tBest loss: 0.046025\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.052389\tBest loss: 0.046025\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.071655\tBest loss: 0.046025\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.046766\tBest loss: 0.046025\tAccuracy: 99.10%\n",
      "18\tValidation loss: 0.051285\tBest loss: 0.046025\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.081054\tBest loss: 0.046025\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.060987\tBest loss: 0.046025\tAccuracy: 98.63%\n",
      "21\tValidation loss: 0.048347\tBest loss: 0.046025\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.047504\tBest loss: 0.046025\tAccuracy: 99.22%\n",
      "23\tValidation loss: 0.063372\tBest loss: 0.046025\tAccuracy: 98.55%\n",
      "24\tValidation loss: 0.049960\tBest loss: 0.046025\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.052182\tBest loss: 0.046025\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.090094\tBest loss: 0.046025\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.046550\tBest loss: 0.046025\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.053117\tBest loss: 0.046025\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.7min\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.111631\tBest loss: 0.111631\tAccuracy: 96.79%\n",
      "1\tValidation loss: 0.062444\tBest loss: 0.062444\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.073034\tBest loss: 0.062444\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.049543\tBest loss: 0.049543\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.052839\tBest loss: 0.049543\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.045138\tBest loss: 0.045138\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.051900\tBest loss: 0.045138\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.046610\tBest loss: 0.045138\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.067332\tBest loss: 0.045138\tAccuracy: 98.32%\n",
      "9\tValidation loss: 0.049512\tBest loss: 0.045138\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.056420\tBest loss: 0.045138\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.072039\tBest loss: 0.045138\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.054286\tBest loss: 0.045138\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.047452\tBest loss: 0.045138\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.046915\tBest loss: 0.045138\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.055306\tBest loss: 0.045138\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.053612\tBest loss: 0.045138\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.069883\tBest loss: 0.045138\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.069384\tBest loss: 0.045138\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.067763\tBest loss: 0.045138\tAccuracy: 98.63%\n",
      "20\tValidation loss: 0.052342\tBest loss: 0.045138\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.062440\tBest loss: 0.045138\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.055551\tBest loss: 0.045138\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.052971\tBest loss: 0.045138\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.062307\tBest loss: 0.045138\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.065346\tBest loss: 0.045138\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.038893\tBest loss: 0.038893\tAccuracy: 99.18%\n",
      "27\tValidation loss: 0.054219\tBest loss: 0.038893\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.060640\tBest loss: 0.038893\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.078602\tBest loss: 0.038893\tAccuracy: 98.51%\n",
      "30\tValidation loss: 0.091049\tBest loss: 0.038893\tAccuracy: 98.44%\n",
      "31\tValidation loss: 0.067221\tBest loss: 0.038893\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.082822\tBest loss: 0.038893\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.063165\tBest loss: 0.038893\tAccuracy: 98.87%\n",
      "34\tValidation loss: 0.065913\tBest loss: 0.038893\tAccuracy: 99.14%\n",
      "35\tValidation loss: 0.053286\tBest loss: 0.038893\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.052742\tBest loss: 0.038893\tAccuracy: 98.94%\n",
      "37\tValidation loss: 0.062609\tBest loss: 0.038893\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.093858\tBest loss: 0.038893\tAccuracy: 98.48%\n",
      "39\tValidation loss: 0.063476\tBest loss: 0.038893\tAccuracy: 98.98%\n",
      "40\tValidation loss: 0.052560\tBest loss: 0.038893\tAccuracy: 98.98%\n",
      "41\tValidation loss: 0.089442\tBest loss: 0.038893\tAccuracy: 98.36%\n",
      "42\tValidation loss: 0.077694\tBest loss: 0.038893\tAccuracy: 98.91%\n",
      "43\tValidation loss: 0.070906\tBest loss: 0.038893\tAccuracy: 98.75%\n",
      "44\tValidation loss: 0.058811\tBest loss: 0.038893\tAccuracy: 98.94%\n",
      "45\tValidation loss: 0.051363\tBest loss: 0.038893\tAccuracy: 98.91%\n",
      "46\tValidation loss: 0.052869\tBest loss: 0.038893\tAccuracy: 99.06%\n",
      "47\tValidation loss: 0.060669\tBest loss: 0.038893\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.7min\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.080920\tBest loss: 0.080920\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.101431\tBest loss: 0.080920\tAccuracy: 97.42%\n",
      "2\tValidation loss: 0.068604\tBest loss: 0.068604\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.046606\tBest loss: 0.046606\tAccuracy: 98.67%\n",
      "4\tValidation loss: 0.045505\tBest loss: 0.045505\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.056966\tBest loss: 0.045505\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.043883\tBest loss: 0.043883\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.041973\tBest loss: 0.041973\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.122165\tBest loss: 0.041973\tAccuracy: 96.99%\n",
      "9\tValidation loss: 0.047489\tBest loss: 0.041973\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.050998\tBest loss: 0.041973\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.061010\tBest loss: 0.041973\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.062885\tBest loss: 0.041973\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.053315\tBest loss: 0.041973\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.068216\tBest loss: 0.041973\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.070855\tBest loss: 0.041973\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.030224\tBest loss: 0.030224\tAccuracy: 99.18%\n",
      "17\tValidation loss: 0.049722\tBest loss: 0.030224\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.042118\tBest loss: 0.030224\tAccuracy: 99.02%\n",
      "19\tValidation loss: 0.049971\tBest loss: 0.030224\tAccuracy: 98.87%\n",
      "20\tValidation loss: 0.033642\tBest loss: 0.030224\tAccuracy: 99.22%\n",
      "21\tValidation loss: 0.042800\tBest loss: 0.030224\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.046445\tBest loss: 0.030224\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.046752\tBest loss: 0.030224\tAccuracy: 99.10%\n",
      "24\tValidation loss: 0.042345\tBest loss: 0.030224\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.034995\tBest loss: 0.030224\tAccuracy: 99.22%\n",
      "26\tValidation loss: 0.047463\tBest loss: 0.030224\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.048464\tBest loss: 0.030224\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.094267\tBest loss: 0.030224\tAccuracy: 98.51%\n",
      "29\tValidation loss: 0.049311\tBest loss: 0.030224\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.054040\tBest loss: 0.030224\tAccuracy: 98.79%\n",
      "31\tValidation loss: 0.044686\tBest loss: 0.030224\tAccuracy: 98.98%\n",
      "32\tValidation loss: 0.052867\tBest loss: 0.030224\tAccuracy: 98.87%\n",
      "33\tValidation loss: 0.046693\tBest loss: 0.030224\tAccuracy: 98.87%\n",
      "34\tValidation loss: 0.056382\tBest loss: 0.030224\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.052602\tBest loss: 0.030224\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.063011\tBest loss: 0.030224\tAccuracy: 98.98%\n",
      "37\tValidation loss: 0.053708\tBest loss: 0.030224\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.2min\n",
      "[CV] n_neurons=50, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.068454\tBest loss: 0.068454\tAccuracy: 98.01%\n",
      "1\tValidation loss: 0.055622\tBest loss: 0.055622\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.049482\tBest loss: 0.049482\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.056469\tBest loss: 0.049482\tAccuracy: 98.59%\n",
      "4\tValidation loss: 0.043440\tBest loss: 0.043440\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.048250\tBest loss: 0.043440\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.055836\tBest loss: 0.043440\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.038468\tBest loss: 0.038468\tAccuracy: 99.02%\n",
      "8\tValidation loss: 0.056241\tBest loss: 0.038468\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.035272\tBest loss: 0.035272\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.036769\tBest loss: 0.035272\tAccuracy: 99.02%\n",
      "11\tValidation loss: 0.045176\tBest loss: 0.035272\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.045042\tBest loss: 0.035272\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.051599\tBest loss: 0.035272\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.038815\tBest loss: 0.035272\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.054628\tBest loss: 0.035272\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.055187\tBest loss: 0.035272\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.041528\tBest loss: 0.035272\tAccuracy: 99.14%\n",
      "18\tValidation loss: 0.045311\tBest loss: 0.035272\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.045801\tBest loss: 0.035272\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.045548\tBest loss: 0.035272\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.056260\tBest loss: 0.035272\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.055546\tBest loss: 0.035272\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.045171\tBest loss: 0.035272\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.073046\tBest loss: 0.035272\tAccuracy: 98.55%\n",
      "25\tValidation loss: 0.061055\tBest loss: 0.035272\tAccuracy: 98.20%\n",
      "26\tValidation loss: 0.060727\tBest loss: 0.035272\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.046095\tBest loss: 0.035272\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.045198\tBest loss: 0.035272\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.045916\tBest loss: 0.035272\tAccuracy: 99.06%\n",
      "30\tValidation loss: 0.061106\tBest loss: 0.035272\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  48.5s\n",
      "[CV] n_neurons=50, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.075920\tBest loss: 0.075920\tAccuracy: 97.62%\n",
      "1\tValidation loss: 0.069492\tBest loss: 0.069492\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.053904\tBest loss: 0.053904\tAccuracy: 98.51%\n",
      "3\tValidation loss: 0.051482\tBest loss: 0.051482\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.048439\tBest loss: 0.048439\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.050816\tBest loss: 0.048439\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.046623\tBest loss: 0.046623\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.041473\tBest loss: 0.041473\tAccuracy: 98.87%\n",
      "8\tValidation loss: 0.037979\tBest loss: 0.037979\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.035710\tBest loss: 0.035710\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.047367\tBest loss: 0.035710\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.049419\tBest loss: 0.035710\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.054647\tBest loss: 0.035710\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.067260\tBest loss: 0.035710\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.053408\tBest loss: 0.035710\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.037960\tBest loss: 0.035710\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.044144\tBest loss: 0.035710\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.047485\tBest loss: 0.035710\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.054550\tBest loss: 0.035710\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.046049\tBest loss: 0.035710\tAccuracy: 98.87%\n",
      "20\tValidation loss: 0.042180\tBest loss: 0.035710\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.037770\tBest loss: 0.035710\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.050026\tBest loss: 0.035710\tAccuracy: 98.98%\n",
      "23\tValidation loss: 0.053110\tBest loss: 0.035710\tAccuracy: 99.02%\n",
      "24\tValidation loss: 0.045502\tBest loss: 0.035710\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.053934\tBest loss: 0.035710\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.051700\tBest loss: 0.035710\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.058355\tBest loss: 0.035710\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.040485\tBest loss: 0.035710\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.047976\tBest loss: 0.035710\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.063929\tBest loss: 0.035710\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  48.8s\n",
      "[CV] n_neurons=50, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.087540\tBest loss: 0.087540\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.065973\tBest loss: 0.065973\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.064450\tBest loss: 0.064450\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.050382\tBest loss: 0.050382\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.047185\tBest loss: 0.047185\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.056153\tBest loss: 0.047185\tAccuracy: 98.24%\n",
      "6\tValidation loss: 0.036572\tBest loss: 0.036572\tAccuracy: 98.98%\n",
      "7\tValidation loss: 0.057738\tBest loss: 0.036572\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.051516\tBest loss: 0.036572\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.041687\tBest loss: 0.036572\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.041549\tBest loss: 0.036572\tAccuracy: 98.98%\n",
      "11\tValidation loss: 0.043846\tBest loss: 0.036572\tAccuracy: 98.87%\n",
      "12\tValidation loss: 0.036206\tBest loss: 0.036206\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.046024\tBest loss: 0.036206\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.043711\tBest loss: 0.036206\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.045793\tBest loss: 0.036206\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.044213\tBest loss: 0.036206\tAccuracy: 99.14%\n",
      "17\tValidation loss: 0.039595\tBest loss: 0.036206\tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.040619\tBest loss: 0.036206\tAccuracy: 99.06%\n",
      "19\tValidation loss: 0.043368\tBest loss: 0.036206\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.037584\tBest loss: 0.036206\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.064694\tBest loss: 0.036206\tAccuracy: 98.44%\n",
      "22\tValidation loss: 0.042497\tBest loss: 0.036206\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.065248\tBest loss: 0.036206\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.048013\tBest loss: 0.036206\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.054938\tBest loss: 0.036206\tAccuracy: 98.91%\n",
      "26\tValidation loss: 0.056335\tBest loss: 0.036206\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.060404\tBest loss: 0.036206\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.068642\tBest loss: 0.036206\tAccuracy: 98.48%\n",
      "29\tValidation loss: 0.035538\tBest loss: 0.035538\tAccuracy: 99.22%\n",
      "30\tValidation loss: 0.050742\tBest loss: 0.035538\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.069779\tBest loss: 0.035538\tAccuracy: 98.55%\n",
      "32\tValidation loss: 0.049421\tBest loss: 0.035538\tAccuracy: 98.94%\n",
      "33\tValidation loss: 0.058122\tBest loss: 0.035538\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.043632\tBest loss: 0.035538\tAccuracy: 99.22%\n",
      "35\tValidation loss: 0.042680\tBest loss: 0.035538\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.047807\tBest loss: 0.035538\tAccuracy: 98.83%\n",
      "37\tValidation loss: 0.050488\tBest loss: 0.035538\tAccuracy: 98.98%\n",
      "38\tValidation loss: 0.038435\tBest loss: 0.035538\tAccuracy: 99.10%\n",
      "39\tValidation loss: 0.049284\tBest loss: 0.035538\tAccuracy: 98.91%\n",
      "40\tValidation loss: 0.041694\tBest loss: 0.035538\tAccuracy: 99.14%\n",
      "41\tValidation loss: 0.056516\tBest loss: 0.035538\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.041300\tBest loss: 0.035538\tAccuracy: 98.91%\n",
      "43\tValidation loss: 0.051188\tBest loss: 0.035538\tAccuracy: 99.14%\n",
      "44\tValidation loss: 0.047007\tBest loss: 0.035538\tAccuracy: 98.94%\n",
      "45\tValidation loss: 0.041435\tBest loss: 0.035538\tAccuracy: 99.14%\n",
      "46\tValidation loss: 0.047193\tBest loss: 0.035538\tAccuracy: 99.10%\n",
      "47\tValidation loss: 0.054683\tBest loss: 0.035538\tAccuracy: 98.79%\n",
      "48\tValidation loss: 0.048369\tBest loss: 0.035538\tAccuracy: 98.91%\n",
      "49\tValidation loss: 0.057901\tBest loss: 0.035538\tAccuracy: 98.71%\n",
      "50\tValidation loss: 0.040334\tBest loss: 0.035538\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total= 1.3min\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.056297\tBest loss: 0.056297\tAccuracy: 98.32%\n",
      "1\tValidation loss: 0.059774\tBest loss: 0.056297\tAccuracy: 98.36%\n",
      "2\tValidation loss: 0.043534\tBest loss: 0.043534\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.047727\tBest loss: 0.043534\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.035495\tBest loss: 0.035495\tAccuracy: 98.79%\n",
      "5\tValidation loss: 0.056833\tBest loss: 0.035495\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.058188\tBest loss: 0.035495\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.038678\tBest loss: 0.035495\tAccuracy: 98.83%\n",
      "8\tValidation loss: 0.034764\tBest loss: 0.034764\tAccuracy: 99.02%\n",
      "9\tValidation loss: 0.039832\tBest loss: 0.034764\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.034491\tBest loss: 0.034491\tAccuracy: 99.06%\n",
      "11\tValidation loss: 0.058531\tBest loss: 0.034491\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.078814\tBest loss: 0.034491\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.044861\tBest loss: 0.034491\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.039017\tBest loss: 0.034491\tAccuracy: 98.94%\n",
      "15\tValidation loss: 0.041216\tBest loss: 0.034491\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.045339\tBest loss: 0.034491\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.045725\tBest loss: 0.034491\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.031743\tBest loss: 0.031743\tAccuracy: 99.26%\n",
      "19\tValidation loss: 0.038907\tBest loss: 0.031743\tAccuracy: 99.18%\n",
      "20\tValidation loss: 0.037080\tBest loss: 0.031743\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.034546\tBest loss: 0.031743\tAccuracy: 99.10%\n",
      "22\tValidation loss: 0.036263\tBest loss: 0.031743\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.041587\tBest loss: 0.031743\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.045325\tBest loss: 0.031743\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.041382\tBest loss: 0.031743\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.043711\tBest loss: 0.031743\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.045540\tBest loss: 0.031743\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.051828\tBest loss: 0.031743\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.037859\tBest loss: 0.031743\tAccuracy: 99.14%\n",
      "30\tValidation loss: 0.028909\tBest loss: 0.028909\tAccuracy: 99.22%\n",
      "31\tValidation loss: 0.038540\tBest loss: 0.028909\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.034801\tBest loss: 0.028909\tAccuracy: 99.18%\n",
      "33\tValidation loss: 0.047964\tBest loss: 0.028909\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.057990\tBest loss: 0.028909\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.043606\tBest loss: 0.028909\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.046079\tBest loss: 0.028909\tAccuracy: 98.94%\n",
      "37\tValidation loss: 0.049867\tBest loss: 0.028909\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.070577\tBest loss: 0.028909\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.068072\tBest loss: 0.028909\tAccuracy: 98.63%\n",
      "40\tValidation loss: 0.040314\tBest loss: 0.028909\tAccuracy: 99.06%\n",
      "41\tValidation loss: 0.039867\tBest loss: 0.028909\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.046136\tBest loss: 0.028909\tAccuracy: 99.18%\n",
      "43\tValidation loss: 0.050790\tBest loss: 0.028909\tAccuracy: 99.22%\n",
      "44\tValidation loss: 0.051682\tBest loss: 0.028909\tAccuracy: 98.94%\n",
      "45\tValidation loss: 0.055962\tBest loss: 0.028909\tAccuracy: 98.98%\n",
      "46\tValidation loss: 0.044321\tBest loss: 0.028909\tAccuracy: 99.18%\n",
      "47\tValidation loss: 0.051358\tBest loss: 0.028909\tAccuracy: 99.10%\n",
      "48\tValidation loss: 0.038873\tBest loss: 0.028909\tAccuracy: 99.30%\n",
      "49\tValidation loss: 0.035044\tBest loss: 0.028909\tAccuracy: 99.18%\n",
      "50\tValidation loss: 0.047198\tBest loss: 0.028909\tAccuracy: 98.94%\n",
      "51\tValidation loss: 0.034297\tBest loss: 0.028909\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total= 2.6min\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.057241\tBest loss: 0.057241\tAccuracy: 98.36%\n",
      "1\tValidation loss: 0.047891\tBest loss: 0.047891\tAccuracy: 98.71%\n",
      "2\tValidation loss: 0.041081\tBest loss: 0.041081\tAccuracy: 98.79%\n",
      "3\tValidation loss: 0.045338\tBest loss: 0.041081\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.045826\tBest loss: 0.041081\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.052203\tBest loss: 0.041081\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.029641\tBest loss: 0.029641\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.036428\tBest loss: 0.029641\tAccuracy: 99.10%\n",
      "8\tValidation loss: 0.030727\tBest loss: 0.029641\tAccuracy: 99.22%\n",
      "9\tValidation loss: 0.034732\tBest loss: 0.029641\tAccuracy: 99.14%\n",
      "10\tValidation loss: 0.033032\tBest loss: 0.029641\tAccuracy: 99.14%\n",
      "11\tValidation loss: 0.032851\tBest loss: 0.029641\tAccuracy: 99.02%\n",
      "12\tValidation loss: 0.032264\tBest loss: 0.029641\tAccuracy: 99.18%\n",
      "13\tValidation loss: 0.038941\tBest loss: 0.029641\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.040315\tBest loss: 0.029641\tAccuracy: 99.26%\n",
      "15\tValidation loss: 0.040401\tBest loss: 0.029641\tAccuracy: 99.10%\n",
      "16\tValidation loss: 0.039319\tBest loss: 0.029641\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.063280\tBest loss: 0.029641\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.051015\tBest loss: 0.029641\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.042942\tBest loss: 0.029641\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.035352\tBest loss: 0.029641\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.038441\tBest loss: 0.029641\tAccuracy: 99.14%\n",
      "22\tValidation loss: 0.036619\tBest loss: 0.029641\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.039171\tBest loss: 0.029641\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.045682\tBest loss: 0.029641\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.032649\tBest loss: 0.029641\tAccuracy: 99.18%\n",
      "26\tValidation loss: 0.048500\tBest loss: 0.029641\tAccuracy: 99.06%\n",
      "27\tValidation loss: 0.046176\tBest loss: 0.029641\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total= 1.4min\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.072202\tBest loss: 0.072202\tAccuracy: 97.58%\n",
      "1\tValidation loss: 0.072452\tBest loss: 0.072202\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.058725\tBest loss: 0.058725\tAccuracy: 98.48%\n",
      "3\tValidation loss: 0.069293\tBest loss: 0.058725\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.041959\tBest loss: 0.041959\tAccuracy: 98.87%\n",
      "5\tValidation loss: 0.044976\tBest loss: 0.041959\tAccuracy: 98.59%\n",
      "6\tValidation loss: 0.036495\tBest loss: 0.036495\tAccuracy: 98.83%\n",
      "7\tValidation loss: 0.038221\tBest loss: 0.036495\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.051126\tBest loss: 0.036495\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.046744\tBest loss: 0.036495\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.035568\tBest loss: 0.035568\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.047235\tBest loss: 0.035568\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.034241\tBest loss: 0.034241\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.046280\tBest loss: 0.034241\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.039851\tBest loss: 0.034241\tAccuracy: 98.94%\n",
      "15\tValidation loss: 0.044602\tBest loss: 0.034241\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.038242\tBest loss: 0.034241\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.039131\tBest loss: 0.034241\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.043425\tBest loss: 0.034241\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.038454\tBest loss: 0.034241\tAccuracy: 99.10%\n",
      "20\tValidation loss: 0.034581\tBest loss: 0.034241\tAccuracy: 99.02%\n",
      "21\tValidation loss: 0.041037\tBest loss: 0.034241\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.042731\tBest loss: 0.034241\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.036467\tBest loss: 0.034241\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.039944\tBest loss: 0.034241\tAccuracy: 99.14%\n",
      "25\tValidation loss: 0.036315\tBest loss: 0.034241\tAccuracy: 99.22%\n",
      "26\tValidation loss: 0.043695\tBest loss: 0.034241\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.045565\tBest loss: 0.034241\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.044928\tBest loss: 0.034241\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.036284\tBest loss: 0.034241\tAccuracy: 99.26%\n",
      "30\tValidation loss: 0.046163\tBest loss: 0.034241\tAccuracy: 99.10%\n",
      "31\tValidation loss: 0.045914\tBest loss: 0.034241\tAccuracy: 98.94%\n",
      "32\tValidation loss: 0.049290\tBest loss: 0.034241\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.032856\tBest loss: 0.032856\tAccuracy: 99.34%\n",
      "34\tValidation loss: 0.041232\tBest loss: 0.032856\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.039385\tBest loss: 0.032856\tAccuracy: 99.26%\n",
      "36\tValidation loss: 0.039346\tBest loss: 0.032856\tAccuracy: 99.18%\n",
      "37\tValidation loss: 0.044991\tBest loss: 0.032856\tAccuracy: 98.98%\n",
      "38\tValidation loss: 0.038330\tBest loss: 0.032856\tAccuracy: 98.98%\n",
      "39\tValidation loss: 0.033720\tBest loss: 0.032856\tAccuracy: 99.10%\n",
      "40\tValidation loss: 0.046713\tBest loss: 0.032856\tAccuracy: 98.79%\n",
      "41\tValidation loss: 0.046787\tBest loss: 0.032856\tAccuracy: 98.94%\n",
      "42\tValidation loss: 0.047652\tBest loss: 0.032856\tAccuracy: 99.14%\n",
      "43\tValidation loss: 0.048487\tBest loss: 0.032856\tAccuracy: 99.06%\n",
      "44\tValidation loss: 0.058403\tBest loss: 0.032856\tAccuracy: 98.91%\n",
      "45\tValidation loss: 0.050030\tBest loss: 0.032856\tAccuracy: 98.98%\n",
      "46\tValidation loss: 0.046058\tBest loss: 0.032856\tAccuracy: 99.14%\n",
      "47\tValidation loss: 0.047910\tBest loss: 0.032856\tAccuracy: 98.98%\n",
      "48\tValidation loss: 0.039757\tBest loss: 0.032856\tAccuracy: 99.34%\n",
      "49\tValidation loss: 0.062784\tBest loss: 0.032856\tAccuracy: 99.10%\n",
      "50\tValidation loss: 0.029901\tBest loss: 0.029901\tAccuracy: 99.30%\n",
      "51\tValidation loss: 0.040020\tBest loss: 0.029901\tAccuracy: 99.18%\n",
      "52\tValidation loss: 0.048543\tBest loss: 0.029901\tAccuracy: 99.22%\n",
      "53\tValidation loss: 0.067312\tBest loss: 0.029901\tAccuracy: 99.10%\n",
      "54\tValidation loss: 0.049256\tBest loss: 0.029901\tAccuracy: 99.10%\n",
      "55\tValidation loss: 0.042277\tBest loss: 0.029901\tAccuracy: 99.14%\n",
      "56\tValidation loss: 0.056173\tBest loss: 0.029901\tAccuracy: 99.10%\n",
      "57\tValidation loss: 0.044007\tBest loss: 0.029901\tAccuracy: 99.34%\n",
      "58\tValidation loss: 0.038953\tBest loss: 0.029901\tAccuracy: 99.30%\n",
      "59\tValidation loss: 0.044843\tBest loss: 0.029901\tAccuracy: 99.22%\n",
      "60\tValidation loss: 0.039741\tBest loss: 0.029901\tAccuracy: 99.18%\n",
      "61\tValidation loss: 0.039242\tBest loss: 0.029901\tAccuracy: 99.02%\n",
      "62\tValidation loss: 0.045419\tBest loss: 0.029901\tAccuracy: 99.10%\n",
      "63\tValidation loss: 0.045691\tBest loss: 0.029901\tAccuracy: 98.91%\n",
      "64\tValidation loss: 0.060611\tBest loss: 0.029901\tAccuracy: 98.83%\n",
      "65\tValidation loss: 0.044480\tBest loss: 0.029901\tAccuracy: 99.14%\n",
      "66\tValidation loss: 0.042276\tBest loss: 0.029901\tAccuracy: 99.22%\n",
      "67\tValidation loss: 0.051425\tBest loss: 0.029901\tAccuracy: 99.06%\n",
      "68\tValidation loss: 0.058890\tBest loss: 0.029901\tAccuracy: 99.06%\n",
      "69\tValidation loss: 0.043852\tBest loss: 0.029901\tAccuracy: 99.10%\n",
      "70\tValidation loss: 0.053511\tBest loss: 0.029901\tAccuracy: 99.10%\n",
      "71\tValidation loss: 0.064265\tBest loss: 0.029901\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total= 3.5min\n",
      "[CV] n_neurons=50, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.171026\tBest loss: 0.171026\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.077764\tBest loss: 0.077764\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.078379\tBest loss: 0.077764\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.072471\tBest loss: 0.072471\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.089605\tBest loss: 0.072471\tAccuracy: 97.69%\n",
      "5\tValidation loss: 0.083917\tBest loss: 0.072471\tAccuracy: 97.89%\n",
      "6\tValidation loss: 0.077126\tBest loss: 0.072471\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.065405\tBest loss: 0.065405\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.061083\tBest loss: 0.061083\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.052751\tBest loss: 0.052751\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.057392\tBest loss: 0.052751\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.079313\tBest loss: 0.052751\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.091934\tBest loss: 0.052751\tAccuracy: 98.12%\n",
      "13\tValidation loss: 0.076973\tBest loss: 0.052751\tAccuracy: 98.16%\n",
      "14\tValidation loss: 0.093465\tBest loss: 0.052751\tAccuracy: 97.81%\n",
      "15\tValidation loss: 0.071675\tBest loss: 0.052751\tAccuracy: 98.59%\n",
      "16\tValidation loss: 0.072923\tBest loss: 0.052751\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.060879\tBest loss: 0.052751\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.063397\tBest loss: 0.052751\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.061213\tBest loss: 0.052751\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.071966\tBest loss: 0.052751\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.059673\tBest loss: 0.052751\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.090196\tBest loss: 0.052751\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.072597\tBest loss: 0.052751\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.071024\tBest loss: 0.052751\tAccuracy: 98.36%\n",
      "25\tValidation loss: 0.066226\tBest loss: 0.052751\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.057644\tBest loss: 0.052751\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.069534\tBest loss: 0.052751\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.058671\tBest loss: 0.052751\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.064137\tBest loss: 0.052751\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.063631\tBest loss: 0.052751\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total=  25.6s\n",
      "[CV] n_neurons=50, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.171403\tBest loss: 0.171403\tAccuracy: 97.11%\n",
      "1\tValidation loss: 0.081203\tBest loss: 0.081203\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.066073\tBest loss: 0.066073\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.067137\tBest loss: 0.066073\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.058396\tBest loss: 0.058396\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.059153\tBest loss: 0.058396\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.069434\tBest loss: 0.058396\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.063157\tBest loss: 0.058396\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.045082\tBest loss: 0.045082\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.043080\tBest loss: 0.043080\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.059333\tBest loss: 0.043080\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.062903\tBest loss: 0.043080\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.073989\tBest loss: 0.043080\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.049150\tBest loss: 0.043080\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.061583\tBest loss: 0.043080\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.053500\tBest loss: 0.043080\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.062050\tBest loss: 0.043080\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.072799\tBest loss: 0.043080\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.070199\tBest loss: 0.043080\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.053690\tBest loss: 0.043080\tAccuracy: 98.87%\n",
      "20\tValidation loss: 0.056384\tBest loss: 0.043080\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.064527\tBest loss: 0.043080\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.072023\tBest loss: 0.043080\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.072340\tBest loss: 0.043080\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.058243\tBest loss: 0.043080\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.060783\tBest loss: 0.043080\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.054292\tBest loss: 0.043080\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.055536\tBest loss: 0.043080\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.044219\tBest loss: 0.043080\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.054249\tBest loss: 0.043080\tAccuracy: 98.98%\n",
      "30\tValidation loss: 0.052880\tBest loss: 0.043080\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total=  25.4s\n",
      "[CV] n_neurons=50, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.149316\tBest loss: 0.149316\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.068320\tBest loss: 0.068320\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.056769\tBest loss: 0.056769\tAccuracy: 98.32%\n",
      "3\tValidation loss: 0.062551\tBest loss: 0.056769\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.062935\tBest loss: 0.056769\tAccuracy: 98.01%\n",
      "5\tValidation loss: 0.067243\tBest loss: 0.056769\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.059707\tBest loss: 0.056769\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.052866\tBest loss: 0.052866\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.049121\tBest loss: 0.049121\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.052977\tBest loss: 0.049121\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.063868\tBest loss: 0.049121\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.057032\tBest loss: 0.049121\tAccuracy: 98.55%\n",
      "12\tValidation loss: 0.045997\tBest loss: 0.045997\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.051624\tBest loss: 0.045997\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.053229\tBest loss: 0.045997\tAccuracy: 98.98%\n",
      "15\tValidation loss: 0.059956\tBest loss: 0.045997\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.055594\tBest loss: 0.045997\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.056928\tBest loss: 0.045997\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.056944\tBest loss: 0.045997\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.077164\tBest loss: 0.045997\tAccuracy: 98.63%\n",
      "20\tValidation loss: 0.062971\tBest loss: 0.045997\tAccuracy: 98.36%\n",
      "21\tValidation loss: 0.053752\tBest loss: 0.045997\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.062117\tBest loss: 0.045997\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.053651\tBest loss: 0.045997\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.072749\tBest loss: 0.045997\tAccuracy: 98.63%\n",
      "25\tValidation loss: 0.071552\tBest loss: 0.045997\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.083182\tBest loss: 0.045997\tAccuracy: 98.59%\n",
      "27\tValidation loss: 0.072292\tBest loss: 0.045997\tAccuracy: 98.67%\n",
      "28\tValidation loss: 0.075386\tBest loss: 0.045997\tAccuracy: 98.79%\n",
      "29\tValidation loss: 0.074179\tBest loss: 0.045997\tAccuracy: 98.51%\n",
      "30\tValidation loss: 0.063132\tBest loss: 0.045997\tAccuracy: 98.83%\n",
      "31\tValidation loss: 0.095248\tBest loss: 0.045997\tAccuracy: 98.48%\n",
      "32\tValidation loss: 0.060818\tBest loss: 0.045997\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.064701\tBest loss: 0.045997\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total=  27.6s\n",
      "[CV] n_neurons=50, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 3.315689\tBest loss: 3.315689\tAccuracy: 90.11%\n",
      "1\tValidation loss: 1.061890\tBest loss: 1.061890\tAccuracy: 85.77%\n",
      "2\tValidation loss: 0.340379\tBest loss: 0.340379\tAccuracy: 93.39%\n",
      "3\tValidation loss: 0.277556\tBest loss: 0.277556\tAccuracy: 93.43%\n",
      "4\tValidation loss: 0.158813\tBest loss: 0.158813\tAccuracy: 96.21%\n",
      "5\tValidation loss: 0.155268\tBest loss: 0.155268\tAccuracy: 95.39%\n",
      "6\tValidation loss: 0.095627\tBest loss: 0.095627\tAccuracy: 97.54%\n",
      "7\tValidation loss: 0.100212\tBest loss: 0.095627\tAccuracy: 97.50%\n",
      "8\tValidation loss: 0.090968\tBest loss: 0.090968\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.189651\tBest loss: 0.090968\tAccuracy: 94.49%\n",
      "10\tValidation loss: 0.071642\tBest loss: 0.071642\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.082961\tBest loss: 0.071642\tAccuracy: 98.16%\n",
      "12\tValidation loss: 0.067694\tBest loss: 0.067694\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.088965\tBest loss: 0.067694\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.084449\tBest loss: 0.067694\tAccuracy: 98.01%\n",
      "15\tValidation loss: 0.073475\tBest loss: 0.067694\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.077648\tBest loss: 0.067694\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.131098\tBest loss: 0.067694\tAccuracy: 97.85%\n",
      "18\tValidation loss: 0.088930\tBest loss: 0.067694\tAccuracy: 98.16%\n",
      "19\tValidation loss: 0.078889\tBest loss: 0.067694\tAccuracy: 98.16%\n",
      "20\tValidation loss: 0.095454\tBest loss: 0.067694\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.068162\tBest loss: 0.067694\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.099519\tBest loss: 0.067694\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.102413\tBest loss: 0.067694\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.124100\tBest loss: 0.067694\tAccuracy: 98.40%\n",
      "25\tValidation loss: 0.070418\tBest loss: 0.067694\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.071639\tBest loss: 0.067694\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.072910\tBest loss: 0.067694\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.096063\tBest loss: 0.067694\tAccuracy: 98.67%\n",
      "29\tValidation loss: 0.085609\tBest loss: 0.067694\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.092054\tBest loss: 0.067694\tAccuracy: 98.44%\n",
      "31\tValidation loss: 0.076729\tBest loss: 0.067694\tAccuracy: 98.32%\n",
      "32\tValidation loss: 0.074586\tBest loss: 0.067694\tAccuracy: 98.59%\n",
      "33\tValidation loss: 0.072825\tBest loss: 0.067694\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0>, total=  28.5s\n",
      "[CV] n_neurons=50, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 2.522118\tBest loss: 2.522118\tAccuracy: 92.81%\n",
      "1\tValidation loss: 0.411442\tBest loss: 0.411442\tAccuracy: 95.78%\n",
      "2\tValidation loss: 0.196589\tBest loss: 0.196589\tAccuracy: 96.40%\n",
      "3\tValidation loss: 0.151509\tBest loss: 0.151509\tAccuracy: 96.36%\n",
      "4\tValidation loss: 0.202238\tBest loss: 0.151509\tAccuracy: 95.23%\n",
      "5\tValidation loss: 0.114028\tBest loss: 0.114028\tAccuracy: 96.91%\n",
      "6\tValidation loss: 0.133638\tBest loss: 0.114028\tAccuracy: 97.11%\n",
      "7\tValidation loss: 0.099942\tBest loss: 0.099942\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.090088\tBest loss: 0.090088\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.105691\tBest loss: 0.090088\tAccuracy: 97.42%\n",
      "10\tValidation loss: 0.081858\tBest loss: 0.081858\tAccuracy: 98.28%\n",
      "11\tValidation loss: 0.106480\tBest loss: 0.081858\tAccuracy: 97.65%\n",
      "12\tValidation loss: 0.104710\tBest loss: 0.081858\tAccuracy: 97.77%\n",
      "13\tValidation loss: 0.083726\tBest loss: 0.081858\tAccuracy: 98.28%\n",
      "14\tValidation loss: 0.091894\tBest loss: 0.081858\tAccuracy: 98.05%\n",
      "15\tValidation loss: 0.108526\tBest loss: 0.081858\tAccuracy: 98.24%\n",
      "16\tValidation loss: 0.077454\tBest loss: 0.077454\tAccuracy: 98.55%\n",
      "17\tValidation loss: 0.098942\tBest loss: 0.077454\tAccuracy: 98.44%\n",
      "18\tValidation loss: 0.124260\tBest loss: 0.077454\tAccuracy: 97.62%\n",
      "19\tValidation loss: 0.115525\tBest loss: 0.077454\tAccuracy: 97.73%\n",
      "20\tValidation loss: 0.111306\tBest loss: 0.077454\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.088100\tBest loss: 0.077454\tAccuracy: 98.55%\n",
      "22\tValidation loss: 0.104341\tBest loss: 0.077454\tAccuracy: 98.08%\n",
      "23\tValidation loss: 0.079418\tBest loss: 0.077454\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.111193\tBest loss: 0.077454\tAccuracy: 98.36%\n",
      "25\tValidation loss: 0.126728\tBest loss: 0.077454\tAccuracy: 98.32%\n",
      "26\tValidation loss: 0.115590\tBest loss: 0.077454\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.107797\tBest loss: 0.077454\tAccuracy: 98.40%\n",
      "28\tValidation loss: 0.087293\tBest loss: 0.077454\tAccuracy: 98.59%\n",
      "29\tValidation loss: 0.099565\tBest loss: 0.077454\tAccuracy: 98.36%\n",
      "30\tValidation loss: 0.113170\tBest loss: 0.077454\tAccuracy: 98.05%\n",
      "31\tValidation loss: 0.116083\tBest loss: 0.077454\tAccuracy: 98.28%\n",
      "32\tValidation loss: 0.112369\tBest loss: 0.077454\tAccuracy: 98.20%\n",
      "33\tValidation loss: 0.120603\tBest loss: 0.077454\tAccuracy: 98.12%\n",
      "34\tValidation loss: 0.100814\tBest loss: 0.077454\tAccuracy: 98.32%\n",
      "35\tValidation loss: 0.098707\tBest loss: 0.077454\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.108879\tBest loss: 0.077454\tAccuracy: 98.12%\n",
      "37\tValidation loss: 0.149465\tBest loss: 0.077454\tAccuracy: 97.73%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0>, total=  31.7s\n",
      "[CV] n_neurons=50, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 3.549922\tBest loss: 3.549922\tAccuracy: 83.07%\n",
      "1\tValidation loss: 0.553088\tBest loss: 0.553088\tAccuracy: 92.22%\n",
      "2\tValidation loss: 0.266301\tBest loss: 0.266301\tAccuracy: 94.10%\n",
      "3\tValidation loss: 0.166373\tBest loss: 0.166373\tAccuracy: 96.05%\n",
      "4\tValidation loss: 0.091973\tBest loss: 0.091973\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.123721\tBest loss: 0.091973\tAccuracy: 97.15%\n",
      "6\tValidation loss: 0.113918\tBest loss: 0.091973\tAccuracy: 97.19%\n",
      "7\tValidation loss: 0.084947\tBest loss: 0.084947\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.086299\tBest loss: 0.084947\tAccuracy: 97.65%\n",
      "9\tValidation loss: 0.070838\tBest loss: 0.070838\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.102802\tBest loss: 0.070838\tAccuracy: 97.69%\n",
      "11\tValidation loss: 0.101869\tBest loss: 0.070838\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.118671\tBest loss: 0.070838\tAccuracy: 97.50%\n",
      "13\tValidation loss: 0.133809\tBest loss: 0.070838\tAccuracy: 97.89%\n",
      "14\tValidation loss: 0.143742\tBest loss: 0.070838\tAccuracy: 97.42%\n",
      "15\tValidation loss: 0.088523\tBest loss: 0.070838\tAccuracy: 98.24%\n",
      "16\tValidation loss: 0.078106\tBest loss: 0.070838\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.121577\tBest loss: 0.070838\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.084054\tBest loss: 0.070838\tAccuracy: 98.32%\n",
      "19\tValidation loss: 0.102872\tBest loss: 0.070838\tAccuracy: 98.08%\n",
      "20\tValidation loss: 0.095216\tBest loss: 0.070838\tAccuracy: 98.51%\n",
      "21\tValidation loss: 0.135796\tBest loss: 0.070838\tAccuracy: 98.32%\n",
      "22\tValidation loss: 0.090811\tBest loss: 0.070838\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.104169\tBest loss: 0.070838\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.122878\tBest loss: 0.070838\tAccuracy: 98.08%\n",
      "25\tValidation loss: 0.095862\tBest loss: 0.070838\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.101499\tBest loss: 0.070838\tAccuracy: 98.55%\n",
      "27\tValidation loss: 0.099798\tBest loss: 0.070838\tAccuracy: 98.32%\n",
      "28\tValidation loss: 0.098558\tBest loss: 0.070838\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.095445\tBest loss: 0.070838\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.110018\tBest loss: 0.070838\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0>, total=  26.2s\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.120445\tBest loss: 0.120445\tAccuracy: 96.99%\n",
      "1\tValidation loss: 0.075442\tBest loss: 0.075442\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.077029\tBest loss: 0.075442\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.082273\tBest loss: 0.075442\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.083294\tBest loss: 0.075442\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.065452\tBest loss: 0.065452\tAccuracy: 98.01%\n",
      "6\tValidation loss: 0.061826\tBest loss: 0.061826\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.062791\tBest loss: 0.061826\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.066690\tBest loss: 0.061826\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.102351\tBest loss: 0.061826\tAccuracy: 97.73%\n",
      "10\tValidation loss: 0.077672\tBest loss: 0.061826\tAccuracy: 97.97%\n",
      "11\tValidation loss: 0.064384\tBest loss: 0.061826\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.060002\tBest loss: 0.060002\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.080841\tBest loss: 0.060002\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.090761\tBest loss: 0.060002\tAccuracy: 97.97%\n",
      "15\tValidation loss: 0.076486\tBest loss: 0.060002\tAccuracy: 98.20%\n",
      "16\tValidation loss: 0.085539\tBest loss: 0.060002\tAccuracy: 97.97%\n",
      "17\tValidation loss: 0.060516\tBest loss: 0.060002\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.078725\tBest loss: 0.060002\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.075777\tBest loss: 0.060002\tAccuracy: 98.32%\n",
      "20\tValidation loss: 0.070327\tBest loss: 0.060002\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.076458\tBest loss: 0.060002\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.089109\tBest loss: 0.060002\tAccuracy: 98.28%\n",
      "23\tValidation loss: 0.067891\tBest loss: 0.060002\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.078354\tBest loss: 0.060002\tAccuracy: 98.36%\n",
      "25\tValidation loss: 0.109646\tBest loss: 0.060002\tAccuracy: 98.05%\n",
      "26\tValidation loss: 0.067939\tBest loss: 0.060002\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.068411\tBest loss: 0.060002\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.086772\tBest loss: 0.060002\tAccuracy: 98.40%\n",
      "29\tValidation loss: 0.087253\tBest loss: 0.060002\tAccuracy: 98.24%\n",
      "30\tValidation loss: 0.082330\tBest loss: 0.060002\tAccuracy: 98.36%\n",
      "31\tValidation loss: 0.080405\tBest loss: 0.060002\tAccuracy: 98.48%\n",
      "32\tValidation loss: 0.079389\tBest loss: 0.060002\tAccuracy: 98.51%\n",
      "33\tValidation loss: 0.094985\tBest loss: 0.060002\tAccuracy: 98.32%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  20.3s\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.152542\tBest loss: 0.152542\tAccuracy: 96.21%\n",
      "1\tValidation loss: 0.094383\tBest loss: 0.094383\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.087811\tBest loss: 0.087811\tAccuracy: 97.42%\n",
      "3\tValidation loss: 0.072199\tBest loss: 0.072199\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.080158\tBest loss: 0.072199\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.060464\tBest loss: 0.060464\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.063076\tBest loss: 0.060464\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.071513\tBest loss: 0.060464\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.066894\tBest loss: 0.060464\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.055525\tBest loss: 0.055525\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.057226\tBest loss: 0.055525\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.051573\tBest loss: 0.051573\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.069014\tBest loss: 0.051573\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.061186\tBest loss: 0.051573\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.075178\tBest loss: 0.051573\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.067463\tBest loss: 0.051573\tAccuracy: 98.16%\n",
      "16\tValidation loss: 0.054549\tBest loss: 0.051573\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.072407\tBest loss: 0.051573\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.080038\tBest loss: 0.051573\tAccuracy: 98.12%\n",
      "19\tValidation loss: 0.086484\tBest loss: 0.051573\tAccuracy: 98.08%\n",
      "20\tValidation loss: 0.061269\tBest loss: 0.051573\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.079179\tBest loss: 0.051573\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.070354\tBest loss: 0.051573\tAccuracy: 98.51%\n",
      "23\tValidation loss: 0.078205\tBest loss: 0.051573\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.059274\tBest loss: 0.051573\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.079058\tBest loss: 0.051573\tAccuracy: 98.63%\n",
      "26\tValidation loss: 0.078356\tBest loss: 0.051573\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.078335\tBest loss: 0.051573\tAccuracy: 98.12%\n",
      "28\tValidation loss: 0.053128\tBest loss: 0.051573\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.066326\tBest loss: 0.051573\tAccuracy: 98.63%\n",
      "30\tValidation loss: 0.084387\tBest loss: 0.051573\tAccuracy: 98.36%\n",
      "31\tValidation loss: 0.071736\tBest loss: 0.051573\tAccuracy: 98.59%\n",
      "32\tValidation loss: 0.053113\tBest loss: 0.051573\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  20.3s\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.146565\tBest loss: 0.146565\tAccuracy: 96.09%\n",
      "1\tValidation loss: 0.090031\tBest loss: 0.090031\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.079856\tBest loss: 0.079856\tAccuracy: 97.42%\n",
      "3\tValidation loss: 0.068727\tBest loss: 0.068727\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.056997\tBest loss: 0.056997\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.055919\tBest loss: 0.055919\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.048222\tBest loss: 0.048222\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.067137\tBest loss: 0.048222\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.054552\tBest loss: 0.048222\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.061003\tBest loss: 0.048222\tAccuracy: 98.16%\n",
      "10\tValidation loss: 0.074672\tBest loss: 0.048222\tAccuracy: 98.08%\n",
      "11\tValidation loss: 0.070448\tBest loss: 0.048222\tAccuracy: 98.08%\n",
      "12\tValidation loss: 0.067015\tBest loss: 0.048222\tAccuracy: 98.20%\n",
      "13\tValidation loss: 0.065074\tBest loss: 0.048222\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.055246\tBest loss: 0.048222\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.063441\tBest loss: 0.048222\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.064316\tBest loss: 0.048222\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.060944\tBest loss: 0.048222\tAccuracy: 98.24%\n",
      "18\tValidation loss: 0.063319\tBest loss: 0.048222\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.074890\tBest loss: 0.048222\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.085622\tBest loss: 0.048222\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.059748\tBest loss: 0.048222\tAccuracy: 98.44%\n",
      "22\tValidation loss: 0.070523\tBest loss: 0.048222\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.070539\tBest loss: 0.048222\tAccuracy: 98.36%\n",
      "24\tValidation loss: 0.058731\tBest loss: 0.048222\tAccuracy: 98.44%\n",
      "25\tValidation loss: 0.070145\tBest loss: 0.048222\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.071499\tBest loss: 0.048222\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.059620\tBest loss: 0.048222\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  17.8s\n",
      "[CV] n_neurons=50, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.067200\tBest loss: 1.067200\tAccuracy: 97.03%\n",
      "1\tValidation loss: 1.582817\tBest loss: 1.067200\tAccuracy: 95.39%\n",
      "2\tValidation loss: 0.357740\tBest loss: 0.357740\tAccuracy: 98.20%\n",
      "3\tValidation loss: 0.241110\tBest loss: 0.241110\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.309555\tBest loss: 0.241110\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.575990\tBest loss: 0.241110\tAccuracy: 96.33%\n",
      "6\tValidation loss: 0.367067\tBest loss: 0.241110\tAccuracy: 96.48%\n",
      "7\tValidation loss: 0.148223\tBest loss: 0.148223\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.198319\tBest loss: 0.148223\tAccuracy: 97.85%\n",
      "9\tValidation loss: 0.143028\tBest loss: 0.143028\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.713428\tBest loss: 0.143028\tAccuracy: 96.83%\n",
      "11\tValidation loss: 0.129968\tBest loss: 0.129968\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.214315\tBest loss: 0.129968\tAccuracy: 97.93%\n",
      "13\tValidation loss: 0.150381\tBest loss: 0.129968\tAccuracy: 98.24%\n",
      "14\tValidation loss: 0.156624\tBest loss: 0.129968\tAccuracy: 97.93%\n",
      "15\tValidation loss: 0.257494\tBest loss: 0.129968\tAccuracy: 97.30%\n",
      "16\tValidation loss: 0.183307\tBest loss: 0.129968\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.134477\tBest loss: 0.129968\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.166087\tBest loss: 0.129968\tAccuracy: 98.20%\n",
      "19\tValidation loss: 1.810037\tBest loss: 0.129968\tAccuracy: 85.26%\n",
      "20\tValidation loss: 0.197759\tBest loss: 0.129968\tAccuracy: 98.36%\n",
      "21\tValidation loss: 0.141861\tBest loss: 0.129968\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.214077\tBest loss: 0.129968\tAccuracy: 97.97%\n",
      "23\tValidation loss: 0.169443\tBest loss: 0.129968\tAccuracy: 98.12%\n",
      "24\tValidation loss: 0.094343\tBest loss: 0.094343\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.108194\tBest loss: 0.094343\tAccuracy: 98.51%\n",
      "26\tValidation loss: 0.641250\tBest loss: 0.094343\tAccuracy: 97.65%\n",
      "27\tValidation loss: 0.133234\tBest loss: 0.094343\tAccuracy: 98.59%\n",
      "28\tValidation loss: 0.092416\tBest loss: 0.092416\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.105750\tBest loss: 0.092416\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.094173\tBest loss: 0.092416\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.132322\tBest loss: 0.092416\tAccuracy: 98.51%\n",
      "32\tValidation loss: 0.636104\tBest loss: 0.092416\tAccuracy: 96.05%\n",
      "33\tValidation loss: 0.271930\tBest loss: 0.092416\tAccuracy: 97.46%\n",
      "34\tValidation loss: 0.113073\tBest loss: 0.092416\tAccuracy: 98.51%\n",
      "35\tValidation loss: 0.127161\tBest loss: 0.092416\tAccuracy: 98.40%\n",
      "36\tValidation loss: 0.097729\tBest loss: 0.092416\tAccuracy: 98.63%\n",
      "37\tValidation loss: 0.159042\tBest loss: 0.092416\tAccuracy: 98.51%\n",
      "38\tValidation loss: 0.169135\tBest loss: 0.092416\tAccuracy: 98.08%\n",
      "39\tValidation loss: 0.110304\tBest loss: 0.092416\tAccuracy: 98.44%\n",
      "40\tValidation loss: 0.096450\tBest loss: 0.092416\tAccuracy: 98.59%\n",
      "41\tValidation loss: 0.075070\tBest loss: 0.075070\tAccuracy: 98.87%\n",
      "42\tValidation loss: 0.088677\tBest loss: 0.075070\tAccuracy: 98.87%\n",
      "43\tValidation loss: 0.232322\tBest loss: 0.075070\tAccuracy: 97.62%\n",
      "44\tValidation loss: 0.169468\tBest loss: 0.075070\tAccuracy: 98.24%\n",
      "45\tValidation loss: 0.159218\tBest loss: 0.075070\tAccuracy: 98.28%\n",
      "46\tValidation loss: 0.149431\tBest loss: 0.075070\tAccuracy: 97.58%\n",
      "47\tValidation loss: 0.110265\tBest loss: 0.075070\tAccuracy: 98.83%\n",
      "48\tValidation loss: 0.096211\tBest loss: 0.075070\tAccuracy: 98.55%\n",
      "49\tValidation loss: 0.169249\tBest loss: 0.075070\tAccuracy: 98.51%\n",
      "50\tValidation loss: 0.107426\tBest loss: 0.075070\tAccuracy: 98.55%\n",
      "51\tValidation loss: 0.126389\tBest loss: 0.075070\tAccuracy: 98.44%\n",
      "52\tValidation loss: 0.097871\tBest loss: 0.075070\tAccuracy: 98.91%\n",
      "53\tValidation loss: 0.263273\tBest loss: 0.075070\tAccuracy: 98.44%\n",
      "54\tValidation loss: 0.319283\tBest loss: 0.075070\tAccuracy: 97.73%\n",
      "55\tValidation loss: 0.148447\tBest loss: 0.075070\tAccuracy: 98.75%\n",
      "56\tValidation loss: 0.188423\tBest loss: 0.075070\tAccuracy: 98.51%\n",
      "57\tValidation loss: 0.109628\tBest loss: 0.075070\tAccuracy: 98.91%\n",
      "58\tValidation loss: 0.100224\tBest loss: 0.075070\tAccuracy: 99.06%\n",
      "59\tValidation loss: 0.198912\tBest loss: 0.075070\tAccuracy: 98.08%\n",
      "60\tValidation loss: 0.184918\tBest loss: 0.075070\tAccuracy: 98.59%\n",
      "61\tValidation loss: 0.125653\tBest loss: 0.075070\tAccuracy: 98.48%\n",
      "62\tValidation loss: 0.142860\tBest loss: 0.075070\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 2.7min\n",
      "[CV] n_neurons=50, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.240054\tBest loss: 1.240054\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.689655\tBest loss: 0.689655\tAccuracy: 96.13%\n",
      "2\tValidation loss: 0.336004\tBest loss: 0.336004\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.301789\tBest loss: 0.301789\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.676396\tBest loss: 0.301789\tAccuracy: 95.66%\n",
      "5\tValidation loss: 0.203186\tBest loss: 0.203186\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.259574\tBest loss: 0.203186\tAccuracy: 97.50%\n",
      "7\tValidation loss: 0.183242\tBest loss: 0.183242\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.186411\tBest loss: 0.183242\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.208086\tBest loss: 0.183242\tAccuracy: 97.85%\n",
      "10\tValidation loss: 0.268148\tBest loss: 0.183242\tAccuracy: 98.08%\n",
      "11\tValidation loss: 0.414758\tBest loss: 0.183242\tAccuracy: 97.93%\n",
      "12\tValidation loss: 0.740853\tBest loss: 0.183242\tAccuracy: 97.65%\n",
      "13\tValidation loss: 0.286725\tBest loss: 0.183242\tAccuracy: 97.34%\n",
      "14\tValidation loss: 0.201148\tBest loss: 0.183242\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.288760\tBest loss: 0.183242\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.205323\tBest loss: 0.183242\tAccuracy: 98.32%\n",
      "17\tValidation loss: 0.156685\tBest loss: 0.156685\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.276226\tBest loss: 0.156685\tAccuracy: 97.38%\n",
      "19\tValidation loss: 0.151984\tBest loss: 0.151984\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.164929\tBest loss: 0.151984\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.874757\tBest loss: 0.151984\tAccuracy: 96.64%\n",
      "22\tValidation loss: 0.230235\tBest loss: 0.151984\tAccuracy: 97.42%\n",
      "23\tValidation loss: 0.171597\tBest loss: 0.151984\tAccuracy: 98.01%\n",
      "24\tValidation loss: 0.141521\tBest loss: 0.141521\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.112776\tBest loss: 0.112776\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.107649\tBest loss: 0.107649\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.121687\tBest loss: 0.107649\tAccuracy: 98.63%\n",
      "28\tValidation loss: 0.193636\tBest loss: 0.107649\tAccuracy: 97.50%\n",
      "29\tValidation loss: 0.160939\tBest loss: 0.107649\tAccuracy: 98.12%\n",
      "30\tValidation loss: 0.182299\tBest loss: 0.107649\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.356685\tBest loss: 0.107649\tAccuracy: 97.46%\n",
      "32\tValidation loss: 0.122239\tBest loss: 0.107649\tAccuracy: 98.67%\n",
      "33\tValidation loss: 0.125699\tBest loss: 0.107649\tAccuracy: 98.59%\n",
      "34\tValidation loss: 0.094297\tBest loss: 0.094297\tAccuracy: 98.63%\n",
      "35\tValidation loss: 0.076618\tBest loss: 0.076618\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.160946\tBest loss: 0.076618\tAccuracy: 98.40%\n",
      "37\tValidation loss: 0.286169\tBest loss: 0.076618\tAccuracy: 97.54%\n",
      "38\tValidation loss: 0.163217\tBest loss: 0.076618\tAccuracy: 98.16%\n",
      "39\tValidation loss: 0.116180\tBest loss: 0.076618\tAccuracy: 98.24%\n",
      "40\tValidation loss: 0.216251\tBest loss: 0.076618\tAccuracy: 98.16%\n",
      "41\tValidation loss: 0.113621\tBest loss: 0.076618\tAccuracy: 98.32%\n",
      "42\tValidation loss: 0.540520\tBest loss: 0.076618\tAccuracy: 95.47%\n",
      "43\tValidation loss: 0.302677\tBest loss: 0.076618\tAccuracy: 97.69%\n",
      "44\tValidation loss: 0.199822\tBest loss: 0.076618\tAccuracy: 98.12%\n",
      "45\tValidation loss: 0.133804\tBest loss: 0.076618\tAccuracy: 98.59%\n",
      "46\tValidation loss: 0.172888\tBest loss: 0.076618\tAccuracy: 98.28%\n",
      "47\tValidation loss: 0.102322\tBest loss: 0.076618\tAccuracy: 98.75%\n",
      "48\tValidation loss: 0.137529\tBest loss: 0.076618\tAccuracy: 98.32%\n",
      "49\tValidation loss: 0.210839\tBest loss: 0.076618\tAccuracy: 98.05%\n",
      "50\tValidation loss: 0.339873\tBest loss: 0.076618\tAccuracy: 98.05%\n",
      "51\tValidation loss: 0.244992\tBest loss: 0.076618\tAccuracy: 98.12%\n",
      "52\tValidation loss: 0.310806\tBest loss: 0.076618\tAccuracy: 97.81%\n",
      "53\tValidation loss: 0.470067\tBest loss: 0.076618\tAccuracy: 94.76%\n",
      "54\tValidation loss: 0.126292\tBest loss: 0.076618\tAccuracy: 98.75%\n",
      "55\tValidation loss: 0.130839\tBest loss: 0.076618\tAccuracy: 98.83%\n",
      "56\tValidation loss: 0.137175\tBest loss: 0.076618\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 2.4min\n",
      "[CV] n_neurons=50, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.483652\tBest loss: 1.483652\tAccuracy: 96.36%\n",
      "1\tValidation loss: 0.787566\tBest loss: 0.787566\tAccuracy: 96.44%\n",
      "2\tValidation loss: 0.368934\tBest loss: 0.368934\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.300013\tBest loss: 0.300013\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.298563\tBest loss: 0.298563\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.322629\tBest loss: 0.298563\tAccuracy: 97.22%\n",
      "6\tValidation loss: 0.186112\tBest loss: 0.186112\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.234804\tBest loss: 0.186112\tAccuracy: 97.81%\n",
      "8\tValidation loss: 0.550456\tBest loss: 0.186112\tAccuracy: 96.52%\n",
      "9\tValidation loss: 0.164775\tBest loss: 0.164775\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.159813\tBest loss: 0.159813\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.326685\tBest loss: 0.159813\tAccuracy: 97.15%\n",
      "12\tValidation loss: 0.266393\tBest loss: 0.159813\tAccuracy: 97.93%\n",
      "13\tValidation loss: 0.203644\tBest loss: 0.159813\tAccuracy: 98.24%\n",
      "14\tValidation loss: 0.154047\tBest loss: 0.154047\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.292570\tBest loss: 0.154047\tAccuracy: 98.28%\n",
      "16\tValidation loss: 0.215942\tBest loss: 0.154047\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.160041\tBest loss: 0.154047\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.111523\tBest loss: 0.111523\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.111961\tBest loss: 0.111523\tAccuracy: 98.28%\n",
      "20\tValidation loss: 0.302785\tBest loss: 0.111523\tAccuracy: 96.60%\n",
      "21\tValidation loss: 0.160682\tBest loss: 0.111523\tAccuracy: 98.28%\n",
      "22\tValidation loss: 0.345831\tBest loss: 0.111523\tAccuracy: 97.46%\n",
      "23\tValidation loss: 0.155200\tBest loss: 0.111523\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.134671\tBest loss: 0.111523\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.194911\tBest loss: 0.111523\tAccuracy: 97.81%\n",
      "26\tValidation loss: 0.197949\tBest loss: 0.111523\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.099019\tBest loss: 0.099019\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.146346\tBest loss: 0.099019\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.271740\tBest loss: 0.099019\tAccuracy: 98.05%\n",
      "30\tValidation loss: 0.166053\tBest loss: 0.099019\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.088035\tBest loss: 0.088035\tAccuracy: 98.98%\n",
      "32\tValidation loss: 0.189782\tBest loss: 0.088035\tAccuracy: 98.24%\n",
      "33\tValidation loss: 0.097673\tBest loss: 0.088035\tAccuracy: 98.79%\n",
      "34\tValidation loss: 0.209168\tBest loss: 0.088035\tAccuracy: 98.24%\n",
      "35\tValidation loss: 0.238291\tBest loss: 0.088035\tAccuracy: 97.97%\n",
      "36\tValidation loss: 0.144434\tBest loss: 0.088035\tAccuracy: 99.14%\n",
      "37\tValidation loss: 0.194573\tBest loss: 0.088035\tAccuracy: 98.01%\n",
      "38\tValidation loss: 0.203795\tBest loss: 0.088035\tAccuracy: 98.36%\n",
      "39\tValidation loss: 0.325953\tBest loss: 0.088035\tAccuracy: 96.13%\n",
      "40\tValidation loss: 0.140212\tBest loss: 0.088035\tAccuracy: 98.24%\n",
      "41\tValidation loss: 0.219095\tBest loss: 0.088035\tAccuracy: 98.48%\n",
      "42\tValidation loss: 0.117436\tBest loss: 0.088035\tAccuracy: 98.83%\n",
      "43\tValidation loss: 0.273824\tBest loss: 0.088035\tAccuracy: 97.54%\n",
      "44\tValidation loss: 0.342816\tBest loss: 0.088035\tAccuracy: 97.34%\n",
      "45\tValidation loss: 0.179445\tBest loss: 0.088035\tAccuracy: 98.63%\n",
      "46\tValidation loss: 0.130039\tBest loss: 0.088035\tAccuracy: 98.59%\n",
      "47\tValidation loss: 0.098385\tBest loss: 0.088035\tAccuracy: 98.79%\n",
      "48\tValidation loss: 0.109026\tBest loss: 0.088035\tAccuracy: 99.10%\n",
      "49\tValidation loss: 0.098041\tBest loss: 0.088035\tAccuracy: 98.91%\n",
      "50\tValidation loss: 0.356308\tBest loss: 0.088035\tAccuracy: 97.46%\n",
      "51\tValidation loss: 0.134539\tBest loss: 0.088035\tAccuracy: 98.94%\n",
      "52\tValidation loss: 0.129117\tBest loss: 0.088035\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 2.2min\n",
      "[CV] n_neurons=50, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.090662\tBest loss: 0.090662\tAccuracy: 97.89%\n",
      "1\tValidation loss: 0.109605\tBest loss: 0.090662\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.063223\tBest loss: 0.063223\tAccuracy: 98.44%\n",
      "3\tValidation loss: 0.055610\tBest loss: 0.055610\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.054771\tBest loss: 0.054771\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.062474\tBest loss: 0.054771\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.089673\tBest loss: 0.054771\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.045699\tBest loss: 0.045699\tAccuracy: 98.91%\n",
      "8\tValidation loss: 0.085220\tBest loss: 0.045699\tAccuracy: 97.58%\n",
      "9\tValidation loss: 0.051762\tBest loss: 0.045699\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.064689\tBest loss: 0.045699\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.052862\tBest loss: 0.045699\tAccuracy: 98.94%\n",
      "12\tValidation loss: 0.085022\tBest loss: 0.045699\tAccuracy: 98.20%\n",
      "13\tValidation loss: 0.048737\tBest loss: 0.045699\tAccuracy: 98.98%\n",
      "14\tValidation loss: 0.055689\tBest loss: 0.045699\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.041821\tBest loss: 0.041821\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.053440\tBest loss: 0.041821\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.058975\tBest loss: 0.041821\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.069552\tBest loss: 0.041821\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.181896\tBest loss: 0.041821\tAccuracy: 96.76%\n",
      "20\tValidation loss: 0.055526\tBest loss: 0.041821\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.044321\tBest loss: 0.041821\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.041013\tBest loss: 0.041013\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.076806\tBest loss: 0.041013\tAccuracy: 98.51%\n",
      "24\tValidation loss: 0.077089\tBest loss: 0.041013\tAccuracy: 98.40%\n",
      "25\tValidation loss: 0.051541\tBest loss: 0.041013\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.042326\tBest loss: 0.041013\tAccuracy: 99.18%\n",
      "27\tValidation loss: 0.051476\tBest loss: 0.041013\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.041167\tBest loss: 0.041013\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.057457\tBest loss: 0.041013\tAccuracy: 98.55%\n",
      "30\tValidation loss: 0.050928\tBest loss: 0.041013\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.068509\tBest loss: 0.041013\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.055020\tBest loss: 0.041013\tAccuracy: 98.87%\n",
      "33\tValidation loss: 0.060334\tBest loss: 0.041013\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.057773\tBest loss: 0.041013\tAccuracy: 98.91%\n",
      "35\tValidation loss: 0.052275\tBest loss: 0.041013\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.045892\tBest loss: 0.041013\tAccuracy: 99.06%\n",
      "37\tValidation loss: 0.059232\tBest loss: 0.041013\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.045747\tBest loss: 0.041013\tAccuracy: 98.91%\n",
      "39\tValidation loss: 0.071536\tBest loss: 0.041013\tAccuracy: 98.83%\n",
      "40\tValidation loss: 0.051788\tBest loss: 0.041013\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.047272\tBest loss: 0.041013\tAccuracy: 98.91%\n",
      "42\tValidation loss: 0.050197\tBest loss: 0.041013\tAccuracy: 98.98%\n",
      "43\tValidation loss: 0.040406\tBest loss: 0.040406\tAccuracy: 99.06%\n",
      "44\tValidation loss: 0.053256\tBest loss: 0.040406\tAccuracy: 98.94%\n",
      "45\tValidation loss: 0.056745\tBest loss: 0.040406\tAccuracy: 98.79%\n",
      "46\tValidation loss: 0.057422\tBest loss: 0.040406\tAccuracy: 98.87%\n",
      "47\tValidation loss: 0.054477\tBest loss: 0.040406\tAccuracy: 98.63%\n",
      "48\tValidation loss: 0.048006\tBest loss: 0.040406\tAccuracy: 98.87%\n",
      "49\tValidation loss: 0.049556\tBest loss: 0.040406\tAccuracy: 99.02%\n",
      "50\tValidation loss: 0.045080\tBest loss: 0.040406\tAccuracy: 98.71%\n",
      "51\tValidation loss: 0.052553\tBest loss: 0.040406\tAccuracy: 98.94%\n",
      "52\tValidation loss: 0.081895\tBest loss: 0.040406\tAccuracy: 98.87%\n",
      "53\tValidation loss: 0.045523\tBest loss: 0.040406\tAccuracy: 99.06%\n",
      "54\tValidation loss: 0.054948\tBest loss: 0.040406\tAccuracy: 98.83%\n",
      "55\tValidation loss: 0.054549\tBest loss: 0.040406\tAccuracy: 98.79%\n",
      "56\tValidation loss: 0.064480\tBest loss: 0.040406\tAccuracy: 98.75%\n",
      "57\tValidation loss: 0.048758\tBest loss: 0.040406\tAccuracy: 98.91%\n",
      "58\tValidation loss: 0.060799\tBest loss: 0.040406\tAccuracy: 99.18%\n",
      "59\tValidation loss: 0.080672\tBest loss: 0.040406\tAccuracy: 98.48%\n",
      "60\tValidation loss: 0.071066\tBest loss: 0.040406\tAccuracy: 98.98%\n",
      "61\tValidation loss: 0.049877\tBest loss: 0.040406\tAccuracy: 98.87%\n",
      "62\tValidation loss: 0.070646\tBest loss: 0.040406\tAccuracy: 98.79%\n",
      "63\tValidation loss: 0.074770\tBest loss: 0.040406\tAccuracy: 98.59%\n",
      "64\tValidation loss: 0.050440\tBest loss: 0.040406\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.9min\n",
      "[CV] n_neurons=50, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.133245\tBest loss: 0.133245\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.080271\tBest loss: 0.080271\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.056570\tBest loss: 0.056570\tAccuracy: 98.44%\n",
      "3\tValidation loss: 0.045147\tBest loss: 0.045147\tAccuracy: 98.75%\n",
      "4\tValidation loss: 0.088355\tBest loss: 0.045147\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.054670\tBest loss: 0.045147\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.059927\tBest loss: 0.045147\tAccuracy: 98.12%\n",
      "7\tValidation loss: 0.053029\tBest loss: 0.045147\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.056079\tBest loss: 0.045147\tAccuracy: 98.44%\n",
      "9\tValidation loss: 0.045312\tBest loss: 0.045147\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.049856\tBest loss: 0.045147\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.051162\tBest loss: 0.045147\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.064917\tBest loss: 0.045147\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.068882\tBest loss: 0.045147\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.057834\tBest loss: 0.045147\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.058373\tBest loss: 0.045147\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.048609\tBest loss: 0.045147\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.043702\tBest loss: 0.043702\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.053870\tBest loss: 0.043702\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.044694\tBest loss: 0.043702\tAccuracy: 98.63%\n",
      "20\tValidation loss: 0.047357\tBest loss: 0.043702\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.066447\tBest loss: 0.043702\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.046206\tBest loss: 0.043702\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.059201\tBest loss: 0.043702\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.060581\tBest loss: 0.043702\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.054931\tBest loss: 0.043702\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.055828\tBest loss: 0.043702\tAccuracy: 98.51%\n",
      "27\tValidation loss: 0.058950\tBest loss: 0.043702\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.064433\tBest loss: 0.043702\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.051498\tBest loss: 0.043702\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.052803\tBest loss: 0.043702\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.047541\tBest loss: 0.043702\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.044935\tBest loss: 0.043702\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.050557\tBest loss: 0.043702\tAccuracy: 98.87%\n",
      "34\tValidation loss: 0.039625\tBest loss: 0.039625\tAccuracy: 99.10%\n",
      "35\tValidation loss: 0.083724\tBest loss: 0.039625\tAccuracy: 97.97%\n",
      "36\tValidation loss: 0.052276\tBest loss: 0.039625\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.045366\tBest loss: 0.039625\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.054182\tBest loss: 0.039625\tAccuracy: 98.91%\n",
      "39\tValidation loss: 0.049942\tBest loss: 0.039625\tAccuracy: 99.06%\n",
      "40\tValidation loss: 0.054775\tBest loss: 0.039625\tAccuracy: 98.94%\n",
      "41\tValidation loss: 0.057322\tBest loss: 0.039625\tAccuracy: 98.71%\n",
      "42\tValidation loss: 0.057183\tBest loss: 0.039625\tAccuracy: 98.91%\n",
      "43\tValidation loss: 0.064898\tBest loss: 0.039625\tAccuracy: 98.83%\n",
      "44\tValidation loss: 0.052345\tBest loss: 0.039625\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.053379\tBest loss: 0.039625\tAccuracy: 98.87%\n",
      "46\tValidation loss: 0.051779\tBest loss: 0.039625\tAccuracy: 98.98%\n",
      "47\tValidation loss: 0.044263\tBest loss: 0.039625\tAccuracy: 98.94%\n",
      "48\tValidation loss: 0.036426\tBest loss: 0.036426\tAccuracy: 99.02%\n",
      "49\tValidation loss: 0.048567\tBest loss: 0.036426\tAccuracy: 98.94%\n",
      "50\tValidation loss: 0.050300\tBest loss: 0.036426\tAccuracy: 98.98%\n",
      "51\tValidation loss: 0.062874\tBest loss: 0.036426\tAccuracy: 98.67%\n",
      "52\tValidation loss: 0.070266\tBest loss: 0.036426\tAccuracy: 98.63%\n",
      "53\tValidation loss: 0.062981\tBest loss: 0.036426\tAccuracy: 98.48%\n",
      "54\tValidation loss: 0.054944\tBest loss: 0.036426\tAccuracy: 98.91%\n",
      "55\tValidation loss: 0.056161\tBest loss: 0.036426\tAccuracy: 98.94%\n",
      "56\tValidation loss: 0.054152\tBest loss: 0.036426\tAccuracy: 98.98%\n",
      "57\tValidation loss: 0.058279\tBest loss: 0.036426\tAccuracy: 98.91%\n",
      "58\tValidation loss: 0.050146\tBest loss: 0.036426\tAccuracy: 98.67%\n",
      "59\tValidation loss: 0.051207\tBest loss: 0.036426\tAccuracy: 99.02%\n",
      "60\tValidation loss: 0.055214\tBest loss: 0.036426\tAccuracy: 98.75%\n",
      "61\tValidation loss: 0.074962\tBest loss: 0.036426\tAccuracy: 98.44%\n",
      "62\tValidation loss: 0.059675\tBest loss: 0.036426\tAccuracy: 98.71%\n",
      "63\tValidation loss: 0.041350\tBest loss: 0.036426\tAccuracy: 99.10%\n",
      "64\tValidation loss: 0.046425\tBest loss: 0.036426\tAccuracy: 99.22%\n",
      "65\tValidation loss: 0.047319\tBest loss: 0.036426\tAccuracy: 98.91%\n",
      "66\tValidation loss: 0.054049\tBest loss: 0.036426\tAccuracy: 98.98%\n",
      "67\tValidation loss: 0.055879\tBest loss: 0.036426\tAccuracy: 98.67%\n",
      "68\tValidation loss: 0.062749\tBest loss: 0.036426\tAccuracy: 98.75%\n",
      "69\tValidation loss: 0.058022\tBest loss: 0.036426\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 3.1min\n",
      "[CV] n_neurons=50, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.069158\tBest loss: 0.069158\tAccuracy: 98.20%\n",
      "1\tValidation loss: 0.087475\tBest loss: 0.069158\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.068453\tBest loss: 0.068453\tAccuracy: 98.20%\n",
      "3\tValidation loss: 0.075554\tBest loss: 0.068453\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.059943\tBest loss: 0.059943\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.064809\tBest loss: 0.059943\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.043519\tBest loss: 0.043519\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.040553\tBest loss: 0.040553\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.069180\tBest loss: 0.040553\tAccuracy: 98.20%\n",
      "9\tValidation loss: 0.037622\tBest loss: 0.037622\tAccuracy: 99.02%\n",
      "10\tValidation loss: 0.044142\tBest loss: 0.037622\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.048692\tBest loss: 0.037622\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.055353\tBest loss: 0.037622\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.044017\tBest loss: 0.037622\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.032541\tBest loss: 0.032541\tAccuracy: 99.22%\n",
      "15\tValidation loss: 0.043827\tBest loss: 0.032541\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.053230\tBest loss: 0.032541\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.078077\tBest loss: 0.032541\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.047860\tBest loss: 0.032541\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.053978\tBest loss: 0.032541\tAccuracy: 98.87%\n",
      "20\tValidation loss: 0.040114\tBest loss: 0.032541\tAccuracy: 99.14%\n",
      "21\tValidation loss: 0.033732\tBest loss: 0.032541\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.047925\tBest loss: 0.032541\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.048094\tBest loss: 0.032541\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.042947\tBest loss: 0.032541\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.052682\tBest loss: 0.032541\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.049475\tBest loss: 0.032541\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.040566\tBest loss: 0.032541\tAccuracy: 99.18%\n",
      "28\tValidation loss: 0.058429\tBest loss: 0.032541\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.049651\tBest loss: 0.032541\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.076187\tBest loss: 0.032541\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.047861\tBest loss: 0.032541\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.048066\tBest loss: 0.032541\tAccuracy: 99.06%\n",
      "33\tValidation loss: 0.073592\tBest loss: 0.032541\tAccuracy: 98.40%\n",
      "34\tValidation loss: 0.032977\tBest loss: 0.032541\tAccuracy: 99.02%\n",
      "35\tValidation loss: 0.043107\tBest loss: 0.032541\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.6min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.085877\tBest loss: 0.085877\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.074115\tBest loss: 0.074115\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.054602\tBest loss: 0.054602\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.053784\tBest loss: 0.053784\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.052961\tBest loss: 0.052961\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.083741\tBest loss: 0.052961\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.055132\tBest loss: 0.052961\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.050518\tBest loss: 0.050518\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.048737\tBest loss: 0.048737\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.052110\tBest loss: 0.048737\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.044729\tBest loss: 0.044729\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.066014\tBest loss: 0.044729\tAccuracy: 98.55%\n",
      "12\tValidation loss: 0.053812\tBest loss: 0.044729\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.056569\tBest loss: 0.044729\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.045211\tBest loss: 0.044729\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.049855\tBest loss: 0.044729\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.065940\tBest loss: 0.044729\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.049010\tBest loss: 0.044729\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.052277\tBest loss: 0.044729\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.067694\tBest loss: 0.044729\tAccuracy: 98.51%\n",
      "20\tValidation loss: 0.051178\tBest loss: 0.044729\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.048776\tBest loss: 0.044729\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.043603\tBest loss: 0.043603\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.056131\tBest loss: 0.043603\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.058280\tBest loss: 0.043603\tAccuracy: 98.94%\n",
      "25\tValidation loss: 0.057147\tBest loss: 0.043603\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.069746\tBest loss: 0.043603\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.035803\tBest loss: 0.035803\tAccuracy: 99.18%\n",
      "28\tValidation loss: 0.046720\tBest loss: 0.035803\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.053236\tBest loss: 0.035803\tAccuracy: 99.10%\n",
      "30\tValidation loss: 0.047986\tBest loss: 0.035803\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.056777\tBest loss: 0.035803\tAccuracy: 98.98%\n",
      "32\tValidation loss: 0.049971\tBest loss: 0.035803\tAccuracy: 98.94%\n",
      "33\tValidation loss: 0.034973\tBest loss: 0.034973\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.059437\tBest loss: 0.034973\tAccuracy: 99.14%\n",
      "35\tValidation loss: 0.090878\tBest loss: 0.034973\tAccuracy: 98.75%\n",
      "36\tValidation loss: 0.123568\tBest loss: 0.034973\tAccuracy: 98.32%\n",
      "37\tValidation loss: 0.061500\tBest loss: 0.034973\tAccuracy: 98.98%\n",
      "38\tValidation loss: 0.061385\tBest loss: 0.034973\tAccuracy: 98.98%\n",
      "39\tValidation loss: 0.046012\tBest loss: 0.034973\tAccuracy: 99.26%\n",
      "40\tValidation loss: 0.044356\tBest loss: 0.034973\tAccuracy: 99.18%\n",
      "41\tValidation loss: 0.081443\tBest loss: 0.034973\tAccuracy: 98.87%\n",
      "42\tValidation loss: 0.056136\tBest loss: 0.034973\tAccuracy: 98.94%\n",
      "43\tValidation loss: 0.062867\tBest loss: 0.034973\tAccuracy: 99.02%\n",
      "44\tValidation loss: 0.048662\tBest loss: 0.034973\tAccuracy: 98.98%\n",
      "45\tValidation loss: 0.058623\tBest loss: 0.034973\tAccuracy: 98.79%\n",
      "46\tValidation loss: 0.049163\tBest loss: 0.034973\tAccuracy: 99.06%\n",
      "47\tValidation loss: 0.070884\tBest loss: 0.034973\tAccuracy: 98.83%\n",
      "48\tValidation loss: 0.065747\tBest loss: 0.034973\tAccuracy: 98.98%\n",
      "49\tValidation loss: 0.071028\tBest loss: 0.034973\tAccuracy: 98.94%\n",
      "50\tValidation loss: 0.065709\tBest loss: 0.034973\tAccuracy: 98.79%\n",
      "51\tValidation loss: 0.080337\tBest loss: 0.034973\tAccuracy: 98.71%\n",
      "52\tValidation loss: 0.058548\tBest loss: 0.034973\tAccuracy: 98.94%\n",
      "53\tValidation loss: 0.083044\tBest loss: 0.034973\tAccuracy: 98.71%\n",
      "54\tValidation loss: 0.048141\tBest loss: 0.034973\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0>, total= 3.6min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.116553\tBest loss: 0.116553\tAccuracy: 96.52%\n",
      "1\tValidation loss: 0.074416\tBest loss: 0.074416\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.046501\tBest loss: 0.046501\tAccuracy: 98.48%\n",
      "3\tValidation loss: 0.053612\tBest loss: 0.046501\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.083274\tBest loss: 0.046501\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.063865\tBest loss: 0.046501\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.040966\tBest loss: 0.040966\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.046594\tBest loss: 0.040966\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.043275\tBest loss: 0.040966\tAccuracy: 98.75%\n",
      "9\tValidation loss: 0.052657\tBest loss: 0.040966\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.047325\tBest loss: 0.040966\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.055735\tBest loss: 0.040966\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.043043\tBest loss: 0.040966\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.063265\tBest loss: 0.040966\tAccuracy: 98.40%\n",
      "14\tValidation loss: 0.037623\tBest loss: 0.037623\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.044141\tBest loss: 0.037623\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.052221\tBest loss: 0.037623\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.041120\tBest loss: 0.037623\tAccuracy: 99.10%\n",
      "18\tValidation loss: 0.060865\tBest loss: 0.037623\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.064474\tBest loss: 0.037623\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.092865\tBest loss: 0.037623\tAccuracy: 98.20%\n",
      "21\tValidation loss: 0.054965\tBest loss: 0.037623\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.039057\tBest loss: 0.037623\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.049298\tBest loss: 0.037623\tAccuracy: 99.02%\n",
      "24\tValidation loss: 0.031720\tBest loss: 0.031720\tAccuracy: 99.22%\n",
      "25\tValidation loss: 0.052065\tBest loss: 0.031720\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.055934\tBest loss: 0.031720\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.045330\tBest loss: 0.031720\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.065170\tBest loss: 0.031720\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.057679\tBest loss: 0.031720\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.058821\tBest loss: 0.031720\tAccuracy: 98.75%\n",
      "31\tValidation loss: 0.056077\tBest loss: 0.031720\tAccuracy: 98.91%\n",
      "32\tValidation loss: 0.048470\tBest loss: 0.031720\tAccuracy: 98.94%\n",
      "33\tValidation loss: 0.048036\tBest loss: 0.031720\tAccuracy: 98.91%\n",
      "34\tValidation loss: 0.053898\tBest loss: 0.031720\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.055234\tBest loss: 0.031720\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.061495\tBest loss: 0.031720\tAccuracy: 98.71%\n",
      "37\tValidation loss: 0.061800\tBest loss: 0.031720\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.068059\tBest loss: 0.031720\tAccuracy: 98.94%\n",
      "39\tValidation loss: 0.099204\tBest loss: 0.031720\tAccuracy: 98.48%\n",
      "40\tValidation loss: 0.052171\tBest loss: 0.031720\tAccuracy: 99.10%\n",
      "41\tValidation loss: 0.065157\tBest loss: 0.031720\tAccuracy: 98.79%\n",
      "42\tValidation loss: 0.053706\tBest loss: 0.031720\tAccuracy: 98.98%\n",
      "43\tValidation loss: 0.070110\tBest loss: 0.031720\tAccuracy: 98.67%\n",
      "44\tValidation loss: 0.070009\tBest loss: 0.031720\tAccuracy: 98.91%\n",
      "45\tValidation loss: 0.043239\tBest loss: 0.031720\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0>, total= 3.0min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.133798\tBest loss: 0.133798\tAccuracy: 96.09%\n",
      "1\tValidation loss: 0.082461\tBest loss: 0.082461\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.054716\tBest loss: 0.054716\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.060686\tBest loss: 0.054716\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.072317\tBest loss: 0.054716\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.058007\tBest loss: 0.054716\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.046562\tBest loss: 0.046562\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.049300\tBest loss: 0.046562\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.111871\tBest loss: 0.046562\tAccuracy: 97.07%\n",
      "9\tValidation loss: 0.052216\tBest loss: 0.046562\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.053799\tBest loss: 0.046562\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.040147\tBest loss: 0.040147\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.038738\tBest loss: 0.038738\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.038374\tBest loss: 0.038374\tAccuracy: 99.18%\n",
      "14\tValidation loss: 0.061575\tBest loss: 0.038374\tAccuracy: 98.55%\n",
      "15\tValidation loss: 0.037887\tBest loss: 0.037887\tAccuracy: 99.18%\n",
      "16\tValidation loss: 0.028402\tBest loss: 0.028402\tAccuracy: 99.26%\n",
      "17\tValidation loss: 0.034806\tBest loss: 0.028402\tAccuracy: 99.26%\n",
      "18\tValidation loss: 0.052274\tBest loss: 0.028402\tAccuracy: 98.98%\n",
      "19\tValidation loss: 0.048893\tBest loss: 0.028402\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.040444\tBest loss: 0.028402\tAccuracy: 99.18%\n",
      "21\tValidation loss: 0.031761\tBest loss: 0.028402\tAccuracy: 99.14%\n",
      "22\tValidation loss: 0.032960\tBest loss: 0.028402\tAccuracy: 99.22%\n",
      "23\tValidation loss: 0.048765\tBest loss: 0.028402\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.039074\tBest loss: 0.028402\tAccuracy: 99.22%\n",
      "25\tValidation loss: 0.062995\tBest loss: 0.028402\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.055279\tBest loss: 0.028402\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.031734\tBest loss: 0.028402\tAccuracy: 99.26%\n",
      "28\tValidation loss: 0.021716\tBest loss: 0.021716\tAccuracy: 99.37%\n",
      "29\tValidation loss: 0.035744\tBest loss: 0.021716\tAccuracy: 99.34%\n",
      "30\tValidation loss: 0.029186\tBest loss: 0.021716\tAccuracy: 99.41%\n",
      "31\tValidation loss: 0.067945\tBest loss: 0.021716\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.040662\tBest loss: 0.021716\tAccuracy: 99.18%\n",
      "33\tValidation loss: 0.039765\tBest loss: 0.021716\tAccuracy: 99.10%\n",
      "34\tValidation loss: 0.044064\tBest loss: 0.021716\tAccuracy: 99.10%\n",
      "35\tValidation loss: 0.044632\tBest loss: 0.021716\tAccuracy: 99.18%\n",
      "36\tValidation loss: 0.093102\tBest loss: 0.021716\tAccuracy: 98.63%\n",
      "37\tValidation loss: 0.031605\tBest loss: 0.021716\tAccuracy: 99.37%\n",
      "38\tValidation loss: 0.051581\tBest loss: 0.021716\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.043025\tBest loss: 0.021716\tAccuracy: 99.18%\n",
      "40\tValidation loss: 0.040209\tBest loss: 0.021716\tAccuracy: 99.22%\n",
      "41\tValidation loss: 0.039766\tBest loss: 0.021716\tAccuracy: 99.49%\n",
      "42\tValidation loss: 0.053456\tBest loss: 0.021716\tAccuracy: 99.14%\n",
      "43\tValidation loss: 0.051671\tBest loss: 0.021716\tAccuracy: 99.18%\n",
      "44\tValidation loss: 0.039833\tBest loss: 0.021716\tAccuracy: 99.22%\n",
      "45\tValidation loss: 0.046076\tBest loss: 0.021716\tAccuracy: 99.37%\n",
      "46\tValidation loss: 0.049689\tBest loss: 0.021716\tAccuracy: 99.22%\n",
      "47\tValidation loss: 0.042000\tBest loss: 0.021716\tAccuracy: 99.37%\n",
      "48\tValidation loss: 0.048054\tBest loss: 0.021716\tAccuracy: 99.26%\n",
      "49\tValidation loss: 0.060904\tBest loss: 0.021716\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0>, total= 3.3min\n",
      "[CV] n_neurons=140, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.093598\tBest loss: 0.093598\tAccuracy: 97.03%\n",
      "1\tValidation loss: 0.167858\tBest loss: 0.093598\tAccuracy: 94.80%\n",
      "2\tValidation loss: 0.066184\tBest loss: 0.066184\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.530384\tBest loss: 0.066184\tAccuracy: 82.88%\n",
      "4\tValidation loss: 0.059103\tBest loss: 0.059103\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.100904\tBest loss: 0.059103\tAccuracy: 97.54%\n",
      "6\tValidation loss: 0.070031\tBest loss: 0.059103\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.068923\tBest loss: 0.059103\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.050799\tBest loss: 0.050799\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.075725\tBest loss: 0.050799\tAccuracy: 97.58%\n",
      "10\tValidation loss: 0.065699\tBest loss: 0.050799\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.044800\tBest loss: 0.044800\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.058891\tBest loss: 0.044800\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.069831\tBest loss: 0.044800\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.063960\tBest loss: 0.044800\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.076187\tBest loss: 0.044800\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.091088\tBest loss: 0.044800\tAccuracy: 97.69%\n",
      "17\tValidation loss: 0.045897\tBest loss: 0.044800\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.048475\tBest loss: 0.044800\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.058809\tBest loss: 0.044800\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.060535\tBest loss: 0.044800\tAccuracy: 98.63%\n",
      "21\tValidation loss: 0.075441\tBest loss: 0.044800\tAccuracy: 98.12%\n",
      "22\tValidation loss: 0.109118\tBest loss: 0.044800\tAccuracy: 97.46%\n",
      "23\tValidation loss: 0.060027\tBest loss: 0.044800\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.044255\tBest loss: 0.044255\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.091230\tBest loss: 0.044255\tAccuracy: 97.85%\n",
      "26\tValidation loss: 0.088282\tBest loss: 0.044255\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.055916\tBest loss: 0.044255\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.146842\tBest loss: 0.044255\tAccuracy: 96.83%\n",
      "29\tValidation loss: 0.062478\tBest loss: 0.044255\tAccuracy: 98.44%\n",
      "30\tValidation loss: 0.059092\tBest loss: 0.044255\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.054313\tBest loss: 0.044255\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.064680\tBest loss: 0.044255\tAccuracy: 98.59%\n",
      "33\tValidation loss: 0.075460\tBest loss: 0.044255\tAccuracy: 98.67%\n",
      "34\tValidation loss: 0.106874\tBest loss: 0.044255\tAccuracy: 98.36%\n",
      "35\tValidation loss: 0.068791\tBest loss: 0.044255\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.052031\tBest loss: 0.044255\tAccuracy: 98.91%\n",
      "37\tValidation loss: 0.130798\tBest loss: 0.044255\tAccuracy: 97.34%\n",
      "38\tValidation loss: 0.094859\tBest loss: 0.044255\tAccuracy: 98.48%\n",
      "39\tValidation loss: 0.053151\tBest loss: 0.044255\tAccuracy: 98.71%\n",
      "40\tValidation loss: 0.046294\tBest loss: 0.044255\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.081898\tBest loss: 0.044255\tAccuracy: 98.94%\n",
      "42\tValidation loss: 0.051136\tBest loss: 0.044255\tAccuracy: 99.10%\n",
      "43\tValidation loss: 0.099525\tBest loss: 0.044255\tAccuracy: 98.08%\n",
      "44\tValidation loss: 0.087184\tBest loss: 0.044255\tAccuracy: 98.20%\n",
      "45\tValidation loss: 0.074986\tBest loss: 0.044255\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=10.6min\n",
      "[CV] n_neurons=140, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.096531\tBest loss: 0.096531\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.088871\tBest loss: 0.088871\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.082196\tBest loss: 0.082196\tAccuracy: 97.42%\n",
      "3\tValidation loss: 0.067494\tBest loss: 0.067494\tAccuracy: 98.01%\n",
      "4\tValidation loss: 0.079879\tBest loss: 0.067494\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.085606\tBest loss: 0.067494\tAccuracy: 97.38%\n",
      "6\tValidation loss: 0.280481\tBest loss: 0.067494\tAccuracy: 92.18%\n",
      "7\tValidation loss: 0.077550\tBest loss: 0.067494\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.066834\tBest loss: 0.066834\tAccuracy: 98.32%\n",
      "9\tValidation loss: 0.056228\tBest loss: 0.056228\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.064967\tBest loss: 0.056228\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.115567\tBest loss: 0.056228\tAccuracy: 97.38%\n",
      "12\tValidation loss: 0.047761\tBest loss: 0.047761\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.047201\tBest loss: 0.047201\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.053769\tBest loss: 0.047201\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.066914\tBest loss: 0.047201\tAccuracy: 98.12%\n",
      "16\tValidation loss: 0.170001\tBest loss: 0.047201\tAccuracy: 95.62%\n",
      "17\tValidation loss: 0.078638\tBest loss: 0.047201\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.062708\tBest loss: 0.047201\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.086324\tBest loss: 0.047201\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.050967\tBest loss: 0.047201\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.048973\tBest loss: 0.047201\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.086268\tBest loss: 0.047201\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.044499\tBest loss: 0.044499\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.055161\tBest loss: 0.044499\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.091904\tBest loss: 0.044499\tAccuracy: 98.28%\n",
      "26\tValidation loss: 0.087726\tBest loss: 0.044499\tAccuracy: 98.32%\n",
      "27\tValidation loss: 0.063919\tBest loss: 0.044499\tAccuracy: 98.63%\n",
      "28\tValidation loss: 0.066844\tBest loss: 0.044499\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.047867\tBest loss: 0.044499\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.058634\tBest loss: 0.044499\tAccuracy: 98.59%\n",
      "31\tValidation loss: 0.047048\tBest loss: 0.044499\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.061298\tBest loss: 0.044499\tAccuracy: 98.40%\n",
      "33\tValidation loss: 0.058931\tBest loss: 0.044499\tAccuracy: 98.98%\n",
      "34\tValidation loss: 0.104049\tBest loss: 0.044499\tAccuracy: 97.85%\n",
      "35\tValidation loss: 0.075921\tBest loss: 0.044499\tAccuracy: 98.63%\n",
      "36\tValidation loss: 0.059164\tBest loss: 0.044499\tAccuracy: 98.75%\n",
      "37\tValidation loss: 0.070616\tBest loss: 0.044499\tAccuracy: 98.44%\n",
      "38\tValidation loss: 0.060444\tBest loss: 0.044499\tAccuracy: 98.71%\n",
      "39\tValidation loss: 0.079328\tBest loss: 0.044499\tAccuracy: 98.55%\n",
      "40\tValidation loss: 0.062645\tBest loss: 0.044499\tAccuracy: 98.59%\n",
      "41\tValidation loss: 0.079861\tBest loss: 0.044499\tAccuracy: 98.63%\n",
      "42\tValidation loss: 0.078887\tBest loss: 0.044499\tAccuracy: 98.36%\n",
      "43\tValidation loss: 0.100405\tBest loss: 0.044499\tAccuracy: 98.44%\n",
      "44\tValidation loss: 0.073034\tBest loss: 0.044499\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=10.4min\n",
      "[CV] n_neurons=140, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.104867\tBest loss: 0.104867\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.149914\tBest loss: 0.104867\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.081318\tBest loss: 0.081318\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.089678\tBest loss: 0.081318\tAccuracy: 96.87%\n",
      "4\tValidation loss: 0.079594\tBest loss: 0.079594\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.054486\tBest loss: 0.054486\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.052993\tBest loss: 0.052993\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.056271\tBest loss: 0.052993\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.071055\tBest loss: 0.052993\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.031977\tBest loss: 0.031977\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.049196\tBest loss: 0.031977\tAccuracy: 98.79%\n",
      "11\tValidation loss: 0.058556\tBest loss: 0.031977\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.050511\tBest loss: 0.031977\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.058526\tBest loss: 0.031977\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.066534\tBest loss: 0.031977\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.040611\tBest loss: 0.031977\tAccuracy: 98.83%\n",
      "16\tValidation loss: 0.066095\tBest loss: 0.031977\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.065072\tBest loss: 0.031977\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.072098\tBest loss: 0.031977\tAccuracy: 98.28%\n",
      "19\tValidation loss: 0.082504\tBest loss: 0.031977\tAccuracy: 98.20%\n",
      "20\tValidation loss: 0.046077\tBest loss: 0.031977\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.071002\tBest loss: 0.031977\tAccuracy: 98.44%\n",
      "22\tValidation loss: 0.045392\tBest loss: 0.031977\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.095620\tBest loss: 0.031977\tAccuracy: 97.62%\n",
      "24\tValidation loss: 0.055638\tBest loss: 0.031977\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.040073\tBest loss: 0.031977\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.054006\tBest loss: 0.031977\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.036089\tBest loss: 0.031977\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.051417\tBest loss: 0.031977\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.037286\tBest loss: 0.031977\tAccuracy: 99.10%\n",
      "30\tValidation loss: 0.055659\tBest loss: 0.031977\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 7.1min\n",
      "[CV] n_neurons=90, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.060558\tBest loss: 0.060558\tAccuracy: 98.24%\n",
      "1\tValidation loss: 0.092502\tBest loss: 0.060558\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.051137\tBest loss: 0.051137\tAccuracy: 98.63%\n",
      "3\tValidation loss: 0.056126\tBest loss: 0.051137\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.045706\tBest loss: 0.045706\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.059471\tBest loss: 0.045706\tAccuracy: 98.32%\n",
      "6\tValidation loss: 0.054383\tBest loss: 0.045706\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.054600\tBest loss: 0.045706\tAccuracy: 98.44%\n",
      "8\tValidation loss: 0.048570\tBest loss: 0.045706\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.044214\tBest loss: 0.044214\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.045772\tBest loss: 0.044214\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.050193\tBest loss: 0.044214\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.049186\tBest loss: 0.044214\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.048452\tBest loss: 0.044214\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.039407\tBest loss: 0.039407\tAccuracy: 99.10%\n",
      "15\tValidation loss: 0.047153\tBest loss: 0.039407\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.056010\tBest loss: 0.039407\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.038046\tBest loss: 0.038046\tAccuracy: 99.14%\n",
      "18\tValidation loss: 0.044444\tBest loss: 0.038046\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.047959\tBest loss: 0.038046\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.068281\tBest loss: 0.038046\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.040935\tBest loss: 0.038046\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.048205\tBest loss: 0.038046\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.049785\tBest loss: 0.038046\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.053432\tBest loss: 0.038046\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.055579\tBest loss: 0.038046\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.039604\tBest loss: 0.038046\tAccuracy: 99.14%\n",
      "27\tValidation loss: 0.041767\tBest loss: 0.038046\tAccuracy: 99.22%\n",
      "28\tValidation loss: 0.055846\tBest loss: 0.038046\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.066435\tBest loss: 0.038046\tAccuracy: 98.83%\n",
      "30\tValidation loss: 0.051827\tBest loss: 0.038046\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.049417\tBest loss: 0.038046\tAccuracy: 99.06%\n",
      "32\tValidation loss: 0.062158\tBest loss: 0.038046\tAccuracy: 98.79%\n",
      "33\tValidation loss: 0.049620\tBest loss: 0.038046\tAccuracy: 98.79%\n",
      "34\tValidation loss: 0.046344\tBest loss: 0.038046\tAccuracy: 98.87%\n",
      "35\tValidation loss: 0.056454\tBest loss: 0.038046\tAccuracy: 98.87%\n",
      "36\tValidation loss: 0.051306\tBest loss: 0.038046\tAccuracy: 98.98%\n",
      "37\tValidation loss: 0.059956\tBest loss: 0.038046\tAccuracy: 98.51%\n",
      "38\tValidation loss: 0.052054\tBest loss: 0.038046\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.4min\n",
      "[CV] n_neurons=90, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.068613\tBest loss: 0.068613\tAccuracy: 98.12%\n",
      "1\tValidation loss: 0.062355\tBest loss: 0.062355\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.044692\tBest loss: 0.044692\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.078460\tBest loss: 0.044692\tAccuracy: 97.77%\n",
      "4\tValidation loss: 0.057355\tBest loss: 0.044692\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.045588\tBest loss: 0.044692\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.049520\tBest loss: 0.044692\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.044372\tBest loss: 0.044372\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.039404\tBest loss: 0.039404\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.050264\tBest loss: 0.039404\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.035973\tBest loss: 0.035973\tAccuracy: 99.14%\n",
      "11\tValidation loss: 0.071828\tBest loss: 0.035973\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.037785\tBest loss: 0.035973\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.054019\tBest loss: 0.035973\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.039013\tBest loss: 0.035973\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.047596\tBest loss: 0.035973\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.060284\tBest loss: 0.035973\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.057578\tBest loss: 0.035973\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.051410\tBest loss: 0.035973\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.073560\tBest loss: 0.035973\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.042723\tBest loss: 0.035973\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.043707\tBest loss: 0.035973\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.037981\tBest loss: 0.035973\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.069369\tBest loss: 0.035973\tAccuracy: 98.55%\n",
      "24\tValidation loss: 0.048060\tBest loss: 0.035973\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.050586\tBest loss: 0.035973\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.042425\tBest loss: 0.035973\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.037618\tBest loss: 0.035973\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.054881\tBest loss: 0.035973\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.039023\tBest loss: 0.035973\tAccuracy: 99.14%\n",
      "30\tValidation loss: 0.052680\tBest loss: 0.035973\tAccuracy: 99.02%\n",
      "31\tValidation loss: 0.044282\tBest loss: 0.035973\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.2min\n",
      "[CV] n_neurons=90, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.071398\tBest loss: 0.071398\tAccuracy: 98.05%\n",
      "1\tValidation loss: 0.067910\tBest loss: 0.067910\tAccuracy: 98.24%\n",
      "2\tValidation loss: 0.049081\tBest loss: 0.049081\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.055907\tBest loss: 0.049081\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.073609\tBest loss: 0.049081\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.061674\tBest loss: 0.049081\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.036622\tBest loss: 0.036622\tAccuracy: 98.91%\n",
      "7\tValidation loss: 0.040366\tBest loss: 0.036622\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.056750\tBest loss: 0.036622\tAccuracy: 98.55%\n",
      "9\tValidation loss: 0.044501\tBest loss: 0.036622\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.043485\tBest loss: 0.036622\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.045000\tBest loss: 0.036622\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.060690\tBest loss: 0.036622\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.061030\tBest loss: 0.036622\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.055644\tBest loss: 0.036622\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.052998\tBest loss: 0.036622\tAccuracy: 98.83%\n",
      "16\tValidation loss: 0.043696\tBest loss: 0.036622\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.038572\tBest loss: 0.036622\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.040306\tBest loss: 0.036622\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.058096\tBest loss: 0.036622\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.033280\tBest loss: 0.033280\tAccuracy: 99.30%\n",
      "21\tValidation loss: 0.056246\tBest loss: 0.033280\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.033341\tBest loss: 0.033280\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.039091\tBest loss: 0.033280\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.044991\tBest loss: 0.033280\tAccuracy: 98.94%\n",
      "25\tValidation loss: 0.037435\tBest loss: 0.033280\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.075938\tBest loss: 0.033280\tAccuracy: 98.75%\n",
      "27\tValidation loss: 0.032861\tBest loss: 0.032861\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.037065\tBest loss: 0.032861\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.055447\tBest loss: 0.032861\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.052945\tBest loss: 0.032861\tAccuracy: 98.75%\n",
      "31\tValidation loss: 0.033931\tBest loss: 0.032861\tAccuracy: 99.22%\n",
      "32\tValidation loss: 0.050754\tBest loss: 0.032861\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.056386\tBest loss: 0.032861\tAccuracy: 98.79%\n",
      "34\tValidation loss: 0.089909\tBest loss: 0.032861\tAccuracy: 98.16%\n",
      "35\tValidation loss: 0.050619\tBest loss: 0.032861\tAccuracy: 98.63%\n",
      "36\tValidation loss: 0.051963\tBest loss: 0.032861\tAccuracy: 98.91%\n",
      "37\tValidation loss: 0.048169\tBest loss: 0.032861\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.050266\tBest loss: 0.032861\tAccuracy: 99.10%\n",
      "39\tValidation loss: 0.049911\tBest loss: 0.032861\tAccuracy: 98.94%\n",
      "40\tValidation loss: 0.063102\tBest loss: 0.032861\tAccuracy: 98.67%\n",
      "41\tValidation loss: 0.044240\tBest loss: 0.032861\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.055548\tBest loss: 0.032861\tAccuracy: 98.91%\n",
      "43\tValidation loss: 0.042692\tBest loss: 0.032861\tAccuracy: 99.18%\n",
      "44\tValidation loss: 0.053828\tBest loss: 0.032861\tAccuracy: 98.91%\n",
      "45\tValidation loss: 0.055543\tBest loss: 0.032861\tAccuracy: 98.83%\n",
      "46\tValidation loss: 0.044401\tBest loss: 0.032861\tAccuracy: 99.14%\n",
      "47\tValidation loss: 0.066562\tBest loss: 0.032861\tAccuracy: 98.98%\n",
      "48\tValidation loss: 0.049364\tBest loss: 0.032861\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.8min\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.126825\tBest loss: 0.126825\tAccuracy: 96.99%\n",
      "1\tValidation loss: 0.171250\tBest loss: 0.126825\tAccuracy: 96.56%\n",
      "2\tValidation loss: 0.114622\tBest loss: 0.114622\tAccuracy: 97.62%\n",
      "3\tValidation loss: 0.097187\tBest loss: 0.097187\tAccuracy: 97.38%\n",
      "4\tValidation loss: 0.100719\tBest loss: 0.097187\tAccuracy: 97.89%\n",
      "5\tValidation loss: 0.075555\tBest loss: 0.075555\tAccuracy: 98.01%\n",
      "6\tValidation loss: 0.064603\tBest loss: 0.064603\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.089636\tBest loss: 0.064603\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.114346\tBest loss: 0.064603\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.080507\tBest loss: 0.064603\tAccuracy: 98.05%\n",
      "10\tValidation loss: 0.067505\tBest loss: 0.064603\tAccuracy: 98.20%\n",
      "11\tValidation loss: 0.064234\tBest loss: 0.064234\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.097405\tBest loss: 0.064234\tAccuracy: 97.50%\n",
      "13\tValidation loss: 0.076937\tBest loss: 0.064234\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.058714\tBest loss: 0.058714\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.083100\tBest loss: 0.058714\tAccuracy: 98.16%\n",
      "16\tValidation loss: 0.098190\tBest loss: 0.058714\tAccuracy: 97.34%\n",
      "17\tValidation loss: 0.073228\tBest loss: 0.058714\tAccuracy: 97.85%\n",
      "18\tValidation loss: 0.105943\tBest loss: 0.058714\tAccuracy: 97.93%\n",
      "19\tValidation loss: 0.303846\tBest loss: 0.058714\tAccuracy: 92.77%\n",
      "20\tValidation loss: 0.058766\tBest loss: 0.058714\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.050622\tBest loss: 0.050622\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.052541\tBest loss: 0.050622\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.059501\tBest loss: 0.050622\tAccuracy: 98.67%\n",
      "24\tValidation loss: 0.062636\tBest loss: 0.050622\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.075199\tBest loss: 0.050622\tAccuracy: 97.97%\n",
      "26\tValidation loss: 0.082305\tBest loss: 0.050622\tAccuracy: 98.12%\n",
      "27\tValidation loss: 0.073116\tBest loss: 0.050622\tAccuracy: 98.48%\n",
      "28\tValidation loss: 0.126498\tBest loss: 0.050622\tAccuracy: 98.20%\n",
      "29\tValidation loss: 0.080544\tBest loss: 0.050622\tAccuracy: 98.08%\n",
      "30\tValidation loss: 0.081855\tBest loss: 0.050622\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.067536\tBest loss: 0.050622\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.066004\tBest loss: 0.050622\tAccuracy: 98.59%\n",
      "33\tValidation loss: 0.057414\tBest loss: 0.050622\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.070069\tBest loss: 0.050622\tAccuracy: 98.51%\n",
      "35\tValidation loss: 0.109233\tBest loss: 0.050622\tAccuracy: 98.08%\n",
      "36\tValidation loss: 0.081039\tBest loss: 0.050622\tAccuracy: 98.40%\n",
      "37\tValidation loss: 0.089081\tBest loss: 0.050622\tAccuracy: 98.36%\n",
      "38\tValidation loss: 0.075658\tBest loss: 0.050622\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.109775\tBest loss: 0.050622\tAccuracy: 98.05%\n",
      "40\tValidation loss: 0.080973\tBest loss: 0.050622\tAccuracy: 98.20%\n",
      "41\tValidation loss: 0.125042\tBest loss: 0.050622\tAccuracy: 98.16%\n",
      "42\tValidation loss: 0.068072\tBest loss: 0.050622\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.8min\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.159458\tBest loss: 0.159458\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.159482\tBest loss: 0.159458\tAccuracy: 96.36%\n",
      "2\tValidation loss: 0.103977\tBest loss: 0.103977\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.061603\tBest loss: 0.061603\tAccuracy: 98.44%\n",
      "4\tValidation loss: 0.112948\tBest loss: 0.061603\tAccuracy: 96.87%\n",
      "5\tValidation loss: 0.087343\tBest loss: 0.061603\tAccuracy: 97.73%\n",
      "6\tValidation loss: 0.067513\tBest loss: 0.061603\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.076062\tBest loss: 0.061603\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.088179\tBest loss: 0.061603\tAccuracy: 97.42%\n",
      "9\tValidation loss: 0.108594\tBest loss: 0.061603\tAccuracy: 97.73%\n",
      "10\tValidation loss: 0.204991\tBest loss: 0.061603\tAccuracy: 95.31%\n",
      "11\tValidation loss: 0.079035\tBest loss: 0.061603\tAccuracy: 98.08%\n",
      "12\tValidation loss: 0.065641\tBest loss: 0.061603\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.055679\tBest loss: 0.055679\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.062203\tBest loss: 0.055679\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.075937\tBest loss: 0.055679\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.148185\tBest loss: 0.055679\tAccuracy: 97.65%\n",
      "17\tValidation loss: 0.060329\tBest loss: 0.055679\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.085786\tBest loss: 0.055679\tAccuracy: 98.05%\n",
      "19\tValidation loss: 0.101036\tBest loss: 0.055679\tAccuracy: 98.01%\n",
      "20\tValidation loss: 0.099754\tBest loss: 0.055679\tAccuracy: 98.20%\n",
      "21\tValidation loss: 0.143203\tBest loss: 0.055679\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.059884\tBest loss: 0.055679\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.052390\tBest loss: 0.052390\tAccuracy: 99.06%\n",
      "24\tValidation loss: 0.052482\tBest loss: 0.052390\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.045024\tBest loss: 0.045024\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.096368\tBest loss: 0.045024\tAccuracy: 98.08%\n",
      "27\tValidation loss: 0.060193\tBest loss: 0.045024\tAccuracy: 98.67%\n",
      "28\tValidation loss: 0.203198\tBest loss: 0.045024\tAccuracy: 95.15%\n",
      "29\tValidation loss: 0.116944\tBest loss: 0.045024\tAccuracy: 98.59%\n",
      "30\tValidation loss: 0.063930\tBest loss: 0.045024\tAccuracy: 98.59%\n",
      "31\tValidation loss: 0.073221\tBest loss: 0.045024\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.096858\tBest loss: 0.045024\tAccuracy: 98.05%\n",
      "33\tValidation loss: 0.156711\tBest loss: 0.045024\tAccuracy: 97.77%\n",
      "34\tValidation loss: 0.051753\tBest loss: 0.045024\tAccuracy: 98.75%\n",
      "35\tValidation loss: 0.057640\tBest loss: 0.045024\tAccuracy: 98.67%\n",
      "36\tValidation loss: 0.058593\tBest loss: 0.045024\tAccuracy: 98.67%\n",
      "37\tValidation loss: 0.051904\tBest loss: 0.045024\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.063312\tBest loss: 0.045024\tAccuracy: 98.75%\n",
      "39\tValidation loss: 0.159877\tBest loss: 0.045024\tAccuracy: 98.24%\n",
      "40\tValidation loss: 0.099116\tBest loss: 0.045024\tAccuracy: 98.44%\n",
      "41\tValidation loss: 1.045430\tBest loss: 0.045024\tAccuracy: 78.81%\n",
      "42\tValidation loss: 0.075898\tBest loss: 0.045024\tAccuracy: 98.63%\n",
      "43\tValidation loss: 0.053538\tBest loss: 0.045024\tAccuracy: 98.67%\n",
      "44\tValidation loss: 0.064269\tBest loss: 0.045024\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.060902\tBest loss: 0.045024\tAccuracy: 98.79%\n",
      "46\tValidation loss: 0.070183\tBest loss: 0.045024\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.0min\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.191744\tBest loss: 0.191744\tAccuracy: 96.48%\n",
      "1\tValidation loss: 1.124855\tBest loss: 0.191744\tAccuracy: 91.87%\n",
      "2\tValidation loss: 0.084252\tBest loss: 0.084252\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.078212\tBest loss: 0.078212\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.120920\tBest loss: 0.078212\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.169930\tBest loss: 0.078212\tAccuracy: 96.79%\n",
      "6\tValidation loss: 0.055416\tBest loss: 0.055416\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.079098\tBest loss: 0.055416\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.191560\tBest loss: 0.055416\tAccuracy: 95.27%\n",
      "9\tValidation loss: 0.091699\tBest loss: 0.055416\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.072204\tBest loss: 0.055416\tAccuracy: 98.48%\n",
      "11\tValidation loss: 0.112637\tBest loss: 0.055416\tAccuracy: 97.26%\n",
      "12\tValidation loss: 0.140165\tBest loss: 0.055416\tAccuracy: 96.25%\n",
      "13\tValidation loss: 0.083315\tBest loss: 0.055416\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.076520\tBest loss: 0.055416\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.058127\tBest loss: 0.055416\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.058058\tBest loss: 0.055416\tAccuracy: 98.71%\n",
      "17\tValidation loss: 0.063477\tBest loss: 0.055416\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.121876\tBest loss: 0.055416\tAccuracy: 98.16%\n",
      "19\tValidation loss: 0.091207\tBest loss: 0.055416\tAccuracy: 98.24%\n",
      "20\tValidation loss: 0.093687\tBest loss: 0.055416\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.088326\tBest loss: 0.055416\tAccuracy: 98.28%\n",
      "22\tValidation loss: 0.072785\tBest loss: 0.055416\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.078561\tBest loss: 0.055416\tAccuracy: 98.20%\n",
      "24\tValidation loss: 0.063206\tBest loss: 0.055416\tAccuracy: 98.83%\n",
      "25\tValidation loss: 0.075864\tBest loss: 0.055416\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.087798\tBest loss: 0.055416\tAccuracy: 97.89%\n",
      "27\tValidation loss: 0.110498\tBest loss: 0.055416\tAccuracy: 97.85%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.2min\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.346750\tBest loss: 0.346750\tAccuracy: 93.43%\n",
      "1\tValidation loss: 0.070406\tBest loss: 0.070406\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.048752\tBest loss: 0.048752\tAccuracy: 98.51%\n",
      "3\tValidation loss: 0.054423\tBest loss: 0.048752\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.045994\tBest loss: 0.045994\tAccuracy: 98.79%\n",
      "5\tValidation loss: 0.079762\tBest loss: 0.045994\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.071879\tBest loss: 0.045994\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.033527\tBest loss: 0.033527\tAccuracy: 99.06%\n",
      "8\tValidation loss: 0.050048\tBest loss: 0.033527\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.060133\tBest loss: 0.033527\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.049280\tBest loss: 0.033527\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.053356\tBest loss: 0.033527\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.057079\tBest loss: 0.033527\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.042209\tBest loss: 0.033527\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.045582\tBest loss: 0.033527\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.040170\tBest loss: 0.033527\tAccuracy: 99.06%\n",
      "16\tValidation loss: 0.057772\tBest loss: 0.033527\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.067767\tBest loss: 0.033527\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.059538\tBest loss: 0.033527\tAccuracy: 98.67%\n",
      "19\tValidation loss: 0.045907\tBest loss: 0.033527\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.058925\tBest loss: 0.033527\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.051917\tBest loss: 0.033527\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.066206\tBest loss: 0.033527\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.053299\tBest loss: 0.033527\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.052008\tBest loss: 0.033527\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.043763\tBest loss: 0.033527\tAccuracy: 99.14%\n",
      "26\tValidation loss: 0.039386\tBest loss: 0.033527\tAccuracy: 99.22%\n",
      "27\tValidation loss: 0.038809\tBest loss: 0.033527\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.037575\tBest loss: 0.033527\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=  45.3s\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.217296\tBest loss: 0.217296\tAccuracy: 96.01%\n",
      "1\tValidation loss: 0.075492\tBest loss: 0.075492\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.067407\tBest loss: 0.067407\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.051181\tBest loss: 0.051181\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.042530\tBest loss: 0.042530\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.060347\tBest loss: 0.042530\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.060533\tBest loss: 0.042530\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.042000\tBest loss: 0.042000\tAccuracy: 98.83%\n",
      "8\tValidation loss: 0.043912\tBest loss: 0.042000\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.087575\tBest loss: 0.042000\tAccuracy: 98.20%\n",
      "10\tValidation loss: 0.042569\tBest loss: 0.042000\tAccuracy: 99.02%\n",
      "11\tValidation loss: 0.037879\tBest loss: 0.037879\tAccuracy: 99.18%\n",
      "12\tValidation loss: 0.043878\tBest loss: 0.037879\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.064276\tBest loss: 0.037879\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.059015\tBest loss: 0.037879\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.043825\tBest loss: 0.037879\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.038067\tBest loss: 0.037879\tAccuracy: 99.10%\n",
      "17\tValidation loss: 0.039753\tBest loss: 0.037879\tAccuracy: 99.14%\n",
      "18\tValidation loss: 0.045413\tBest loss: 0.037879\tAccuracy: 98.98%\n",
      "19\tValidation loss: 0.038547\tBest loss: 0.037879\tAccuracy: 99.30%\n",
      "20\tValidation loss: 0.073157\tBest loss: 0.037879\tAccuracy: 98.24%\n",
      "21\tValidation loss: 0.046928\tBest loss: 0.037879\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.056034\tBest loss: 0.037879\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.039803\tBest loss: 0.037879\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.032128\tBest loss: 0.032128\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.041506\tBest loss: 0.032128\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.034129\tBest loss: 0.032128\tAccuracy: 99.18%\n",
      "27\tValidation loss: 0.038727\tBest loss: 0.032128\tAccuracy: 99.14%\n",
      "28\tValidation loss: 0.038422\tBest loss: 0.032128\tAccuracy: 99.22%\n",
      "29\tValidation loss: 0.032523\tBest loss: 0.032128\tAccuracy: 99.14%\n",
      "30\tValidation loss: 0.057237\tBest loss: 0.032128\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.055562\tBest loss: 0.032128\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.044468\tBest loss: 0.032128\tAccuracy: 99.14%\n",
      "33\tValidation loss: 0.063394\tBest loss: 0.032128\tAccuracy: 98.91%\n",
      "34\tValidation loss: 0.054697\tBest loss: 0.032128\tAccuracy: 98.91%\n",
      "35\tValidation loss: 0.044641\tBest loss: 0.032128\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.051789\tBest loss: 0.032128\tAccuracy: 98.83%\n",
      "37\tValidation loss: 0.044842\tBest loss: 0.032128\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.055166\tBest loss: 0.032128\tAccuracy: 98.91%\n",
      "39\tValidation loss: 0.042249\tBest loss: 0.032128\tAccuracy: 99.18%\n",
      "40\tValidation loss: 0.055867\tBest loss: 0.032128\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.059663\tBest loss: 0.032128\tAccuracy: 98.71%\n",
      "42\tValidation loss: 0.044998\tBest loss: 0.032128\tAccuracy: 99.26%\n",
      "43\tValidation loss: 0.045714\tBest loss: 0.032128\tAccuracy: 99.14%\n",
      "44\tValidation loss: 0.048897\tBest loss: 0.032128\tAccuracy: 99.06%\n",
      "45\tValidation loss: 0.037082\tBest loss: 0.032128\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 1.2min\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.159489\tBest loss: 0.159489\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.072417\tBest loss: 0.072417\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.043321\tBest loss: 0.043321\tAccuracy: 98.79%\n",
      "3\tValidation loss: 0.051518\tBest loss: 0.043321\tAccuracy: 98.67%\n",
      "4\tValidation loss: 0.060759\tBest loss: 0.043321\tAccuracy: 98.55%\n",
      "5\tValidation loss: 0.057614\tBest loss: 0.043321\tAccuracy: 98.79%\n",
      "6\tValidation loss: 0.056901\tBest loss: 0.043321\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.060183\tBest loss: 0.043321\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.047383\tBest loss: 0.043321\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.059550\tBest loss: 0.043321\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.045944\tBest loss: 0.043321\tAccuracy: 98.91%\n",
      "11\tValidation loss: 0.051056\tBest loss: 0.043321\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.049100\tBest loss: 0.043321\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.067857\tBest loss: 0.043321\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.058046\tBest loss: 0.043321\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.054200\tBest loss: 0.043321\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.053733\tBest loss: 0.043321\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.079526\tBest loss: 0.043321\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.048837\tBest loss: 0.043321\tAccuracy: 98.98%\n",
      "19\tValidation loss: 0.080658\tBest loss: 0.043321\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.069573\tBest loss: 0.043321\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.048335\tBest loss: 0.043321\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.040550\tBest loss: 0.040550\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.039731\tBest loss: 0.039731\tAccuracy: 99.02%\n",
      "24\tValidation loss: 0.038790\tBest loss: 0.038790\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.047405\tBest loss: 0.038790\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.038348\tBest loss: 0.038348\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.036417\tBest loss: 0.036417\tAccuracy: 99.26%\n",
      "28\tValidation loss: 0.036314\tBest loss: 0.036314\tAccuracy: 99.30%\n",
      "29\tValidation loss: 0.049991\tBest loss: 0.036314\tAccuracy: 99.18%\n",
      "30\tValidation loss: 0.045765\tBest loss: 0.036314\tAccuracy: 99.06%\n",
      "31\tValidation loss: 0.055844\tBest loss: 0.036314\tAccuracy: 98.98%\n",
      "32\tValidation loss: 0.045809\tBest loss: 0.036314\tAccuracy: 98.98%\n",
      "33\tValidation loss: 0.060083\tBest loss: 0.036314\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.041187\tBest loss: 0.036314\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.034160\tBest loss: 0.034160\tAccuracy: 99.34%\n",
      "36\tValidation loss: 0.040696\tBest loss: 0.034160\tAccuracy: 99.14%\n",
      "37\tValidation loss: 0.046568\tBest loss: 0.034160\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.047632\tBest loss: 0.034160\tAccuracy: 99.18%\n",
      "39\tValidation loss: 0.039406\tBest loss: 0.034160\tAccuracy: 99.22%\n",
      "40\tValidation loss: 0.047508\tBest loss: 0.034160\tAccuracy: 99.22%\n",
      "41\tValidation loss: 0.040828\tBest loss: 0.034160\tAccuracy: 99.30%\n",
      "42\tValidation loss: 0.038340\tBest loss: 0.034160\tAccuracy: 99.30%\n",
      "43\tValidation loss: 0.113447\tBest loss: 0.034160\tAccuracy: 98.28%\n",
      "44\tValidation loss: 0.055863\tBest loss: 0.034160\tAccuracy: 98.87%\n",
      "45\tValidation loss: 0.070680\tBest loss: 0.034160\tAccuracy: 98.87%\n",
      "46\tValidation loss: 0.044207\tBest loss: 0.034160\tAccuracy: 99.10%\n",
      "47\tValidation loss: 0.059088\tBest loss: 0.034160\tAccuracy: 99.14%\n",
      "48\tValidation loss: 0.051058\tBest loss: 0.034160\tAccuracy: 99.14%\n",
      "49\tValidation loss: 0.045735\tBest loss: 0.034160\tAccuracy: 99.26%\n",
      "50\tValidation loss: 0.055754\tBest loss: 0.034160\tAccuracy: 98.79%\n",
      "51\tValidation loss: 0.045933\tBest loss: 0.034160\tAccuracy: 99.14%\n",
      "52\tValidation loss: 0.040717\tBest loss: 0.034160\tAccuracy: 99.22%\n",
      "53\tValidation loss: 0.053227\tBest loss: 0.034160\tAccuracy: 99.02%\n",
      "54\tValidation loss: 0.043761\tBest loss: 0.034160\tAccuracy: 99.22%\n",
      "55\tValidation loss: 0.050944\tBest loss: 0.034160\tAccuracy: 99.22%\n",
      "56\tValidation loss: 0.052714\tBest loss: 0.034160\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 1.4min\n",
      "[CV] n_neurons=70, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.097424\tBest loss: 0.097424\tAccuracy: 97.73%\n",
      "1\tValidation loss: 0.105154\tBest loss: 0.097424\tAccuracy: 97.54%\n",
      "2\tValidation loss: 0.061843\tBest loss: 0.061843\tAccuracy: 98.32%\n",
      "3\tValidation loss: 0.084619\tBest loss: 0.061843\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.069339\tBest loss: 0.061843\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.065375\tBest loss: 0.061843\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.075801\tBest loss: 0.061843\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.071221\tBest loss: 0.061843\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.066282\tBest loss: 0.061843\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.051685\tBest loss: 0.051685\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.054859\tBest loss: 0.051685\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.050106\tBest loss: 0.050106\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.114687\tBest loss: 0.050106\tAccuracy: 97.38%\n",
      "13\tValidation loss: 0.042991\tBest loss: 0.042991\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.071425\tBest loss: 0.042991\tAccuracy: 98.55%\n",
      "15\tValidation loss: 0.094463\tBest loss: 0.042991\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.071402\tBest loss: 0.042991\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.131149\tBest loss: 0.042991\tAccuracy: 96.52%\n",
      "18\tValidation loss: 0.055976\tBest loss: 0.042991\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.145907\tBest loss: 0.042991\tAccuracy: 97.81%\n",
      "20\tValidation loss: 0.081240\tBest loss: 0.042991\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.056401\tBest loss: 0.042991\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.070462\tBest loss: 0.042991\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.068674\tBest loss: 0.042991\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.056582\tBest loss: 0.042991\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.055270\tBest loss: 0.042991\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.062711\tBest loss: 0.042991\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.045370\tBest loss: 0.042991\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.054093\tBest loss: 0.042991\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.087534\tBest loss: 0.042991\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.116152\tBest loss: 0.042991\tAccuracy: 97.85%\n",
      "31\tValidation loss: 0.044228\tBest loss: 0.042991\tAccuracy: 99.06%\n",
      "32\tValidation loss: 0.061590\tBest loss: 0.042991\tAccuracy: 98.94%\n",
      "33\tValidation loss: 0.085580\tBest loss: 0.042991\tAccuracy: 98.91%\n",
      "34\tValidation loss: 0.046722\tBest loss: 0.042991\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.7min\n",
      "[CV] n_neurons=70, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.087228\tBest loss: 0.087228\tAccuracy: 97.65%\n",
      "1\tValidation loss: 0.113210\tBest loss: 0.087228\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.065457\tBest loss: 0.065457\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.053003\tBest loss: 0.053003\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.079728\tBest loss: 0.053003\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.062055\tBest loss: 0.053003\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.071337\tBest loss: 0.053003\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.059155\tBest loss: 0.053003\tAccuracy: 98.44%\n",
      "8\tValidation loss: 0.046165\tBest loss: 0.046165\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.052007\tBest loss: 0.046165\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.061048\tBest loss: 0.046165\tAccuracy: 98.48%\n",
      "11\tValidation loss: 0.059643\tBest loss: 0.046165\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.066486\tBest loss: 0.046165\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.070570\tBest loss: 0.046165\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.141590\tBest loss: 0.046165\tAccuracy: 96.91%\n",
      "15\tValidation loss: 0.081647\tBest loss: 0.046165\tAccuracy: 98.12%\n",
      "16\tValidation loss: 0.049712\tBest loss: 0.046165\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.041115\tBest loss: 0.041115\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.051416\tBest loss: 0.041115\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.065760\tBest loss: 0.041115\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.071856\tBest loss: 0.041115\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.074423\tBest loss: 0.041115\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.049302\tBest loss: 0.041115\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.059187\tBest loss: 0.041115\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.102700\tBest loss: 0.041115\tAccuracy: 97.46%\n",
      "25\tValidation loss: 0.054224\tBest loss: 0.041115\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.048571\tBest loss: 0.041115\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.071364\tBest loss: 0.041115\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.080527\tBest loss: 0.041115\tAccuracy: 98.55%\n",
      "29\tValidation loss: 0.039726\tBest loss: 0.039726\tAccuracy: 98.98%\n",
      "30\tValidation loss: 0.088127\tBest loss: 0.039726\tAccuracy: 98.44%\n",
      "31\tValidation loss: 0.079309\tBest loss: 0.039726\tAccuracy: 98.63%\n",
      "32\tValidation loss: 0.051809\tBest loss: 0.039726\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.072382\tBest loss: 0.039726\tAccuracy: 98.59%\n",
      "34\tValidation loss: 0.056264\tBest loss: 0.039726\tAccuracy: 98.75%\n",
      "35\tValidation loss: 0.046148\tBest loss: 0.039726\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.133091\tBest loss: 0.039726\tAccuracy: 97.93%\n",
      "37\tValidation loss: 0.086216\tBest loss: 0.039726\tAccuracy: 98.63%\n",
      "38\tValidation loss: 0.058681\tBest loss: 0.039726\tAccuracy: 98.83%\n",
      "39\tValidation loss: 0.078413\tBest loss: 0.039726\tAccuracy: 98.87%\n",
      "40\tValidation loss: 0.078448\tBest loss: 0.039726\tAccuracy: 98.63%\n",
      "41\tValidation loss: 0.160407\tBest loss: 0.039726\tAccuracy: 97.62%\n",
      "42\tValidation loss: 0.064841\tBest loss: 0.039726\tAccuracy: 98.59%\n",
      "43\tValidation loss: 0.058976\tBest loss: 0.039726\tAccuracy: 98.71%\n",
      "44\tValidation loss: 0.048353\tBest loss: 0.039726\tAccuracy: 98.98%\n",
      "45\tValidation loss: 0.071827\tBest loss: 0.039726\tAccuracy: 98.79%\n",
      "46\tValidation loss: 0.052148\tBest loss: 0.039726\tAccuracy: 98.91%\n",
      "47\tValidation loss: 0.064131\tBest loss: 0.039726\tAccuracy: 98.94%\n",
      "48\tValidation loss: 0.064483\tBest loss: 0.039726\tAccuracy: 98.79%\n",
      "49\tValidation loss: 0.059968\tBest loss: 0.039726\tAccuracy: 98.83%\n",
      "50\tValidation loss: 0.077966\tBest loss: 0.039726\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.5min\n",
      "[CV] n_neurons=70, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.160194\tBest loss: 0.160194\tAccuracy: 96.76%\n",
      "1\tValidation loss: 0.118222\tBest loss: 0.118222\tAccuracy: 97.81%\n",
      "2\tValidation loss: 0.104037\tBest loss: 0.104037\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.060700\tBest loss: 0.060700\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.054654\tBest loss: 0.054654\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.168074\tBest loss: 0.054654\tAccuracy: 96.21%\n",
      "6\tValidation loss: 0.049449\tBest loss: 0.049449\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.039818\tBest loss: 0.039818\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.207205\tBest loss: 0.039818\tAccuracy: 96.91%\n",
      "9\tValidation loss: 0.044344\tBest loss: 0.039818\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.043080\tBest loss: 0.039818\tAccuracy: 99.02%\n",
      "11\tValidation loss: 0.050335\tBest loss: 0.039818\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.051218\tBest loss: 0.039818\tAccuracy: 98.98%\n",
      "13\tValidation loss: 0.043911\tBest loss: 0.039818\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.121390\tBest loss: 0.039818\tAccuracy: 97.15%\n",
      "15\tValidation loss: 0.080782\tBest loss: 0.039818\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.035940\tBest loss: 0.035940\tAccuracy: 99.18%\n",
      "17\tValidation loss: 0.089997\tBest loss: 0.035940\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.076905\tBest loss: 0.035940\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.061345\tBest loss: 0.035940\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.052007\tBest loss: 0.035940\tAccuracy: 98.94%\n",
      "21\tValidation loss: 0.042837\tBest loss: 0.035940\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.033711\tBest loss: 0.033711\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.103319\tBest loss: 0.033711\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.068843\tBest loss: 0.033711\tAccuracy: 98.55%\n",
      "25\tValidation loss: 0.045999\tBest loss: 0.033711\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.080811\tBest loss: 0.033711\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.044368\tBest loss: 0.033711\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.038589\tBest loss: 0.033711\tAccuracy: 99.30%\n",
      "29\tValidation loss: 0.054954\tBest loss: 0.033711\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.102869\tBest loss: 0.033711\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.048669\tBest loss: 0.033711\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.123760\tBest loss: 0.033711\tAccuracy: 98.48%\n",
      "33\tValidation loss: 0.075131\tBest loss: 0.033711\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.059613\tBest loss: 0.033711\tAccuracy: 98.91%\n",
      "35\tValidation loss: 0.042317\tBest loss: 0.033711\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.048868\tBest loss: 0.033711\tAccuracy: 99.06%\n",
      "37\tValidation loss: 0.052669\tBest loss: 0.033711\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.047878\tBest loss: 0.033711\tAccuracy: 99.22%\n",
      "39\tValidation loss: 0.066238\tBest loss: 0.033711\tAccuracy: 98.91%\n",
      "40\tValidation loss: 0.053489\tBest loss: 0.033711\tAccuracy: 99.02%\n",
      "41\tValidation loss: 0.074819\tBest loss: 0.033711\tAccuracy: 98.63%\n",
      "42\tValidation loss: 0.096714\tBest loss: 0.033711\tAccuracy: 98.59%\n",
      "43\tValidation loss: 0.063514\tBest loss: 0.033711\tAccuracy: 99.10%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.05, batch_size=50, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.2min\n",
      "[CV] n_neurons=30, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.327107\tBest loss: 0.327107\tAccuracy: 94.68%\n",
      "1\tValidation loss: 0.098625\tBest loss: 0.098625\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.083474\tBest loss: 0.083474\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.136641\tBest loss: 0.083474\tAccuracy: 96.44%\n",
      "4\tValidation loss: 0.060337\tBest loss: 0.060337\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.089668\tBest loss: 0.060337\tAccuracy: 97.65%\n",
      "6\tValidation loss: 0.065865\tBest loss: 0.060337\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.046559\tBest loss: 0.046559\tAccuracy: 98.71%\n",
      "8\tValidation loss: 0.134008\tBest loss: 0.046559\tAccuracy: 95.43%\n",
      "9\tValidation loss: 0.067809\tBest loss: 0.046559\tAccuracy: 97.73%\n",
      "10\tValidation loss: 0.076464\tBest loss: 0.046559\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.043049\tBest loss: 0.043049\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.058787\tBest loss: 0.043049\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.047256\tBest loss: 0.043049\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.056823\tBest loss: 0.043049\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.049506\tBest loss: 0.043049\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.073014\tBest loss: 0.043049\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.054137\tBest loss: 0.043049\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.051349\tBest loss: 0.043049\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.051275\tBest loss: 0.043049\tAccuracy: 98.51%\n",
      "20\tValidation loss: 0.055968\tBest loss: 0.043049\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.070109\tBest loss: 0.043049\tAccuracy: 98.24%\n",
      "22\tValidation loss: 0.045530\tBest loss: 0.043049\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.047445\tBest loss: 0.043049\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.048835\tBest loss: 0.043049\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.040597\tBest loss: 0.040597\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.056654\tBest loss: 0.040597\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.040119\tBest loss: 0.040119\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.053052\tBest loss: 0.040119\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.053140\tBest loss: 0.040119\tAccuracy: 98.55%\n",
      "30\tValidation loss: 0.042719\tBest loss: 0.040119\tAccuracy: 98.71%\n",
      "31\tValidation loss: 0.063277\tBest loss: 0.040119\tAccuracy: 98.12%\n",
      "32\tValidation loss: 0.044144\tBest loss: 0.040119\tAccuracy: 98.79%\n",
      "33\tValidation loss: 0.052737\tBest loss: 0.040119\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.040931\tBest loss: 0.040119\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.041330\tBest loss: 0.040119\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.050426\tBest loss: 0.040119\tAccuracy: 98.71%\n",
      "37\tValidation loss: 0.056499\tBest loss: 0.040119\tAccuracy: 98.59%\n",
      "38\tValidation loss: 0.055284\tBest loss: 0.040119\tAccuracy: 98.32%\n",
      "39\tValidation loss: 0.051623\tBest loss: 0.040119\tAccuracy: 98.75%\n",
      "40\tValidation loss: 0.041635\tBest loss: 0.040119\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.051206\tBest loss: 0.040119\tAccuracy: 98.67%\n",
      "42\tValidation loss: 0.045427\tBest loss: 0.040119\tAccuracy: 98.98%\n",
      "43\tValidation loss: 0.042665\tBest loss: 0.040119\tAccuracy: 99.06%\n",
      "44\tValidation loss: 0.051305\tBest loss: 0.040119\tAccuracy: 98.51%\n",
      "45\tValidation loss: 0.050658\tBest loss: 0.040119\tAccuracy: 98.83%\n",
      "46\tValidation loss: 0.046476\tBest loss: 0.040119\tAccuracy: 98.87%\n",
      "47\tValidation loss: 0.049186\tBest loss: 0.040119\tAccuracy: 98.55%\n",
      "48\tValidation loss: 0.052975\tBest loss: 0.040119\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 7.3min\n",
      "[CV] n_neurons=30, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.347967\tBest loss: 0.347967\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.113802\tBest loss: 0.113802\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.105135\tBest loss: 0.105135\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.081493\tBest loss: 0.081493\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.075805\tBest loss: 0.075805\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.062771\tBest loss: 0.062771\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.068670\tBest loss: 0.062771\tAccuracy: 97.85%\n",
      "7\tValidation loss: 0.071638\tBest loss: 0.062771\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.077524\tBest loss: 0.062771\tAccuracy: 97.42%\n",
      "9\tValidation loss: 0.085624\tBest loss: 0.062771\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.080072\tBest loss: 0.062771\tAccuracy: 97.73%\n",
      "11\tValidation loss: 0.090972\tBest loss: 0.062771\tAccuracy: 97.03%\n",
      "12\tValidation loss: 0.073023\tBest loss: 0.062771\tAccuracy: 97.77%\n",
      "13\tValidation loss: 0.067636\tBest loss: 0.062771\tAccuracy: 98.01%\n",
      "14\tValidation loss: 0.057844\tBest loss: 0.057844\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.146224\tBest loss: 0.057844\tAccuracy: 94.96%\n",
      "16\tValidation loss: 0.061264\tBest loss: 0.057844\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.052449\tBest loss: 0.052449\tAccuracy: 98.44%\n",
      "18\tValidation loss: 0.058068\tBest loss: 0.052449\tAccuracy: 98.12%\n",
      "19\tValidation loss: 0.064274\tBest loss: 0.052449\tAccuracy: 97.89%\n",
      "20\tValidation loss: 0.059186\tBest loss: 0.052449\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.041519\tBest loss: 0.041519\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.084739\tBest loss: 0.041519\tAccuracy: 97.30%\n",
      "23\tValidation loss: 0.069257\tBest loss: 0.041519\tAccuracy: 98.01%\n",
      "24\tValidation loss: 0.047425\tBest loss: 0.041519\tAccuracy: 98.48%\n",
      "25\tValidation loss: 0.061281\tBest loss: 0.041519\tAccuracy: 97.89%\n",
      "26\tValidation loss: 0.041757\tBest loss: 0.041519\tAccuracy: 98.79%\n",
      "27\tValidation loss: 0.042858\tBest loss: 0.041519\tAccuracy: 98.63%\n",
      "28\tValidation loss: 0.049846\tBest loss: 0.041519\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.050779\tBest loss: 0.041519\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.054165\tBest loss: 0.041519\tAccuracy: 98.44%\n",
      "31\tValidation loss: 0.049092\tBest loss: 0.041519\tAccuracy: 98.44%\n",
      "32\tValidation loss: 0.066064\tBest loss: 0.041519\tAccuracy: 98.08%\n",
      "33\tValidation loss: 0.052399\tBest loss: 0.041519\tAccuracy: 98.48%\n",
      "34\tValidation loss: 0.077822\tBest loss: 0.041519\tAccuracy: 97.46%\n",
      "35\tValidation loss: 0.060534\tBest loss: 0.041519\tAccuracy: 98.05%\n",
      "36\tValidation loss: 0.047378\tBest loss: 0.041519\tAccuracy: 98.36%\n",
      "37\tValidation loss: 0.037489\tBest loss: 0.037489\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.050555\tBest loss: 0.037489\tAccuracy: 98.55%\n",
      "39\tValidation loss: 0.055100\tBest loss: 0.037489\tAccuracy: 98.51%\n",
      "40\tValidation loss: 0.044224\tBest loss: 0.037489\tAccuracy: 98.59%\n",
      "41\tValidation loss: 0.045019\tBest loss: 0.037489\tAccuracy: 98.55%\n",
      "42\tValidation loss: 0.060674\tBest loss: 0.037489\tAccuracy: 98.20%\n",
      "43\tValidation loss: 0.037991\tBest loss: 0.037489\tAccuracy: 98.94%\n",
      "44\tValidation loss: 0.052007\tBest loss: 0.037489\tAccuracy: 98.48%\n",
      "45\tValidation loss: 0.071509\tBest loss: 0.037489\tAccuracy: 98.08%\n",
      "46\tValidation loss: 0.048769\tBest loss: 0.037489\tAccuracy: 98.59%\n",
      "47\tValidation loss: 0.047163\tBest loss: 0.037489\tAccuracy: 98.63%\n",
      "48\tValidation loss: 0.037507\tBest loss: 0.037489\tAccuracy: 98.91%\n",
      "49\tValidation loss: 0.042882\tBest loss: 0.037489\tAccuracy: 98.71%\n",
      "50\tValidation loss: 0.050452\tBest loss: 0.037489\tAccuracy: 98.28%\n",
      "51\tValidation loss: 0.034507\tBest loss: 0.034507\tAccuracy: 98.75%\n",
      "52\tValidation loss: 0.040758\tBest loss: 0.034507\tAccuracy: 98.79%\n",
      "53\tValidation loss: 0.058934\tBest loss: 0.034507\tAccuracy: 98.63%\n",
      "54\tValidation loss: 0.045611\tBest loss: 0.034507\tAccuracy: 98.71%\n",
      "55\tValidation loss: 0.040119\tBest loss: 0.034507\tAccuracy: 98.71%\n",
      "56\tValidation loss: 0.061105\tBest loss: 0.034507\tAccuracy: 98.20%\n",
      "57\tValidation loss: 0.049051\tBest loss: 0.034507\tAccuracy: 98.32%\n",
      "58\tValidation loss: 0.064133\tBest loss: 0.034507\tAccuracy: 97.97%\n",
      "59\tValidation loss: 0.053316\tBest loss: 0.034507\tAccuracy: 98.51%\n",
      "60\tValidation loss: 0.049865\tBest loss: 0.034507\tAccuracy: 98.71%\n",
      "61\tValidation loss: 0.041611\tBest loss: 0.034507\tAccuracy: 98.59%\n",
      "62\tValidation loss: 0.039336\tBest loss: 0.034507\tAccuracy: 98.71%\n",
      "63\tValidation loss: 0.042493\tBest loss: 0.034507\tAccuracy: 98.67%\n",
      "64\tValidation loss: 0.053330\tBest loss: 0.034507\tAccuracy: 98.55%\n",
      "65\tValidation loss: 0.033708\tBest loss: 0.033708\tAccuracy: 98.98%\n",
      "66\tValidation loss: 0.040987\tBest loss: 0.033708\tAccuracy: 98.83%\n",
      "67\tValidation loss: 0.037983\tBest loss: 0.033708\tAccuracy: 98.79%\n",
      "68\tValidation loss: 0.047647\tBest loss: 0.033708\tAccuracy: 98.59%\n",
      "69\tValidation loss: 0.064943\tBest loss: 0.033708\tAccuracy: 98.08%\n",
      "70\tValidation loss: 0.046724\tBest loss: 0.033708\tAccuracy: 98.71%\n",
      "71\tValidation loss: 0.043863\tBest loss: 0.033708\tAccuracy: 98.75%\n",
      "72\tValidation loss: 0.039072\tBest loss: 0.033708\tAccuracy: 98.67%\n",
      "73\tValidation loss: 0.038028\tBest loss: 0.033708\tAccuracy: 98.87%\n",
      "74\tValidation loss: 0.038574\tBest loss: 0.033708\tAccuracy: 98.79%\n",
      "75\tValidation loss: 0.047301\tBest loss: 0.033708\tAccuracy: 98.44%\n",
      "76\tValidation loss: 0.039303\tBest loss: 0.033708\tAccuracy: 98.67%\n",
      "77\tValidation loss: 0.048657\tBest loss: 0.033708\tAccuracy: 98.71%\n",
      "78\tValidation loss: 0.037850\tBest loss: 0.033708\tAccuracy: 98.87%\n",
      "79\tValidation loss: 0.038636\tBest loss: 0.033708\tAccuracy: 98.98%\n",
      "80\tValidation loss: 0.033656\tBest loss: 0.033656\tAccuracy: 98.98%\n",
      "81\tValidation loss: 0.035911\tBest loss: 0.033656\tAccuracy: 98.79%\n",
      "82\tValidation loss: 0.046392\tBest loss: 0.033656\tAccuracy: 98.75%\n",
      "83\tValidation loss: 0.043142\tBest loss: 0.033656\tAccuracy: 98.67%\n",
      "84\tValidation loss: 0.039273\tBest loss: 0.033656\tAccuracy: 98.94%\n",
      "85\tValidation loss: 0.049281\tBest loss: 0.033656\tAccuracy: 98.48%\n",
      "86\tValidation loss: 0.070060\tBest loss: 0.033656\tAccuracy: 98.20%\n",
      "87\tValidation loss: 0.043648\tBest loss: 0.033656\tAccuracy: 98.83%\n",
      "88\tValidation loss: 0.055260\tBest loss: 0.033656\tAccuracy: 98.36%\n",
      "89\tValidation loss: 0.046832\tBest loss: 0.033656\tAccuracy: 98.63%\n",
      "90\tValidation loss: 0.050208\tBest loss: 0.033656\tAccuracy: 98.51%\n",
      "91\tValidation loss: 0.044687\tBest loss: 0.033656\tAccuracy: 98.63%\n",
      "92\tValidation loss: 0.045898\tBest loss: 0.033656\tAccuracy: 98.51%\n",
      "93\tValidation loss: 0.038005\tBest loss: 0.033656\tAccuracy: 98.87%\n",
      "94\tValidation loss: 0.044921\tBest loss: 0.033656\tAccuracy: 98.75%\n",
      "95\tValidation loss: 0.046408\tBest loss: 0.033656\tAccuracy: 98.67%\n",
      "96\tValidation loss: 0.053181\tBest loss: 0.033656\tAccuracy: 98.63%\n",
      "97\tValidation loss: 0.048427\tBest loss: 0.033656\tAccuracy: 98.67%\n",
      "98\tValidation loss: 0.037453\tBest loss: 0.033656\tAccuracy: 98.87%\n",
      "99\tValidation loss: 0.036887\tBest loss: 0.033656\tAccuracy: 98.98%\n",
      "100\tValidation loss: 0.055146\tBest loss: 0.033656\tAccuracy: 98.63%\n",
      "101\tValidation loss: 0.054055\tBest loss: 0.033656\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total=14.9min\n",
      "[CV] n_neurons=30, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.269984\tBest loss: 0.269984\tAccuracy: 95.74%\n",
      "1\tValidation loss: 0.137697\tBest loss: 0.137697\tAccuracy: 97.26%\n",
      "2\tValidation loss: 0.120043\tBest loss: 0.120043\tAccuracy: 96.48%\n",
      "3\tValidation loss: 0.101037\tBest loss: 0.101037\tAccuracy: 97.73%\n",
      "4\tValidation loss: 0.088487\tBest loss: 0.088487\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.110950\tBest loss: 0.088487\tAccuracy: 96.48%\n",
      "6\tValidation loss: 0.067582\tBest loss: 0.067582\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.138795\tBest loss: 0.067582\tAccuracy: 96.21%\n",
      "8\tValidation loss: 0.058482\tBest loss: 0.058482\tAccuracy: 98.32%\n",
      "9\tValidation loss: 0.044782\tBest loss: 0.044782\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.059268\tBest loss: 0.044782\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.067560\tBest loss: 0.044782\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.056172\tBest loss: 0.044782\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.064089\tBest loss: 0.044782\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.052484\tBest loss: 0.044782\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.047929\tBest loss: 0.044782\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.036841\tBest loss: 0.036841\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.045137\tBest loss: 0.036841\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.046102\tBest loss: 0.036841\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.035854\tBest loss: 0.035854\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.039010\tBest loss: 0.035854\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.052859\tBest loss: 0.035854\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.049648\tBest loss: 0.035854\tAccuracy: 98.59%\n",
      "23\tValidation loss: 0.040264\tBest loss: 0.035854\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.035745\tBest loss: 0.035745\tAccuracy: 99.10%\n",
      "25\tValidation loss: 0.047535\tBest loss: 0.035745\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.038588\tBest loss: 0.035745\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.067404\tBest loss: 0.035745\tAccuracy: 97.89%\n",
      "28\tValidation loss: 0.038724\tBest loss: 0.035745\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.040244\tBest loss: 0.035745\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.043344\tBest loss: 0.035745\tAccuracy: 98.75%\n",
      "31\tValidation loss: 0.040332\tBest loss: 0.035745\tAccuracy: 98.44%\n",
      "32\tValidation loss: 0.052201\tBest loss: 0.035745\tAccuracy: 98.59%\n",
      "33\tValidation loss: 0.040003\tBest loss: 0.035745\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.037457\tBest loss: 0.035745\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.045824\tBest loss: 0.035745\tAccuracy: 98.67%\n",
      "36\tValidation loss: 0.041962\tBest loss: 0.035745\tAccuracy: 98.75%\n",
      "37\tValidation loss: 0.036637\tBest loss: 0.035745\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.041701\tBest loss: 0.035745\tAccuracy: 98.94%\n",
      "39\tValidation loss: 0.036427\tBest loss: 0.035745\tAccuracy: 98.83%\n",
      "40\tValidation loss: 0.041541\tBest loss: 0.035745\tAccuracy: 98.94%\n",
      "41\tValidation loss: 0.043659\tBest loss: 0.035745\tAccuracy: 98.79%\n",
      "42\tValidation loss: 0.047598\tBest loss: 0.035745\tAccuracy: 98.55%\n",
      "43\tValidation loss: 0.037599\tBest loss: 0.035745\tAccuracy: 99.02%\n",
      "44\tValidation loss: 0.042194\tBest loss: 0.035745\tAccuracy: 98.75%\n",
      "45\tValidation loss: 0.038197\tBest loss: 0.035745\tAccuracy: 99.14%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 6.8min\n",
      "[CV] n_neurons=10, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.999, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 2.853400\tBest loss: 2.853400\tAccuracy: 78.97%\n",
      "1\tValidation loss: 2.482207\tBest loss: 2.482207\tAccuracy: 87.26%\n",
      "2\tValidation loss: 2.107919\tBest loss: 2.107919\tAccuracy: 88.98%\n",
      "3\tValidation loss: 2.615988\tBest loss: 2.107919\tAccuracy: 87.14%\n",
      "4\tValidation loss: 2.019284\tBest loss: 2.019284\tAccuracy: 90.03%\n",
      "5\tValidation loss: 1.819084\tBest loss: 1.819084\tAccuracy: 93.00%\n",
      "6\tValidation loss: 3.288987\tBest loss: 1.819084\tAccuracy: 87.96%\n",
      "7\tValidation loss: 3.472727\tBest loss: 1.819084\tAccuracy: 87.69%\n",
      "8\tValidation loss: 2.984731\tBest loss: 1.819084\tAccuracy: 89.48%\n",
      "9\tValidation loss: 2.965201\tBest loss: 1.819084\tAccuracy: 89.41%\n",
      "10\tValidation loss: 3.377176\tBest loss: 1.819084\tAccuracy: 89.13%\n",
      "11\tValidation loss: 2.259524\tBest loss: 1.819084\tAccuracy: 91.13%\n",
      "12\tValidation loss: 2.139353\tBest loss: 1.819084\tAccuracy: 93.08%\n",
      "13\tValidation loss: 1.880664\tBest loss: 1.819084\tAccuracy: 93.12%\n",
      "14\tValidation loss: 1.769930\tBest loss: 1.769930\tAccuracy: 92.53%\n",
      "15\tValidation loss: 3.491017\tBest loss: 1.769930\tAccuracy: 88.90%\n",
      "16\tValidation loss: 2.624630\tBest loss: 1.769930\tAccuracy: 89.95%\n",
      "17\tValidation loss: 3.256673\tBest loss: 1.769930\tAccuracy: 88.47%\n",
      "18\tValidation loss: 2.384886\tBest loss: 1.769930\tAccuracy: 89.60%\n",
      "19\tValidation loss: 2.133664\tBest loss: 1.769930\tAccuracy: 92.49%\n",
      "20\tValidation loss: 1.850550\tBest loss: 1.769930\tAccuracy: 91.13%\n",
      "21\tValidation loss: 2.895165\tBest loss: 1.769930\tAccuracy: 88.70%\n",
      "22\tValidation loss: 3.280144\tBest loss: 1.769930\tAccuracy: 90.58%\n",
      "23\tValidation loss: 1.795122\tBest loss: 1.769930\tAccuracy: 93.16%\n",
      "24\tValidation loss: 1.878834\tBest loss: 1.769930\tAccuracy: 93.75%\n",
      "25\tValidation loss: 1.208994\tBest loss: 1.208994\tAccuracy: 94.45%\n",
      "26\tValidation loss: 2.006043\tBest loss: 1.208994\tAccuracy: 91.16%\n",
      "27\tValidation loss: 1.927055\tBest loss: 1.208994\tAccuracy: 91.91%\n",
      "28\tValidation loss: 1.865816\tBest loss: 1.208994\tAccuracy: 92.81%\n",
      "29\tValidation loss: 2.036798\tBest loss: 1.208994\tAccuracy: 92.26%\n",
      "30\tValidation loss: 1.729356\tBest loss: 1.208994\tAccuracy: 92.81%\n",
      "31\tValidation loss: 1.655402\tBest loss: 1.208994\tAccuracy: 92.57%\n",
      "32\tValidation loss: 1.123189\tBest loss: 1.123189\tAccuracy: 93.67%\n",
      "33\tValidation loss: 1.785327\tBest loss: 1.123189\tAccuracy: 92.73%\n",
      "34\tValidation loss: 1.468680\tBest loss: 1.123189\tAccuracy: 93.75%\n",
      "35\tValidation loss: 1.387905\tBest loss: 1.123189\tAccuracy: 93.94%\n",
      "36\tValidation loss: 0.955620\tBest loss: 0.955620\tAccuracy: 95.58%\n",
      "37\tValidation loss: 1.179067\tBest loss: 0.955620\tAccuracy: 94.88%\n",
      "38\tValidation loss: 1.366310\tBest loss: 0.955620\tAccuracy: 94.92%\n",
      "39\tValidation loss: 1.238029\tBest loss: 0.955620\tAccuracy: 95.15%\n",
      "40\tValidation loss: 1.237574\tBest loss: 0.955620\tAccuracy: 94.96%\n",
      "41\tValidation loss: 0.887969\tBest loss: 0.887969\tAccuracy: 95.90%\n",
      "42\tValidation loss: 1.223746\tBest loss: 0.887969\tAccuracy: 94.92%\n",
      "43\tValidation loss: 1.035946\tBest loss: 0.887969\tAccuracy: 95.58%\n",
      "44\tValidation loss: 1.034341\tBest loss: 0.887969\tAccuracy: 95.70%\n",
      "45\tValidation loss: 1.119978\tBest loss: 0.887969\tAccuracy: 94.53%\n",
      "46\tValidation loss: 0.814376\tBest loss: 0.814376\tAccuracy: 96.52%\n",
      "47\tValidation loss: 1.116869\tBest loss: 0.814376\tAccuracy: 95.15%\n",
      "48\tValidation loss: 0.794706\tBest loss: 0.794706\tAccuracy: 96.56%\n",
      "49\tValidation loss: 1.002403\tBest loss: 0.794706\tAccuracy: 95.15%\n",
      "50\tValidation loss: 1.138901\tBest loss: 0.794706\tAccuracy: 94.76%\n",
      "51\tValidation loss: 0.943072\tBest loss: 0.794706\tAccuracy: 95.90%\n",
      "52\tValidation loss: 0.849564\tBest loss: 0.794706\tAccuracy: 96.09%\n",
      "53\tValidation loss: 1.010632\tBest loss: 0.794706\tAccuracy: 95.78%\n",
      "54\tValidation loss: 1.108424\tBest loss: 0.794706\tAccuracy: 94.96%\n",
      "55\tValidation loss: 0.668054\tBest loss: 0.668054\tAccuracy: 96.52%\n",
      "56\tValidation loss: 0.768355\tBest loss: 0.668054\tAccuracy: 96.36%\n",
      "57\tValidation loss: 0.846999\tBest loss: 0.668054\tAccuracy: 95.93%\n",
      "58\tValidation loss: 0.901524\tBest loss: 0.668054\tAccuracy: 95.70%\n",
      "59\tValidation loss: 1.039766\tBest loss: 0.668054\tAccuracy: 95.31%\n",
      "60\tValidation loss: 0.750691\tBest loss: 0.668054\tAccuracy: 96.25%\n",
      "61\tValidation loss: 1.254395\tBest loss: 0.668054\tAccuracy: 94.02%\n",
      "62\tValidation loss: 1.037224\tBest loss: 0.668054\tAccuracy: 95.04%\n",
      "63\tValidation loss: 0.609888\tBest loss: 0.609888\tAccuracy: 97.30%\n",
      "64\tValidation loss: 0.832975\tBest loss: 0.609888\tAccuracy: 95.74%\n",
      "65\tValidation loss: 0.761242\tBest loss: 0.609888\tAccuracy: 96.25%\n",
      "66\tValidation loss: 0.603087\tBest loss: 0.603087\tAccuracy: 97.30%\n",
      "67\tValidation loss: 0.600050\tBest loss: 0.600050\tAccuracy: 97.07%\n",
      "68\tValidation loss: 0.530055\tBest loss: 0.530055\tAccuracy: 97.46%\n",
      "69\tValidation loss: 0.740618\tBest loss: 0.530055\tAccuracy: 95.93%\n",
      "70\tValidation loss: 0.761925\tBest loss: 0.530055\tAccuracy: 95.97%\n",
      "71\tValidation loss: 0.874753\tBest loss: 0.530055\tAccuracy: 95.04%\n",
      "72\tValidation loss: 0.683222\tBest loss: 0.530055\tAccuracy: 96.79%\n",
      "73\tValidation loss: 0.872683\tBest loss: 0.530055\tAccuracy: 95.93%\n",
      "74\tValidation loss: 0.683047\tBest loss: 0.530055\tAccuracy: 96.33%\n",
      "75\tValidation loss: 0.782973\tBest loss: 0.530055\tAccuracy: 96.48%\n",
      "76\tValidation loss: 0.723990\tBest loss: 0.530055\tAccuracy: 96.68%\n",
      "77\tValidation loss: 0.677234\tBest loss: 0.530055\tAccuracy: 96.25%\n",
      "78\tValidation loss: 0.600409\tBest loss: 0.530055\tAccuracy: 96.79%\n",
      "79\tValidation loss: 0.856763\tBest loss: 0.530055\tAccuracy: 95.70%\n",
      "80\tValidation loss: 0.563851\tBest loss: 0.530055\tAccuracy: 96.56%\n",
      "81\tValidation loss: 0.505660\tBest loss: 0.505660\tAccuracy: 97.22%\n",
      "82\tValidation loss: 0.786350\tBest loss: 0.505660\tAccuracy: 95.58%\n",
      "83\tValidation loss: 0.698539\tBest loss: 0.505660\tAccuracy: 96.40%\n",
      "84\tValidation loss: 0.577301\tBest loss: 0.505660\tAccuracy: 97.19%\n",
      "85\tValidation loss: 0.594629\tBest loss: 0.505660\tAccuracy: 97.03%\n",
      "86\tValidation loss: 0.614326\tBest loss: 0.505660\tAccuracy: 96.79%\n",
      "87\tValidation loss: 0.803659\tBest loss: 0.505660\tAccuracy: 96.17%\n",
      "88\tValidation loss: 0.459491\tBest loss: 0.459491\tAccuracy: 97.34%\n",
      "89\tValidation loss: 0.618249\tBest loss: 0.459491\tAccuracy: 97.15%\n",
      "90\tValidation loss: 0.721200\tBest loss: 0.459491\tAccuracy: 95.66%\n",
      "91\tValidation loss: 0.526722\tBest loss: 0.459491\tAccuracy: 96.64%\n",
      "92\tValidation loss: 0.752279\tBest loss: 0.459491\tAccuracy: 95.93%\n",
      "93\tValidation loss: 0.569315\tBest loss: 0.459491\tAccuracy: 97.34%\n",
      "94\tValidation loss: 0.532681\tBest loss: 0.459491\tAccuracy: 96.99%\n",
      "95\tValidation loss: 0.728716\tBest loss: 0.459491\tAccuracy: 96.68%\n",
      "96\tValidation loss: 0.607005\tBest loss: 0.459491\tAccuracy: 96.99%\n",
      "97\tValidation loss: 0.670889\tBest loss: 0.459491\tAccuracy: 96.83%\n",
      "98\tValidation loss: 0.505383\tBest loss: 0.459491\tAccuracy: 97.22%\n",
      "99\tValidation loss: 0.478973\tBest loss: 0.459491\tAccuracy: 97.34%\n",
      "100\tValidation loss: 0.539500\tBest loss: 0.459491\tAccuracy: 97.26%\n",
      "101\tValidation loss: 0.551161\tBest loss: 0.459491\tAccuracy: 97.15%\n",
      "102\tValidation loss: 0.507462\tBest loss: 0.459491\tAccuracy: 96.99%\n",
      "103\tValidation loss: 0.577465\tBest loss: 0.459491\tAccuracy: 96.95%\n",
      "104\tValidation loss: 0.460370\tBest loss: 0.459491\tAccuracy: 97.38%\n",
      "105\tValidation loss: 0.422080\tBest loss: 0.422080\tAccuracy: 97.22%\n",
      "106\tValidation loss: 0.456331\tBest loss: 0.422080\tAccuracy: 96.79%\n",
      "107\tValidation loss: 0.405488\tBest loss: 0.405488\tAccuracy: 97.50%\n",
      "108\tValidation loss: 0.479830\tBest loss: 0.405488\tAccuracy: 97.38%\n",
      "109\tValidation loss: 0.600975\tBest loss: 0.405488\tAccuracy: 97.15%\n",
      "110\tValidation loss: 0.450140\tBest loss: 0.405488\tAccuracy: 96.33%\n",
      "111\tValidation loss: 0.557054\tBest loss: 0.405488\tAccuracy: 96.72%\n",
      "112\tValidation loss: 0.495870\tBest loss: 0.405488\tAccuracy: 96.99%\n",
      "113\tValidation loss: 0.495407\tBest loss: 0.405488\tAccuracy: 97.03%\n",
      "114\tValidation loss: 0.445246\tBest loss: 0.405488\tAccuracy: 97.07%\n",
      "115\tValidation loss: 0.444337\tBest loss: 0.405488\tAccuracy: 97.30%\n",
      "116\tValidation loss: 0.514869\tBest loss: 0.405488\tAccuracy: 96.99%\n",
      "117\tValidation loss: 0.569068\tBest loss: 0.405488\tAccuracy: 96.87%\n",
      "118\tValidation loss: 0.578119\tBest loss: 0.405488\tAccuracy: 96.44%\n",
      "119\tValidation loss: 0.676108\tBest loss: 0.405488\tAccuracy: 96.09%\n",
      "120\tValidation loss: 0.530176\tBest loss: 0.405488\tAccuracy: 96.83%\n",
      "121\tValidation loss: 0.508271\tBest loss: 0.405488\tAccuracy: 96.95%\n",
      "122\tValidation loss: 0.393738\tBest loss: 0.393738\tAccuracy: 97.46%\n",
      "123\tValidation loss: 0.389468\tBest loss: 0.389468\tAccuracy: 97.50%\n",
      "124\tValidation loss: 0.401616\tBest loss: 0.389468\tAccuracy: 97.58%\n",
      "125\tValidation loss: 0.379964\tBest loss: 0.379964\tAccuracy: 97.58%\n",
      "126\tValidation loss: 0.362956\tBest loss: 0.362956\tAccuracy: 97.62%\n",
      "127\tValidation loss: 0.391295\tBest loss: 0.362956\tAccuracy: 97.58%\n",
      "128\tValidation loss: 0.501349\tBest loss: 0.362956\tAccuracy: 96.72%\n",
      "129\tValidation loss: 0.459174\tBest loss: 0.362956\tAccuracy: 97.07%\n",
      "130\tValidation loss: 0.443967\tBest loss: 0.362956\tAccuracy: 96.99%\n",
      "131\tValidation loss: 0.467658\tBest loss: 0.362956\tAccuracy: 97.11%\n",
      "132\tValidation loss: 0.342616\tBest loss: 0.342616\tAccuracy: 97.85%\n",
      "133\tValidation loss: 0.543985\tBest loss: 0.342616\tAccuracy: 96.56%\n",
      "134\tValidation loss: 0.397775\tBest loss: 0.342616\tAccuracy: 97.65%\n",
      "135\tValidation loss: 0.365177\tBest loss: 0.342616\tAccuracy: 97.42%\n",
      "136\tValidation loss: 0.600754\tBest loss: 0.342616\tAccuracy: 96.29%\n",
      "137\tValidation loss: 0.419804\tBest loss: 0.342616\tAccuracy: 97.07%\n",
      "138\tValidation loss: 0.445804\tBest loss: 0.342616\tAccuracy: 97.26%\n",
      "139\tValidation loss: 0.447776\tBest loss: 0.342616\tAccuracy: 97.38%\n",
      "140\tValidation loss: 0.442015\tBest loss: 0.342616\tAccuracy: 97.19%\n",
      "141\tValidation loss: 0.456092\tBest loss: 0.342616\tAccuracy: 97.54%\n",
      "142\tValidation loss: 0.502007\tBest loss: 0.342616\tAccuracy: 96.83%\n",
      "143\tValidation loss: 0.448048\tBest loss: 0.342616\tAccuracy: 97.38%\n",
      "144\tValidation loss: 0.442408\tBest loss: 0.342616\tAccuracy: 96.99%\n",
      "145\tValidation loss: 0.365108\tBest loss: 0.342616\tAccuracy: 97.77%\n",
      "146\tValidation loss: 0.421852\tBest loss: 0.342616\tAccuracy: 97.46%\n",
      "147\tValidation loss: 0.405863\tBest loss: 0.342616\tAccuracy: 97.62%\n",
      "148\tValidation loss: 0.408118\tBest loss: 0.342616\tAccuracy: 97.38%\n",
      "149\tValidation loss: 0.367832\tBest loss: 0.342616\tAccuracy: 97.50%\n",
      "150\tValidation loss: 0.431553\tBest loss: 0.342616\tAccuracy: 97.34%\n",
      "151\tValidation loss: 0.389452\tBest loss: 0.342616\tAccuracy: 97.62%\n",
      "152\tValidation loss: 0.498188\tBest loss: 0.342616\tAccuracy: 97.07%\n",
      "153\tValidation loss: 0.379736\tBest loss: 0.342616\tAccuracy: 97.54%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.999, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 1.1min\n",
      "[CV] n_neurons=10, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.999, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 2.980834\tBest loss: 2.980834\tAccuracy: 72.32%\n",
      "1\tValidation loss: 4.021273\tBest loss: 2.980834\tAccuracy: 68.02%\n",
      "2\tValidation loss: 6.984614\tBest loss: 2.980834\tAccuracy: 59.34%\n",
      "3\tValidation loss: 4.441311\tBest loss: 2.980834\tAccuracy: 65.60%\n",
      "4\tValidation loss: 3.942636\tBest loss: 2.980834\tAccuracy: 69.74%\n",
      "5\tValidation loss: 4.728429\tBest loss: 2.980834\tAccuracy: 70.64%\n",
      "6\tValidation loss: 4.974747\tBest loss: 2.980834\tAccuracy: 70.13%\n",
      "7\tValidation loss: 3.104644\tBest loss: 2.980834\tAccuracy: 78.11%\n",
      "8\tValidation loss: 2.944365\tBest loss: 2.944365\tAccuracy: 74.82%\n",
      "9\tValidation loss: 7.881295\tBest loss: 2.944365\tAccuracy: 65.32%\n",
      "10\tValidation loss: 6.627918\tBest loss: 2.944365\tAccuracy: 68.92%\n",
      "11\tValidation loss: 4.844396\tBest loss: 2.944365\tAccuracy: 71.27%\n",
      "12\tValidation loss: 4.792271\tBest loss: 2.944365\tAccuracy: 73.10%\n",
      "13\tValidation loss: 7.745402\tBest loss: 2.944365\tAccuracy: 72.36%\n",
      "14\tValidation loss: 4.376364\tBest loss: 2.944365\tAccuracy: 78.73%\n",
      "15\tValidation loss: 7.241686\tBest loss: 2.944365\tAccuracy: 73.49%\n",
      "16\tValidation loss: 4.435533\tBest loss: 2.944365\tAccuracy: 81.63%\n",
      "17\tValidation loss: 4.166861\tBest loss: 2.944365\tAccuracy: 81.12%\n",
      "18\tValidation loss: 8.034748\tBest loss: 2.944365\tAccuracy: 72.40%\n",
      "19\tValidation loss: 8.408092\tBest loss: 2.944365\tAccuracy: 75.14%\n",
      "20\tValidation loss: 8.486304\tBest loss: 2.944365\tAccuracy: 69.31%\n",
      "21\tValidation loss: 7.639736\tBest loss: 2.944365\tAccuracy: 71.89%\n",
      "22\tValidation loss: 4.569373\tBest loss: 2.944365\tAccuracy: 77.17%\n",
      "23\tValidation loss: 4.948383\tBest loss: 2.944365\tAccuracy: 80.26%\n",
      "24\tValidation loss: 3.627118\tBest loss: 2.944365\tAccuracy: 79.91%\n",
      "25\tValidation loss: 6.327276\tBest loss: 2.944365\tAccuracy: 74.98%\n",
      "26\tValidation loss: 3.006051\tBest loss: 2.944365\tAccuracy: 86.16%\n",
      "27\tValidation loss: 3.215136\tBest loss: 2.944365\tAccuracy: 81.78%\n",
      "28\tValidation loss: 4.274556\tBest loss: 2.944365\tAccuracy: 78.54%\n",
      "29\tValidation loss: 3.872590\tBest loss: 2.944365\tAccuracy: 81.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.999, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=  15.0s\n",
      "[CV] n_neurons=10, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.999, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 18.232214\tBest loss: 18.232214\tAccuracy: 39.01%\n",
      "1\tValidation loss: 14.169520\tBest loss: 14.169520\tAccuracy: 40.58%\n",
      "2\tValidation loss: 9.194292\tBest loss: 9.194292\tAccuracy: 59.11%\n",
      "3\tValidation loss: 10.666149\tBest loss: 9.194292\tAccuracy: 43.47%\n",
      "4\tValidation loss: 11.456501\tBest loss: 9.194292\tAccuracy: 42.53%\n",
      "5\tValidation loss: 10.841198\tBest loss: 9.194292\tAccuracy: 42.10%\n",
      "6\tValidation loss: 13.959662\tBest loss: 9.194292\tAccuracy: 46.64%\n",
      "7\tValidation loss: 16.715631\tBest loss: 9.194292\tAccuracy: 44.41%\n",
      "8\tValidation loss: 18.099304\tBest loss: 9.194292\tAccuracy: 48.40%\n",
      "9\tValidation loss: 18.034906\tBest loss: 9.194292\tAccuracy: 39.99%\n",
      "10\tValidation loss: 11.486943\tBest loss: 9.194292\tAccuracy: 65.52%\n",
      "11\tValidation loss: 7.197437\tBest loss: 7.197437\tAccuracy: 68.45%\n",
      "12\tValidation loss: 8.253073\tBest loss: 7.197437\tAccuracy: 56.41%\n",
      "13\tValidation loss: 10.775035\tBest loss: 7.197437\tAccuracy: 54.38%\n",
      "14\tValidation loss: 5.972532\tBest loss: 5.972532\tAccuracy: 70.91%\n",
      "15\tValidation loss: 6.057696\tBest loss: 5.972532\tAccuracy: 74.28%\n",
      "16\tValidation loss: 5.937275\tBest loss: 5.937275\tAccuracy: 75.76%\n",
      "17\tValidation loss: 6.758423\tBest loss: 5.937275\tAccuracy: 72.36%\n",
      "18\tValidation loss: 6.634386\tBest loss: 5.937275\tAccuracy: 73.22%\n",
      "19\tValidation loss: 4.302288\tBest loss: 4.302288\tAccuracy: 76.78%\n",
      "20\tValidation loss: 5.211366\tBest loss: 4.302288\tAccuracy: 77.80%\n",
      "21\tValidation loss: 5.452347\tBest loss: 4.302288\tAccuracy: 71.46%\n",
      "22\tValidation loss: 7.403076\tBest loss: 4.302288\tAccuracy: 73.77%\n",
      "23\tValidation loss: 8.815062\tBest loss: 4.302288\tAccuracy: 68.41%\n",
      "24\tValidation loss: 5.301427\tBest loss: 4.302288\tAccuracy: 68.49%\n",
      "25\tValidation loss: 7.449187\tBest loss: 4.302288\tAccuracy: 65.44%\n",
      "26\tValidation loss: 8.905149\tBest loss: 4.302288\tAccuracy: 66.54%\n",
      "27\tValidation loss: 8.478518\tBest loss: 4.302288\tAccuracy: 68.06%\n",
      "28\tValidation loss: 8.019326\tBest loss: 4.302288\tAccuracy: 69.12%\n",
      "29\tValidation loss: 10.673393\tBest loss: 4.302288\tAccuracy: 65.17%\n",
      "30\tValidation loss: 10.299927\tBest loss: 4.302288\tAccuracy: 64.58%\n",
      "31\tValidation loss: 10.676591\tBest loss: 4.302288\tAccuracy: 59.27%\n",
      "32\tValidation loss: 8.330484\tBest loss: 4.302288\tAccuracy: 65.01%\n",
      "33\tValidation loss: 8.212389\tBest loss: 4.302288\tAccuracy: 64.23%\n",
      "34\tValidation loss: 9.485540\tBest loss: 4.302288\tAccuracy: 66.65%\n",
      "35\tValidation loss: 8.583515\tBest loss: 4.302288\tAccuracy: 67.36%\n",
      "36\tValidation loss: 10.696973\tBest loss: 4.302288\tAccuracy: 65.17%\n",
      "37\tValidation loss: 7.887938\tBest loss: 4.302288\tAccuracy: 69.90%\n",
      "38\tValidation loss: 5.346806\tBest loss: 4.302288\tAccuracy: 73.22%\n",
      "39\tValidation loss: 5.695708\tBest loss: 4.302288\tAccuracy: 70.33%\n",
      "40\tValidation loss: 5.983422\tBest loss: 4.302288\tAccuracy: 71.34%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.999, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=  19.5s\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.780392\tBest loss: 1.780392\tAccuracy: 90.42%\n",
      "1\tValidation loss: 0.298831\tBest loss: 0.298831\tAccuracy: 96.48%\n",
      "2\tValidation loss: 0.151732\tBest loss: 0.151732\tAccuracy: 96.64%\n",
      "3\tValidation loss: 0.092062\tBest loss: 0.092062\tAccuracy: 97.50%\n",
      "4\tValidation loss: 0.073160\tBest loss: 0.073160\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.099517\tBest loss: 0.073160\tAccuracy: 97.22%\n",
      "6\tValidation loss: 0.075711\tBest loss: 0.073160\tAccuracy: 97.77%\n",
      "7\tValidation loss: 0.068608\tBest loss: 0.068608\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.099124\tBest loss: 0.068608\tAccuracy: 97.34%\n",
      "9\tValidation loss: 0.080822\tBest loss: 0.068608\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.073122\tBest loss: 0.068608\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.077620\tBest loss: 0.068608\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.070976\tBest loss: 0.068608\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.061078\tBest loss: 0.061078\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.079843\tBest loss: 0.061078\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.084961\tBest loss: 0.061078\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.102807\tBest loss: 0.061078\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.080190\tBest loss: 0.061078\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.114989\tBest loss: 0.061078\tAccuracy: 98.01%\n",
      "19\tValidation loss: 0.102307\tBest loss: 0.061078\tAccuracy: 98.24%\n",
      "20\tValidation loss: 0.069213\tBest loss: 0.061078\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.075473\tBest loss: 0.061078\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.067187\tBest loss: 0.061078\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.075072\tBest loss: 0.061078\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.126434\tBest loss: 0.061078\tAccuracy: 97.58%\n",
      "25\tValidation loss: 0.087770\tBest loss: 0.061078\tAccuracy: 98.24%\n",
      "26\tValidation loss: 0.078080\tBest loss: 0.061078\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.066009\tBest loss: 0.061078\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.101841\tBest loss: 0.061078\tAccuracy: 98.40%\n",
      "29\tValidation loss: 0.070925\tBest loss: 0.061078\tAccuracy: 98.63%\n",
      "30\tValidation loss: 0.094974\tBest loss: 0.061078\tAccuracy: 98.55%\n",
      "31\tValidation loss: 0.093994\tBest loss: 0.061078\tAccuracy: 98.67%\n",
      "32\tValidation loss: 0.072238\tBest loss: 0.061078\tAccuracy: 98.79%\n",
      "33\tValidation loss: 0.073384\tBest loss: 0.061078\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.073304\tBest loss: 0.061078\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0>, total=  39.1s\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.721217\tBest loss: 1.721217\tAccuracy: 92.34%\n",
      "1\tValidation loss: 0.349493\tBest loss: 0.349493\tAccuracy: 96.09%\n",
      "2\tValidation loss: 0.197126\tBest loss: 0.197126\tAccuracy: 96.01%\n",
      "3\tValidation loss: 0.123070\tBest loss: 0.123070\tAccuracy: 96.99%\n",
      "4\tValidation loss: 0.098801\tBest loss: 0.098801\tAccuracy: 97.38%\n",
      "5\tValidation loss: 0.070985\tBest loss: 0.070985\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.088920\tBest loss: 0.070985\tAccuracy: 97.65%\n",
      "7\tValidation loss: 0.076645\tBest loss: 0.070985\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.065369\tBest loss: 0.065369\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.065150\tBest loss: 0.065150\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.142793\tBest loss: 0.065150\tAccuracy: 96.64%\n",
      "11\tValidation loss: 0.070942\tBest loss: 0.065150\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.064435\tBest loss: 0.064435\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.059470\tBest loss: 0.059470\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.072697\tBest loss: 0.059470\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.066432\tBest loss: 0.059470\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.081944\tBest loss: 0.059470\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.080759\tBest loss: 0.059470\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.083500\tBest loss: 0.059470\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.077971\tBest loss: 0.059470\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.084780\tBest loss: 0.059470\tAccuracy: 98.51%\n",
      "21\tValidation loss: 0.048452\tBest loss: 0.048452\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.072040\tBest loss: 0.048452\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.092369\tBest loss: 0.048452\tAccuracy: 98.32%\n",
      "24\tValidation loss: 0.075166\tBest loss: 0.048452\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.080691\tBest loss: 0.048452\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.075275\tBest loss: 0.048452\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.083828\tBest loss: 0.048452\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.098842\tBest loss: 0.048452\tAccuracy: 98.55%\n",
      "29\tValidation loss: 0.113733\tBest loss: 0.048452\tAccuracy: 97.89%\n",
      "30\tValidation loss: 0.074783\tBest loss: 0.048452\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.104815\tBest loss: 0.048452\tAccuracy: 98.28%\n",
      "32\tValidation loss: 0.099263\tBest loss: 0.048452\tAccuracy: 98.24%\n",
      "33\tValidation loss: 0.089940\tBest loss: 0.048452\tAccuracy: 98.51%\n",
      "34\tValidation loss: 0.060775\tBest loss: 0.048452\tAccuracy: 98.75%\n",
      "35\tValidation loss: 0.077105\tBest loss: 0.048452\tAccuracy: 98.63%\n",
      "36\tValidation loss: 0.068554\tBest loss: 0.048452\tAccuracy: 98.91%\n",
      "37\tValidation loss: 0.056809\tBest loss: 0.048452\tAccuracy: 98.87%\n",
      "38\tValidation loss: 0.056812\tBest loss: 0.048452\tAccuracy: 98.83%\n",
      "39\tValidation loss: 0.058123\tBest loss: 0.048452\tAccuracy: 98.91%\n",
      "40\tValidation loss: 0.059675\tBest loss: 0.048452\tAccuracy: 98.79%\n",
      "41\tValidation loss: 0.056194\tBest loss: 0.048452\tAccuracy: 98.75%\n",
      "42\tValidation loss: 0.054165\tBest loss: 0.048452\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0>, total=  47.5s\n",
      "[CV] n_neurons=100, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 2.615620\tBest loss: 2.615620\tAccuracy: 85.07%\n",
      "1\tValidation loss: 0.295949\tBest loss: 0.295949\tAccuracy: 95.74%\n",
      "2\tValidation loss: 0.131680\tBest loss: 0.131680\tAccuracy: 97.15%\n",
      "3\tValidation loss: 0.091457\tBest loss: 0.091457\tAccuracy: 97.69%\n",
      "4\tValidation loss: 0.070148\tBest loss: 0.070148\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.065321\tBest loss: 0.065321\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.068512\tBest loss: 0.065321\tAccuracy: 97.77%\n",
      "7\tValidation loss: 0.065674\tBest loss: 0.065321\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.092865\tBest loss: 0.065321\tAccuracy: 97.30%\n",
      "9\tValidation loss: 0.071002\tBest loss: 0.065321\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.065575\tBest loss: 0.065321\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.074241\tBest loss: 0.065321\tAccuracy: 98.24%\n",
      "12\tValidation loss: 0.051172\tBest loss: 0.051172\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.062622\tBest loss: 0.051172\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.053614\tBest loss: 0.051172\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.059044\tBest loss: 0.051172\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.058178\tBest loss: 0.051172\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.063050\tBest loss: 0.051172\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.065997\tBest loss: 0.051172\tAccuracy: 98.44%\n",
      "19\tValidation loss: 0.062982\tBest loss: 0.051172\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.055431\tBest loss: 0.051172\tAccuracy: 98.63%\n",
      "21\tValidation loss: 0.083019\tBest loss: 0.051172\tAccuracy: 98.28%\n",
      "22\tValidation loss: 0.056578\tBest loss: 0.051172\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.053797\tBest loss: 0.051172\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.067932\tBest loss: 0.051172\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.056800\tBest loss: 0.051172\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.084771\tBest loss: 0.051172\tAccuracy: 98.40%\n",
      "27\tValidation loss: 0.067897\tBest loss: 0.051172\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.066263\tBest loss: 0.051172\tAccuracy: 98.79%\n",
      "29\tValidation loss: 0.057415\tBest loss: 0.051172\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.065912\tBest loss: 0.051172\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.064961\tBest loss: 0.051172\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.066136\tBest loss: 0.051172\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.091485\tBest loss: 0.051172\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.05, batch_size=500, batch_norm_momentum=0.99, activation=<function elu at 0x7fabf3fc68b0>, total=  38.2s\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.071792\tBest loss: 0.071792\tAccuracy: 97.85%\n",
      "1\tValidation loss: 0.077680\tBest loss: 0.071792\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.054875\tBest loss: 0.054875\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.090113\tBest loss: 0.054875\tAccuracy: 97.30%\n",
      "4\tValidation loss: 0.047767\tBest loss: 0.047767\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.051802\tBest loss: 0.047767\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.057738\tBest loss: 0.047767\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.042421\tBest loss: 0.042421\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.043898\tBest loss: 0.042421\tAccuracy: 98.55%\n",
      "9\tValidation loss: 0.046625\tBest loss: 0.042421\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.044034\tBest loss: 0.042421\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.054227\tBest loss: 0.042421\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.036287\tBest loss: 0.036287\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.058836\tBest loss: 0.036287\tAccuracy: 98.28%\n",
      "14\tValidation loss: 0.040510\tBest loss: 0.036287\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.037023\tBest loss: 0.036287\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.039317\tBest loss: 0.036287\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.041445\tBest loss: 0.036287\tAccuracy: 98.83%\n",
      "18\tValidation loss: 0.038711\tBest loss: 0.036287\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.032447\tBest loss: 0.032447\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.048678\tBest loss: 0.032447\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.040612\tBest loss: 0.032447\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.034207\tBest loss: 0.032447\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.035937\tBest loss: 0.032447\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.053911\tBest loss: 0.032447\tAccuracy: 98.51%\n",
      "25\tValidation loss: 0.033203\tBest loss: 0.032447\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.048860\tBest loss: 0.032447\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.039645\tBest loss: 0.032447\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.043853\tBest loss: 0.032447\tAccuracy: 99.06%\n",
      "29\tValidation loss: 0.044733\tBest loss: 0.032447\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.054895\tBest loss: 0.032447\tAccuracy: 98.83%\n",
      "31\tValidation loss: 0.070763\tBest loss: 0.032447\tAccuracy: 98.48%\n",
      "32\tValidation loss: 0.041545\tBest loss: 0.032447\tAccuracy: 98.94%\n",
      "33\tValidation loss: 0.053769\tBest loss: 0.032447\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.036864\tBest loss: 0.032447\tAccuracy: 98.98%\n",
      "35\tValidation loss: 0.040575\tBest loss: 0.032447\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.041794\tBest loss: 0.032447\tAccuracy: 99.14%\n",
      "37\tValidation loss: 0.058114\tBest loss: 0.032447\tAccuracy: 98.63%\n",
      "38\tValidation loss: 0.040791\tBest loss: 0.032447\tAccuracy: 98.98%\n",
      "39\tValidation loss: 0.051227\tBest loss: 0.032447\tAccuracy: 98.83%\n",
      "40\tValidation loss: 0.049671\tBest loss: 0.032447\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 9.6min\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.086739\tBest loss: 0.086739\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.069175\tBest loss: 0.069175\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.064626\tBest loss: 0.064626\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.067399\tBest loss: 0.064626\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.050983\tBest loss: 0.050983\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.048006\tBest loss: 0.048006\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.047805\tBest loss: 0.047805\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.051799\tBest loss: 0.047805\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.047644\tBest loss: 0.047644\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.040264\tBest loss: 0.040264\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.040559\tBest loss: 0.040264\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.042564\tBest loss: 0.040264\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.045461\tBest loss: 0.040264\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.040275\tBest loss: 0.040264\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.055798\tBest loss: 0.040264\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.041134\tBest loss: 0.040264\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.048122\tBest loss: 0.040264\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.047048\tBest loss: 0.040264\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.037983\tBest loss: 0.037983\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.039256\tBest loss: 0.037983\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.036614\tBest loss: 0.036614\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.043421\tBest loss: 0.036614\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.054515\tBest loss: 0.036614\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.044192\tBest loss: 0.036614\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.033782\tBest loss: 0.033782\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.036993\tBest loss: 0.033782\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.028728\tBest loss: 0.028728\tAccuracy: 99.10%\n",
      "27\tValidation loss: 0.037367\tBest loss: 0.028728\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.035718\tBest loss: 0.028728\tAccuracy: 99.02%\n",
      "29\tValidation loss: 0.044061\tBest loss: 0.028728\tAccuracy: 98.83%\n",
      "30\tValidation loss: 0.032360\tBest loss: 0.028728\tAccuracy: 99.14%\n",
      "31\tValidation loss: 0.025766\tBest loss: 0.025766\tAccuracy: 99.26%\n",
      "32\tValidation loss: 0.037586\tBest loss: 0.025766\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.038084\tBest loss: 0.025766\tAccuracy: 98.98%\n",
      "34\tValidation loss: 0.037216\tBest loss: 0.025766\tAccuracy: 99.10%\n",
      "35\tValidation loss: 0.044954\tBest loss: 0.025766\tAccuracy: 98.83%\n",
      "36\tValidation loss: 0.039136\tBest loss: 0.025766\tAccuracy: 98.94%\n",
      "37\tValidation loss: 0.036544\tBest loss: 0.025766\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.045184\tBest loss: 0.025766\tAccuracy: 98.98%\n",
      "39\tValidation loss: 0.037332\tBest loss: 0.025766\tAccuracy: 99.06%\n",
      "40\tValidation loss: 0.031225\tBest loss: 0.025766\tAccuracy: 99.18%\n",
      "41\tValidation loss: 0.038933\tBest loss: 0.025766\tAccuracy: 98.98%\n",
      "42\tValidation loss: 0.033542\tBest loss: 0.025766\tAccuracy: 99.22%\n",
      "43\tValidation loss: 0.041133\tBest loss: 0.025766\tAccuracy: 98.83%\n",
      "44\tValidation loss: 0.043703\tBest loss: 0.025766\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.040595\tBest loss: 0.025766\tAccuracy: 99.18%\n",
      "46\tValidation loss: 0.039702\tBest loss: 0.025766\tAccuracy: 98.98%\n",
      "47\tValidation loss: 0.040032\tBest loss: 0.025766\tAccuracy: 99.02%\n",
      "48\tValidation loss: 0.040365\tBest loss: 0.025766\tAccuracy: 98.94%\n",
      "49\tValidation loss: 0.053884\tBest loss: 0.025766\tAccuracy: 98.67%\n",
      "50\tValidation loss: 0.041117\tBest loss: 0.025766\tAccuracy: 99.22%\n",
      "51\tValidation loss: 0.038130\tBest loss: 0.025766\tAccuracy: 98.87%\n",
      "52\tValidation loss: 0.036163\tBest loss: 0.025766\tAccuracy: 99.14%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=12.1min\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.103964\tBest loss: 0.103964\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.071139\tBest loss: 0.071139\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.063479\tBest loss: 0.063479\tAccuracy: 98.32%\n",
      "3\tValidation loss: 0.052062\tBest loss: 0.052062\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.052598\tBest loss: 0.052062\tAccuracy: 98.40%\n",
      "5\tValidation loss: 0.046404\tBest loss: 0.046404\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.040405\tBest loss: 0.040405\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.040297\tBest loss: 0.040297\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.036107\tBest loss: 0.036107\tAccuracy: 98.75%\n",
      "9\tValidation loss: 0.040651\tBest loss: 0.036107\tAccuracy: 98.79%\n",
      "10\tValidation loss: 0.035759\tBest loss: 0.035759\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.046864\tBest loss: 0.035759\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.035151\tBest loss: 0.035151\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.026783\tBest loss: 0.026783\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.044408\tBest loss: 0.026783\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.038923\tBest loss: 0.026783\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.036604\tBest loss: 0.026783\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.046012\tBest loss: 0.026783\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.040258\tBest loss: 0.026783\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.030383\tBest loss: 0.026783\tAccuracy: 99.02%\n",
      "20\tValidation loss: 0.033201\tBest loss: 0.026783\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.034938\tBest loss: 0.026783\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.031660\tBest loss: 0.026783\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.035816\tBest loss: 0.026783\tAccuracy: 99.06%\n",
      "24\tValidation loss: 0.030210\tBest loss: 0.026783\tAccuracy: 99.26%\n",
      "25\tValidation loss: 0.027263\tBest loss: 0.026783\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.035830\tBest loss: 0.026783\tAccuracy: 99.06%\n",
      "27\tValidation loss: 0.054371\tBest loss: 0.026783\tAccuracy: 98.44%\n",
      "28\tValidation loss: 0.031654\tBest loss: 0.026783\tAccuracy: 99.14%\n",
      "29\tValidation loss: 0.034355\tBest loss: 0.026783\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.024306\tBest loss: 0.024306\tAccuracy: 99.34%\n",
      "31\tValidation loss: 0.037283\tBest loss: 0.024306\tAccuracy: 98.94%\n",
      "32\tValidation loss: 0.032141\tBest loss: 0.024306\tAccuracy: 99.06%\n",
      "33\tValidation loss: 0.048850\tBest loss: 0.024306\tAccuracy: 98.91%\n",
      "34\tValidation loss: 0.041708\tBest loss: 0.024306\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.042459\tBest loss: 0.024306\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.039317\tBest loss: 0.024306\tAccuracy: 99.06%\n",
      "37\tValidation loss: 0.024429\tBest loss: 0.024306\tAccuracy: 99.18%\n",
      "38\tValidation loss: 0.031860\tBest loss: 0.024306\tAccuracy: 99.22%\n",
      "39\tValidation loss: 0.027988\tBest loss: 0.024306\tAccuracy: 99.26%\n",
      "40\tValidation loss: 0.031724\tBest loss: 0.024306\tAccuracy: 99.26%\n",
      "41\tValidation loss: 0.038152\tBest loss: 0.024306\tAccuracy: 99.14%\n",
      "42\tValidation loss: 0.038346\tBest loss: 0.024306\tAccuracy: 98.94%\n",
      "43\tValidation loss: 0.035207\tBest loss: 0.024306\tAccuracy: 99.06%\n",
      "44\tValidation loss: 0.044779\tBest loss: 0.024306\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.037219\tBest loss: 0.024306\tAccuracy: 99.14%\n",
      "46\tValidation loss: 0.041082\tBest loss: 0.024306\tAccuracy: 98.87%\n",
      "47\tValidation loss: 0.034175\tBest loss: 0.024306\tAccuracy: 99.02%\n",
      "48\tValidation loss: 0.037088\tBest loss: 0.024306\tAccuracy: 99.06%\n",
      "49\tValidation loss: 0.042917\tBest loss: 0.024306\tAccuracy: 99.02%\n",
      "50\tValidation loss: 0.047159\tBest loss: 0.024306\tAccuracy: 98.91%\n",
      "51\tValidation loss: 0.036133\tBest loss: 0.024306\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=12.0min\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.132980\tBest loss: 0.132980\tAccuracy: 96.29%\n",
      "1\tValidation loss: 0.078336\tBest loss: 0.078336\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.090658\tBest loss: 0.078336\tAccuracy: 97.03%\n",
      "3\tValidation loss: 0.075382\tBest loss: 0.075382\tAccuracy: 97.73%\n",
      "4\tValidation loss: 0.107522\tBest loss: 0.075382\tAccuracy: 96.68%\n",
      "5\tValidation loss: 0.063382\tBest loss: 0.063382\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.048171\tBest loss: 0.048171\tAccuracy: 98.51%\n",
      "7\tValidation loss: 0.067495\tBest loss: 0.048171\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.053463\tBest loss: 0.048171\tAccuracy: 98.55%\n",
      "9\tValidation loss: 0.053354\tBest loss: 0.048171\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.052406\tBest loss: 0.048171\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.069709\tBest loss: 0.048171\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.068628\tBest loss: 0.048171\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.051978\tBest loss: 0.048171\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.063577\tBest loss: 0.048171\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.054822\tBest loss: 0.048171\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.072440\tBest loss: 0.048171\tAccuracy: 98.32%\n",
      "17\tValidation loss: 0.120770\tBest loss: 0.048171\tAccuracy: 97.58%\n",
      "18\tValidation loss: 0.094606\tBest loss: 0.048171\tAccuracy: 97.89%\n",
      "19\tValidation loss: 0.056922\tBest loss: 0.048171\tAccuracy: 98.87%\n",
      "20\tValidation loss: 0.065535\tBest loss: 0.048171\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.056564\tBest loss: 0.048171\tAccuracy: 98.44%\n",
      "22\tValidation loss: 0.056269\tBest loss: 0.048171\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.056748\tBest loss: 0.048171\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.061716\tBest loss: 0.048171\tAccuracy: 98.36%\n",
      "25\tValidation loss: 0.062031\tBest loss: 0.048171\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.084710\tBest loss: 0.048171\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.092754\tBest loss: 0.048171\tAccuracy: 98.32%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0>, total=  18.5s\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.117764\tBest loss: 0.117764\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.078963\tBest loss: 0.078963\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.082760\tBest loss: 0.078963\tAccuracy: 97.19%\n",
      "3\tValidation loss: 0.062036\tBest loss: 0.062036\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.071080\tBest loss: 0.062036\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.058782\tBest loss: 0.058782\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.065868\tBest loss: 0.058782\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.049889\tBest loss: 0.049889\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.051335\tBest loss: 0.049889\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.059227\tBest loss: 0.049889\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.047196\tBest loss: 0.047196\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.049241\tBest loss: 0.047196\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.047402\tBest loss: 0.047196\tAccuracy: 98.71%\n",
      "13\tValidation loss: 0.045673\tBest loss: 0.045673\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.072350\tBest loss: 0.045673\tAccuracy: 98.36%\n",
      "15\tValidation loss: 0.073150\tBest loss: 0.045673\tAccuracy: 98.44%\n",
      "16\tValidation loss: 0.055561\tBest loss: 0.045673\tAccuracy: 98.51%\n",
      "17\tValidation loss: 0.078851\tBest loss: 0.045673\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.048305\tBest loss: 0.045673\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.064995\tBest loss: 0.045673\tAccuracy: 98.28%\n",
      "20\tValidation loss: 0.063302\tBest loss: 0.045673\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.039176\tBest loss: 0.039176\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.041146\tBest loss: 0.039176\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.042203\tBest loss: 0.039176\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.044391\tBest loss: 0.039176\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.044493\tBest loss: 0.039176\tAccuracy: 98.94%\n",
      "26\tValidation loss: 0.045964\tBest loss: 0.039176\tAccuracy: 99.10%\n",
      "27\tValidation loss: 0.055876\tBest loss: 0.039176\tAccuracy: 98.87%\n",
      "28\tValidation loss: 0.050076\tBest loss: 0.039176\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.055544\tBest loss: 0.039176\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.067488\tBest loss: 0.039176\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.091163\tBest loss: 0.039176\tAccuracy: 98.08%\n",
      "32\tValidation loss: 0.077577\tBest loss: 0.039176\tAccuracy: 98.08%\n",
      "33\tValidation loss: 0.075131\tBest loss: 0.039176\tAccuracy: 98.51%\n",
      "34\tValidation loss: 0.068202\tBest loss: 0.039176\tAccuracy: 98.40%\n",
      "35\tValidation loss: 0.060269\tBest loss: 0.039176\tAccuracy: 98.44%\n",
      "36\tValidation loss: 0.051910\tBest loss: 0.039176\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.050381\tBest loss: 0.039176\tAccuracy: 98.87%\n",
      "38\tValidation loss: 0.054927\tBest loss: 0.039176\tAccuracy: 98.87%\n",
      "39\tValidation loss: 0.043047\tBest loss: 0.039176\tAccuracy: 99.06%\n",
      "40\tValidation loss: 0.050696\tBest loss: 0.039176\tAccuracy: 98.94%\n",
      "41\tValidation loss: 0.068067\tBest loss: 0.039176\tAccuracy: 98.71%\n",
      "42\tValidation loss: 0.057326\tBest loss: 0.039176\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0>, total=  27.2s\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.102161\tBest loss: 0.102161\tAccuracy: 97.03%\n",
      "1\tValidation loss: 0.075553\tBest loss: 0.075553\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.068959\tBest loss: 0.068959\tAccuracy: 97.46%\n",
      "3\tValidation loss: 0.060403\tBest loss: 0.060403\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.062905\tBest loss: 0.060403\tAccuracy: 98.01%\n",
      "5\tValidation loss: 0.055851\tBest loss: 0.055851\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.064952\tBest loss: 0.055851\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.051167\tBest loss: 0.051167\tAccuracy: 98.32%\n",
      "8\tValidation loss: 0.055890\tBest loss: 0.051167\tAccuracy: 98.44%\n",
      "9\tValidation loss: 0.046558\tBest loss: 0.046558\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.054153\tBest loss: 0.046558\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.077876\tBest loss: 0.046558\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.056740\tBest loss: 0.046558\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.064550\tBest loss: 0.046558\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.045576\tBest loss: 0.045576\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.047634\tBest loss: 0.045576\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.049540\tBest loss: 0.045576\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.058866\tBest loss: 0.045576\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.058163\tBest loss: 0.045576\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.048953\tBest loss: 0.045576\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.055170\tBest loss: 0.045576\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.049723\tBest loss: 0.045576\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.045149\tBest loss: 0.045149\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.047119\tBest loss: 0.045149\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.061291\tBest loss: 0.045149\tAccuracy: 98.63%\n",
      "25\tValidation loss: 0.054485\tBest loss: 0.045149\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.079859\tBest loss: 0.045149\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.075566\tBest loss: 0.045149\tAccuracy: 98.59%\n",
      "28\tValidation loss: 0.064274\tBest loss: 0.045149\tAccuracy: 98.55%\n",
      "29\tValidation loss: 0.053241\tBest loss: 0.045149\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.061839\tBest loss: 0.045149\tAccuracy: 98.75%\n",
      "31\tValidation loss: 0.064020\tBest loss: 0.045149\tAccuracy: 98.59%\n",
      "32\tValidation loss: 0.043409\tBest loss: 0.043409\tAccuracy: 98.87%\n",
      "33\tValidation loss: 0.049034\tBest loss: 0.043409\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.053550\tBest loss: 0.043409\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.055438\tBest loss: 0.043409\tAccuracy: 98.87%\n",
      "36\tValidation loss: 0.065526\tBest loss: 0.043409\tAccuracy: 98.51%\n",
      "37\tValidation loss: 0.049153\tBest loss: 0.043409\tAccuracy: 98.87%\n",
      "38\tValidation loss: 0.054491\tBest loss: 0.043409\tAccuracy: 98.87%\n",
      "39\tValidation loss: 0.046889\tBest loss: 0.043409\tAccuracy: 98.91%\n",
      "40\tValidation loss: 0.039677\tBest loss: 0.039677\tAccuracy: 99.18%\n",
      "41\tValidation loss: 0.039912\tBest loss: 0.039677\tAccuracy: 98.94%\n",
      "42\tValidation loss: 0.036274\tBest loss: 0.036274\tAccuracy: 99.06%\n",
      "43\tValidation loss: 0.033595\tBest loss: 0.033595\tAccuracy: 99.10%\n",
      "44\tValidation loss: 0.034466\tBest loss: 0.033595\tAccuracy: 99.18%\n",
      "45\tValidation loss: 0.035413\tBest loss: 0.033595\tAccuracy: 99.06%\n",
      "46\tValidation loss: 0.036138\tBest loss: 0.033595\tAccuracy: 99.10%\n",
      "47\tValidation loss: 0.042801\tBest loss: 0.033595\tAccuracy: 99.10%\n",
      "48\tValidation loss: 0.034828\tBest loss: 0.033595\tAccuracy: 99.26%\n",
      "49\tValidation loss: 0.098951\tBest loss: 0.033595\tAccuracy: 98.40%\n",
      "50\tValidation loss: 0.069062\tBest loss: 0.033595\tAccuracy: 98.71%\n",
      "51\tValidation loss: 0.078334\tBest loss: 0.033595\tAccuracy: 98.51%\n",
      "52\tValidation loss: 0.085708\tBest loss: 0.033595\tAccuracy: 98.20%\n",
      "53\tValidation loss: 0.058725\tBest loss: 0.033595\tAccuracy: 98.91%\n",
      "54\tValidation loss: 0.059264\tBest loss: 0.033595\tAccuracy: 98.79%\n",
      "55\tValidation loss: 0.074704\tBest loss: 0.033595\tAccuracy: 98.59%\n",
      "56\tValidation loss: 0.059548\tBest loss: 0.033595\tAccuracy: 98.55%\n",
      "57\tValidation loss: 0.056509\tBest loss: 0.033595\tAccuracy: 98.71%\n",
      "58\tValidation loss: 0.052791\tBest loss: 0.033595\tAccuracy: 98.87%\n",
      "59\tValidation loss: 0.047779\tBest loss: 0.033595\tAccuracy: 98.98%\n",
      "60\tValidation loss: 0.045296\tBest loss: 0.033595\tAccuracy: 99.02%\n",
      "61\tValidation loss: 0.049525\tBest loss: 0.033595\tAccuracy: 98.98%\n",
      "62\tValidation loss: 0.062622\tBest loss: 0.033595\tAccuracy: 98.91%\n",
      "63\tValidation loss: 0.057444\tBest loss: 0.033595\tAccuracy: 98.55%\n",
      "64\tValidation loss: 0.053124\tBest loss: 0.033595\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.95, activation=<function elu at 0x7fabf3fc68b0>, total=  40.0s\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 6.392025\tBest loss: 6.392025\tAccuracy: 94.96%\n",
      "1\tValidation loss: 2.070424\tBest loss: 2.070424\tAccuracy: 96.56%\n",
      "2\tValidation loss: 0.786021\tBest loss: 0.786021\tAccuracy: 97.54%\n",
      "3\tValidation loss: 0.601409\tBest loss: 0.601409\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.873891\tBest loss: 0.601409\tAccuracy: 96.52%\n",
      "5\tValidation loss: 0.686707\tBest loss: 0.601409\tAccuracy: 97.22%\n",
      "6\tValidation loss: 0.283610\tBest loss: 0.283610\tAccuracy: 98.08%\n",
      "7\tValidation loss: 1.371752\tBest loss: 0.283610\tAccuracy: 96.29%\n",
      "8\tValidation loss: 0.486657\tBest loss: 0.283610\tAccuracy: 96.60%\n",
      "9\tValidation loss: 0.381432\tBest loss: 0.283610\tAccuracy: 97.22%\n",
      "10\tValidation loss: 0.289723\tBest loss: 0.283610\tAccuracy: 97.42%\n",
      "11\tValidation loss: 0.135036\tBest loss: 0.135036\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.195021\tBest loss: 0.135036\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.162370\tBest loss: 0.135036\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.243942\tBest loss: 0.135036\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.372086\tBest loss: 0.135036\tAccuracy: 95.70%\n",
      "16\tValidation loss: 0.445514\tBest loss: 0.135036\tAccuracy: 96.40%\n",
      "17\tValidation loss: 0.148764\tBest loss: 0.135036\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.110474\tBest loss: 0.110474\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.678287\tBest loss: 0.110474\tAccuracy: 94.61%\n",
      "20\tValidation loss: 0.137520\tBest loss: 0.110474\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.117870\tBest loss: 0.110474\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.116361\tBest loss: 0.110474\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.160221\tBest loss: 0.110474\tAccuracy: 97.65%\n",
      "24\tValidation loss: 0.150562\tBest loss: 0.110474\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.100650\tBest loss: 0.100650\tAccuracy: 98.36%\n",
      "26\tValidation loss: 0.110956\tBest loss: 0.100650\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.103610\tBest loss: 0.100650\tAccuracy: 98.55%\n",
      "28\tValidation loss: 0.172303\tBest loss: 0.100650\tAccuracy: 98.32%\n",
      "29\tValidation loss: 0.164445\tBest loss: 0.100650\tAccuracy: 98.36%\n",
      "30\tValidation loss: 0.200847\tBest loss: 0.100650\tAccuracy: 98.48%\n",
      "31\tValidation loss: 0.116062\tBest loss: 0.100650\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.297575\tBest loss: 0.100650\tAccuracy: 97.54%\n",
      "33\tValidation loss: 0.180442\tBest loss: 0.100650\tAccuracy: 98.51%\n",
      "34\tValidation loss: 0.139494\tBest loss: 0.100650\tAccuracy: 98.71%\n",
      "35\tValidation loss: 0.206244\tBest loss: 0.100650\tAccuracy: 97.38%\n",
      "36\tValidation loss: 0.166068\tBest loss: 0.100650\tAccuracy: 97.93%\n",
      "37\tValidation loss: 0.104614\tBest loss: 0.100650\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.055078\tBest loss: 0.055078\tAccuracy: 98.87%\n",
      "39\tValidation loss: 0.137229\tBest loss: 0.055078\tAccuracy: 98.51%\n",
      "40\tValidation loss: 0.146636\tBest loss: 0.055078\tAccuracy: 98.05%\n",
      "41\tValidation loss: 0.116613\tBest loss: 0.055078\tAccuracy: 98.12%\n",
      "42\tValidation loss: 0.105792\tBest loss: 0.055078\tAccuracy: 98.94%\n",
      "43\tValidation loss: 0.123839\tBest loss: 0.055078\tAccuracy: 98.32%\n",
      "44\tValidation loss: 0.186613\tBest loss: 0.055078\tAccuracy: 98.71%\n",
      "45\tValidation loss: 0.111481\tBest loss: 0.055078\tAccuracy: 98.59%\n",
      "46\tValidation loss: 0.067911\tBest loss: 0.055078\tAccuracy: 98.98%\n",
      "47\tValidation loss: 0.108765\tBest loss: 0.055078\tAccuracy: 98.36%\n",
      "48\tValidation loss: 0.121784\tBest loss: 0.055078\tAccuracy: 98.55%\n",
      "49\tValidation loss: 0.130531\tBest loss: 0.055078\tAccuracy: 98.24%\n",
      "50\tValidation loss: 0.102983\tBest loss: 0.055078\tAccuracy: 98.79%\n",
      "51\tValidation loss: 0.116611\tBest loss: 0.055078\tAccuracy: 98.91%\n",
      "52\tValidation loss: 0.097284\tBest loss: 0.055078\tAccuracy: 98.91%\n",
      "53\tValidation loss: 0.323598\tBest loss: 0.055078\tAccuracy: 97.46%\n",
      "54\tValidation loss: 0.175838\tBest loss: 0.055078\tAccuracy: 98.32%\n",
      "55\tValidation loss: 0.176816\tBest loss: 0.055078\tAccuracy: 98.40%\n",
      "56\tValidation loss: 0.143231\tBest loss: 0.055078\tAccuracy: 98.51%\n",
      "57\tValidation loss: 0.123332\tBest loss: 0.055078\tAccuracy: 98.87%\n",
      "58\tValidation loss: 0.184815\tBest loss: 0.055078\tAccuracy: 97.77%\n",
      "59\tValidation loss: 0.117900\tBest loss: 0.055078\tAccuracy: 98.51%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 2.7min\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 6.683778\tBest loss: 6.683778\tAccuracy: 95.54%\n",
      "1\tValidation loss: 2.081848\tBest loss: 2.081848\tAccuracy: 97.38%\n",
      "2\tValidation loss: 0.972169\tBest loss: 0.972169\tAccuracy: 97.73%\n",
      "3\tValidation loss: 1.060817\tBest loss: 0.972169\tAccuracy: 96.44%\n",
      "4\tValidation loss: 1.316449\tBest loss: 0.972169\tAccuracy: 96.09%\n",
      "5\tValidation loss: 0.546603\tBest loss: 0.546603\tAccuracy: 97.62%\n",
      "6\tValidation loss: 0.290167\tBest loss: 0.290167\tAccuracy: 98.32%\n",
      "7\tValidation loss: 8.077637\tBest loss: 0.290167\tAccuracy: 77.72%\n",
      "8\tValidation loss: 0.239005\tBest loss: 0.239005\tAccuracy: 98.20%\n",
      "9\tValidation loss: 0.287829\tBest loss: 0.239005\tAccuracy: 97.46%\n",
      "10\tValidation loss: 0.594696\tBest loss: 0.239005\tAccuracy: 97.30%\n",
      "11\tValidation loss: 0.222742\tBest loss: 0.222742\tAccuracy: 98.16%\n",
      "12\tValidation loss: 0.276186\tBest loss: 0.222742\tAccuracy: 98.28%\n",
      "13\tValidation loss: 0.188945\tBest loss: 0.188945\tAccuracy: 98.28%\n",
      "14\tValidation loss: 0.156125\tBest loss: 0.156125\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.303371\tBest loss: 0.156125\tAccuracy: 97.81%\n",
      "16\tValidation loss: 0.315481\tBest loss: 0.156125\tAccuracy: 96.79%\n",
      "17\tValidation loss: 0.201657\tBest loss: 0.156125\tAccuracy: 97.69%\n",
      "18\tValidation loss: 0.197991\tBest loss: 0.156125\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.117174\tBest loss: 0.117174\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.986870\tBest loss: 0.117174\tAccuracy: 94.53%\n",
      "21\tValidation loss: 0.348288\tBest loss: 0.117174\tAccuracy: 97.46%\n",
      "22\tValidation loss: 0.469212\tBest loss: 0.117174\tAccuracy: 97.11%\n",
      "23\tValidation loss: 0.133525\tBest loss: 0.117174\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.091411\tBest loss: 0.091411\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.210799\tBest loss: 0.091411\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.143017\tBest loss: 0.091411\tAccuracy: 98.16%\n",
      "27\tValidation loss: 0.181920\tBest loss: 0.091411\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.178769\tBest loss: 0.091411\tAccuracy: 98.44%\n",
      "29\tValidation loss: 0.139989\tBest loss: 0.091411\tAccuracy: 98.32%\n",
      "30\tValidation loss: 0.152911\tBest loss: 0.091411\tAccuracy: 98.16%\n",
      "31\tValidation loss: 0.140346\tBest loss: 0.091411\tAccuracy: 98.24%\n",
      "32\tValidation loss: 0.206738\tBest loss: 0.091411\tAccuracy: 97.93%\n",
      "33\tValidation loss: 0.176137\tBest loss: 0.091411\tAccuracy: 98.16%\n",
      "34\tValidation loss: 0.155483\tBest loss: 0.091411\tAccuracy: 98.40%\n",
      "35\tValidation loss: 0.159611\tBest loss: 0.091411\tAccuracy: 98.08%\n",
      "36\tValidation loss: 0.078832\tBest loss: 0.078832\tAccuracy: 98.44%\n",
      "37\tValidation loss: 0.143435\tBest loss: 0.078832\tAccuracy: 98.28%\n",
      "38\tValidation loss: 0.111016\tBest loss: 0.078832\tAccuracy: 98.40%\n",
      "39\tValidation loss: 0.106728\tBest loss: 0.078832\tAccuracy: 98.67%\n",
      "40\tValidation loss: 0.119042\tBest loss: 0.078832\tAccuracy: 98.48%\n",
      "41\tValidation loss: 0.161490\tBest loss: 0.078832\tAccuracy: 97.30%\n",
      "42\tValidation loss: 0.194668\tBest loss: 0.078832\tAccuracy: 98.20%\n",
      "43\tValidation loss: 0.168806\tBest loss: 0.078832\tAccuracy: 97.34%\n",
      "44\tValidation loss: 0.237645\tBest loss: 0.078832\tAccuracy: 98.01%\n",
      "45\tValidation loss: 0.141860\tBest loss: 0.078832\tAccuracy: 98.44%\n",
      "46\tValidation loss: 0.078451\tBest loss: 0.078451\tAccuracy: 98.71%\n",
      "47\tValidation loss: 0.138569\tBest loss: 0.078451\tAccuracy: 98.12%\n",
      "48\tValidation loss: 0.076002\tBest loss: 0.076002\tAccuracy: 98.67%\n",
      "49\tValidation loss: 0.187761\tBest loss: 0.076002\tAccuracy: 98.01%\n",
      "50\tValidation loss: 0.126130\tBest loss: 0.076002\tAccuracy: 98.75%\n",
      "51\tValidation loss: 0.111958\tBest loss: 0.076002\tAccuracy: 98.63%\n",
      "52\tValidation loss: 0.176151\tBest loss: 0.076002\tAccuracy: 98.40%\n",
      "53\tValidation loss: 0.123975\tBest loss: 0.076002\tAccuracy: 98.79%\n",
      "54\tValidation loss: 0.147648\tBest loss: 0.076002\tAccuracy: 98.79%\n",
      "55\tValidation loss: 0.136008\tBest loss: 0.076002\tAccuracy: 98.36%\n",
      "56\tValidation loss: 6.016300\tBest loss: 0.076002\tAccuracy: 71.11%\n",
      "57\tValidation loss: 0.113363\tBest loss: 0.076002\tAccuracy: 98.55%\n",
      "58\tValidation loss: 0.115544\tBest loss: 0.076002\tAccuracy: 98.83%\n",
      "59\tValidation loss: 0.149806\tBest loss: 0.076002\tAccuracy: 98.36%\n",
      "60\tValidation loss: 0.173699\tBest loss: 0.076002\tAccuracy: 98.51%\n",
      "61\tValidation loss: 0.121021\tBest loss: 0.076002\tAccuracy: 98.79%\n",
      "62\tValidation loss: 0.149897\tBest loss: 0.076002\tAccuracy: 98.59%\n",
      "63\tValidation loss: 0.180545\tBest loss: 0.076002\tAccuracy: 98.40%\n",
      "64\tValidation loss: 0.113327\tBest loss: 0.076002\tAccuracy: 98.67%\n",
      "65\tValidation loss: 0.131574\tBest loss: 0.076002\tAccuracy: 98.55%\n",
      "66\tValidation loss: 0.071641\tBest loss: 0.071641\tAccuracy: 98.98%\n",
      "67\tValidation loss: 0.193375\tBest loss: 0.071641\tAccuracy: 98.32%\n",
      "68\tValidation loss: 0.255760\tBest loss: 0.071641\tAccuracy: 97.22%\n",
      "69\tValidation loss: 0.337486\tBest loss: 0.071641\tAccuracy: 97.85%\n",
      "70\tValidation loss: 0.103219\tBest loss: 0.071641\tAccuracy: 98.91%\n",
      "71\tValidation loss: 0.187205\tBest loss: 0.071641\tAccuracy: 98.12%\n",
      "72\tValidation loss: 0.346791\tBest loss: 0.071641\tAccuracy: 98.01%\n",
      "73\tValidation loss: 0.077646\tBest loss: 0.071641\tAccuracy: 99.06%\n",
      "74\tValidation loss: 0.125898\tBest loss: 0.071641\tAccuracy: 98.94%\n",
      "75\tValidation loss: 0.097927\tBest loss: 0.071641\tAccuracy: 98.83%\n",
      "76\tValidation loss: 0.104388\tBest loss: 0.071641\tAccuracy: 98.83%\n",
      "77\tValidation loss: 0.370121\tBest loss: 0.071641\tAccuracy: 95.78%\n",
      "78\tValidation loss: 0.144803\tBest loss: 0.071641\tAccuracy: 98.91%\n",
      "79\tValidation loss: 0.289954\tBest loss: 0.071641\tAccuracy: 98.12%\n",
      "80\tValidation loss: 0.133649\tBest loss: 0.071641\tAccuracy: 98.40%\n",
      "81\tValidation loss: 0.111672\tBest loss: 0.071641\tAccuracy: 98.91%\n",
      "82\tValidation loss: 0.084635\tBest loss: 0.071641\tAccuracy: 99.02%\n",
      "83\tValidation loss: 0.092817\tBest loss: 0.071641\tAccuracy: 98.83%\n",
      "84\tValidation loss: 0.083568\tBest loss: 0.071641\tAccuracy: 99.02%\n",
      "85\tValidation loss: 0.117058\tBest loss: 0.071641\tAccuracy: 98.94%\n",
      "86\tValidation loss: 0.661856\tBest loss: 0.071641\tAccuracy: 93.51%\n",
      "87\tValidation loss: 0.182168\tBest loss: 0.071641\tAccuracy: 98.16%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 3.9min\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 4.964477\tBest loss: 4.964477\tAccuracy: 96.09%\n",
      "1\tValidation loss: 1.983439\tBest loss: 1.983439\tAccuracy: 95.78%\n",
      "2\tValidation loss: 1.284423\tBest loss: 1.284423\tAccuracy: 97.07%\n",
      "3\tValidation loss: 0.435301\tBest loss: 0.435301\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.412065\tBest loss: 0.412065\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.465882\tBest loss: 0.412065\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.171501\tBest loss: 0.171501\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.377023\tBest loss: 0.171501\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.364642\tBest loss: 0.171501\tAccuracy: 97.03%\n",
      "9\tValidation loss: 0.230678\tBest loss: 0.171501\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.248883\tBest loss: 0.171501\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.247408\tBest loss: 0.171501\tAccuracy: 98.24%\n",
      "12\tValidation loss: 0.160069\tBest loss: 0.160069\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.224974\tBest loss: 0.160069\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.272322\tBest loss: 0.160069\tAccuracy: 97.93%\n",
      "15\tValidation loss: 0.187102\tBest loss: 0.160069\tAccuracy: 98.01%\n",
      "16\tValidation loss: 0.210363\tBest loss: 0.160069\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.177148\tBest loss: 0.160069\tAccuracy: 98.24%\n",
      "18\tValidation loss: 0.342524\tBest loss: 0.160069\tAccuracy: 96.09%\n",
      "19\tValidation loss: 0.160520\tBest loss: 0.160069\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.110487\tBest loss: 0.110487\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.185219\tBest loss: 0.110487\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.178621\tBest loss: 0.110487\tAccuracy: 98.32%\n",
      "23\tValidation loss: 0.253544\tBest loss: 0.110487\tAccuracy: 97.19%\n",
      "24\tValidation loss: 0.147101\tBest loss: 0.110487\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.210402\tBest loss: 0.110487\tAccuracy: 97.93%\n",
      "26\tValidation loss: 0.359753\tBest loss: 0.110487\tAccuracy: 97.73%\n",
      "27\tValidation loss: 0.282589\tBest loss: 0.110487\tAccuracy: 97.77%\n",
      "28\tValidation loss: 0.087767\tBest loss: 0.087767\tAccuracy: 98.98%\n",
      "29\tValidation loss: 0.230751\tBest loss: 0.087767\tAccuracy: 98.16%\n",
      "30\tValidation loss: 0.097312\tBest loss: 0.087767\tAccuracy: 98.59%\n",
      "31\tValidation loss: 1.029021\tBest loss: 0.087767\tAccuracy: 95.54%\n",
      "32\tValidation loss: 15.362367\tBest loss: 0.087767\tAccuracy: 52.50%\n",
      "33\tValidation loss: 0.397006\tBest loss: 0.087767\tAccuracy: 96.25%\n",
      "34\tValidation loss: 0.116900\tBest loss: 0.087767\tAccuracy: 98.32%\n",
      "35\tValidation loss: 0.133373\tBest loss: 0.087767\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.130500\tBest loss: 0.087767\tAccuracy: 98.75%\n",
      "37\tValidation loss: 0.382230\tBest loss: 0.087767\tAccuracy: 95.27%\n",
      "38\tValidation loss: 0.077150\tBest loss: 0.077150\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.148155\tBest loss: 0.077150\tAccuracy: 98.44%\n",
      "40\tValidation loss: 0.098475\tBest loss: 0.077150\tAccuracy: 98.98%\n",
      "41\tValidation loss: 0.121513\tBest loss: 0.077150\tAccuracy: 98.40%\n",
      "42\tValidation loss: 0.177729\tBest loss: 0.077150\tAccuracy: 98.48%\n",
      "43\tValidation loss: 0.208026\tBest loss: 0.077150\tAccuracy: 98.40%\n",
      "44\tValidation loss: 0.103074\tBest loss: 0.077150\tAccuracy: 98.71%\n",
      "45\tValidation loss: 0.166104\tBest loss: 0.077150\tAccuracy: 98.16%\n",
      "46\tValidation loss: 0.064820\tBest loss: 0.064820\tAccuracy: 99.02%\n",
      "47\tValidation loss: 0.045702\tBest loss: 0.045702\tAccuracy: 99.14%\n",
      "48\tValidation loss: 0.139818\tBest loss: 0.045702\tAccuracy: 98.55%\n",
      "49\tValidation loss: 0.182599\tBest loss: 0.045702\tAccuracy: 97.69%\n",
      "50\tValidation loss: 0.117109\tBest loss: 0.045702\tAccuracy: 98.40%\n",
      "51\tValidation loss: 0.118298\tBest loss: 0.045702\tAccuracy: 98.71%\n",
      "52\tValidation loss: 0.065692\tBest loss: 0.045702\tAccuracy: 98.94%\n",
      "53\tValidation loss: 0.070484\tBest loss: 0.045702\tAccuracy: 99.14%\n",
      "54\tValidation loss: 0.095032\tBest loss: 0.045702\tAccuracy: 98.75%\n",
      "55\tValidation loss: 0.092218\tBest loss: 0.045702\tAccuracy: 98.83%\n",
      "56\tValidation loss: 0.575951\tBest loss: 0.045702\tAccuracy: 97.11%\n",
      "57\tValidation loss: 0.145154\tBest loss: 0.045702\tAccuracy: 98.87%\n",
      "58\tValidation loss: 0.104761\tBest loss: 0.045702\tAccuracy: 98.71%\n",
      "59\tValidation loss: 0.088693\tBest loss: 0.045702\tAccuracy: 99.06%\n",
      "60\tValidation loss: 0.066655\tBest loss: 0.045702\tAccuracy: 99.10%\n",
      "61\tValidation loss: 0.111258\tBest loss: 0.045702\tAccuracy: 98.63%\n",
      "62\tValidation loss: 0.068344\tBest loss: 0.045702\tAccuracy: 98.87%\n",
      "63\tValidation loss: 0.093085\tBest loss: 0.045702\tAccuracy: 98.83%\n",
      "64\tValidation loss: 0.062969\tBest loss: 0.045702\tAccuracy: 99.18%\n",
      "65\tValidation loss: 0.071968\tBest loss: 0.045702\tAccuracy: 99.02%\n",
      "66\tValidation loss: 0.113302\tBest loss: 0.045702\tAccuracy: 98.67%\n",
      "67\tValidation loss: 0.071438\tBest loss: 0.045702\tAccuracy: 98.83%\n",
      "68\tValidation loss: 0.157399\tBest loss: 0.045702\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 3.1min\n",
      "[CV] n_neurons=90, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.087538\tBest loss: 0.087538\tAccuracy: 97.65%\n",
      "1\tValidation loss: 0.072635\tBest loss: 0.072635\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.055160\tBest loss: 0.055160\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.089685\tBest loss: 0.055160\tAccuracy: 97.73%\n",
      "4\tValidation loss: 0.069195\tBest loss: 0.055160\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.058054\tBest loss: 0.055160\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.068753\tBest loss: 0.055160\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.057328\tBest loss: 0.055160\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.084878\tBest loss: 0.055160\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.057665\tBest loss: 0.055160\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.058262\tBest loss: 0.055160\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.078428\tBest loss: 0.055160\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.071748\tBest loss: 0.055160\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.058838\tBest loss: 0.055160\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.059906\tBest loss: 0.055160\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.054382\tBest loss: 0.054382\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.060553\tBest loss: 0.054382\tAccuracy: 98.32%\n",
      "17\tValidation loss: 0.062959\tBest loss: 0.054382\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.077238\tBest loss: 0.054382\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.070816\tBest loss: 0.054382\tAccuracy: 98.63%\n",
      "20\tValidation loss: 0.131573\tBest loss: 0.054382\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.069258\tBest loss: 0.054382\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.056525\tBest loss: 0.054382\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.046686\tBest loss: 0.046686\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.062443\tBest loss: 0.046686\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.063419\tBest loss: 0.046686\tAccuracy: 98.63%\n",
      "26\tValidation loss: 0.077293\tBest loss: 0.046686\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.100086\tBest loss: 0.046686\tAccuracy: 98.67%\n",
      "28\tValidation loss: 0.051372\tBest loss: 0.046686\tAccuracy: 99.22%\n",
      "29\tValidation loss: 0.080148\tBest loss: 0.046686\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.062550\tBest loss: 0.046686\tAccuracy: 99.14%\n",
      "31\tValidation loss: 0.043126\tBest loss: 0.043126\tAccuracy: 98.94%\n",
      "32\tValidation loss: 0.084364\tBest loss: 0.043126\tAccuracy: 98.12%\n",
      "33\tValidation loss: 0.090464\tBest loss: 0.043126\tAccuracy: 98.55%\n",
      "34\tValidation loss: 0.067684\tBest loss: 0.043126\tAccuracy: 98.87%\n",
      "35\tValidation loss: 0.065282\tBest loss: 0.043126\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.065119\tBest loss: 0.043126\tAccuracy: 98.98%\n",
      "37\tValidation loss: 0.073903\tBest loss: 0.043126\tAccuracy: 98.87%\n",
      "38\tValidation loss: 0.073120\tBest loss: 0.043126\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.076306\tBest loss: 0.043126\tAccuracy: 98.67%\n",
      "40\tValidation loss: 0.107808\tBest loss: 0.043126\tAccuracy: 98.44%\n",
      "41\tValidation loss: 0.128388\tBest loss: 0.043126\tAccuracy: 98.32%\n",
      "42\tValidation loss: 0.083766\tBest loss: 0.043126\tAccuracy: 98.87%\n",
      "43\tValidation loss: 0.103260\tBest loss: 0.043126\tAccuracy: 98.91%\n",
      "44\tValidation loss: 0.077757\tBest loss: 0.043126\tAccuracy: 98.63%\n",
      "45\tValidation loss: 0.079694\tBest loss: 0.043126\tAccuracy: 98.55%\n",
      "46\tValidation loss: 0.115612\tBest loss: 0.043126\tAccuracy: 98.36%\n",
      "47\tValidation loss: 0.077728\tBest loss: 0.043126\tAccuracy: 98.79%\n",
      "48\tValidation loss: 0.106218\tBest loss: 0.043126\tAccuracy: 98.79%\n",
      "49\tValidation loss: 0.098588\tBest loss: 0.043126\tAccuracy: 98.55%\n",
      "50\tValidation loss: 0.069495\tBest loss: 0.043126\tAccuracy: 98.83%\n",
      "51\tValidation loss: 0.094638\tBest loss: 0.043126\tAccuracy: 98.71%\n",
      "52\tValidation loss: 0.082183\tBest loss: 0.043126\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.9min\n",
      "[CV] n_neurons=90, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.086833\tBest loss: 0.086833\tAccuracy: 97.62%\n",
      "1\tValidation loss: 0.085568\tBest loss: 0.085568\tAccuracy: 97.46%\n",
      "2\tValidation loss: 0.069386\tBest loss: 0.069386\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.064057\tBest loss: 0.064057\tAccuracy: 98.01%\n",
      "4\tValidation loss: 0.059730\tBest loss: 0.059730\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.049733\tBest loss: 0.049733\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.058264\tBest loss: 0.049733\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.058107\tBest loss: 0.049733\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.050049\tBest loss: 0.049733\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.055937\tBest loss: 0.049733\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.079244\tBest loss: 0.049733\tAccuracy: 98.32%\n",
      "11\tValidation loss: 0.060526\tBest loss: 0.049733\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.054069\tBest loss: 0.049733\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.062361\tBest loss: 0.049733\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.071790\tBest loss: 0.049733\tAccuracy: 98.36%\n",
      "15\tValidation loss: 0.052187\tBest loss: 0.049733\tAccuracy: 98.44%\n",
      "16\tValidation loss: 0.054364\tBest loss: 0.049733\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.047052\tBest loss: 0.047052\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.048589\tBest loss: 0.047052\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.048172\tBest loss: 0.047052\tAccuracy: 99.10%\n",
      "20\tValidation loss: 0.064889\tBest loss: 0.047052\tAccuracy: 98.87%\n",
      "21\tValidation loss: 0.074207\tBest loss: 0.047052\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.039814\tBest loss: 0.039814\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.065572\tBest loss: 0.039814\tAccuracy: 98.44%\n",
      "24\tValidation loss: 0.046549\tBest loss: 0.039814\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.055189\tBest loss: 0.039814\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.050448\tBest loss: 0.039814\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.053122\tBest loss: 0.039814\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.064710\tBest loss: 0.039814\tAccuracy: 98.67%\n",
      "29\tValidation loss: 0.104031\tBest loss: 0.039814\tAccuracy: 97.97%\n",
      "30\tValidation loss: 0.118848\tBest loss: 0.039814\tAccuracy: 98.28%\n",
      "31\tValidation loss: 0.071035\tBest loss: 0.039814\tAccuracy: 98.36%\n",
      "32\tValidation loss: 0.065607\tBest loss: 0.039814\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.093671\tBest loss: 0.039814\tAccuracy: 98.44%\n",
      "34\tValidation loss: 0.100282\tBest loss: 0.039814\tAccuracy: 98.71%\n",
      "35\tValidation loss: 0.118823\tBest loss: 0.039814\tAccuracy: 98.32%\n",
      "36\tValidation loss: 0.054906\tBest loss: 0.039814\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.064141\tBest loss: 0.039814\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.088415\tBest loss: 0.039814\tAccuracy: 98.59%\n",
      "39\tValidation loss: 0.089906\tBest loss: 0.039814\tAccuracy: 98.79%\n",
      "40\tValidation loss: 0.076488\tBest loss: 0.039814\tAccuracy: 98.67%\n",
      "41\tValidation loss: 0.068766\tBest loss: 0.039814\tAccuracy: 98.75%\n",
      "42\tValidation loss: 0.093030\tBest loss: 0.039814\tAccuracy: 98.59%\n",
      "43\tValidation loss: 0.087038\tBest loss: 0.039814\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.6min\n",
      "[CV] n_neurons=90, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.077658\tBest loss: 0.077658\tAccuracy: 97.73%\n",
      "1\tValidation loss: 0.073003\tBest loss: 0.073003\tAccuracy: 97.89%\n",
      "2\tValidation loss: 0.077684\tBest loss: 0.073003\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.055072\tBest loss: 0.055072\tAccuracy: 98.63%\n",
      "4\tValidation loss: 0.074326\tBest loss: 0.055072\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.077503\tBest loss: 0.055072\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.072822\tBest loss: 0.055072\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.061943\tBest loss: 0.055072\tAccuracy: 98.44%\n",
      "8\tValidation loss: 0.095932\tBest loss: 0.055072\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.047152\tBest loss: 0.047152\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.061579\tBest loss: 0.047152\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.053643\tBest loss: 0.047152\tAccuracy: 98.55%\n",
      "12\tValidation loss: 0.059538\tBest loss: 0.047152\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.033836\tBest loss: 0.033836\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.035679\tBest loss: 0.033836\tAccuracy: 99.10%\n",
      "15\tValidation loss: 0.053135\tBest loss: 0.033836\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.055689\tBest loss: 0.033836\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.059478\tBest loss: 0.033836\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.067789\tBest loss: 0.033836\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.058665\tBest loss: 0.033836\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.034646\tBest loss: 0.033836\tAccuracy: 99.18%\n",
      "21\tValidation loss: 0.054334\tBest loss: 0.033836\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.043716\tBest loss: 0.033836\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.059501\tBest loss: 0.033836\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.052995\tBest loss: 0.033836\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.051764\tBest loss: 0.033836\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.039522\tBest loss: 0.033836\tAccuracy: 99.34%\n",
      "27\tValidation loss: 0.076820\tBest loss: 0.033836\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.066980\tBest loss: 0.033836\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.058837\tBest loss: 0.033836\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.078160\tBest loss: 0.033836\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.059114\tBest loss: 0.033836\tAccuracy: 99.14%\n",
      "32\tValidation loss: 0.071245\tBest loss: 0.033836\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.058448\tBest loss: 0.033836\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.073471\tBest loss: 0.033836\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.3min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.073700\tBest loss: 0.073700\tAccuracy: 97.93%\n",
      "1\tValidation loss: 0.098141\tBest loss: 0.073700\tAccuracy: 97.07%\n",
      "2\tValidation loss: 0.047303\tBest loss: 0.047303\tAccuracy: 98.71%\n",
      "3\tValidation loss: 0.052714\tBest loss: 0.047303\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.042324\tBest loss: 0.042324\tAccuracy: 98.83%\n",
      "5\tValidation loss: 0.057846\tBest loss: 0.042324\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.059926\tBest loss: 0.042324\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.053679\tBest loss: 0.042324\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.051282\tBest loss: 0.042324\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.042869\tBest loss: 0.042324\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.054725\tBest loss: 0.042324\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.048310\tBest loss: 0.042324\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.046278\tBest loss: 0.042324\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.036370\tBest loss: 0.036370\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.044835\tBest loss: 0.036370\tAccuracy: 99.02%\n",
      "15\tValidation loss: 0.047750\tBest loss: 0.036370\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.052726\tBest loss: 0.036370\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.071046\tBest loss: 0.036370\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.069336\tBest loss: 0.036370\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.086487\tBest loss: 0.036370\tAccuracy: 98.16%\n",
      "20\tValidation loss: 0.042103\tBest loss: 0.036370\tAccuracy: 98.94%\n",
      "21\tValidation loss: 0.036216\tBest loss: 0.036216\tAccuracy: 99.18%\n",
      "22\tValidation loss: 0.043854\tBest loss: 0.036216\tAccuracy: 99.26%\n",
      "23\tValidation loss: 0.036502\tBest loss: 0.036216\tAccuracy: 99.10%\n",
      "24\tValidation loss: 0.044896\tBest loss: 0.036216\tAccuracy: 98.83%\n",
      "25\tValidation loss: 0.039219\tBest loss: 0.036216\tAccuracy: 99.14%\n",
      "26\tValidation loss: 0.042993\tBest loss: 0.036216\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.038630\tBest loss: 0.036216\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.055410\tBest loss: 0.036216\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.038869\tBest loss: 0.036216\tAccuracy: 99.10%\n",
      "30\tValidation loss: 0.035655\tBest loss: 0.035655\tAccuracy: 99.30%\n",
      "31\tValidation loss: 0.038226\tBest loss: 0.035655\tAccuracy: 99.34%\n",
      "32\tValidation loss: 0.042304\tBest loss: 0.035655\tAccuracy: 99.22%\n",
      "33\tValidation loss: 0.045586\tBest loss: 0.035655\tAccuracy: 99.02%\n",
      "34\tValidation loss: 0.049757\tBest loss: 0.035655\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.047560\tBest loss: 0.035655\tAccuracy: 98.91%\n",
      "36\tValidation loss: 0.038345\tBest loss: 0.035655\tAccuracy: 99.18%\n",
      "37\tValidation loss: 0.044723\tBest loss: 0.035655\tAccuracy: 98.87%\n",
      "38\tValidation loss: 0.051766\tBest loss: 0.035655\tAccuracy: 98.98%\n",
      "39\tValidation loss: 0.068276\tBest loss: 0.035655\tAccuracy: 98.79%\n",
      "40\tValidation loss: 0.061114\tBest loss: 0.035655\tAccuracy: 98.98%\n",
      "41\tValidation loss: 0.043320\tBest loss: 0.035655\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.044312\tBest loss: 0.035655\tAccuracy: 99.22%\n",
      "43\tValidation loss: 0.048447\tBest loss: 0.035655\tAccuracy: 98.91%\n",
      "44\tValidation loss: 0.057142\tBest loss: 0.035655\tAccuracy: 98.75%\n",
      "45\tValidation loss: 0.051080\tBest loss: 0.035655\tAccuracy: 99.14%\n",
      "46\tValidation loss: 0.047858\tBest loss: 0.035655\tAccuracy: 98.98%\n",
      "47\tValidation loss: 0.067059\tBest loss: 0.035655\tAccuracy: 98.79%\n",
      "48\tValidation loss: 0.066772\tBest loss: 0.035655\tAccuracy: 98.98%\n",
      "49\tValidation loss: 0.049859\tBest loss: 0.035655\tAccuracy: 99.18%\n",
      "50\tValidation loss: 0.077627\tBest loss: 0.035655\tAccuracy: 98.16%\n",
      "51\tValidation loss: 0.043152\tBest loss: 0.035655\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 3.1min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.080197\tBest loss: 0.080197\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.061315\tBest loss: 0.061315\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.046325\tBest loss: 0.046325\tAccuracy: 98.67%\n",
      "3\tValidation loss: 0.044486\tBest loss: 0.044486\tAccuracy: 98.44%\n",
      "4\tValidation loss: 0.046310\tBest loss: 0.044486\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.040928\tBest loss: 0.040928\tAccuracy: 98.91%\n",
      "6\tValidation loss: 0.042748\tBest loss: 0.040928\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.061401\tBest loss: 0.040928\tAccuracy: 98.44%\n",
      "8\tValidation loss: 0.064840\tBest loss: 0.040928\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.029366\tBest loss: 0.029366\tAccuracy: 99.14%\n",
      "10\tValidation loss: 0.040297\tBest loss: 0.029366\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.033774\tBest loss: 0.029366\tAccuracy: 99.02%\n",
      "12\tValidation loss: 0.038428\tBest loss: 0.029366\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.030998\tBest loss: 0.029366\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.044107\tBest loss: 0.029366\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.041605\tBest loss: 0.029366\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.036281\tBest loss: 0.029366\tAccuracy: 99.14%\n",
      "17\tValidation loss: 0.051142\tBest loss: 0.029366\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.049742\tBest loss: 0.029366\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.056357\tBest loss: 0.029366\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.043203\tBest loss: 0.029366\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.042654\tBest loss: 0.029366\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.042716\tBest loss: 0.029366\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.046337\tBest loss: 0.029366\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.038436\tBest loss: 0.029366\tAccuracy: 99.14%\n",
      "25\tValidation loss: 0.040819\tBest loss: 0.029366\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.040563\tBest loss: 0.029366\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.040046\tBest loss: 0.029366\tAccuracy: 99.18%\n",
      "28\tValidation loss: 0.049394\tBest loss: 0.029366\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.050752\tBest loss: 0.029366\tAccuracy: 99.02%\n",
      "30\tValidation loss: 0.056266\tBest loss: 0.029366\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.9min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.072522\tBest loss: 0.072522\tAccuracy: 97.89%\n",
      "1\tValidation loss: 0.078490\tBest loss: 0.072522\tAccuracy: 98.20%\n",
      "2\tValidation loss: 0.072511\tBest loss: 0.072511\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.062735\tBest loss: 0.062735\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.046405\tBest loss: 0.046405\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.031374\tBest loss: 0.031374\tAccuracy: 99.02%\n",
      "6\tValidation loss: 0.044137\tBest loss: 0.031374\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.041121\tBest loss: 0.031374\tAccuracy: 99.10%\n",
      "8\tValidation loss: 0.085171\tBest loss: 0.031374\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.052173\tBest loss: 0.031374\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.031855\tBest loss: 0.031374\tAccuracy: 99.06%\n",
      "11\tValidation loss: 0.046449\tBest loss: 0.031374\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.035484\tBest loss: 0.031374\tAccuracy: 99.14%\n",
      "13\tValidation loss: 0.054099\tBest loss: 0.031374\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.047229\tBest loss: 0.031374\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.029677\tBest loss: 0.029677\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.042947\tBest loss: 0.029677\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.036302\tBest loss: 0.029677\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.034457\tBest loss: 0.029677\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.039202\tBest loss: 0.029677\tAccuracy: 98.87%\n",
      "20\tValidation loss: 0.033941\tBest loss: 0.029677\tAccuracy: 99.14%\n",
      "21\tValidation loss: 0.034755\tBest loss: 0.029677\tAccuracy: 99.18%\n",
      "22\tValidation loss: 0.040969\tBest loss: 0.029677\tAccuracy: 98.98%\n",
      "23\tValidation loss: 0.055719\tBest loss: 0.029677\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.050247\tBest loss: 0.029677\tAccuracy: 98.94%\n",
      "25\tValidation loss: 0.051080\tBest loss: 0.029677\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.078659\tBest loss: 0.029677\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.062560\tBest loss: 0.029677\tAccuracy: 99.18%\n",
      "28\tValidation loss: 0.037696\tBest loss: 0.029677\tAccuracy: 99.26%\n",
      "29\tValidation loss: 0.057164\tBest loss: 0.029677\tAccuracy: 98.83%\n",
      "30\tValidation loss: 0.049686\tBest loss: 0.029677\tAccuracy: 99.06%\n",
      "31\tValidation loss: 0.075467\tBest loss: 0.029677\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.046090\tBest loss: 0.029677\tAccuracy: 98.98%\n",
      "33\tValidation loss: 0.047970\tBest loss: 0.029677\tAccuracy: 98.79%\n",
      "34\tValidation loss: 0.048657\tBest loss: 0.029677\tAccuracy: 99.02%\n",
      "35\tValidation loss: 0.044174\tBest loss: 0.029677\tAccuracy: 98.87%\n",
      "36\tValidation loss: 0.056662\tBest loss: 0.029677\tAccuracy: 99.10%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 2.2min\n",
      "[CV] n_neurons=160, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.141685\tBest loss: 1.141685\tAccuracy: 93.39%\n",
      "1\tValidation loss: 2.777115\tBest loss: 1.141685\tAccuracy: 78.69%\n",
      "2\tValidation loss: 1.317949\tBest loss: 1.141685\tAccuracy: 79.83%\n",
      "3\tValidation loss: 0.266750\tBest loss: 0.266750\tAccuracy: 94.84%\n",
      "4\tValidation loss: 0.121251\tBest loss: 0.121251\tAccuracy: 97.11%\n",
      "5\tValidation loss: 0.107112\tBest loss: 0.107112\tAccuracy: 96.68%\n",
      "6\tValidation loss: 0.558016\tBest loss: 0.107112\tAccuracy: 85.38%\n",
      "7\tValidation loss: 0.080085\tBest loss: 0.080085\tAccuracy: 97.93%\n",
      "8\tValidation loss: 0.084293\tBest loss: 0.080085\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.122492\tBest loss: 0.080085\tAccuracy: 96.83%\n",
      "10\tValidation loss: 0.080493\tBest loss: 0.080085\tAccuracy: 97.46%\n",
      "11\tValidation loss: 0.115684\tBest loss: 0.080085\tAccuracy: 97.42%\n",
      "12\tValidation loss: 0.071518\tBest loss: 0.071518\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.080348\tBest loss: 0.071518\tAccuracy: 97.89%\n",
      "14\tValidation loss: 0.078540\tBest loss: 0.071518\tAccuracy: 97.69%\n",
      "15\tValidation loss: 0.203130\tBest loss: 0.071518\tAccuracy: 95.58%\n",
      "16\tValidation loss: 0.081728\tBest loss: 0.071518\tAccuracy: 98.08%\n",
      "17\tValidation loss: 0.109562\tBest loss: 0.071518\tAccuracy: 97.22%\n",
      "18\tValidation loss: 0.066468\tBest loss: 0.066468\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.094821\tBest loss: 0.066468\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.060257\tBest loss: 0.060257\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.082623\tBest loss: 0.060257\tAccuracy: 97.58%\n",
      "22\tValidation loss: 0.042444\tBest loss: 0.042444\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.119909\tBest loss: 0.042444\tAccuracy: 97.54%\n",
      "24\tValidation loss: 0.067075\tBest loss: 0.042444\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.062788\tBest loss: 0.042444\tAccuracy: 98.44%\n",
      "26\tValidation loss: 0.125395\tBest loss: 0.042444\tAccuracy: 97.97%\n",
      "27\tValidation loss: 0.063282\tBest loss: 0.042444\tAccuracy: 98.55%\n",
      "28\tValidation loss: 0.046538\tBest loss: 0.042444\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.055331\tBest loss: 0.042444\tAccuracy: 99.14%\n",
      "30\tValidation loss: 0.042635\tBest loss: 0.042444\tAccuracy: 99.02%\n",
      "31\tValidation loss: 0.158908\tBest loss: 0.042444\tAccuracy: 96.83%\n",
      "32\tValidation loss: 0.048310\tBest loss: 0.042444\tAccuracy: 99.06%\n",
      "33\tValidation loss: 0.076466\tBest loss: 0.042444\tAccuracy: 98.44%\n",
      "34\tValidation loss: 0.234082\tBest loss: 0.042444\tAccuracy: 96.09%\n",
      "35\tValidation loss: 0.131635\tBest loss: 0.042444\tAccuracy: 97.65%\n",
      "36\tValidation loss: 0.067300\tBest loss: 0.042444\tAccuracy: 98.71%\n",
      "37\tValidation loss: 0.285663\tBest loss: 0.042444\tAccuracy: 95.78%\n",
      "38\tValidation loss: 0.065004\tBest loss: 0.042444\tAccuracy: 98.87%\n",
      "39\tValidation loss: 0.051605\tBest loss: 0.042444\tAccuracy: 98.98%\n",
      "40\tValidation loss: 0.069032\tBest loss: 0.042444\tAccuracy: 98.79%\n",
      "41\tValidation loss: 0.082818\tBest loss: 0.042444\tAccuracy: 98.83%\n",
      "42\tValidation loss: 0.071571\tBest loss: 0.042444\tAccuracy: 99.02%\n",
      "43\tValidation loss: 0.084164\tBest loss: 0.042444\tAccuracy: 97.97%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 9.5min\n",
      "[CV] n_neurons=160, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.514530\tBest loss: 0.514530\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.322751\tBest loss: 0.322751\tAccuracy: 96.52%\n",
      "2\tValidation loss: 0.198184\tBest loss: 0.198184\tAccuracy: 95.97%\n",
      "3\tValidation loss: 0.316883\tBest loss: 0.198184\tAccuracy: 93.47%\n",
      "4\tValidation loss: 0.170092\tBest loss: 0.170092\tAccuracy: 96.72%\n",
      "5\tValidation loss: 0.164185\tBest loss: 0.164185\tAccuracy: 97.30%\n",
      "6\tValidation loss: 0.137622\tBest loss: 0.137622\tAccuracy: 96.21%\n",
      "7\tValidation loss: 0.165749\tBest loss: 0.137622\tAccuracy: 95.35%\n",
      "8\tValidation loss: 0.061708\tBest loss: 0.061708\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.188117\tBest loss: 0.061708\tAccuracy: 94.76%\n",
      "10\tValidation loss: 0.096267\tBest loss: 0.061708\tAccuracy: 97.30%\n",
      "11\tValidation loss: 0.170466\tBest loss: 0.061708\tAccuracy: 97.30%\n",
      "12\tValidation loss: 0.097398\tBest loss: 0.061708\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.121903\tBest loss: 0.061708\tAccuracy: 96.52%\n",
      "14\tValidation loss: 0.090034\tBest loss: 0.061708\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.125176\tBest loss: 0.061708\tAccuracy: 97.19%\n",
      "16\tValidation loss: 0.070656\tBest loss: 0.061708\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.170447\tBest loss: 0.061708\tAccuracy: 96.05%\n",
      "18\tValidation loss: 0.078569\tBest loss: 0.061708\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.086908\tBest loss: 0.061708\tAccuracy: 97.85%\n",
      "20\tValidation loss: 0.090246\tBest loss: 0.061708\tAccuracy: 98.28%\n",
      "21\tValidation loss: 0.082312\tBest loss: 0.061708\tAccuracy: 98.05%\n",
      "22\tValidation loss: 0.072512\tBest loss: 0.061708\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.115016\tBest loss: 0.061708\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.077821\tBest loss: 0.061708\tAccuracy: 98.16%\n",
      "25\tValidation loss: 0.080459\tBest loss: 0.061708\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.058336\tBest loss: 0.058336\tAccuracy: 98.75%\n",
      "27\tValidation loss: 0.128371\tBest loss: 0.058336\tAccuracy: 97.30%\n",
      "28\tValidation loss: 0.133010\tBest loss: 0.058336\tAccuracy: 97.58%\n",
      "29\tValidation loss: 0.054856\tBest loss: 0.054856\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.063739\tBest loss: 0.054856\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.054622\tBest loss: 0.054622\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.068902\tBest loss: 0.054622\tAccuracy: 98.28%\n",
      "33\tValidation loss: 0.065115\tBest loss: 0.054622\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.112232\tBest loss: 0.054622\tAccuracy: 97.50%\n",
      "35\tValidation loss: 0.075107\tBest loss: 0.054622\tAccuracy: 98.48%\n",
      "36\tValidation loss: 0.069833\tBest loss: 0.054622\tAccuracy: 98.71%\n",
      "37\tValidation loss: 0.067343\tBest loss: 0.054622\tAccuracy: 98.55%\n",
      "38\tValidation loss: 0.057288\tBest loss: 0.054622\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.207268\tBest loss: 0.054622\tAccuracy: 97.26%\n",
      "40\tValidation loss: 0.075970\tBest loss: 0.054622\tAccuracy: 98.59%\n",
      "41\tValidation loss: 0.083454\tBest loss: 0.054622\tAccuracy: 98.67%\n",
      "42\tValidation loss: 0.089793\tBest loss: 0.054622\tAccuracy: 98.20%\n",
      "43\tValidation loss: 0.056905\tBest loss: 0.054622\tAccuracy: 98.79%\n",
      "44\tValidation loss: 0.163540\tBest loss: 0.054622\tAccuracy: 98.40%\n",
      "45\tValidation loss: 0.125802\tBest loss: 0.054622\tAccuracy: 98.16%\n",
      "46\tValidation loss: 0.185559\tBest loss: 0.054622\tAccuracy: 96.68%\n",
      "47\tValidation loss: 0.054124\tBest loss: 0.054124\tAccuracy: 98.71%\n",
      "48\tValidation loss: 0.122593\tBest loss: 0.054124\tAccuracy: 97.93%\n",
      "49\tValidation loss: 0.107365\tBest loss: 0.054124\tAccuracy: 98.67%\n",
      "50\tValidation loss: 0.135047\tBest loss: 0.054124\tAccuracy: 98.36%\n",
      "51\tValidation loss: 0.096654\tBest loss: 0.054124\tAccuracy: 98.67%\n",
      "52\tValidation loss: 0.091441\tBest loss: 0.054124\tAccuracy: 98.75%\n",
      "53\tValidation loss: 0.090273\tBest loss: 0.054124\tAccuracy: 98.67%\n",
      "54\tValidation loss: 0.140654\tBest loss: 0.054124\tAccuracy: 97.58%\n",
      "55\tValidation loss: 0.065863\tBest loss: 0.054124\tAccuracy: 98.91%\n",
      "56\tValidation loss: 0.078640\tBest loss: 0.054124\tAccuracy: 98.51%\n",
      "57\tValidation loss: 0.162471\tBest loss: 0.054124\tAccuracy: 97.11%\n",
      "58\tValidation loss: 0.158517\tBest loss: 0.054124\tAccuracy: 97.97%\n",
      "59\tValidation loss: 0.088071\tBest loss: 0.054124\tAccuracy: 98.32%\n",
      "60\tValidation loss: 0.062416\tBest loss: 0.054124\tAccuracy: 98.55%\n",
      "61\tValidation loss: 0.123959\tBest loss: 0.054124\tAccuracy: 98.51%\n",
      "62\tValidation loss: 0.073889\tBest loss: 0.054124\tAccuracy: 98.55%\n",
      "63\tValidation loss: 0.068604\tBest loss: 0.054124\tAccuracy: 98.55%\n",
      "64\tValidation loss: 0.114951\tBest loss: 0.054124\tAccuracy: 98.67%\n",
      "65\tValidation loss: 0.073655\tBest loss: 0.054124\tAccuracy: 98.75%\n",
      "66\tValidation loss: 0.204478\tBest loss: 0.054124\tAccuracy: 97.50%\n",
      "67\tValidation loss: 0.072263\tBest loss: 0.054124\tAccuracy: 98.83%\n",
      "68\tValidation loss: 0.094449\tBest loss: 0.054124\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total=14.8min\n",
      "[CV] n_neurons=160, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.050917\tBest loss: 1.050917\tAccuracy: 92.42%\n",
      "1\tValidation loss: 0.365162\tBest loss: 0.365162\tAccuracy: 96.52%\n",
      "2\tValidation loss: 0.823429\tBest loss: 0.365162\tAccuracy: 89.60%\n",
      "3\tValidation loss: 0.561021\tBest loss: 0.365162\tAccuracy: 88.74%\n",
      "4\tValidation loss: 0.494070\tBest loss: 0.365162\tAccuracy: 93.75%\n",
      "5\tValidation loss: 0.125847\tBest loss: 0.125847\tAccuracy: 96.44%\n",
      "6\tValidation loss: 0.123083\tBest loss: 0.123083\tAccuracy: 97.42%\n",
      "7\tValidation loss: 0.089482\tBest loss: 0.089482\tAccuracy: 97.93%\n",
      "8\tValidation loss: 0.487111\tBest loss: 0.089482\tAccuracy: 85.50%\n",
      "9\tValidation loss: 0.139348\tBest loss: 0.089482\tAccuracy: 96.60%\n",
      "10\tValidation loss: 0.137840\tBest loss: 0.089482\tAccuracy: 96.44%\n",
      "11\tValidation loss: 0.137524\tBest loss: 0.089482\tAccuracy: 96.56%\n",
      "12\tValidation loss: 0.049860\tBest loss: 0.049860\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.051864\tBest loss: 0.049860\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.072806\tBest loss: 0.049860\tAccuracy: 98.24%\n",
      "15\tValidation loss: 0.120616\tBest loss: 0.049860\tAccuracy: 96.40%\n",
      "16\tValidation loss: 0.226000\tBest loss: 0.049860\tAccuracy: 93.98%\n",
      "17\tValidation loss: 0.057712\tBest loss: 0.049860\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.108772\tBest loss: 0.049860\tAccuracy: 97.62%\n",
      "19\tValidation loss: 0.520368\tBest loss: 0.049860\tAccuracy: 87.22%\n",
      "20\tValidation loss: 0.062324\tBest loss: 0.049860\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.068988\tBest loss: 0.049860\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.078366\tBest loss: 0.049860\tAccuracy: 97.69%\n",
      "23\tValidation loss: 0.105615\tBest loss: 0.049860\tAccuracy: 97.62%\n",
      "24\tValidation loss: 0.065700\tBest loss: 0.049860\tAccuracy: 98.44%\n",
      "25\tValidation loss: 0.102443\tBest loss: 0.049860\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.122674\tBest loss: 0.049860\tAccuracy: 97.58%\n",
      "27\tValidation loss: 0.141402\tBest loss: 0.049860\tAccuracy: 97.22%\n",
      "28\tValidation loss: 0.142124\tBest loss: 0.049860\tAccuracy: 97.07%\n",
      "29\tValidation loss: 0.048814\tBest loss: 0.048814\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.061927\tBest loss: 0.048814\tAccuracy: 98.83%\n",
      "31\tValidation loss: 0.092515\tBest loss: 0.048814\tAccuracy: 98.51%\n",
      "32\tValidation loss: 0.076424\tBest loss: 0.048814\tAccuracy: 98.08%\n",
      "33\tValidation loss: 0.044922\tBest loss: 0.044922\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.057562\tBest loss: 0.044922\tAccuracy: 98.63%\n",
      "35\tValidation loss: 0.102751\tBest loss: 0.044922\tAccuracy: 97.62%\n",
      "36\tValidation loss: 0.061731\tBest loss: 0.044922\tAccuracy: 98.16%\n",
      "37\tValidation loss: 0.059245\tBest loss: 0.044922\tAccuracy: 98.79%\n",
      "38\tValidation loss: 0.066806\tBest loss: 0.044922\tAccuracy: 98.75%\n",
      "39\tValidation loss: 0.057944\tBest loss: 0.044922\tAccuracy: 98.63%\n",
      "40\tValidation loss: 0.045576\tBest loss: 0.044922\tAccuracy: 99.02%\n",
      "41\tValidation loss: 0.077259\tBest loss: 0.044922\tAccuracy: 98.40%\n",
      "42\tValidation loss: 0.089033\tBest loss: 0.044922\tAccuracy: 98.59%\n",
      "43\tValidation loss: 0.045095\tBest loss: 0.044922\tAccuracy: 98.79%\n",
      "44\tValidation loss: 0.063516\tBest loss: 0.044922\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.121583\tBest loss: 0.044922\tAccuracy: 98.20%\n",
      "46\tValidation loss: 0.059041\tBest loss: 0.044922\tAccuracy: 98.67%\n",
      "47\tValidation loss: 0.094437\tBest loss: 0.044922\tAccuracy: 98.32%\n",
      "48\tValidation loss: 0.063973\tBest loss: 0.044922\tAccuracy: 98.91%\n",
      "49\tValidation loss: 0.058623\tBest loss: 0.044922\tAccuracy: 99.06%\n",
      "50\tValidation loss: 0.172465\tBest loss: 0.044922\tAccuracy: 98.24%\n",
      "51\tValidation loss: 0.079237\tBest loss: 0.044922\tAccuracy: 98.40%\n",
      "52\tValidation loss: 0.077495\tBest loss: 0.044922\tAccuracy: 98.40%\n",
      "53\tValidation loss: 0.042978\tBest loss: 0.042978\tAccuracy: 98.59%\n",
      "54\tValidation loss: 0.125986\tBest loss: 0.042978\tAccuracy: 98.44%\n",
      "55\tValidation loss: 0.085609\tBest loss: 0.042978\tAccuracy: 98.59%\n",
      "56\tValidation loss: 0.078628\tBest loss: 0.042978\tAccuracy: 98.36%\n",
      "57\tValidation loss: 0.095601\tBest loss: 0.042978\tAccuracy: 98.63%\n",
      "58\tValidation loss: 0.053905\tBest loss: 0.042978\tAccuracy: 99.18%\n",
      "59\tValidation loss: 0.075429\tBest loss: 0.042978\tAccuracy: 98.67%\n",
      "60\tValidation loss: 0.054777\tBest loss: 0.042978\tAccuracy: 98.87%\n",
      "61\tValidation loss: 0.088004\tBest loss: 0.042978\tAccuracy: 98.36%\n",
      "62\tValidation loss: 0.051949\tBest loss: 0.042978\tAccuracy: 98.98%\n",
      "63\tValidation loss: 0.111413\tBest loss: 0.042978\tAccuracy: 97.93%\n",
      "64\tValidation loss: 0.109017\tBest loss: 0.042978\tAccuracy: 98.28%\n",
      "65\tValidation loss: 0.057952\tBest loss: 0.042978\tAccuracy: 99.06%\n",
      "66\tValidation loss: 0.080136\tBest loss: 0.042978\tAccuracy: 99.02%\n",
      "67\tValidation loss: 0.092082\tBest loss: 0.042978\tAccuracy: 98.71%\n",
      "68\tValidation loss: 0.045026\tBest loss: 0.042978\tAccuracy: 98.98%\n",
      "69\tValidation loss: 0.125367\tBest loss: 0.042978\tAccuracy: 99.02%\n",
      "70\tValidation loss: 0.087899\tBest loss: 0.042978\tAccuracy: 98.16%\n",
      "71\tValidation loss: 0.088934\tBest loss: 0.042978\tAccuracy: 98.63%\n",
      "72\tValidation loss: 0.072954\tBest loss: 0.042978\tAccuracy: 98.51%\n",
      "73\tValidation loss: 0.101330\tBest loss: 0.042978\tAccuracy: 98.44%\n",
      "74\tValidation loss: 0.104201\tBest loss: 0.042978\tAccuracy: 98.36%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total=16.2min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.096794\tBest loss: 0.096794\tAccuracy: 97.11%\n",
      "1\tValidation loss: 0.072397\tBest loss: 0.072397\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.061053\tBest loss: 0.061053\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.066923\tBest loss: 0.061053\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.058827\tBest loss: 0.058827\tAccuracy: 98.08%\n",
      "5\tValidation loss: 0.052614\tBest loss: 0.052614\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.056614\tBest loss: 0.052614\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.066862\tBest loss: 0.052614\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.056912\tBest loss: 0.052614\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.044359\tBest loss: 0.044359\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.045003\tBest loss: 0.044359\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.032647\tBest loss: 0.032647\tAccuracy: 99.02%\n",
      "12\tValidation loss: 0.046426\tBest loss: 0.032647\tAccuracy: 98.71%\n",
      "13\tValidation loss: 0.050716\tBest loss: 0.032647\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.038948\tBest loss: 0.032647\tAccuracy: 98.94%\n",
      "15\tValidation loss: 0.056108\tBest loss: 0.032647\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.045467\tBest loss: 0.032647\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.029574\tBest loss: 0.029574\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.039531\tBest loss: 0.029574\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.047896\tBest loss: 0.029574\tAccuracy: 98.67%\n",
      "20\tValidation loss: 0.039586\tBest loss: 0.029574\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.047056\tBest loss: 0.029574\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.044539\tBest loss: 0.029574\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.064137\tBest loss: 0.029574\tAccuracy: 98.44%\n",
      "24\tValidation loss: 0.049721\tBest loss: 0.029574\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.046189\tBest loss: 0.029574\tAccuracy: 98.71%\n",
      "26\tValidation loss: 0.049234\tBest loss: 0.029574\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.047386\tBest loss: 0.029574\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.047336\tBest loss: 0.029574\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.041310\tBest loss: 0.029574\tAccuracy: 99.02%\n",
      "30\tValidation loss: 0.056722\tBest loss: 0.029574\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.051816\tBest loss: 0.029574\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.047899\tBest loss: 0.029574\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.040691\tBest loss: 0.029574\tAccuracy: 99.02%\n",
      "34\tValidation loss: 0.044557\tBest loss: 0.029574\tAccuracy: 98.91%\n",
      "35\tValidation loss: 0.043304\tBest loss: 0.029574\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.059997\tBest loss: 0.029574\tAccuracy: 98.75%\n",
      "37\tValidation loss: 0.055333\tBest loss: 0.029574\tAccuracy: 98.79%\n",
      "38\tValidation loss: 0.046821\tBest loss: 0.029574\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 8.5min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.110020\tBest loss: 0.110020\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.076039\tBest loss: 0.076039\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.063682\tBest loss: 0.063682\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.060165\tBest loss: 0.060165\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.050314\tBest loss: 0.050314\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.047426\tBest loss: 0.047426\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.048939\tBest loss: 0.047426\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.045238\tBest loss: 0.045238\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.038072\tBest loss: 0.038072\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.046685\tBest loss: 0.038072\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.043639\tBest loss: 0.038072\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.043911\tBest loss: 0.038072\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.035526\tBest loss: 0.035526\tAccuracy: 99.10%\n",
      "13\tValidation loss: 0.034022\tBest loss: 0.034022\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.031550\tBest loss: 0.031550\tAccuracy: 98.94%\n",
      "15\tValidation loss: 0.032143\tBest loss: 0.031550\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.034389\tBest loss: 0.031550\tAccuracy: 98.94%\n",
      "17\tValidation loss: 0.038884\tBest loss: 0.031550\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.037547\tBest loss: 0.031550\tAccuracy: 99.18%\n",
      "19\tValidation loss: 0.031703\tBest loss: 0.031550\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.039781\tBest loss: 0.031550\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.045774\tBest loss: 0.031550\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.042711\tBest loss: 0.031550\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.037972\tBest loss: 0.031550\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.030948\tBest loss: 0.030948\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.031215\tBest loss: 0.030948\tAccuracy: 98.94%\n",
      "26\tValidation loss: 0.050246\tBest loss: 0.030948\tAccuracy: 98.75%\n",
      "27\tValidation loss: 0.030103\tBest loss: 0.030103\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.034161\tBest loss: 0.030103\tAccuracy: 98.98%\n",
      "29\tValidation loss: 0.034371\tBest loss: 0.030103\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.047723\tBest loss: 0.030103\tAccuracy: 98.48%\n",
      "31\tValidation loss: 0.029872\tBest loss: 0.029872\tAccuracy: 99.14%\n",
      "32\tValidation loss: 0.033845\tBest loss: 0.029872\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.038638\tBest loss: 0.029872\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.042490\tBest loss: 0.029872\tAccuracy: 98.67%\n",
      "35\tValidation loss: 0.033398\tBest loss: 0.029872\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.024775\tBest loss: 0.024775\tAccuracy: 99.34%\n",
      "37\tValidation loss: 0.035073\tBest loss: 0.024775\tAccuracy: 99.10%\n",
      "38\tValidation loss: 0.034956\tBest loss: 0.024775\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.042403\tBest loss: 0.024775\tAccuracy: 98.83%\n",
      "40\tValidation loss: 0.039734\tBest loss: 0.024775\tAccuracy: 98.71%\n",
      "41\tValidation loss: 0.058409\tBest loss: 0.024775\tAccuracy: 98.71%\n",
      "42\tValidation loss: 0.043368\tBest loss: 0.024775\tAccuracy: 99.02%\n",
      "43\tValidation loss: 0.048783\tBest loss: 0.024775\tAccuracy: 98.75%\n",
      "44\tValidation loss: 0.056418\tBest loss: 0.024775\tAccuracy: 98.63%\n",
      "45\tValidation loss: 0.044634\tBest loss: 0.024775\tAccuracy: 99.06%\n",
      "46\tValidation loss: 0.049452\tBest loss: 0.024775\tAccuracy: 98.67%\n",
      "47\tValidation loss: 0.035324\tBest loss: 0.024775\tAccuracy: 99.02%\n",
      "48\tValidation loss: 0.034454\tBest loss: 0.024775\tAccuracy: 98.94%\n",
      "49\tValidation loss: 0.034562\tBest loss: 0.024775\tAccuracy: 99.18%\n",
      "50\tValidation loss: 0.034024\tBest loss: 0.024775\tAccuracy: 99.22%\n",
      "51\tValidation loss: 0.032842\tBest loss: 0.024775\tAccuracy: 99.34%\n",
      "52\tValidation loss: 0.037955\tBest loss: 0.024775\tAccuracy: 98.94%\n",
      "53\tValidation loss: 0.047617\tBest loss: 0.024775\tAccuracy: 98.71%\n",
      "54\tValidation loss: 0.028332\tBest loss: 0.024775\tAccuracy: 99.26%\n",
      "55\tValidation loss: 0.043873\tBest loss: 0.024775\tAccuracy: 99.06%\n",
      "56\tValidation loss: 0.042548\tBest loss: 0.024775\tAccuracy: 98.87%\n",
      "57\tValidation loss: 0.047357\tBest loss: 0.024775\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total=12.6min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.119035\tBest loss: 0.119035\tAccuracy: 96.21%\n",
      "1\tValidation loss: 0.064255\tBest loss: 0.064255\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.077913\tBest loss: 0.064255\tAccuracy: 97.34%\n",
      "3\tValidation loss: 0.057918\tBest loss: 0.057918\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.045668\tBest loss: 0.045668\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.052712\tBest loss: 0.045668\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.034697\tBest loss: 0.034697\tAccuracy: 99.22%\n",
      "7\tValidation loss: 0.059424\tBest loss: 0.034697\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.058427\tBest loss: 0.034697\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.037489\tBest loss: 0.034697\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.043856\tBest loss: 0.034697\tAccuracy: 98.79%\n",
      "11\tValidation loss: 0.068578\tBest loss: 0.034697\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.042647\tBest loss: 0.034697\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.044854\tBest loss: 0.034697\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.039106\tBest loss: 0.034697\tAccuracy: 98.98%\n",
      "15\tValidation loss: 0.034540\tBest loss: 0.034540\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.053678\tBest loss: 0.034540\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.055476\tBest loss: 0.034540\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.037499\tBest loss: 0.034540\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.029943\tBest loss: 0.029943\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.027675\tBest loss: 0.027675\tAccuracy: 99.14%\n",
      "21\tValidation loss: 0.035550\tBest loss: 0.027675\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.030087\tBest loss: 0.027675\tAccuracy: 99.26%\n",
      "23\tValidation loss: 0.055394\tBest loss: 0.027675\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.033862\tBest loss: 0.027675\tAccuracy: 99.30%\n",
      "25\tValidation loss: 0.025157\tBest loss: 0.025157\tAccuracy: 99.34%\n",
      "26\tValidation loss: 0.035975\tBest loss: 0.025157\tAccuracy: 99.14%\n",
      "27\tValidation loss: 0.031106\tBest loss: 0.025157\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.034436\tBest loss: 0.025157\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.030890\tBest loss: 0.025157\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.027830\tBest loss: 0.025157\tAccuracy: 99.14%\n",
      "31\tValidation loss: 0.031760\tBest loss: 0.025157\tAccuracy: 99.34%\n",
      "32\tValidation loss: 0.045368\tBest loss: 0.025157\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.033274\tBest loss: 0.025157\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.029430\tBest loss: 0.025157\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.041438\tBest loss: 0.025157\tAccuracy: 98.79%\n",
      "36\tValidation loss: 0.030536\tBest loss: 0.025157\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.039030\tBest loss: 0.025157\tAccuracy: 98.98%\n",
      "38\tValidation loss: 0.026850\tBest loss: 0.025157\tAccuracy: 99.34%\n",
      "39\tValidation loss: 0.040413\tBest loss: 0.025157\tAccuracy: 98.98%\n",
      "40\tValidation loss: 0.042398\tBest loss: 0.025157\tAccuracy: 99.22%\n",
      "41\tValidation loss: 0.032868\tBest loss: 0.025157\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.051148\tBest loss: 0.025157\tAccuracy: 98.79%\n",
      "43\tValidation loss: 0.042428\tBest loss: 0.025157\tAccuracy: 98.79%\n",
      "44\tValidation loss: 0.031468\tBest loss: 0.025157\tAccuracy: 99.18%\n",
      "45\tValidation loss: 0.050754\tBest loss: 0.025157\tAccuracy: 98.71%\n",
      "46\tValidation loss: 0.042783\tBest loss: 0.025157\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total=10.3min\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.074483\tBest loss: 0.074483\tAccuracy: 97.73%\n",
      "1\tValidation loss: 0.093439\tBest loss: 0.074483\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.077353\tBest loss: 0.074483\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.123355\tBest loss: 0.074483\tAccuracy: 97.07%\n",
      "4\tValidation loss: 0.050077\tBest loss: 0.050077\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.093786\tBest loss: 0.050077\tAccuracy: 97.81%\n",
      "6\tValidation loss: 0.072405\tBest loss: 0.050077\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.073837\tBest loss: 0.050077\tAccuracy: 98.32%\n",
      "8\tValidation loss: 0.074892\tBest loss: 0.050077\tAccuracy: 98.01%\n",
      "9\tValidation loss: 0.078906\tBest loss: 0.050077\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.059590\tBest loss: 0.050077\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.065446\tBest loss: 0.050077\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.056493\tBest loss: 0.050077\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.062695\tBest loss: 0.050077\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.074399\tBest loss: 0.050077\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.062117\tBest loss: 0.050077\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.080875\tBest loss: 0.050077\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.068002\tBest loss: 0.050077\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.065190\tBest loss: 0.050077\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.057902\tBest loss: 0.050077\tAccuracy: 98.55%\n",
      "20\tValidation loss: 0.077301\tBest loss: 0.050077\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.068393\tBest loss: 0.050077\tAccuracy: 98.44%\n",
      "22\tValidation loss: 0.067583\tBest loss: 0.050077\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.054376\tBest loss: 0.050077\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.068042\tBest loss: 0.050077\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.081860\tBest loss: 0.050077\tAccuracy: 98.36%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total=  45.8s\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.086655\tBest loss: 0.086655\tAccuracy: 97.30%\n",
      "1\tValidation loss: 0.141389\tBest loss: 0.086655\tAccuracy: 96.72%\n",
      "2\tValidation loss: 0.120963\tBest loss: 0.086655\tAccuracy: 97.42%\n",
      "3\tValidation loss: 0.049569\tBest loss: 0.049569\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.052225\tBest loss: 0.049569\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.055421\tBest loss: 0.049569\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.070727\tBest loss: 0.049569\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.063468\tBest loss: 0.049569\tAccuracy: 98.44%\n",
      "8\tValidation loss: 0.067317\tBest loss: 0.049569\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.056797\tBest loss: 0.049569\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.070449\tBest loss: 0.049569\tAccuracy: 98.24%\n",
      "11\tValidation loss: 0.078007\tBest loss: 0.049569\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.042557\tBest loss: 0.042557\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.051247\tBest loss: 0.042557\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.076785\tBest loss: 0.042557\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.045608\tBest loss: 0.042557\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.040478\tBest loss: 0.040478\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.065370\tBest loss: 0.040478\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.074630\tBest loss: 0.040478\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.063658\tBest loss: 0.040478\tAccuracy: 98.55%\n",
      "20\tValidation loss: 0.067570\tBest loss: 0.040478\tAccuracy: 98.67%\n",
      "21\tValidation loss: 0.064913\tBest loss: 0.040478\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.063048\tBest loss: 0.040478\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.063588\tBest loss: 0.040478\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.051048\tBest loss: 0.040478\tAccuracy: 98.94%\n",
      "25\tValidation loss: 0.054005\tBest loss: 0.040478\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.059039\tBest loss: 0.040478\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.088338\tBest loss: 0.040478\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.076126\tBest loss: 0.040478\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.054594\tBest loss: 0.040478\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.083243\tBest loss: 0.040478\tAccuracy: 98.67%\n",
      "31\tValidation loss: 0.072616\tBest loss: 0.040478\tAccuracy: 98.63%\n",
      "32\tValidation loss: 0.076707\tBest loss: 0.040478\tAccuracy: 98.55%\n",
      "33\tValidation loss: 0.060476\tBest loss: 0.040478\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.074925\tBest loss: 0.040478\tAccuracy: 98.59%\n",
      "35\tValidation loss: 0.084757\tBest loss: 0.040478\tAccuracy: 98.63%\n",
      "36\tValidation loss: 0.052414\tBest loss: 0.040478\tAccuracy: 98.94%\n",
      "37\tValidation loss: 0.039210\tBest loss: 0.039210\tAccuracy: 99.26%\n",
      "38\tValidation loss: 0.077100\tBest loss: 0.039210\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.091300\tBest loss: 0.039210\tAccuracy: 98.55%\n",
      "40\tValidation loss: 0.061964\tBest loss: 0.039210\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.097531\tBest loss: 0.039210\tAccuracy: 98.20%\n",
      "42\tValidation loss: 0.092571\tBest loss: 0.039210\tAccuracy: 98.75%\n",
      "43\tValidation loss: 0.093510\tBest loss: 0.039210\tAccuracy: 98.55%\n",
      "44\tValidation loss: 0.076892\tBest loss: 0.039210\tAccuracy: 98.63%\n",
      "45\tValidation loss: 0.066194\tBest loss: 0.039210\tAccuracy: 98.71%\n",
      "46\tValidation loss: 0.068218\tBest loss: 0.039210\tAccuracy: 98.71%\n",
      "47\tValidation loss: 0.073452\tBest loss: 0.039210\tAccuracy: 98.79%\n",
      "48\tValidation loss: 0.085976\tBest loss: 0.039210\tAccuracy: 98.67%\n",
      "49\tValidation loss: 0.122539\tBest loss: 0.039210\tAccuracy: 98.48%\n",
      "50\tValidation loss: 0.080430\tBest loss: 0.039210\tAccuracy: 98.63%\n",
      "51\tValidation loss: 0.082798\tBest loss: 0.039210\tAccuracy: 98.63%\n",
      "52\tValidation loss: 0.104803\tBest loss: 0.039210\tAccuracy: 98.36%\n",
      "53\tValidation loss: 0.055496\tBest loss: 0.039210\tAccuracy: 98.91%\n",
      "54\tValidation loss: 0.059009\tBest loss: 0.039210\tAccuracy: 99.10%\n",
      "55\tValidation loss: 0.086272\tBest loss: 0.039210\tAccuracy: 98.91%\n",
      "56\tValidation loss: 0.091949\tBest loss: 0.039210\tAccuracy: 98.71%\n",
      "57\tValidation loss: 0.102617\tBest loss: 0.039210\tAccuracy: 98.83%\n",
      "58\tValidation loss: 0.102567\tBest loss: 0.039210\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total= 1.7min\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.083341\tBest loss: 0.083341\tAccuracy: 97.34%\n",
      "1\tValidation loss: 0.082956\tBest loss: 0.082956\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.055762\tBest loss: 0.055762\tAccuracy: 98.44%\n",
      "3\tValidation loss: 0.059471\tBest loss: 0.055762\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.074573\tBest loss: 0.055762\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.040699\tBest loss: 0.040699\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.042419\tBest loss: 0.040699\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.051723\tBest loss: 0.040699\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.059370\tBest loss: 0.040699\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.047806\tBest loss: 0.040699\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.048710\tBest loss: 0.040699\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.063351\tBest loss: 0.040699\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.056025\tBest loss: 0.040699\tAccuracy: 98.71%\n",
      "13\tValidation loss: 0.064087\tBest loss: 0.040699\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.040839\tBest loss: 0.040699\tAccuracy: 98.98%\n",
      "15\tValidation loss: 0.063877\tBest loss: 0.040699\tAccuracy: 98.83%\n",
      "16\tValidation loss: 0.037128\tBest loss: 0.037128\tAccuracy: 99.18%\n",
      "17\tValidation loss: 0.070096\tBest loss: 0.037128\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.053695\tBest loss: 0.037128\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.059660\tBest loss: 0.037128\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.038900\tBest loss: 0.037128\tAccuracy: 99.14%\n",
      "21\tValidation loss: 0.052688\tBest loss: 0.037128\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.046804\tBest loss: 0.037128\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.057202\tBest loss: 0.037128\tAccuracy: 98.55%\n",
      "24\tValidation loss: 0.058259\tBest loss: 0.037128\tAccuracy: 98.94%\n",
      "25\tValidation loss: 0.076932\tBest loss: 0.037128\tAccuracy: 98.51%\n",
      "26\tValidation loss: 0.077344\tBest loss: 0.037128\tAccuracy: 98.40%\n",
      "27\tValidation loss: 0.048837\tBest loss: 0.037128\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.077538\tBest loss: 0.037128\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.071517\tBest loss: 0.037128\tAccuracy: 98.83%\n",
      "30\tValidation loss: 0.046859\tBest loss: 0.037128\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.046899\tBest loss: 0.037128\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.054472\tBest loss: 0.037128\tAccuracy: 98.87%\n",
      "33\tValidation loss: 0.051073\tBest loss: 0.037128\tAccuracy: 98.98%\n",
      "34\tValidation loss: 0.075130\tBest loss: 0.037128\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.060037\tBest loss: 0.037128\tAccuracy: 98.79%\n",
      "36\tValidation loss: 0.079621\tBest loss: 0.037128\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.061998\tBest loss: 0.037128\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=100, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total= 1.1min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.122895\tBest loss: 0.122895\tAccuracy: 96.25%\n",
      "1\tValidation loss: 0.082370\tBest loss: 0.082370\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.174535\tBest loss: 0.082370\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.726329\tBest loss: 0.082370\tAccuracy: 94.14%\n",
      "4\tValidation loss: 0.274901\tBest loss: 0.082370\tAccuracy: 97.77%\n",
      "5\tValidation loss: 0.223637\tBest loss: 0.082370\tAccuracy: 97.58%\n",
      "6\tValidation loss: 0.218293\tBest loss: 0.082370\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.331849\tBest loss: 0.082370\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.163198\tBest loss: 0.082370\tAccuracy: 98.55%\n",
      "9\tValidation loss: 0.368307\tBest loss: 0.082370\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.361779\tBest loss: 0.082370\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.279851\tBest loss: 0.082370\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.447339\tBest loss: 0.082370\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.321409\tBest loss: 0.082370\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.307107\tBest loss: 0.082370\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.697912\tBest loss: 0.082370\tAccuracy: 97.26%\n",
      "16\tValidation loss: 0.394191\tBest loss: 0.082370\tAccuracy: 98.12%\n",
      "17\tValidation loss: 0.587537\tBest loss: 0.082370\tAccuracy: 97.93%\n",
      "18\tValidation loss: 0.585388\tBest loss: 0.082370\tAccuracy: 98.24%\n",
      "19\tValidation loss: 0.774608\tBest loss: 0.082370\tAccuracy: 97.69%\n",
      "20\tValidation loss: 0.554038\tBest loss: 0.082370\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.492717\tBest loss: 0.082370\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.592833\tBest loss: 0.082370\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0>, total= 5.0min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.228595\tBest loss: 0.228595\tAccuracy: 94.29%\n",
      "1\tValidation loss: 0.103502\tBest loss: 0.103502\tAccuracy: 97.22%\n",
      "2\tValidation loss: 0.155472\tBest loss: 0.103502\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.555194\tBest loss: 0.103502\tAccuracy: 92.85%\n",
      "4\tValidation loss: 0.289281\tBest loss: 0.103502\tAccuracy: 97.07%\n",
      "5\tValidation loss: 0.291750\tBest loss: 0.103502\tAccuracy: 97.81%\n",
      "6\tValidation loss: 0.230710\tBest loss: 0.103502\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.243465\tBest loss: 0.103502\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.572676\tBest loss: 0.103502\tAccuracy: 97.50%\n",
      "9\tValidation loss: 1.101736\tBest loss: 0.103502\tAccuracy: 97.34%\n",
      "10\tValidation loss: 0.378059\tBest loss: 0.103502\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.675043\tBest loss: 0.103502\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.328527\tBest loss: 0.103502\tAccuracy: 98.28%\n",
      "13\tValidation loss: 0.819243\tBest loss: 0.103502\tAccuracy: 97.11%\n",
      "14\tValidation loss: 0.546284\tBest loss: 0.103502\tAccuracy: 98.36%\n",
      "15\tValidation loss: 2.359326\tBest loss: 0.103502\tAccuracy: 95.00%\n",
      "16\tValidation loss: 0.652478\tBest loss: 0.103502\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.693667\tBest loss: 0.103502\tAccuracy: 97.46%\n",
      "18\tValidation loss: 0.636674\tBest loss: 0.103502\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.609779\tBest loss: 0.103502\tAccuracy: 98.20%\n",
      "20\tValidation loss: 0.758416\tBest loss: 0.103502\tAccuracy: 98.36%\n",
      "21\tValidation loss: 0.875702\tBest loss: 0.103502\tAccuracy: 97.50%\n",
      "22\tValidation loss: 1.040049\tBest loss: 0.103502\tAccuracy: 97.22%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0>, total= 5.0min\n",
      "[CV] n_neurons=140, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.322759\tBest loss: 0.322759\tAccuracy: 88.00%\n",
      "1\tValidation loss: 0.374671\tBest loss: 0.322759\tAccuracy: 96.36%\n",
      "2\tValidation loss: 3.283690\tBest loss: 0.322759\tAccuracy: 76.11%\n",
      "3\tValidation loss: 0.157386\tBest loss: 0.157386\tAccuracy: 97.07%\n",
      "4\tValidation loss: 0.331474\tBest loss: 0.157386\tAccuracy: 96.17%\n",
      "5\tValidation loss: 0.149269\tBest loss: 0.149269\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.305540\tBest loss: 0.149269\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.274474\tBest loss: 0.149269\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.565660\tBest loss: 0.149269\tAccuracy: 97.19%\n",
      "9\tValidation loss: 0.300634\tBest loss: 0.149269\tAccuracy: 98.16%\n",
      "10\tValidation loss: 0.488222\tBest loss: 0.149269\tAccuracy: 98.28%\n",
      "11\tValidation loss: 0.708508\tBest loss: 0.149269\tAccuracy: 96.29%\n",
      "12\tValidation loss: 0.309753\tBest loss: 0.149269\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.491474\tBest loss: 0.149269\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.755632\tBest loss: 0.149269\tAccuracy: 96.79%\n",
      "15\tValidation loss: 0.418372\tBest loss: 0.149269\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.757516\tBest loss: 0.149269\tAccuracy: 97.11%\n",
      "17\tValidation loss: 0.706554\tBest loss: 0.149269\tAccuracy: 97.26%\n",
      "18\tValidation loss: 0.611379\tBest loss: 0.149269\tAccuracy: 97.77%\n",
      "19\tValidation loss: 0.395453\tBest loss: 0.149269\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.542244\tBest loss: 0.149269\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.244011\tBest loss: 0.149269\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.547593\tBest loss: 0.149269\tAccuracy: 97.85%\n",
      "23\tValidation loss: 0.465651\tBest loss: 0.149269\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.474116\tBest loss: 0.149269\tAccuracy: 98.55%\n",
      "25\tValidation loss: 0.512834\tBest loss: 0.149269\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.486612\tBest loss: 0.149269\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function elu at 0x7fabf3fc68b0>, total= 5.9min\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.211668\tBest loss: 0.211668\tAccuracy: 93.28%\n",
      "1\tValidation loss: 0.142740\tBest loss: 0.142740\tAccuracy: 95.74%\n",
      "2\tValidation loss: 0.149321\tBest loss: 0.142740\tAccuracy: 95.93%\n",
      "3\tValidation loss: 0.164248\tBest loss: 0.142740\tAccuracy: 95.19%\n",
      "4\tValidation loss: 0.092730\tBest loss: 0.092730\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.116537\tBest loss: 0.092730\tAccuracy: 96.95%\n",
      "6\tValidation loss: 0.214254\tBest loss: 0.092730\tAccuracy: 92.38%\n",
      "7\tValidation loss: 0.142766\tBest loss: 0.092730\tAccuracy: 96.76%\n",
      "8\tValidation loss: 0.079078\tBest loss: 0.079078\tAccuracy: 97.85%\n",
      "9\tValidation loss: 0.121874\tBest loss: 0.079078\tAccuracy: 97.15%\n",
      "10\tValidation loss: 0.072030\tBest loss: 0.072030\tAccuracy: 98.05%\n",
      "11\tValidation loss: 0.089783\tBest loss: 0.072030\tAccuracy: 97.62%\n",
      "12\tValidation loss: 0.074704\tBest loss: 0.072030\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.094235\tBest loss: 0.072030\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.087755\tBest loss: 0.072030\tAccuracy: 98.05%\n",
      "15\tValidation loss: 0.125230\tBest loss: 0.072030\tAccuracy: 96.36%\n",
      "16\tValidation loss: 0.127678\tBest loss: 0.072030\tAccuracy: 97.34%\n",
      "17\tValidation loss: 0.078956\tBest loss: 0.072030\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.096935\tBest loss: 0.072030\tAccuracy: 97.62%\n",
      "19\tValidation loss: 0.121650\tBest loss: 0.072030\tAccuracy: 96.83%\n",
      "20\tValidation loss: 0.063052\tBest loss: 0.063052\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.078831\tBest loss: 0.063052\tAccuracy: 98.01%\n",
      "22\tValidation loss: 0.080294\tBest loss: 0.063052\tAccuracy: 98.08%\n",
      "23\tValidation loss: 0.111518\tBest loss: 0.063052\tAccuracy: 97.54%\n",
      "24\tValidation loss: 0.080049\tBest loss: 0.063052\tAccuracy: 98.05%\n",
      "25\tValidation loss: 0.068219\tBest loss: 0.063052\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.092582\tBest loss: 0.063052\tAccuracy: 97.62%\n",
      "27\tValidation loss: 0.141691\tBest loss: 0.063052\tAccuracy: 96.56%\n",
      "28\tValidation loss: 0.103845\tBest loss: 0.063052\tAccuracy: 97.34%\n",
      "29\tValidation loss: 0.116863\tBest loss: 0.063052\tAccuracy: 96.95%\n",
      "30\tValidation loss: 0.065380\tBest loss: 0.063052\tAccuracy: 98.20%\n",
      "31\tValidation loss: 0.113951\tBest loss: 0.063052\tAccuracy: 97.11%\n",
      "32\tValidation loss: 0.123137\tBest loss: 0.063052\tAccuracy: 96.87%\n",
      "33\tValidation loss: 0.076385\tBest loss: 0.063052\tAccuracy: 98.24%\n",
      "34\tValidation loss: 0.104432\tBest loss: 0.063052\tAccuracy: 98.12%\n",
      "35\tValidation loss: 0.066160\tBest loss: 0.063052\tAccuracy: 98.59%\n",
      "36\tValidation loss: 0.089849\tBest loss: 0.063052\tAccuracy: 97.89%\n",
      "37\tValidation loss: 0.069751\tBest loss: 0.063052\tAccuracy: 98.40%\n",
      "38\tValidation loss: 0.119744\tBest loss: 0.063052\tAccuracy: 97.11%\n",
      "39\tValidation loss: 0.104543\tBest loss: 0.063052\tAccuracy: 97.42%\n",
      "40\tValidation loss: 0.087896\tBest loss: 0.063052\tAccuracy: 97.97%\n",
      "41\tValidation loss: 0.072972\tBest loss: 0.063052\tAccuracy: 98.32%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 6.8min\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.110997\tBest loss: 0.110997\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.144754\tBest loss: 0.110997\tAccuracy: 95.82%\n",
      "2\tValidation loss: 0.116778\tBest loss: 0.110997\tAccuracy: 96.72%\n",
      "3\tValidation loss: 0.234818\tBest loss: 0.110997\tAccuracy: 93.59%\n",
      "4\tValidation loss: 0.117963\tBest loss: 0.110997\tAccuracy: 96.25%\n",
      "5\tValidation loss: 0.078521\tBest loss: 0.078521\tAccuracy: 97.85%\n",
      "6\tValidation loss: 0.128725\tBest loss: 0.078521\tAccuracy: 96.79%\n",
      "7\tValidation loss: 0.136469\tBest loss: 0.078521\tAccuracy: 95.62%\n",
      "8\tValidation loss: 0.089308\tBest loss: 0.078521\tAccuracy: 97.69%\n",
      "9\tValidation loss: 0.084945\tBest loss: 0.078521\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.102933\tBest loss: 0.078521\tAccuracy: 97.62%\n",
      "11\tValidation loss: 0.108230\tBest loss: 0.078521\tAccuracy: 97.38%\n",
      "12\tValidation loss: 0.072417\tBest loss: 0.072417\tAccuracy: 98.28%\n",
      "13\tValidation loss: 0.083275\tBest loss: 0.072417\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.094255\tBest loss: 0.072417\tAccuracy: 97.62%\n",
      "15\tValidation loss: 0.115186\tBest loss: 0.072417\tAccuracy: 97.22%\n",
      "16\tValidation loss: 0.115549\tBest loss: 0.072417\tAccuracy: 96.99%\n",
      "17\tValidation loss: 0.124730\tBest loss: 0.072417\tAccuracy: 96.87%\n",
      "18\tValidation loss: 0.085306\tBest loss: 0.072417\tAccuracy: 98.12%\n",
      "19\tValidation loss: 0.091037\tBest loss: 0.072417\tAccuracy: 97.54%\n",
      "20\tValidation loss: 0.088549\tBest loss: 0.072417\tAccuracy: 97.85%\n",
      "21\tValidation loss: 0.084978\tBest loss: 0.072417\tAccuracy: 98.12%\n",
      "22\tValidation loss: 0.072607\tBest loss: 0.072417\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.102077\tBest loss: 0.072417\tAccuracy: 97.34%\n",
      "24\tValidation loss: 0.111382\tBest loss: 0.072417\tAccuracy: 97.46%\n",
      "25\tValidation loss: 0.144847\tBest loss: 0.072417\tAccuracy: 96.76%\n",
      "26\tValidation loss: 0.091100\tBest loss: 0.072417\tAccuracy: 98.16%\n",
      "27\tValidation loss: 0.106190\tBest loss: 0.072417\tAccuracy: 97.73%\n",
      "28\tValidation loss: 0.125264\tBest loss: 0.072417\tAccuracy: 97.22%\n",
      "29\tValidation loss: 0.089654\tBest loss: 0.072417\tAccuracy: 98.05%\n",
      "30\tValidation loss: 0.225283\tBest loss: 0.072417\tAccuracy: 94.72%\n",
      "31\tValidation loss: 0.116182\tBest loss: 0.072417\tAccuracy: 97.50%\n",
      "32\tValidation loss: 0.076284\tBest loss: 0.072417\tAccuracy: 98.20%\n",
      "33\tValidation loss: 0.136080\tBest loss: 0.072417\tAccuracy: 96.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 5.6min\n",
      "[CV] n_neurons=30, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.170895\tBest loss: 0.170895\tAccuracy: 95.11%\n",
      "1\tValidation loss: 0.153415\tBest loss: 0.153415\tAccuracy: 96.13%\n",
      "2\tValidation loss: 0.148213\tBest loss: 0.148213\tAccuracy: 95.66%\n",
      "3\tValidation loss: 0.132550\tBest loss: 0.132550\tAccuracy: 96.25%\n",
      "4\tValidation loss: 0.112299\tBest loss: 0.112299\tAccuracy: 97.11%\n",
      "5\tValidation loss: 0.138850\tBest loss: 0.112299\tAccuracy: 96.68%\n",
      "6\tValidation loss: 0.081258\tBest loss: 0.081258\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.082995\tBest loss: 0.081258\tAccuracy: 97.89%\n",
      "8\tValidation loss: 0.077396\tBest loss: 0.077396\tAccuracy: 97.69%\n",
      "9\tValidation loss: 0.083388\tBest loss: 0.077396\tAccuracy: 97.50%\n",
      "10\tValidation loss: 0.079030\tBest loss: 0.077396\tAccuracy: 97.89%\n",
      "11\tValidation loss: 0.096783\tBest loss: 0.077396\tAccuracy: 97.22%\n",
      "12\tValidation loss: 0.053674\tBest loss: 0.053674\tAccuracy: 98.44%\n",
      "13\tValidation loss: 0.063410\tBest loss: 0.053674\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.083244\tBest loss: 0.053674\tAccuracy: 98.01%\n",
      "15\tValidation loss: 0.060929\tBest loss: 0.053674\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.126419\tBest loss: 0.053674\tAccuracy: 96.99%\n",
      "17\tValidation loss: 0.087608\tBest loss: 0.053674\tAccuracy: 98.08%\n",
      "18\tValidation loss: 0.142814\tBest loss: 0.053674\tAccuracy: 96.60%\n",
      "19\tValidation loss: 0.070822\tBest loss: 0.053674\tAccuracy: 97.93%\n",
      "20\tValidation loss: 0.069450\tBest loss: 0.053674\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.051528\tBest loss: 0.051528\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.057865\tBest loss: 0.051528\tAccuracy: 98.32%\n",
      "23\tValidation loss: 0.089052\tBest loss: 0.051528\tAccuracy: 97.65%\n",
      "24\tValidation loss: 0.064373\tBest loss: 0.051528\tAccuracy: 98.05%\n",
      "25\tValidation loss: 0.054409\tBest loss: 0.051528\tAccuracy: 98.51%\n",
      "26\tValidation loss: 0.079991\tBest loss: 0.051528\tAccuracy: 98.01%\n",
      "27\tValidation loss: 0.065188\tBest loss: 0.051528\tAccuracy: 98.28%\n",
      "28\tValidation loss: 0.058178\tBest loss: 0.051528\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.074007\tBest loss: 0.051528\tAccuracy: 97.85%\n",
      "30\tValidation loss: 0.057958\tBest loss: 0.051528\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.106529\tBest loss: 0.051528\tAccuracy: 97.11%\n",
      "32\tValidation loss: 0.068854\tBest loss: 0.051528\tAccuracy: 98.20%\n",
      "33\tValidation loss: 0.061971\tBest loss: 0.051528\tAccuracy: 98.01%\n",
      "34\tValidation loss: 0.054939\tBest loss: 0.051528\tAccuracy: 98.44%\n",
      "35\tValidation loss: 0.063903\tBest loss: 0.051528\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.059668\tBest loss: 0.051528\tAccuracy: 98.91%\n",
      "37\tValidation loss: 0.055544\tBest loss: 0.051528\tAccuracy: 98.59%\n",
      "38\tValidation loss: 0.081127\tBest loss: 0.051528\tAccuracy: 97.77%\n",
      "39\tValidation loss: 0.055025\tBest loss: 0.051528\tAccuracy: 98.48%\n",
      "40\tValidation loss: 0.064929\tBest loss: 0.051528\tAccuracy: 98.32%\n",
      "41\tValidation loss: 0.148604\tBest loss: 0.051528\tAccuracy: 96.79%\n",
      "42\tValidation loss: 0.085266\tBest loss: 0.051528\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 7.0min\n",
      "[CV] n_neurons=120, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 11.806684\tBest loss: 11.806684\tAccuracy: 94.41%\n",
      "1\tValidation loss: 3.287657\tBest loss: 3.287657\tAccuracy: 96.01%\n",
      "2\tValidation loss: 4.176331\tBest loss: 3.287657\tAccuracy: 93.98%\n",
      "3\tValidation loss: 2.574033\tBest loss: 2.574033\tAccuracy: 95.23%\n",
      "4\tValidation loss: 1.798975\tBest loss: 1.798975\tAccuracy: 96.29%\n",
      "5\tValidation loss: 0.865716\tBest loss: 0.865716\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.483843\tBest loss: 0.483843\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.598311\tBest loss: 0.483843\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.549078\tBest loss: 0.483843\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.534653\tBest loss: 0.483843\tAccuracy: 97.85%\n",
      "10\tValidation loss: 0.618589\tBest loss: 0.483843\tAccuracy: 97.54%\n",
      "11\tValidation loss: 0.527413\tBest loss: 0.483843\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.291247\tBest loss: 0.291247\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.310863\tBest loss: 0.291247\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.268509\tBest loss: 0.268509\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.313376\tBest loss: 0.268509\tAccuracy: 97.81%\n",
      "16\tValidation loss: 0.463886\tBest loss: 0.268509\tAccuracy: 97.65%\n",
      "17\tValidation loss: 0.244752\tBest loss: 0.244752\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.193809\tBest loss: 0.193809\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.477146\tBest loss: 0.193809\tAccuracy: 97.03%\n",
      "20\tValidation loss: 0.177315\tBest loss: 0.177315\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.141076\tBest loss: 0.141076\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.150404\tBest loss: 0.141076\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.167909\tBest loss: 0.141076\tAccuracy: 98.24%\n",
      "24\tValidation loss: 0.130769\tBest loss: 0.130769\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.118078\tBest loss: 0.118078\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.293118\tBest loss: 0.118078\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.212482\tBest loss: 0.118078\tAccuracy: 98.28%\n",
      "28\tValidation loss: 0.176310\tBest loss: 0.118078\tAccuracy: 98.51%\n",
      "29\tValidation loss: 0.183152\tBest loss: 0.118078\tAccuracy: 98.55%\n",
      "30\tValidation loss: 0.171901\tBest loss: 0.118078\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.587511\tBest loss: 0.118078\tAccuracy: 91.87%\n",
      "32\tValidation loss: 0.210347\tBest loss: 0.118078\tAccuracy: 98.08%\n",
      "33\tValidation loss: 0.121236\tBest loss: 0.118078\tAccuracy: 98.71%\n",
      "34\tValidation loss: 0.135667\tBest loss: 0.118078\tAccuracy: 98.87%\n",
      "35\tValidation loss: 0.163153\tBest loss: 0.118078\tAccuracy: 98.12%\n",
      "36\tValidation loss: 0.200162\tBest loss: 0.118078\tAccuracy: 98.55%\n",
      "37\tValidation loss: 0.180625\tBest loss: 0.118078\tAccuracy: 98.32%\n",
      "38\tValidation loss: 0.195464\tBest loss: 0.118078\tAccuracy: 98.36%\n",
      "39\tValidation loss: 0.121220\tBest loss: 0.118078\tAccuracy: 98.79%\n",
      "40\tValidation loss: 0.093976\tBest loss: 0.093976\tAccuracy: 98.94%\n",
      "41\tValidation loss: 0.166254\tBest loss: 0.093976\tAccuracy: 98.63%\n",
      "42\tValidation loss: 0.122355\tBest loss: 0.093976\tAccuracy: 98.75%\n",
      "43\tValidation loss: 0.131960\tBest loss: 0.093976\tAccuracy: 98.71%\n",
      "44\tValidation loss: 0.164539\tBest loss: 0.093976\tAccuracy: 98.55%\n",
      "45\tValidation loss: 0.168699\tBest loss: 0.093976\tAccuracy: 98.36%\n",
      "46\tValidation loss: 0.099336\tBest loss: 0.093976\tAccuracy: 98.79%\n",
      "47\tValidation loss: 0.079334\tBest loss: 0.079334\tAccuracy: 98.91%\n",
      "48\tValidation loss: 0.140355\tBest loss: 0.079334\tAccuracy: 98.44%\n",
      "49\tValidation loss: 0.101754\tBest loss: 0.079334\tAccuracy: 98.98%\n",
      "50\tValidation loss: 0.109663\tBest loss: 0.079334\tAccuracy: 98.75%\n",
      "51\tValidation loss: 0.183682\tBest loss: 0.079334\tAccuracy: 97.81%\n",
      "52\tValidation loss: 0.111175\tBest loss: 0.079334\tAccuracy: 98.75%\n",
      "53\tValidation loss: 0.111420\tBest loss: 0.079334\tAccuracy: 98.51%\n",
      "54\tValidation loss: 0.124663\tBest loss: 0.079334\tAccuracy: 98.75%\n",
      "55\tValidation loss: 0.111093\tBest loss: 0.079334\tAccuracy: 98.91%\n",
      "56\tValidation loss: 0.128695\tBest loss: 0.079334\tAccuracy: 98.71%\n",
      "57\tValidation loss: 0.135433\tBest loss: 0.079334\tAccuracy: 98.63%\n",
      "58\tValidation loss: 0.145583\tBest loss: 0.079334\tAccuracy: 98.44%\n",
      "59\tValidation loss: 0.095254\tBest loss: 0.079334\tAccuracy: 99.10%\n",
      "60\tValidation loss: 0.100207\tBest loss: 0.079334\tAccuracy: 98.94%\n",
      "61\tValidation loss: 0.085966\tBest loss: 0.079334\tAccuracy: 99.18%\n",
      "62\tValidation loss: 0.111490\tBest loss: 0.079334\tAccuracy: 98.75%\n",
      "63\tValidation loss: 0.107061\tBest loss: 0.079334\tAccuracy: 98.94%\n",
      "64\tValidation loss: 0.184879\tBest loss: 0.079334\tAccuracy: 98.28%\n",
      "65\tValidation loss: 0.078037\tBest loss: 0.078037\tAccuracy: 99.02%\n",
      "66\tValidation loss: 0.095329\tBest loss: 0.078037\tAccuracy: 98.87%\n",
      "67\tValidation loss: 0.108011\tBest loss: 0.078037\tAccuracy: 98.71%\n",
      "68\tValidation loss: 0.131348\tBest loss: 0.078037\tAccuracy: 98.75%\n",
      "69\tValidation loss: 0.092929\tBest loss: 0.078037\tAccuracy: 98.91%\n",
      "70\tValidation loss: 0.147937\tBest loss: 0.078037\tAccuracy: 98.91%\n",
      "71\tValidation loss: 0.201474\tBest loss: 0.078037\tAccuracy: 98.16%\n",
      "72\tValidation loss: 0.185978\tBest loss: 0.078037\tAccuracy: 98.75%\n",
      "73\tValidation loss: 0.120577\tBest loss: 0.078037\tAccuracy: 98.83%\n",
      "74\tValidation loss: 0.109639\tBest loss: 0.078037\tAccuracy: 98.79%\n",
      "75\tValidation loss: 0.108370\tBest loss: 0.078037\tAccuracy: 99.06%\n",
      "76\tValidation loss: 0.086075\tBest loss: 0.078037\tAccuracy: 98.91%\n",
      "77\tValidation loss: 0.075828\tBest loss: 0.075828\tAccuracy: 98.79%\n",
      "78\tValidation loss: 0.076216\tBest loss: 0.075828\tAccuracy: 98.98%\n",
      "79\tValidation loss: 0.090922\tBest loss: 0.075828\tAccuracy: 98.98%\n",
      "80\tValidation loss: 0.092857\tBest loss: 0.075828\tAccuracy: 98.94%\n",
      "81\tValidation loss: 0.100503\tBest loss: 0.075828\tAccuracy: 98.91%\n",
      "82\tValidation loss: 0.094321\tBest loss: 0.075828\tAccuracy: 98.91%\n",
      "83\tValidation loss: 0.082487\tBest loss: 0.075828\tAccuracy: 99.10%\n",
      "84\tValidation loss: 0.080508\tBest loss: 0.075828\tAccuracy: 98.98%\n",
      "85\tValidation loss: 0.089402\tBest loss: 0.075828\tAccuracy: 98.79%\n",
      "86\tValidation loss: 0.080490\tBest loss: 0.075828\tAccuracy: 98.79%\n",
      "87\tValidation loss: 0.141175\tBest loss: 0.075828\tAccuracy: 98.75%\n",
      "88\tValidation loss: 0.124249\tBest loss: 0.075828\tAccuracy: 98.98%\n",
      "89\tValidation loss: 0.463557\tBest loss: 0.075828\tAccuracy: 90.30%\n",
      "90\tValidation loss: 0.120052\tBest loss: 0.075828\tAccuracy: 98.67%\n",
      "91\tValidation loss: 0.082723\tBest loss: 0.075828\tAccuracy: 99.18%\n",
      "92\tValidation loss: 0.065177\tBest loss: 0.065177\tAccuracy: 99.26%\n",
      "93\tValidation loss: 0.088747\tBest loss: 0.065177\tAccuracy: 99.02%\n",
      "94\tValidation loss: 0.054341\tBest loss: 0.054341\tAccuracy: 99.06%\n",
      "95\tValidation loss: 0.084435\tBest loss: 0.054341\tAccuracy: 98.91%\n",
      "96\tValidation loss: 0.088332\tBest loss: 0.054341\tAccuracy: 98.83%\n",
      "97\tValidation loss: 0.101150\tBest loss: 0.054341\tAccuracy: 98.71%\n",
      "98\tValidation loss: 0.085621\tBest loss: 0.054341\tAccuracy: 98.79%\n",
      "99\tValidation loss: 0.071166\tBest loss: 0.054341\tAccuracy: 98.91%\n",
      "100\tValidation loss: 0.116971\tBest loss: 0.054341\tAccuracy: 98.87%\n",
      "101\tValidation loss: 0.141428\tBest loss: 0.054341\tAccuracy: 98.71%\n",
      "102\tValidation loss: 0.092086\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "103\tValidation loss: 0.094266\tBest loss: 0.054341\tAccuracy: 99.06%\n",
      "104\tValidation loss: 0.108230\tBest loss: 0.054341\tAccuracy: 98.44%\n",
      "105\tValidation loss: 0.074984\tBest loss: 0.054341\tAccuracy: 98.91%\n",
      "106\tValidation loss: 0.067069\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "107\tValidation loss: 0.069800\tBest loss: 0.054341\tAccuracy: 98.94%\n",
      "108\tValidation loss: 0.062747\tBest loss: 0.054341\tAccuracy: 99.14%\n",
      "109\tValidation loss: 0.076593\tBest loss: 0.054341\tAccuracy: 99.02%\n",
      "110\tValidation loss: 0.080258\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "111\tValidation loss: 0.079373\tBest loss: 0.054341\tAccuracy: 98.91%\n",
      "112\tValidation loss: 0.075031\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "113\tValidation loss: 0.064946\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "114\tValidation loss: 0.093827\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "115\tValidation loss: 0.078342\tBest loss: 0.054341\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 4.4min\n",
      "[CV] n_neurons=120, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 7.773367\tBest loss: 7.773367\tAccuracy: 95.04%\n",
      "1\tValidation loss: 4.538598\tBest loss: 4.538598\tAccuracy: 94.21%\n",
      "2\tValidation loss: 1.135247\tBest loss: 1.135247\tAccuracy: 97.73%\n",
      "3\tValidation loss: 4.678753\tBest loss: 1.135247\tAccuracy: 93.28%\n",
      "4\tValidation loss: 0.595837\tBest loss: 0.595837\tAccuracy: 97.89%\n",
      "5\tValidation loss: 0.740806\tBest loss: 0.595837\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.452508\tBest loss: 0.452508\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.494397\tBest loss: 0.452508\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.514287\tBest loss: 0.452508\tAccuracy: 97.50%\n",
      "9\tValidation loss: 0.232439\tBest loss: 0.232439\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.466927\tBest loss: 0.232439\tAccuracy: 97.34%\n",
      "11\tValidation loss: 0.342300\tBest loss: 0.232439\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.258312\tBest loss: 0.232439\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.165680\tBest loss: 0.165680\tAccuracy: 98.98%\n",
      "14\tValidation loss: 0.350254\tBest loss: 0.165680\tAccuracy: 97.65%\n",
      "15\tValidation loss: 0.636490\tBest loss: 0.165680\tAccuracy: 96.01%\n",
      "16\tValidation loss: 0.217085\tBest loss: 0.165680\tAccuracy: 98.71%\n",
      "17\tValidation loss: 0.364919\tBest loss: 0.165680\tAccuracy: 97.65%\n",
      "18\tValidation loss: 0.148959\tBest loss: 0.148959\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.240159\tBest loss: 0.148959\tAccuracy: 97.73%\n",
      "20\tValidation loss: 0.148173\tBest loss: 0.148173\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.171904\tBest loss: 0.148173\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.214219\tBest loss: 0.148173\tAccuracy: 98.59%\n",
      "23\tValidation loss: 0.302084\tBest loss: 0.148173\tAccuracy: 98.12%\n",
      "24\tValidation loss: 0.141709\tBest loss: 0.141709\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.209974\tBest loss: 0.141709\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.184054\tBest loss: 0.141709\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.184275\tBest loss: 0.141709\tAccuracy: 98.63%\n",
      "28\tValidation loss: 0.141175\tBest loss: 0.141175\tAccuracy: 98.67%\n",
      "29\tValidation loss: 0.108181\tBest loss: 0.108181\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.150325\tBest loss: 0.108181\tAccuracy: 98.75%\n",
      "31\tValidation loss: 0.198295\tBest loss: 0.108181\tAccuracy: 98.12%\n",
      "32\tValidation loss: 0.115849\tBest loss: 0.108181\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.184822\tBest loss: 0.108181\tAccuracy: 98.63%\n",
      "34\tValidation loss: 0.132127\tBest loss: 0.108181\tAccuracy: 98.63%\n",
      "35\tValidation loss: 0.116184\tBest loss: 0.108181\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.155845\tBest loss: 0.108181\tAccuracy: 98.51%\n",
      "37\tValidation loss: 0.087256\tBest loss: 0.087256\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.130013\tBest loss: 0.087256\tAccuracy: 98.94%\n",
      "39\tValidation loss: 0.089131\tBest loss: 0.087256\tAccuracy: 99.06%\n",
      "40\tValidation loss: 0.132238\tBest loss: 0.087256\tAccuracy: 98.98%\n",
      "41\tValidation loss: 0.095658\tBest loss: 0.087256\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.154765\tBest loss: 0.087256\tAccuracy: 98.63%\n",
      "43\tValidation loss: 0.110178\tBest loss: 0.087256\tAccuracy: 98.98%\n",
      "44\tValidation loss: 0.138174\tBest loss: 0.087256\tAccuracy: 98.83%\n",
      "45\tValidation loss: 0.195324\tBest loss: 0.087256\tAccuracy: 98.16%\n",
      "46\tValidation loss: 0.109032\tBest loss: 0.087256\tAccuracy: 99.10%\n",
      "47\tValidation loss: 2.002368\tBest loss: 0.087256\tAccuracy: 79.20%\n",
      "48\tValidation loss: 0.223167\tBest loss: 0.087256\tAccuracy: 98.28%\n",
      "49\tValidation loss: 0.115162\tBest loss: 0.087256\tAccuracy: 98.91%\n",
      "50\tValidation loss: 0.102750\tBest loss: 0.087256\tAccuracy: 98.87%\n",
      "51\tValidation loss: 0.105370\tBest loss: 0.087256\tAccuracy: 99.06%\n",
      "52\tValidation loss: 0.161970\tBest loss: 0.087256\tAccuracy: 98.55%\n",
      "53\tValidation loss: 0.141388\tBest loss: 0.087256\tAccuracy: 98.63%\n",
      "54\tValidation loss: 0.156017\tBest loss: 0.087256\tAccuracy: 98.67%\n",
      "55\tValidation loss: 0.109463\tBest loss: 0.087256\tAccuracy: 99.02%\n",
      "56\tValidation loss: 0.154390\tBest loss: 0.087256\tAccuracy: 98.71%\n",
      "57\tValidation loss: 0.086256\tBest loss: 0.086256\tAccuracy: 98.98%\n",
      "58\tValidation loss: 0.094430\tBest loss: 0.086256\tAccuracy: 99.02%\n",
      "59\tValidation loss: 0.075674\tBest loss: 0.075674\tAccuracy: 99.06%\n",
      "60\tValidation loss: 0.123839\tBest loss: 0.075674\tAccuracy: 98.48%\n",
      "61\tValidation loss: 0.101080\tBest loss: 0.075674\tAccuracy: 99.10%\n",
      "62\tValidation loss: 0.087230\tBest loss: 0.075674\tAccuracy: 99.18%\n",
      "63\tValidation loss: 0.103250\tBest loss: 0.075674\tAccuracy: 98.91%\n",
      "64\tValidation loss: 0.126452\tBest loss: 0.075674\tAccuracy: 98.83%\n",
      "65\tValidation loss: 1.484665\tBest loss: 0.075674\tAccuracy: 83.89%\n",
      "66\tValidation loss: 0.102304\tBest loss: 0.075674\tAccuracy: 98.63%\n",
      "67\tValidation loss: 0.068456\tBest loss: 0.068456\tAccuracy: 98.91%\n",
      "68\tValidation loss: 0.100565\tBest loss: 0.068456\tAccuracy: 98.94%\n",
      "69\tValidation loss: 0.113505\tBest loss: 0.068456\tAccuracy: 98.87%\n",
      "70\tValidation loss: 0.084179\tBest loss: 0.068456\tAccuracy: 98.94%\n",
      "71\tValidation loss: 0.096239\tBest loss: 0.068456\tAccuracy: 99.02%\n",
      "72\tValidation loss: 0.119938\tBest loss: 0.068456\tAccuracy: 98.83%\n",
      "73\tValidation loss: 0.092593\tBest loss: 0.068456\tAccuracy: 98.94%\n",
      "74\tValidation loss: 0.073152\tBest loss: 0.068456\tAccuracy: 99.06%\n",
      "75\tValidation loss: 0.128399\tBest loss: 0.068456\tAccuracy: 98.83%\n",
      "76\tValidation loss: 0.111212\tBest loss: 0.068456\tAccuracy: 98.79%\n",
      "77\tValidation loss: 0.080156\tBest loss: 0.068456\tAccuracy: 98.71%\n",
      "78\tValidation loss: 0.063347\tBest loss: 0.063347\tAccuracy: 99.18%\n",
      "79\tValidation loss: 0.075248\tBest loss: 0.063347\tAccuracy: 99.06%\n",
      "80\tValidation loss: 0.081316\tBest loss: 0.063347\tAccuracy: 98.75%\n",
      "81\tValidation loss: 0.074077\tBest loss: 0.063347\tAccuracy: 98.75%\n",
      "82\tValidation loss: 0.080799\tBest loss: 0.063347\tAccuracy: 99.10%\n",
      "83\tValidation loss: 0.065427\tBest loss: 0.063347\tAccuracy: 99.26%\n",
      "84\tValidation loss: 0.109154\tBest loss: 0.063347\tAccuracy: 98.59%\n",
      "85\tValidation loss: 0.075400\tBest loss: 0.063347\tAccuracy: 99.06%\n",
      "86\tValidation loss: 0.074072\tBest loss: 0.063347\tAccuracy: 98.83%\n",
      "87\tValidation loss: 0.088944\tBest loss: 0.063347\tAccuracy: 98.87%\n",
      "88\tValidation loss: 0.072802\tBest loss: 0.063347\tAccuracy: 98.98%\n",
      "89\tValidation loss: 0.114511\tBest loss: 0.063347\tAccuracy: 98.91%\n",
      "90\tValidation loss: 0.087510\tBest loss: 0.063347\tAccuracy: 98.91%\n",
      "91\tValidation loss: 0.114301\tBest loss: 0.063347\tAccuracy: 98.63%\n",
      "92\tValidation loss: 0.136564\tBest loss: 0.063347\tAccuracy: 98.55%\n",
      "93\tValidation loss: 0.103288\tBest loss: 0.063347\tAccuracy: 98.87%\n",
      "94\tValidation loss: 0.072262\tBest loss: 0.063347\tAccuracy: 98.91%\n",
      "95\tValidation loss: 0.068705\tBest loss: 0.063347\tAccuracy: 99.10%\n",
      "96\tValidation loss: 0.072798\tBest loss: 0.063347\tAccuracy: 99.10%\n",
      "97\tValidation loss: 0.083380\tBest loss: 0.063347\tAccuracy: 99.22%\n",
      "98\tValidation loss: 0.086266\tBest loss: 0.063347\tAccuracy: 99.10%\n",
      "99\tValidation loss: 0.114073\tBest loss: 0.063347\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 3.8min\n",
      "[CV] n_neurons=120, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 6.837966\tBest loss: 6.837966\tAccuracy: 96.33%\n",
      "1\tValidation loss: 2.302394\tBest loss: 2.302394\tAccuracy: 96.56%\n",
      "2\tValidation loss: 2.588918\tBest loss: 2.302394\tAccuracy: 95.93%\n",
      "3\tValidation loss: 1.866980\tBest loss: 1.866980\tAccuracy: 96.87%\n",
      "4\tValidation loss: 1.724703\tBest loss: 1.724703\tAccuracy: 96.05%\n",
      "5\tValidation loss: 0.621009\tBest loss: 0.621009\tAccuracy: 97.62%\n",
      "6\tValidation loss: 0.932723\tBest loss: 0.621009\tAccuracy: 96.36%\n",
      "7\tValidation loss: 0.352494\tBest loss: 0.352494\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.456840\tBest loss: 0.352494\tAccuracy: 97.77%\n",
      "9\tValidation loss: 0.413621\tBest loss: 0.352494\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.334816\tBest loss: 0.334816\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.313298\tBest loss: 0.313298\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.307143\tBest loss: 0.307143\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.173724\tBest loss: 0.173724\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.268919\tBest loss: 0.173724\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.350216\tBest loss: 0.173724\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.244363\tBest loss: 0.173724\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.284446\tBest loss: 0.173724\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.337297\tBest loss: 0.173724\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.203884\tBest loss: 0.173724\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.179364\tBest loss: 0.173724\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.269785\tBest loss: 0.173724\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.156373\tBest loss: 0.156373\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.247358\tBest loss: 0.156373\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.187507\tBest loss: 0.156373\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.292582\tBest loss: 0.156373\tAccuracy: 98.36%\n",
      "26\tValidation loss: 0.417302\tBest loss: 0.156373\tAccuracy: 97.34%\n",
      "27\tValidation loss: 0.188820\tBest loss: 0.156373\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.145350\tBest loss: 0.145350\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.259837\tBest loss: 0.145350\tAccuracy: 98.16%\n",
      "30\tValidation loss: 0.285161\tBest loss: 0.145350\tAccuracy: 97.85%\n",
      "31\tValidation loss: 0.116631\tBest loss: 0.116631\tAccuracy: 98.71%\n",
      "32\tValidation loss: 0.181828\tBest loss: 0.116631\tAccuracy: 98.28%\n",
      "33\tValidation loss: 0.106679\tBest loss: 0.106679\tAccuracy: 99.10%\n",
      "34\tValidation loss: 0.121630\tBest loss: 0.106679\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.175417\tBest loss: 0.106679\tAccuracy: 98.63%\n",
      "36\tValidation loss: 0.136567\tBest loss: 0.106679\tAccuracy: 99.06%\n",
      "37\tValidation loss: 0.125995\tBest loss: 0.106679\tAccuracy: 99.10%\n",
      "38\tValidation loss: 0.322012\tBest loss: 0.106679\tAccuracy: 97.93%\n",
      "39\tValidation loss: 0.174226\tBest loss: 0.106679\tAccuracy: 98.91%\n",
      "40\tValidation loss: 0.096553\tBest loss: 0.096553\tAccuracy: 99.02%\n",
      "41\tValidation loss: 0.115009\tBest loss: 0.096553\tAccuracy: 98.83%\n",
      "42\tValidation loss: 0.139455\tBest loss: 0.096553\tAccuracy: 98.94%\n",
      "43\tValidation loss: 0.164981\tBest loss: 0.096553\tAccuracy: 98.67%\n",
      "44\tValidation loss: 0.220950\tBest loss: 0.096553\tAccuracy: 96.99%\n",
      "45\tValidation loss: 0.252611\tBest loss: 0.096553\tAccuracy: 98.36%\n",
      "46\tValidation loss: 0.143120\tBest loss: 0.096553\tAccuracy: 98.79%\n",
      "47\tValidation loss: 0.090771\tBest loss: 0.090771\tAccuracy: 99.02%\n",
      "48\tValidation loss: 0.136755\tBest loss: 0.090771\tAccuracy: 99.10%\n",
      "49\tValidation loss: 0.109265\tBest loss: 0.090771\tAccuracy: 98.91%\n",
      "50\tValidation loss: 0.117930\tBest loss: 0.090771\tAccuracy: 98.83%\n",
      "51\tValidation loss: 0.138318\tBest loss: 0.090771\tAccuracy: 98.75%\n",
      "52\tValidation loss: 0.121906\tBest loss: 0.090771\tAccuracy: 98.87%\n",
      "53\tValidation loss: 0.074955\tBest loss: 0.074955\tAccuracy: 99.18%\n",
      "54\tValidation loss: 0.086042\tBest loss: 0.074955\tAccuracy: 99.22%\n",
      "55\tValidation loss: 0.105537\tBest loss: 0.074955\tAccuracy: 98.59%\n",
      "56\tValidation loss: 0.083379\tBest loss: 0.074955\tAccuracy: 99.06%\n",
      "57\tValidation loss: 0.107599\tBest loss: 0.074955\tAccuracy: 98.98%\n",
      "58\tValidation loss: 0.121511\tBest loss: 0.074955\tAccuracy: 98.94%\n",
      "59\tValidation loss: 0.097287\tBest loss: 0.074955\tAccuracy: 98.75%\n",
      "60\tValidation loss: 0.105723\tBest loss: 0.074955\tAccuracy: 99.14%\n",
      "61\tValidation loss: 0.094773\tBest loss: 0.074955\tAccuracy: 98.91%\n",
      "62\tValidation loss: 0.087921\tBest loss: 0.074955\tAccuracy: 98.94%\n",
      "63\tValidation loss: 0.111458\tBest loss: 0.074955\tAccuracy: 98.79%\n",
      "64\tValidation loss: 0.109616\tBest loss: 0.074955\tAccuracy: 98.59%\n",
      "65\tValidation loss: 0.089649\tBest loss: 0.074955\tAccuracy: 98.63%\n",
      "66\tValidation loss: 0.088088\tBest loss: 0.074955\tAccuracy: 98.91%\n",
      "67\tValidation loss: 6.809287\tBest loss: 0.074955\tAccuracy: 74.55%\n",
      "68\tValidation loss: 0.149628\tBest loss: 0.074955\tAccuracy: 98.75%\n",
      "69\tValidation loss: 0.185468\tBest loss: 0.074955\tAccuracy: 98.59%\n",
      "70\tValidation loss: 0.068456\tBest loss: 0.068456\tAccuracy: 99.30%\n",
      "71\tValidation loss: 0.077845\tBest loss: 0.068456\tAccuracy: 98.83%\n",
      "72\tValidation loss: 0.071522\tBest loss: 0.068456\tAccuracy: 99.10%\n",
      "73\tValidation loss: 0.068142\tBest loss: 0.068142\tAccuracy: 99.14%\n",
      "74\tValidation loss: 0.098021\tBest loss: 0.068142\tAccuracy: 98.83%\n",
      "75\tValidation loss: 0.067433\tBest loss: 0.067433\tAccuracy: 99.22%\n",
      "76\tValidation loss: 0.094644\tBest loss: 0.067433\tAccuracy: 98.98%\n",
      "77\tValidation loss: 0.082467\tBest loss: 0.067433\tAccuracy: 99.10%\n",
      "78\tValidation loss: 0.054095\tBest loss: 0.054095\tAccuracy: 99.37%\n",
      "79\tValidation loss: 0.070975\tBest loss: 0.054095\tAccuracy: 99.06%\n",
      "80\tValidation loss: 0.063915\tBest loss: 0.054095\tAccuracy: 99.22%\n",
      "81\tValidation loss: 0.102776\tBest loss: 0.054095\tAccuracy: 98.59%\n",
      "82\tValidation loss: 0.087985\tBest loss: 0.054095\tAccuracy: 99.18%\n",
      "83\tValidation loss: 0.075249\tBest loss: 0.054095\tAccuracy: 99.06%\n",
      "84\tValidation loss: 7.022431\tBest loss: 0.054095\tAccuracy: 57.43%\n",
      "85\tValidation loss: 10.902169\tBest loss: 0.054095\tAccuracy: 75.18%\n",
      "86\tValidation loss: 0.423836\tBest loss: 0.054095\tAccuracy: 93.59%\n",
      "87\tValidation loss: 0.160835\tBest loss: 0.054095\tAccuracy: 97.50%\n",
      "88\tValidation loss: 0.112894\tBest loss: 0.054095\tAccuracy: 98.67%\n",
      "89\tValidation loss: 0.102529\tBest loss: 0.054095\tAccuracy: 98.91%\n",
      "90\tValidation loss: 0.077498\tBest loss: 0.054095\tAccuracy: 99.06%\n",
      "91\tValidation loss: 0.085634\tBest loss: 0.054095\tAccuracy: 99.18%\n",
      "92\tValidation loss: 0.109808\tBest loss: 0.054095\tAccuracy: 98.94%\n",
      "93\tValidation loss: 0.077842\tBest loss: 0.054095\tAccuracy: 98.98%\n",
      "94\tValidation loss: 0.091772\tBest loss: 0.054095\tAccuracy: 98.83%\n",
      "95\tValidation loss: 0.095704\tBest loss: 0.054095\tAccuracy: 98.87%\n",
      "96\tValidation loss: 0.107526\tBest loss: 0.054095\tAccuracy: 98.48%\n",
      "97\tValidation loss: 0.078349\tBest loss: 0.054095\tAccuracy: 98.91%\n",
      "98\tValidation loss: 0.069366\tBest loss: 0.054095\tAccuracy: 99.10%\n",
      "99\tValidation loss: 0.109369\tBest loss: 0.054095\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.05, batch_size=100, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 3.7min\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.088624\tBest loss: 0.088624\tAccuracy: 97.34%\n",
      "1\tValidation loss: 0.062253\tBest loss: 0.062253\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.054737\tBest loss: 0.054737\tAccuracy: 98.40%\n",
      "3\tValidation loss: 0.051029\tBest loss: 0.051029\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.046218\tBest loss: 0.046218\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.047659\tBest loss: 0.046218\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.054659\tBest loss: 0.046218\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.034843\tBest loss: 0.034843\tAccuracy: 98.91%\n",
      "8\tValidation loss: 0.050137\tBest loss: 0.034843\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.044115\tBest loss: 0.034843\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.063667\tBest loss: 0.034843\tAccuracy: 98.24%\n",
      "11\tValidation loss: 0.041217\tBest loss: 0.034843\tAccuracy: 98.94%\n",
      "12\tValidation loss: 0.038451\tBest loss: 0.034843\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.040121\tBest loss: 0.034843\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.044596\tBest loss: 0.034843\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.042830\tBest loss: 0.034843\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.048676\tBest loss: 0.034843\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.058322\tBest loss: 0.034843\tAccuracy: 98.83%\n",
      "18\tValidation loss: 0.050721\tBest loss: 0.034843\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.056851\tBest loss: 0.034843\tAccuracy: 98.55%\n",
      "20\tValidation loss: 0.051533\tBest loss: 0.034843\tAccuracy: 98.94%\n",
      "21\tValidation loss: 0.053966\tBest loss: 0.034843\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.062574\tBest loss: 0.034843\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.055673\tBest loss: 0.034843\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.054527\tBest loss: 0.034843\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.051459\tBest loss: 0.034843\tAccuracy: 98.91%\n",
      "26\tValidation loss: 0.071218\tBest loss: 0.034843\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.050610\tBest loss: 0.034843\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.043563\tBest loss: 0.034843\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 1.5min\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.086684\tBest loss: 0.086684\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.073487\tBest loss: 0.073487\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.049072\tBest loss: 0.049072\tAccuracy: 98.48%\n",
      "3\tValidation loss: 0.041644\tBest loss: 0.041644\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.057522\tBest loss: 0.041644\tAccuracy: 98.36%\n",
      "5\tValidation loss: 0.044954\tBest loss: 0.041644\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.050509\tBest loss: 0.041644\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.041776\tBest loss: 0.041644\tAccuracy: 98.94%\n",
      "8\tValidation loss: 0.045894\tBest loss: 0.041644\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.052949\tBest loss: 0.041644\tAccuracy: 98.24%\n",
      "10\tValidation loss: 0.039700\tBest loss: 0.039700\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.043492\tBest loss: 0.039700\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.033268\tBest loss: 0.033268\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.046600\tBest loss: 0.033268\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.043848\tBest loss: 0.033268\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.037911\tBest loss: 0.033268\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.054606\tBest loss: 0.033268\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.041452\tBest loss: 0.033268\tAccuracy: 99.18%\n",
      "18\tValidation loss: 0.041811\tBest loss: 0.033268\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.053579\tBest loss: 0.033268\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.055684\tBest loss: 0.033268\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.043469\tBest loss: 0.033268\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.045719\tBest loss: 0.033268\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.060713\tBest loss: 0.033268\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.044483\tBest loss: 0.033268\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.049668\tBest loss: 0.033268\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.070457\tBest loss: 0.033268\tAccuracy: 98.59%\n",
      "27\tValidation loss: 0.044831\tBest loss: 0.033268\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.051879\tBest loss: 0.033268\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.056548\tBest loss: 0.033268\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.057307\tBest loss: 0.033268\tAccuracy: 98.75%\n",
      "31\tValidation loss: 0.045638\tBest loss: 0.033268\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.050561\tBest loss: 0.033268\tAccuracy: 99.10%\n",
      "33\tValidation loss: 0.047686\tBest loss: 0.033268\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 1.7min\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.096155\tBest loss: 0.096155\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.079999\tBest loss: 0.079999\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.088860\tBest loss: 0.079999\tAccuracy: 97.65%\n",
      "3\tValidation loss: 0.041149\tBest loss: 0.041149\tAccuracy: 98.63%\n",
      "4\tValidation loss: 0.058424\tBest loss: 0.041149\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.048616\tBest loss: 0.041149\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.045494\tBest loss: 0.041149\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.035852\tBest loss: 0.035852\tAccuracy: 98.91%\n",
      "8\tValidation loss: 0.074631\tBest loss: 0.035852\tAccuracy: 98.05%\n",
      "9\tValidation loss: 0.043423\tBest loss: 0.035852\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.048186\tBest loss: 0.035852\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.043169\tBest loss: 0.035852\tAccuracy: 98.87%\n",
      "12\tValidation loss: 0.039451\tBest loss: 0.035852\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.042204\tBest loss: 0.035852\tAccuracy: 99.18%\n",
      "14\tValidation loss: 0.043352\tBest loss: 0.035852\tAccuracy: 99.02%\n",
      "15\tValidation loss: 0.038010\tBest loss: 0.035852\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.039963\tBest loss: 0.035852\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.042159\tBest loss: 0.035852\tAccuracy: 99.06%\n",
      "18\tValidation loss: 0.037969\tBest loss: 0.035852\tAccuracy: 99.14%\n",
      "19\tValidation loss: 0.048715\tBest loss: 0.035852\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.042630\tBest loss: 0.035852\tAccuracy: 99.02%\n",
      "21\tValidation loss: 0.031737\tBest loss: 0.031737\tAccuracy: 99.22%\n",
      "22\tValidation loss: 0.036675\tBest loss: 0.031737\tAccuracy: 99.34%\n",
      "23\tValidation loss: 0.039209\tBest loss: 0.031737\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.045701\tBest loss: 0.031737\tAccuracy: 99.22%\n",
      "25\tValidation loss: 0.041924\tBest loss: 0.031737\tAccuracy: 99.14%\n",
      "26\tValidation loss: 0.048514\tBest loss: 0.031737\tAccuracy: 99.10%\n",
      "27\tValidation loss: 0.053229\tBest loss: 0.031737\tAccuracy: 99.18%\n",
      "28\tValidation loss: 0.056197\tBest loss: 0.031737\tAccuracy: 98.79%\n",
      "29\tValidation loss: 0.060953\tBest loss: 0.031737\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.052717\tBest loss: 0.031737\tAccuracy: 98.98%\n",
      "31\tValidation loss: 0.037014\tBest loss: 0.031737\tAccuracy: 99.18%\n",
      "32\tValidation loss: 0.062979\tBest loss: 0.031737\tAccuracy: 98.79%\n",
      "33\tValidation loss: 0.042676\tBest loss: 0.031737\tAccuracy: 99.10%\n",
      "34\tValidation loss: 0.048222\tBest loss: 0.031737\tAccuracy: 99.02%\n",
      "35\tValidation loss: 0.037357\tBest loss: 0.031737\tAccuracy: 99.34%\n",
      "36\tValidation loss: 0.050226\tBest loss: 0.031737\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.057587\tBest loss: 0.031737\tAccuracy: 98.94%\n",
      "38\tValidation loss: 0.044515\tBest loss: 0.031737\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.042744\tBest loss: 0.031737\tAccuracy: 99.18%\n",
      "40\tValidation loss: 0.063134\tBest loss: 0.031737\tAccuracy: 99.02%\n",
      "41\tValidation loss: 0.070445\tBest loss: 0.031737\tAccuracy: 98.98%\n",
      "42\tValidation loss: 0.047480\tBest loss: 0.031737\tAccuracy: 99.26%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 2.2min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.168295\tBest loss: 0.168295\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.081845\tBest loss: 0.081845\tAccuracy: 97.81%\n",
      "2\tValidation loss: 0.051883\tBest loss: 0.051883\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.049582\tBest loss: 0.049582\tAccuracy: 98.67%\n",
      "4\tValidation loss: 0.063891\tBest loss: 0.049582\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.076003\tBest loss: 0.049582\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.043694\tBest loss: 0.043694\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.044916\tBest loss: 0.043694\tAccuracy: 99.10%\n",
      "8\tValidation loss: 0.046908\tBest loss: 0.043694\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.062531\tBest loss: 0.043694\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.079677\tBest loss: 0.043694\tAccuracy: 97.89%\n",
      "11\tValidation loss: 0.045359\tBest loss: 0.043694\tAccuracy: 98.94%\n",
      "12\tValidation loss: 0.055839\tBest loss: 0.043694\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.040682\tBest loss: 0.040682\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.034193\tBest loss: 0.034193\tAccuracy: 99.26%\n",
      "15\tValidation loss: 0.036062\tBest loss: 0.034193\tAccuracy: 99.22%\n",
      "16\tValidation loss: 0.041866\tBest loss: 0.034193\tAccuracy: 99.10%\n",
      "17\tValidation loss: 0.046736\tBest loss: 0.034193\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.045491\tBest loss: 0.034193\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.040353\tBest loss: 0.034193\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.051876\tBest loss: 0.034193\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.043229\tBest loss: 0.034193\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.038559\tBest loss: 0.034193\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.037320\tBest loss: 0.034193\tAccuracy: 99.26%\n",
      "24\tValidation loss: 0.046719\tBest loss: 0.034193\tAccuracy: 99.10%\n",
      "25\tValidation loss: 0.033819\tBest loss: 0.033819\tAccuracy: 99.34%\n",
      "26\tValidation loss: 0.037842\tBest loss: 0.033819\tAccuracy: 99.22%\n",
      "27\tValidation loss: 0.036995\tBest loss: 0.033819\tAccuracy: 99.30%\n",
      "28\tValidation loss: 0.036981\tBest loss: 0.033819\tAccuracy: 99.18%\n",
      "29\tValidation loss: 0.039192\tBest loss: 0.033819\tAccuracy: 99.22%\n",
      "30\tValidation loss: 0.043041\tBest loss: 0.033819\tAccuracy: 99.30%\n",
      "31\tValidation loss: 0.049164\tBest loss: 0.033819\tAccuracy: 99.10%\n",
      "32\tValidation loss: 0.122907\tBest loss: 0.033819\tAccuracy: 97.89%\n",
      "33\tValidation loss: 0.065066\tBest loss: 0.033819\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.086946\tBest loss: 0.033819\tAccuracy: 98.28%\n",
      "35\tValidation loss: 0.063394\tBest loss: 0.033819\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.057608\tBest loss: 0.033819\tAccuracy: 98.91%\n",
      "37\tValidation loss: 0.060138\tBest loss: 0.033819\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.057397\tBest loss: 0.033819\tAccuracy: 98.83%\n",
      "39\tValidation loss: 0.040155\tBest loss: 0.033819\tAccuracy: 99.14%\n",
      "40\tValidation loss: 0.043839\tBest loss: 0.033819\tAccuracy: 99.22%\n",
      "41\tValidation loss: 0.046499\tBest loss: 0.033819\tAccuracy: 99.14%\n",
      "42\tValidation loss: 0.045846\tBest loss: 0.033819\tAccuracy: 99.14%\n",
      "43\tValidation loss: 0.045171\tBest loss: 0.033819\tAccuracy: 99.22%\n",
      "44\tValidation loss: 0.045972\tBest loss: 0.033819\tAccuracy: 99.22%\n",
      "45\tValidation loss: 0.046357\tBest loss: 0.033819\tAccuracy: 99.18%\n",
      "46\tValidation loss: 0.047147\tBest loss: 0.033819\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.0min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.221507\tBest loss: 0.221507\tAccuracy: 95.74%\n",
      "1\tValidation loss: 0.062766\tBest loss: 0.062766\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.075228\tBest loss: 0.062766\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.064315\tBest loss: 0.062766\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.064894\tBest loss: 0.062766\tAccuracy: 98.36%\n",
      "5\tValidation loss: 0.047889\tBest loss: 0.047889\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.062234\tBest loss: 0.047889\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.032452\tBest loss: 0.032452\tAccuracy: 99.14%\n",
      "8\tValidation loss: 0.045441\tBest loss: 0.032452\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.041570\tBest loss: 0.032452\tAccuracy: 99.06%\n",
      "10\tValidation loss: 0.048771\tBest loss: 0.032452\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.052725\tBest loss: 0.032452\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.050036\tBest loss: 0.032452\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.049818\tBest loss: 0.032452\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.083472\tBest loss: 0.032452\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.053127\tBest loss: 0.032452\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.040483\tBest loss: 0.032452\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.042349\tBest loss: 0.032452\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.079804\tBest loss: 0.032452\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.074369\tBest loss: 0.032452\tAccuracy: 98.67%\n",
      "20\tValidation loss: 0.054956\tBest loss: 0.032452\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.048350\tBest loss: 0.032452\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.053647\tBest loss: 0.032452\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.055580\tBest loss: 0.032452\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.056111\tBest loss: 0.032452\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.043545\tBest loss: 0.032452\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.048992\tBest loss: 0.032452\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.059492\tBest loss: 0.032452\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.041042\tBest loss: 0.032452\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total=  38.6s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.149914\tBest loss: 0.149914\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.053150\tBest loss: 0.053150\tAccuracy: 98.44%\n",
      "2\tValidation loss: 0.050869\tBest loss: 0.050869\tAccuracy: 98.63%\n",
      "3\tValidation loss: 0.053812\tBest loss: 0.050869\tAccuracy: 98.83%\n",
      "4\tValidation loss: 0.049992\tBest loss: 0.049992\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.035993\tBest loss: 0.035993\tAccuracy: 98.79%\n",
      "6\tValidation loss: 0.032987\tBest loss: 0.032987\tAccuracy: 98.91%\n",
      "7\tValidation loss: 0.055341\tBest loss: 0.032987\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.088554\tBest loss: 0.032987\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.064184\tBest loss: 0.032987\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.056734\tBest loss: 0.032987\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.057246\tBest loss: 0.032987\tAccuracy: 98.87%\n",
      "12\tValidation loss: 0.048585\tBest loss: 0.032987\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.053674\tBest loss: 0.032987\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.040766\tBest loss: 0.032987\tAccuracy: 99.18%\n",
      "15\tValidation loss: 0.038200\tBest loss: 0.032987\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.060498\tBest loss: 0.032987\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.046573\tBest loss: 0.032987\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.047785\tBest loss: 0.032987\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.043632\tBest loss: 0.032987\tAccuracy: 99.02%\n",
      "20\tValidation loss: 0.069298\tBest loss: 0.032987\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.041263\tBest loss: 0.032987\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.041422\tBest loss: 0.032987\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.041362\tBest loss: 0.032987\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.040001\tBest loss: 0.032987\tAccuracy: 98.83%\n",
      "25\tValidation loss: 0.040956\tBest loss: 0.032987\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.035570\tBest loss: 0.032987\tAccuracy: 99.26%\n",
      "27\tValidation loss: 0.074090\tBest loss: 0.032987\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.98, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total=  37.5s\n",
      "[CV] n_neurons=70, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.070292\tBest loss: 0.070292\tAccuracy: 97.97%\n",
      "1\tValidation loss: 0.095272\tBest loss: 0.070292\tAccuracy: 97.07%\n",
      "2\tValidation loss: 0.046771\tBest loss: 0.046771\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.069093\tBest loss: 0.046771\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.054902\tBest loss: 0.046771\tAccuracy: 98.55%\n",
      "5\tValidation loss: 0.053942\tBest loss: 0.046771\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.087254\tBest loss: 0.046771\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.039336\tBest loss: 0.039336\tAccuracy: 99.02%\n",
      "8\tValidation loss: 0.042024\tBest loss: 0.039336\tAccuracy: 98.98%\n",
      "9\tValidation loss: 0.055468\tBest loss: 0.039336\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.038359\tBest loss: 0.038359\tAccuracy: 99.02%\n",
      "11\tValidation loss: 0.047228\tBest loss: 0.038359\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.068966\tBest loss: 0.038359\tAccuracy: 98.28%\n",
      "13\tValidation loss: 0.045650\tBest loss: 0.038359\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.060335\tBest loss: 0.038359\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.046783\tBest loss: 0.038359\tAccuracy: 99.10%\n",
      "16\tValidation loss: 0.051026\tBest loss: 0.038359\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.047053\tBest loss: 0.038359\tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.053887\tBest loss: 0.038359\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.046085\tBest loss: 0.038359\tAccuracy: 98.75%\n",
      "20\tValidation loss: 0.049440\tBest loss: 0.038359\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.058931\tBest loss: 0.038359\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.045800\tBest loss: 0.038359\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.036709\tBest loss: 0.036709\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.042695\tBest loss: 0.036709\tAccuracy: 98.83%\n",
      "25\tValidation loss: 0.041314\tBest loss: 0.036709\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.057636\tBest loss: 0.036709\tAccuracy: 98.79%\n",
      "27\tValidation loss: 0.047774\tBest loss: 0.036709\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.043116\tBest loss: 0.036709\tAccuracy: 98.98%\n",
      "29\tValidation loss: 0.043080\tBest loss: 0.036709\tAccuracy: 99.02%\n",
      "30\tValidation loss: 0.052363\tBest loss: 0.036709\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.047215\tBest loss: 0.036709\tAccuracy: 98.98%\n",
      "32\tValidation loss: 0.046736\tBest loss: 0.036709\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.042968\tBest loss: 0.036709\tAccuracy: 99.14%\n",
      "34\tValidation loss: 0.044669\tBest loss: 0.036709\tAccuracy: 99.10%\n",
      "35\tValidation loss: 0.043923\tBest loss: 0.036709\tAccuracy: 99.14%\n",
      "36\tValidation loss: 0.044458\tBest loss: 0.036709\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.046377\tBest loss: 0.036709\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.049028\tBest loss: 0.036709\tAccuracy: 99.14%\n",
      "39\tValidation loss: 0.045257\tBest loss: 0.036709\tAccuracy: 98.94%\n",
      "40\tValidation loss: 0.057647\tBest loss: 0.036709\tAccuracy: 98.83%\n",
      "41\tValidation loss: 0.035990\tBest loss: 0.035990\tAccuracy: 98.98%\n",
      "42\tValidation loss: 0.042309\tBest loss: 0.035990\tAccuracy: 99.10%\n",
      "43\tValidation loss: 0.044360\tBest loss: 0.035990\tAccuracy: 98.87%\n",
      "44\tValidation loss: 0.035473\tBest loss: 0.035473\tAccuracy: 99.18%\n",
      "45\tValidation loss: 0.047288\tBest loss: 0.035473\tAccuracy: 99.02%\n",
      "46\tValidation loss: 0.048103\tBest loss: 0.035473\tAccuracy: 98.94%\n",
      "47\tValidation loss: 0.048921\tBest loss: 0.035473\tAccuracy: 99.14%\n",
      "48\tValidation loss: 0.043357\tBest loss: 0.035473\tAccuracy: 99.06%\n",
      "49\tValidation loss: 0.040042\tBest loss: 0.035473\tAccuracy: 99.18%\n",
      "50\tValidation loss: 0.039545\tBest loss: 0.035473\tAccuracy: 98.91%\n",
      "51\tValidation loss: 0.047173\tBest loss: 0.035473\tAccuracy: 98.83%\n",
      "52\tValidation loss: 0.046515\tBest loss: 0.035473\tAccuracy: 98.75%\n",
      "53\tValidation loss: 0.056887\tBest loss: 0.035473\tAccuracy: 98.75%\n",
      "54\tValidation loss: 0.051729\tBest loss: 0.035473\tAccuracy: 98.94%\n",
      "55\tValidation loss: 0.046901\tBest loss: 0.035473\tAccuracy: 99.02%\n",
      "56\tValidation loss: 0.055002\tBest loss: 0.035473\tAccuracy: 98.94%\n",
      "57\tValidation loss: 0.048271\tBest loss: 0.035473\tAccuracy: 99.02%\n",
      "58\tValidation loss: 0.041196\tBest loss: 0.035473\tAccuracy: 99.14%\n",
      "59\tValidation loss: 0.042108\tBest loss: 0.035473\tAccuracy: 98.98%\n",
      "60\tValidation loss: 0.044759\tBest loss: 0.035473\tAccuracy: 99.06%\n",
      "61\tValidation loss: 0.047033\tBest loss: 0.035473\tAccuracy: 99.10%\n",
      "62\tValidation loss: 0.046350\tBest loss: 0.035473\tAccuracy: 99.06%\n",
      "63\tValidation loss: 0.058994\tBest loss: 0.035473\tAccuracy: 98.71%\n",
      "64\tValidation loss: 0.054130\tBest loss: 0.035473\tAccuracy: 99.06%\n",
      "65\tValidation loss: 0.054240\tBest loss: 0.035473\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total= 2.9min\n",
      "[CV] n_neurons=70, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.064155\tBest loss: 0.064155\tAccuracy: 98.08%\n",
      "1\tValidation loss: 0.062193\tBest loss: 0.062193\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.057530\tBest loss: 0.057530\tAccuracy: 98.40%\n",
      "3\tValidation loss: 0.044306\tBest loss: 0.044306\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.066437\tBest loss: 0.044306\tAccuracy: 98.40%\n",
      "5\tValidation loss: 0.056756\tBest loss: 0.044306\tAccuracy: 98.20%\n",
      "6\tValidation loss: 0.036981\tBest loss: 0.036981\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.042438\tBest loss: 0.036981\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.037908\tBest loss: 0.036981\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.034742\tBest loss: 0.034742\tAccuracy: 99.18%\n",
      "10\tValidation loss: 0.032522\tBest loss: 0.032522\tAccuracy: 99.10%\n",
      "11\tValidation loss: 0.049726\tBest loss: 0.032522\tAccuracy: 98.79%\n",
      "12\tValidation loss: 0.038582\tBest loss: 0.032522\tAccuracy: 99.10%\n",
      "13\tValidation loss: 0.051313\tBest loss: 0.032522\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.051051\tBest loss: 0.032522\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.052956\tBest loss: 0.032522\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.044822\tBest loss: 0.032522\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.056974\tBest loss: 0.032522\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.048504\tBest loss: 0.032522\tAccuracy: 99.02%\n",
      "19\tValidation loss: 0.058213\tBest loss: 0.032522\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.040374\tBest loss: 0.032522\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.068715\tBest loss: 0.032522\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.036355\tBest loss: 0.032522\tAccuracy: 99.18%\n",
      "23\tValidation loss: 0.045996\tBest loss: 0.032522\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.036839\tBest loss: 0.032522\tAccuracy: 99.34%\n",
      "25\tValidation loss: 0.056402\tBest loss: 0.032522\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.051948\tBest loss: 0.032522\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.048540\tBest loss: 0.032522\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.055340\tBest loss: 0.032522\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.050237\tBest loss: 0.032522\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.057011\tBest loss: 0.032522\tAccuracy: 99.02%\n",
      "31\tValidation loss: 0.049152\tBest loss: 0.032522\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total= 1.5min\n",
      "[CV] n_neurons=70, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.095058\tBest loss: 0.095058\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.064359\tBest loss: 0.064359\tAccuracy: 98.28%\n",
      "2\tValidation loss: 0.049660\tBest loss: 0.049660\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.045887\tBest loss: 0.045887\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.059139\tBest loss: 0.045887\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.049400\tBest loss: 0.045887\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.058422\tBest loss: 0.045887\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.040970\tBest loss: 0.040970\tAccuracy: 98.91%\n",
      "8\tValidation loss: 0.052071\tBest loss: 0.040970\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.045130\tBest loss: 0.040970\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.040682\tBest loss: 0.040682\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.053470\tBest loss: 0.040682\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.048870\tBest loss: 0.040682\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.047082\tBest loss: 0.040682\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.046309\tBest loss: 0.040682\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.035189\tBest loss: 0.035189\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.036687\tBest loss: 0.035189\tAccuracy: 99.10%\n",
      "17\tValidation loss: 0.052829\tBest loss: 0.035189\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.038226\tBest loss: 0.035189\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.039349\tBest loss: 0.035189\tAccuracy: 99.10%\n",
      "20\tValidation loss: 0.047675\tBest loss: 0.035189\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.025868\tBest loss: 0.025868\tAccuracy: 99.26%\n",
      "22\tValidation loss: 0.037619\tBest loss: 0.025868\tAccuracy: 99.30%\n",
      "23\tValidation loss: 0.040345\tBest loss: 0.025868\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.040502\tBest loss: 0.025868\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.046781\tBest loss: 0.025868\tAccuracy: 99.02%\n",
      "26\tValidation loss: 0.044844\tBest loss: 0.025868\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.065475\tBest loss: 0.025868\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.046597\tBest loss: 0.025868\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.042465\tBest loss: 0.025868\tAccuracy: 98.98%\n",
      "30\tValidation loss: 0.036855\tBest loss: 0.025868\tAccuracy: 99.18%\n",
      "31\tValidation loss: 0.036555\tBest loss: 0.025868\tAccuracy: 99.06%\n",
      "32\tValidation loss: 0.040578\tBest loss: 0.025868\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.043280\tBest loss: 0.025868\tAccuracy: 99.02%\n",
      "34\tValidation loss: 0.034182\tBest loss: 0.025868\tAccuracy: 99.22%\n",
      "35\tValidation loss: 0.038230\tBest loss: 0.025868\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.045422\tBest loss: 0.025868\tAccuracy: 98.94%\n",
      "37\tValidation loss: 0.051354\tBest loss: 0.025868\tAccuracy: 98.94%\n",
      "38\tValidation loss: 0.042234\tBest loss: 0.025868\tAccuracy: 99.06%\n",
      "39\tValidation loss: 0.029408\tBest loss: 0.025868\tAccuracy: 99.37%\n",
      "40\tValidation loss: 0.041961\tBest loss: 0.025868\tAccuracy: 99.14%\n",
      "41\tValidation loss: 0.044312\tBest loss: 0.025868\tAccuracy: 99.06%\n",
      "42\tValidation loss: 0.045509\tBest loss: 0.025868\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.02, batch_size=50, batch_norm_momentum=0.95, activation=<function relu at 0x7fabf3f8d0d0>, total= 1.9min\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.610748\tBest loss: 0.610748\tAccuracy: 92.53%\n",
      "1\tValidation loss: 0.547581\tBest loss: 0.547581\tAccuracy: 93.63%\n",
      "2\tValidation loss: 0.766693\tBest loss: 0.547581\tAccuracy: 89.68%\n",
      "3\tValidation loss: 0.421270\tBest loss: 0.421270\tAccuracy: 91.28%\n",
      "4\tValidation loss: 0.922394\tBest loss: 0.421270\tAccuracy: 87.14%\n",
      "5\tValidation loss: 0.433558\tBest loss: 0.421270\tAccuracy: 84.28%\n",
      "6\tValidation loss: 0.303837\tBest loss: 0.303837\tAccuracy: 95.86%\n",
      "7\tValidation loss: 0.078876\tBest loss: 0.078876\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.147699\tBest loss: 0.078876\tAccuracy: 95.78%\n",
      "9\tValidation loss: 0.086060\tBest loss: 0.078876\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.295785\tBest loss: 0.078876\tAccuracy: 93.67%\n",
      "11\tValidation loss: 0.146543\tBest loss: 0.078876\tAccuracy: 96.48%\n",
      "12\tValidation loss: 0.657675\tBest loss: 0.078876\tAccuracy: 92.53%\n",
      "13\tValidation loss: 0.090423\tBest loss: 0.078876\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.116600\tBest loss: 0.078876\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.147919\tBest loss: 0.078876\tAccuracy: 97.30%\n",
      "16\tValidation loss: 0.085235\tBest loss: 0.078876\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.205611\tBest loss: 0.078876\tAccuracy: 96.60%\n",
      "18\tValidation loss: 0.140212\tBest loss: 0.078876\tAccuracy: 98.24%\n",
      "19\tValidation loss: 0.066231\tBest loss: 0.066231\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.090986\tBest loss: 0.066231\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.117747\tBest loss: 0.066231\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.282637\tBest loss: 0.066231\tAccuracy: 95.47%\n",
      "23\tValidation loss: 0.204951\tBest loss: 0.066231\tAccuracy: 96.83%\n",
      "24\tValidation loss: 0.654261\tBest loss: 0.066231\tAccuracy: 94.02%\n",
      "25\tValidation loss: 0.106939\tBest loss: 0.066231\tAccuracy: 98.32%\n",
      "26\tValidation loss: 0.127437\tBest loss: 0.066231\tAccuracy: 97.58%\n",
      "27\tValidation loss: 0.087163\tBest loss: 0.066231\tAccuracy: 98.44%\n",
      "28\tValidation loss: 0.125730\tBest loss: 0.066231\tAccuracy: 98.24%\n",
      "29\tValidation loss: 0.233145\tBest loss: 0.066231\tAccuracy: 97.15%\n",
      "30\tValidation loss: 0.262090\tBest loss: 0.066231\tAccuracy: 96.72%\n",
      "31\tValidation loss: 0.122977\tBest loss: 0.066231\tAccuracy: 98.48%\n",
      "32\tValidation loss: 0.200267\tBest loss: 0.066231\tAccuracy: 97.73%\n",
      "33\tValidation loss: 0.139658\tBest loss: 0.066231\tAccuracy: 97.73%\n",
      "34\tValidation loss: 0.204296\tBest loss: 0.066231\tAccuracy: 98.05%\n",
      "35\tValidation loss: 0.124708\tBest loss: 0.066231\tAccuracy: 98.40%\n",
      "36\tValidation loss: 0.111474\tBest loss: 0.066231\tAccuracy: 98.71%\n",
      "37\tValidation loss: 0.147497\tBest loss: 0.066231\tAccuracy: 98.40%\n",
      "38\tValidation loss: 0.146709\tBest loss: 0.066231\tAccuracy: 98.36%\n",
      "39\tValidation loss: 0.138595\tBest loss: 0.066231\tAccuracy: 98.44%\n",
      "40\tValidation loss: 0.118303\tBest loss: 0.066231\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 7.7min\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.542575\tBest loss: 0.542575\tAccuracy: 94.72%\n",
      "1\tValidation loss: 2.083454\tBest loss: 0.542575\tAccuracy: 83.07%\n",
      "2\tValidation loss: 0.631968\tBest loss: 0.542575\tAccuracy: 88.78%\n",
      "3\tValidation loss: 1.253254\tBest loss: 0.542575\tAccuracy: 79.32%\n",
      "4\tValidation loss: 1.289011\tBest loss: 0.542575\tAccuracy: 86.90%\n",
      "5\tValidation loss: 0.140129\tBest loss: 0.140129\tAccuracy: 97.11%\n",
      "6\tValidation loss: 0.534311\tBest loss: 0.140129\tAccuracy: 94.18%\n",
      "7\tValidation loss: 0.151392\tBest loss: 0.140129\tAccuracy: 97.26%\n",
      "8\tValidation loss: 0.414971\tBest loss: 0.140129\tAccuracy: 92.92%\n",
      "9\tValidation loss: 1.073797\tBest loss: 0.140129\tAccuracy: 94.41%\n",
      "10\tValidation loss: 0.149475\tBest loss: 0.140129\tAccuracy: 96.36%\n",
      "11\tValidation loss: 0.158151\tBest loss: 0.140129\tAccuracy: 96.95%\n",
      "12\tValidation loss: 0.109267\tBest loss: 0.109267\tAccuracy: 98.12%\n",
      "13\tValidation loss: 0.104285\tBest loss: 0.104285\tAccuracy: 97.93%\n",
      "14\tValidation loss: 0.092688\tBest loss: 0.092688\tAccuracy: 98.32%\n",
      "15\tValidation loss: 0.275388\tBest loss: 0.092688\tAccuracy: 96.76%\n",
      "16\tValidation loss: 0.204453\tBest loss: 0.092688\tAccuracy: 98.20%\n",
      "17\tValidation loss: 0.426820\tBest loss: 0.092688\tAccuracy: 91.32%\n",
      "18\tValidation loss: 0.056529\tBest loss: 0.056529\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.119788\tBest loss: 0.056529\tAccuracy: 97.50%\n",
      "20\tValidation loss: 0.096620\tBest loss: 0.056529\tAccuracy: 98.51%\n",
      "21\tValidation loss: 0.174886\tBest loss: 0.056529\tAccuracy: 96.95%\n",
      "22\tValidation loss: 0.092786\tBest loss: 0.056529\tAccuracy: 98.51%\n",
      "23\tValidation loss: 0.120077\tBest loss: 0.056529\tAccuracy: 97.77%\n",
      "24\tValidation loss: 0.251015\tBest loss: 0.056529\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.128659\tBest loss: 0.056529\tAccuracy: 97.77%\n",
      "26\tValidation loss: 0.210280\tBest loss: 0.056529\tAccuracy: 96.72%\n",
      "27\tValidation loss: 0.115883\tBest loss: 0.056529\tAccuracy: 98.40%\n",
      "28\tValidation loss: 0.148436\tBest loss: 0.056529\tAccuracy: 97.77%\n",
      "29\tValidation loss: 0.131547\tBest loss: 0.056529\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.145910\tBest loss: 0.056529\tAccuracy: 98.16%\n",
      "31\tValidation loss: 0.103880\tBest loss: 0.056529\tAccuracy: 98.32%\n",
      "32\tValidation loss: 0.235413\tBest loss: 0.056529\tAccuracy: 97.58%\n",
      "33\tValidation loss: 0.164193\tBest loss: 0.056529\tAccuracy: 98.40%\n",
      "34\tValidation loss: 0.094909\tBest loss: 0.056529\tAccuracy: 98.48%\n",
      "35\tValidation loss: 0.125584\tBest loss: 0.056529\tAccuracy: 98.16%\n",
      "36\tValidation loss: 0.233956\tBest loss: 0.056529\tAccuracy: 97.85%\n",
      "37\tValidation loss: 0.345233\tBest loss: 0.056529\tAccuracy: 96.40%\n",
      "38\tValidation loss: 0.125508\tBest loss: 0.056529\tAccuracy: 98.67%\n",
      "39\tValidation loss: 0.114236\tBest loss: 0.056529\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 7.5min\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.823026\tBest loss: 0.823026\tAccuracy: 89.56%\n",
      "1\tValidation loss: 0.404363\tBest loss: 0.404363\tAccuracy: 95.90%\n",
      "2\tValidation loss: 0.270490\tBest loss: 0.270490\tAccuracy: 94.76%\n",
      "3\tValidation loss: 0.409216\tBest loss: 0.270490\tAccuracy: 89.13%\n",
      "4\tValidation loss: 0.244776\tBest loss: 0.244776\tAccuracy: 94.29%\n",
      "5\tValidation loss: 0.069227\tBest loss: 0.069227\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.129988\tBest loss: 0.069227\tAccuracy: 97.50%\n",
      "7\tValidation loss: 0.116647\tBest loss: 0.069227\tAccuracy: 96.56%\n",
      "8\tValidation loss: 0.262887\tBest loss: 0.069227\tAccuracy: 95.58%\n",
      "9\tValidation loss: 1.873117\tBest loss: 0.069227\tAccuracy: 85.26%\n",
      "10\tValidation loss: 0.160533\tBest loss: 0.069227\tAccuracy: 96.21%\n",
      "11\tValidation loss: 0.116700\tBest loss: 0.069227\tAccuracy: 97.15%\n",
      "12\tValidation loss: 0.186261\tBest loss: 0.069227\tAccuracy: 97.65%\n",
      "13\tValidation loss: 0.158312\tBest loss: 0.069227\tAccuracy: 97.26%\n",
      "14\tValidation loss: 0.142050\tBest loss: 0.069227\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.114085\tBest loss: 0.069227\tAccuracy: 97.65%\n",
      "16\tValidation loss: 0.151499\tBest loss: 0.069227\tAccuracy: 97.62%\n",
      "17\tValidation loss: 0.136158\tBest loss: 0.069227\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.178161\tBest loss: 0.069227\tAccuracy: 96.87%\n",
      "19\tValidation loss: 0.063659\tBest loss: 0.063659\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.160406\tBest loss: 0.063659\tAccuracy: 97.77%\n",
      "21\tValidation loss: 0.136104\tBest loss: 0.063659\tAccuracy: 97.97%\n",
      "22\tValidation loss: 0.048485\tBest loss: 0.048485\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.332973\tBest loss: 0.048485\tAccuracy: 95.90%\n",
      "24\tValidation loss: 0.060804\tBest loss: 0.048485\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.074335\tBest loss: 0.048485\tAccuracy: 98.51%\n",
      "26\tValidation loss: 0.171687\tBest loss: 0.048485\tAccuracy: 97.03%\n",
      "27\tValidation loss: 0.173861\tBest loss: 0.048485\tAccuracy: 97.77%\n",
      "28\tValidation loss: 0.238202\tBest loss: 0.048485\tAccuracy: 96.76%\n",
      "29\tValidation loss: 0.152624\tBest loss: 0.048485\tAccuracy: 98.59%\n",
      "30\tValidation loss: 0.096990\tBest loss: 0.048485\tAccuracy: 98.79%\n",
      "31\tValidation loss: 0.150078\tBest loss: 0.048485\tAccuracy: 98.01%\n",
      "32\tValidation loss: 0.174923\tBest loss: 0.048485\tAccuracy: 97.46%\n",
      "33\tValidation loss: 0.071846\tBest loss: 0.048485\tAccuracy: 98.91%\n",
      "34\tValidation loss: 0.157688\tBest loss: 0.048485\tAccuracy: 98.44%\n",
      "35\tValidation loss: 0.250962\tBest loss: 0.048485\tAccuracy: 96.25%\n",
      "36\tValidation loss: 0.235725\tBest loss: 0.048485\tAccuracy: 97.58%\n",
      "37\tValidation loss: 0.138219\tBest loss: 0.048485\tAccuracy: 98.55%\n",
      "38\tValidation loss: 0.084351\tBest loss: 0.048485\tAccuracy: 98.83%\n",
      "39\tValidation loss: 0.107786\tBest loss: 0.048485\tAccuracy: 99.02%\n",
      "40\tValidation loss: 0.318282\tBest loss: 0.048485\tAccuracy: 97.30%\n",
      "41\tValidation loss: 0.179753\tBest loss: 0.048485\tAccuracy: 98.44%\n",
      "42\tValidation loss: 0.225393\tBest loss: 0.048485\tAccuracy: 97.77%\n",
      "43\tValidation loss: 0.089535\tBest loss: 0.048485\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=10, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 8.2min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 1.576587\tBest loss: 1.576587\tAccuracy: 93.16%\n",
      "1\tValidation loss: 0.259115\tBest loss: 0.259115\tAccuracy: 96.76%\n",
      "2\tValidation loss: 0.185144\tBest loss: 0.185144\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.103151\tBest loss: 0.103151\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.091448\tBest loss: 0.091448\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.114310\tBest loss: 0.091448\tAccuracy: 98.01%\n",
      "6\tValidation loss: 0.066094\tBest loss: 0.066094\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.079985\tBest loss: 0.066094\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.081181\tBest loss: 0.066094\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.109059\tBest loss: 0.066094\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.054994\tBest loss: 0.054994\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.111327\tBest loss: 0.054994\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.063927\tBest loss: 0.054994\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.051713\tBest loss: 0.051713\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.047203\tBest loss: 0.047203\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.067806\tBest loss: 0.047203\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.065895\tBest loss: 0.047203\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.088219\tBest loss: 0.047203\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.067884\tBest loss: 0.047203\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.066965\tBest loss: 0.047203\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.050226\tBest loss: 0.047203\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.081559\tBest loss: 0.047203\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.060927\tBest loss: 0.047203\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.062716\tBest loss: 0.047203\tAccuracy: 98.67%\n",
      "24\tValidation loss: 0.064716\tBest loss: 0.047203\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.062758\tBest loss: 0.047203\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.072904\tBest loss: 0.047203\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.052965\tBest loss: 0.047203\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.081714\tBest loss: 0.047203\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.068617\tBest loss: 0.047203\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.077296\tBest loss: 0.047203\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.061786\tBest loss: 0.047203\tAccuracy: 98.79%\n",
      "32\tValidation loss: 0.078778\tBest loss: 0.047203\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.058343\tBest loss: 0.047203\tAccuracy: 98.67%\n",
      "34\tValidation loss: 0.076061\tBest loss: 0.047203\tAccuracy: 98.71%\n",
      "35\tValidation loss: 0.071013\tBest loss: 0.047203\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total=  56.7s\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 1.094949\tBest loss: 1.094949\tAccuracy: 95.62%\n",
      "1\tValidation loss: 0.318585\tBest loss: 0.318585\tAccuracy: 96.40%\n",
      "2\tValidation loss: 0.129661\tBest loss: 0.129661\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.083625\tBest loss: 0.083625\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.065354\tBest loss: 0.065354\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.061945\tBest loss: 0.061945\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.058833\tBest loss: 0.058833\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.079062\tBest loss: 0.058833\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.071269\tBest loss: 0.058833\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.066796\tBest loss: 0.058833\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.052614\tBest loss: 0.052614\tAccuracy: 98.98%\n",
      "11\tValidation loss: 0.061105\tBest loss: 0.052614\tAccuracy: 98.55%\n",
      "12\tValidation loss: 0.046518\tBest loss: 0.046518\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.050161\tBest loss: 0.046518\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.049980\tBest loss: 0.046518\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.065885\tBest loss: 0.046518\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.059430\tBest loss: 0.046518\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.063677\tBest loss: 0.046518\tAccuracy: 98.67%\n",
      "18\tValidation loss: 0.083643\tBest loss: 0.046518\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.043894\tBest loss: 0.043894\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.042531\tBest loss: 0.042531\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.063643\tBest loss: 0.042531\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.045644\tBest loss: 0.042531\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.050237\tBest loss: 0.042531\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.075084\tBest loss: 0.042531\tAccuracy: 98.51%\n",
      "25\tValidation loss: 0.065257\tBest loss: 0.042531\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.064005\tBest loss: 0.042531\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.068079\tBest loss: 0.042531\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.064124\tBest loss: 0.042531\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.065717\tBest loss: 0.042531\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.068412\tBest loss: 0.042531\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.061974\tBest loss: 0.042531\tAccuracy: 98.63%\n",
      "32\tValidation loss: 0.052157\tBest loss: 0.042531\tAccuracy: 98.98%\n",
      "33\tValidation loss: 0.047325\tBest loss: 0.042531\tAccuracy: 99.02%\n",
      "34\tValidation loss: 0.049052\tBest loss: 0.042531\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.058187\tBest loss: 0.042531\tAccuracy: 98.91%\n",
      "36\tValidation loss: 0.046850\tBest loss: 0.042531\tAccuracy: 99.18%\n",
      "37\tValidation loss: 0.051196\tBest loss: 0.042531\tAccuracy: 98.94%\n",
      "38\tValidation loss: 0.065984\tBest loss: 0.042531\tAccuracy: 98.75%\n",
      "39\tValidation loss: 0.042886\tBest loss: 0.042531\tAccuracy: 99.30%\n",
      "40\tValidation loss: 0.101358\tBest loss: 0.042531\tAccuracy: 98.05%\n",
      "41\tValidation loss: 0.068221\tBest loss: 0.042531\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.1min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 1.349729\tBest loss: 1.349729\tAccuracy: 94.45%\n",
      "1\tValidation loss: 0.253508\tBest loss: 0.253508\tAccuracy: 96.79%\n",
      "2\tValidation loss: 0.120510\tBest loss: 0.120510\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.110899\tBest loss: 0.110899\tAccuracy: 98.01%\n",
      "4\tValidation loss: 0.145047\tBest loss: 0.110899\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.050077\tBest loss: 0.050077\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.060694\tBest loss: 0.050077\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.052093\tBest loss: 0.050077\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.059686\tBest loss: 0.050077\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.068891\tBest loss: 0.050077\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.059188\tBest loss: 0.050077\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.051503\tBest loss: 0.050077\tAccuracy: 99.02%\n",
      "12\tValidation loss: 0.066150\tBest loss: 0.050077\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.043812\tBest loss: 0.043812\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.069421\tBest loss: 0.043812\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.055337\tBest loss: 0.043812\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.062990\tBest loss: 0.043812\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.050078\tBest loss: 0.043812\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.074866\tBest loss: 0.043812\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.037059\tBest loss: 0.037059\tAccuracy: 99.26%\n",
      "20\tValidation loss: 0.052918\tBest loss: 0.037059\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.058509\tBest loss: 0.037059\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.049996\tBest loss: 0.037059\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.052645\tBest loss: 0.037059\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.049121\tBest loss: 0.037059\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.050369\tBest loss: 0.037059\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.093804\tBest loss: 0.037059\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.086038\tBest loss: 0.037059\tAccuracy: 98.36%\n",
      "28\tValidation loss: 0.057420\tBest loss: 0.037059\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.054848\tBest loss: 0.037059\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.081015\tBest loss: 0.037059\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.042028\tBest loss: 0.037059\tAccuracy: 99.14%\n",
      "32\tValidation loss: 0.044162\tBest loss: 0.037059\tAccuracy: 99.06%\n",
      "33\tValidation loss: 0.053506\tBest loss: 0.037059\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.077385\tBest loss: 0.037059\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.096151\tBest loss: 0.037059\tAccuracy: 98.16%\n",
      "36\tValidation loss: 0.064070\tBest loss: 0.037059\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.045576\tBest loss: 0.037059\tAccuracy: 99.06%\n",
      "38\tValidation loss: 0.054749\tBest loss: 0.037059\tAccuracy: 98.98%\n",
      "39\tValidation loss: 0.044186\tBest loss: 0.037059\tAccuracy: 99.14%\n",
      "40\tValidation loss: 0.033338\tBest loss: 0.033338\tAccuracy: 99.41%\n",
      "41\tValidation loss: 0.045632\tBest loss: 0.033338\tAccuracy: 99.22%\n",
      "42\tValidation loss: 0.047984\tBest loss: 0.033338\tAccuracy: 99.18%\n",
      "43\tValidation loss: 0.043689\tBest loss: 0.033338\tAccuracy: 99.18%\n",
      "44\tValidation loss: 0.037221\tBest loss: 0.033338\tAccuracy: 99.18%\n",
      "45\tValidation loss: 0.032262\tBest loss: 0.032262\tAccuracy: 99.30%\n",
      "46\tValidation loss: 0.032641\tBest loss: 0.032262\tAccuracy: 99.26%\n",
      "47\tValidation loss: 0.032184\tBest loss: 0.032184\tAccuracy: 99.34%\n",
      "48\tValidation loss: 0.033240\tBest loss: 0.032184\tAccuracy: 99.37%\n",
      "49\tValidation loss: 0.034701\tBest loss: 0.032184\tAccuracy: 99.30%\n",
      "50\tValidation loss: 0.032859\tBest loss: 0.032184\tAccuracy: 99.34%\n",
      "51\tValidation loss: 0.032826\tBest loss: 0.032184\tAccuracy: 99.37%\n",
      "52\tValidation loss: 0.033089\tBest loss: 0.032184\tAccuracy: 99.37%\n",
      "53\tValidation loss: 0.033072\tBest loss: 0.032184\tAccuracy: 99.41%\n",
      "54\tValidation loss: 0.032696\tBest loss: 0.032184\tAccuracy: 99.41%\n",
      "55\tValidation loss: 0.032554\tBest loss: 0.032184\tAccuracy: 99.41%\n",
      "56\tValidation loss: 0.033279\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "57\tValidation loss: 0.033041\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "58\tValidation loss: 0.033115\tBest loss: 0.032184\tAccuracy: 99.41%\n",
      "59\tValidation loss: 0.033206\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "60\tValidation loss: 0.033200\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "61\tValidation loss: 0.033308\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "62\tValidation loss: 0.033294\tBest loss: 0.032184\tAccuracy: 99.37%\n",
      "63\tValidation loss: 0.032247\tBest loss: 0.032184\tAccuracy: 99.41%\n",
      "64\tValidation loss: 0.032207\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "65\tValidation loss: 0.032291\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "66\tValidation loss: 0.032376\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "67\tValidation loss: 0.032500\tBest loss: 0.032184\tAccuracy: 99.45%\n",
      "68\tValidation loss: 0.032540\tBest loss: 0.032184\tAccuracy: 99.49%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.7min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.291345\tBest loss: 0.291345\tAccuracy: 95.07%\n",
      "1\tValidation loss: 0.157172\tBest loss: 0.157172\tAccuracy: 96.79%\n",
      "2\tValidation loss: 0.095299\tBest loss: 0.095299\tAccuracy: 97.30%\n",
      "3\tValidation loss: 0.071007\tBest loss: 0.071007\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.076838\tBest loss: 0.071007\tAccuracy: 98.01%\n",
      "5\tValidation loss: 0.109377\tBest loss: 0.071007\tAccuracy: 97.62%\n",
      "6\tValidation loss: 0.057658\tBest loss: 0.057658\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.051683\tBest loss: 0.051683\tAccuracy: 99.10%\n",
      "8\tValidation loss: 0.049216\tBest loss: 0.049216\tAccuracy: 98.75%\n",
      "9\tValidation loss: 0.070401\tBest loss: 0.049216\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.106821\tBest loss: 0.049216\tAccuracy: 97.65%\n",
      "11\tValidation loss: 0.054473\tBest loss: 0.049216\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.065539\tBest loss: 0.049216\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.047092\tBest loss: 0.047092\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.039614\tBest loss: 0.039614\tAccuracy: 99.18%\n",
      "15\tValidation loss: 0.040017\tBest loss: 0.039614\tAccuracy: 99.14%\n",
      "16\tValidation loss: 0.048471\tBest loss: 0.039614\tAccuracy: 99.10%\n",
      "17\tValidation loss: 0.051712\tBest loss: 0.039614\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.050459\tBest loss: 0.039614\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.041733\tBest loss: 0.039614\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.055088\tBest loss: 0.039614\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.048281\tBest loss: 0.039614\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.042633\tBest loss: 0.039614\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.040516\tBest loss: 0.039614\tAccuracy: 99.22%\n",
      "24\tValidation loss: 0.049723\tBest loss: 0.039614\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.034233\tBest loss: 0.034233\tAccuracy: 99.34%\n",
      "26\tValidation loss: 0.039156\tBest loss: 0.034233\tAccuracy: 99.18%\n",
      "27\tValidation loss: 0.038584\tBest loss: 0.034233\tAccuracy: 99.26%\n",
      "28\tValidation loss: 0.038271\tBest loss: 0.034233\tAccuracy: 99.26%\n",
      "29\tValidation loss: 0.039517\tBest loss: 0.034233\tAccuracy: 99.30%\n",
      "30\tValidation loss: 0.042934\tBest loss: 0.034233\tAccuracy: 99.26%\n",
      "31\tValidation loss: 0.051311\tBest loss: 0.034233\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.136445\tBest loss: 0.034233\tAccuracy: 97.69%\n",
      "33\tValidation loss: 0.076188\tBest loss: 0.034233\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.113149\tBest loss: 0.034233\tAccuracy: 98.16%\n",
      "35\tValidation loss: 0.072543\tBest loss: 0.034233\tAccuracy: 98.98%\n",
      "36\tValidation loss: 0.063444\tBest loss: 0.034233\tAccuracy: 98.87%\n",
      "37\tValidation loss: 0.070079\tBest loss: 0.034233\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.066034\tBest loss: 0.034233\tAccuracy: 98.67%\n",
      "39\tValidation loss: 0.045127\tBest loss: 0.034233\tAccuracy: 99.10%\n",
      "40\tValidation loss: 0.045462\tBest loss: 0.034233\tAccuracy: 99.18%\n",
      "41\tValidation loss: 0.049004\tBest loss: 0.034233\tAccuracy: 99.06%\n",
      "42\tValidation loss: 0.047025\tBest loss: 0.034233\tAccuracy: 99.14%\n",
      "43\tValidation loss: 0.045344\tBest loss: 0.034233\tAccuracy: 99.18%\n",
      "44\tValidation loss: 0.045818\tBest loss: 0.034233\tAccuracy: 99.22%\n",
      "45\tValidation loss: 0.046049\tBest loss: 0.034233\tAccuracy: 99.14%\n",
      "46\tValidation loss: 0.046689\tBest loss: 0.034233\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.0min\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.372978\tBest loss: 0.372978\tAccuracy: 94.49%\n",
      "1\tValidation loss: 0.109405\tBest loss: 0.109405\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.145592\tBest loss: 0.109405\tAccuracy: 96.87%\n",
      "3\tValidation loss: 0.075015\tBest loss: 0.075015\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.090136\tBest loss: 0.075015\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.066192\tBest loss: 0.066192\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.071267\tBest loss: 0.066192\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.040060\tBest loss: 0.040060\tAccuracy: 98.91%\n",
      "8\tValidation loss: 0.049665\tBest loss: 0.040060\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.046905\tBest loss: 0.040060\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.054765\tBest loss: 0.040060\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.063983\tBest loss: 0.040060\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.061252\tBest loss: 0.040060\tAccuracy: 98.71%\n",
      "13\tValidation loss: 0.055055\tBest loss: 0.040060\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.092771\tBest loss: 0.040060\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.057840\tBest loss: 0.040060\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.049227\tBest loss: 0.040060\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.050533\tBest loss: 0.040060\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.093797\tBest loss: 0.040060\tAccuracy: 98.44%\n",
      "19\tValidation loss: 0.081597\tBest loss: 0.040060\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.058955\tBest loss: 0.040060\tAccuracy: 98.87%\n",
      "21\tValidation loss: 0.053209\tBest loss: 0.040060\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.057127\tBest loss: 0.040060\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.062539\tBest loss: 0.040060\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.062113\tBest loss: 0.040060\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.046045\tBest loss: 0.040060\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.049611\tBest loss: 0.040060\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.063782\tBest loss: 0.040060\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.044490\tBest loss: 0.040060\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total=  38.6s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0> \n",
      "0\tValidation loss: 0.350586\tBest loss: 0.350586\tAccuracy: 94.45%\n",
      "1\tValidation loss: 0.081019\tBest loss: 0.081019\tAccuracy: 97.89%\n",
      "2\tValidation loss: 0.084814\tBest loss: 0.081019\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.073200\tBest loss: 0.073200\tAccuracy: 98.75%\n",
      "4\tValidation loss: 0.062006\tBest loss: 0.062006\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.045838\tBest loss: 0.045838\tAccuracy: 98.98%\n",
      "6\tValidation loss: 0.038820\tBest loss: 0.038820\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.061066\tBest loss: 0.038820\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.085908\tBest loss: 0.038820\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.078782\tBest loss: 0.038820\tAccuracy: 98.16%\n",
      "10\tValidation loss: 0.064328\tBest loss: 0.038820\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.065184\tBest loss: 0.038820\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.056173\tBest loss: 0.038820\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.060546\tBest loss: 0.038820\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.044995\tBest loss: 0.038820\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.041912\tBest loss: 0.038820\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.067122\tBest loss: 0.038820\tAccuracy: 98.94%\n",
      "17\tValidation loss: 0.050547\tBest loss: 0.038820\tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.054253\tBest loss: 0.038820\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.045316\tBest loss: 0.038820\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.072787\tBest loss: 0.038820\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.043420\tBest loss: 0.038820\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.045833\tBest loss: 0.038820\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.045305\tBest loss: 0.038820\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.046262\tBest loss: 0.038820\tAccuracy: 98.83%\n",
      "25\tValidation loss: 0.045718\tBest loss: 0.038820\tAccuracy: 98.94%\n",
      "26\tValidation loss: 0.037713\tBest loss: 0.037713\tAccuracy: 99.26%\n",
      "27\tValidation loss: 0.077206\tBest loss: 0.037713\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.054518\tBest loss: 0.037713\tAccuracy: 98.98%\n",
      "29\tValidation loss: 0.044860\tBest loss: 0.037713\tAccuracy: 99.10%\n",
      "30\tValidation loss: 0.050006\tBest loss: 0.037713\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.039510\tBest loss: 0.037713\tAccuracy: 99.18%\n",
      "32\tValidation loss: 0.050109\tBest loss: 0.037713\tAccuracy: 98.94%\n",
      "33\tValidation loss: 0.081168\tBest loss: 0.037713\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.067610\tBest loss: 0.037713\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.043456\tBest loss: 0.037713\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.061942\tBest loss: 0.037713\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.041017\tBest loss: 0.037713\tAccuracy: 98.91%\n",
      "38\tValidation loss: 0.039766\tBest loss: 0.037713\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.038783\tBest loss: 0.037713\tAccuracy: 99.18%\n",
      "40\tValidation loss: 0.039667\tBest loss: 0.037713\tAccuracy: 99.10%\n",
      "41\tValidation loss: 0.039174\tBest loss: 0.037713\tAccuracy: 99.10%\n",
      "42\tValidation loss: 0.039047\tBest loss: 0.037713\tAccuracy: 99.06%\n",
      "43\tValidation loss: 0.038699\tBest loss: 0.037713\tAccuracy: 99.06%\n",
      "44\tValidation loss: 0.039279\tBest loss: 0.037713\tAccuracy: 99.10%\n",
      "45\tValidation loss: 0.039553\tBest loss: 0.037713\tAccuracy: 99.10%\n",
      "46\tValidation loss: 0.040745\tBest loss: 0.037713\tAccuracy: 99.18%\n",
      "47\tValidation loss: 0.041406\tBest loss: 0.037713\tAccuracy: 99.26%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.99, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>, total= 1.0min\n",
      "[CV] n_neurons=100, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.152800\tBest loss: 0.152800\tAccuracy: 95.62%\n",
      "1\tValidation loss: 0.105844\tBest loss: 0.105844\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.110785\tBest loss: 0.105844\tAccuracy: 96.60%\n",
      "3\tValidation loss: 0.088595\tBest loss: 0.088595\tAccuracy: 96.83%\n",
      "4\tValidation loss: 0.085842\tBest loss: 0.085842\tAccuracy: 96.99%\n",
      "5\tValidation loss: 0.073951\tBest loss: 0.073951\tAccuracy: 97.65%\n",
      "6\tValidation loss: 0.084589\tBest loss: 0.073951\tAccuracy: 97.81%\n",
      "7\tValidation loss: 0.064332\tBest loss: 0.064332\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.066543\tBest loss: 0.064332\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.098861\tBest loss: 0.064332\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.064791\tBest loss: 0.064332\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.067951\tBest loss: 0.064332\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.065996\tBest loss: 0.064332\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.062859\tBest loss: 0.062859\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.064693\tBest loss: 0.062859\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.078378\tBest loss: 0.062859\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.091608\tBest loss: 0.062859\tAccuracy: 97.97%\n",
      "17\tValidation loss: 0.068364\tBest loss: 0.062859\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.084054\tBest loss: 0.062859\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.086687\tBest loss: 0.062859\tAccuracy: 98.20%\n",
      "20\tValidation loss: 0.072726\tBest loss: 0.062859\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.074997\tBest loss: 0.062859\tAccuracy: 98.32%\n",
      "22\tValidation loss: 0.067195\tBest loss: 0.062859\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.069583\tBest loss: 0.062859\tAccuracy: 98.67%\n",
      "24\tValidation loss: 0.074244\tBest loss: 0.062859\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.059226\tBest loss: 0.059226\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.090710\tBest loss: 0.059226\tAccuracy: 98.12%\n",
      "27\tValidation loss: 0.072555\tBest loss: 0.059226\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.064514\tBest loss: 0.059226\tAccuracy: 98.67%\n",
      "29\tValidation loss: 0.072321\tBest loss: 0.059226\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.096028\tBest loss: 0.059226\tAccuracy: 98.28%\n",
      "31\tValidation loss: 0.074413\tBest loss: 0.059226\tAccuracy: 98.44%\n",
      "32\tValidation loss: 0.070344\tBest loss: 0.059226\tAccuracy: 98.36%\n",
      "33\tValidation loss: 0.091949\tBest loss: 0.059226\tAccuracy: 98.40%\n",
      "34\tValidation loss: 0.076296\tBest loss: 0.059226\tAccuracy: 98.36%\n",
      "35\tValidation loss: 0.077691\tBest loss: 0.059226\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.087273\tBest loss: 0.059226\tAccuracy: 98.63%\n",
      "37\tValidation loss: 0.087202\tBest loss: 0.059226\tAccuracy: 98.44%\n",
      "38\tValidation loss: 0.080524\tBest loss: 0.059226\tAccuracy: 98.63%\n",
      "39\tValidation loss: 0.087405\tBest loss: 0.059226\tAccuracy: 98.36%\n",
      "40\tValidation loss: 0.083719\tBest loss: 0.059226\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.095394\tBest loss: 0.059226\tAccuracy: 98.48%\n",
      "42\tValidation loss: 0.072682\tBest loss: 0.059226\tAccuracy: 98.79%\n",
      "43\tValidation loss: 0.063836\tBest loss: 0.059226\tAccuracy: 98.75%\n",
      "44\tValidation loss: 0.078238\tBest loss: 0.059226\tAccuracy: 98.51%\n",
      "45\tValidation loss: 0.071359\tBest loss: 0.059226\tAccuracy: 98.59%\n",
      "46\tValidation loss: 0.072645\tBest loss: 0.059226\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total=  52.2s\n",
      "[CV] n_neurons=100, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.165283\tBest loss: 0.165283\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.106444\tBest loss: 0.106444\tAccuracy: 96.95%\n",
      "2\tValidation loss: 0.089783\tBest loss: 0.089783\tAccuracy: 97.26%\n",
      "3\tValidation loss: 0.088135\tBest loss: 0.088135\tAccuracy: 96.95%\n",
      "4\tValidation loss: 0.113103\tBest loss: 0.088135\tAccuracy: 96.36%\n",
      "5\tValidation loss: 0.064385\tBest loss: 0.064385\tAccuracy: 97.85%\n",
      "6\tValidation loss: 0.047296\tBest loss: 0.047296\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.058109\tBest loss: 0.047296\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.058800\tBest loss: 0.047296\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.070502\tBest loss: 0.047296\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.070990\tBest loss: 0.047296\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.077629\tBest loss: 0.047296\tAccuracy: 98.16%\n",
      "12\tValidation loss: 0.066574\tBest loss: 0.047296\tAccuracy: 98.36%\n",
      "13\tValidation loss: 0.057521\tBest loss: 0.047296\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.070321\tBest loss: 0.047296\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.050916\tBest loss: 0.047296\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.049137\tBest loss: 0.047296\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.060247\tBest loss: 0.047296\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.072853\tBest loss: 0.047296\tAccuracy: 98.36%\n",
      "19\tValidation loss: 0.074541\tBest loss: 0.047296\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.061123\tBest loss: 0.047296\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.069808\tBest loss: 0.047296\tAccuracy: 98.55%\n",
      "22\tValidation loss: 0.072157\tBest loss: 0.047296\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.068095\tBest loss: 0.047296\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.059680\tBest loss: 0.047296\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.063703\tBest loss: 0.047296\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.044895\tBest loss: 0.044895\tAccuracy: 99.06%\n",
      "27\tValidation loss: 0.064612\tBest loss: 0.044895\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.090895\tBest loss: 0.044895\tAccuracy: 98.48%\n",
      "29\tValidation loss: 0.073447\tBest loss: 0.044895\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.087925\tBest loss: 0.044895\tAccuracy: 98.59%\n",
      "31\tValidation loss: 0.078840\tBest loss: 0.044895\tAccuracy: 98.40%\n",
      "32\tValidation loss: 0.062911\tBest loss: 0.044895\tAccuracy: 98.63%\n",
      "33\tValidation loss: 0.072262\tBest loss: 0.044895\tAccuracy: 98.63%\n",
      "34\tValidation loss: 0.067507\tBest loss: 0.044895\tAccuracy: 98.67%\n",
      "35\tValidation loss: 0.066688\tBest loss: 0.044895\tAccuracy: 98.51%\n",
      "36\tValidation loss: 0.070736\tBest loss: 0.044895\tAccuracy: 98.83%\n",
      "37\tValidation loss: 0.103795\tBest loss: 0.044895\tAccuracy: 98.24%\n",
      "38\tValidation loss: 0.058419\tBest loss: 0.044895\tAccuracy: 98.87%\n",
      "39\tValidation loss: 0.054872\tBest loss: 0.044895\tAccuracy: 98.91%\n",
      "40\tValidation loss: 0.053437\tBest loss: 0.044895\tAccuracy: 99.02%\n",
      "41\tValidation loss: 0.053132\tBest loss: 0.044895\tAccuracy: 98.87%\n",
      "42\tValidation loss: 0.054472\tBest loss: 0.044895\tAccuracy: 98.94%\n",
      "43\tValidation loss: 0.061816\tBest loss: 0.044895\tAccuracy: 98.87%\n",
      "44\tValidation loss: 0.060925\tBest loss: 0.044895\tAccuracy: 98.87%\n",
      "45\tValidation loss: 0.066349\tBest loss: 0.044895\tAccuracy: 98.94%\n",
      "46\tValidation loss: 0.056947\tBest loss: 0.044895\tAccuracy: 98.94%\n",
      "47\tValidation loss: 0.065192\tBest loss: 0.044895\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total=  52.7s\n",
      "[CV] n_neurons=100, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.157265\tBest loss: 0.157265\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.095969\tBest loss: 0.095969\tAccuracy: 96.99%\n",
      "2\tValidation loss: 0.092380\tBest loss: 0.092380\tAccuracy: 97.03%\n",
      "3\tValidation loss: 0.078617\tBest loss: 0.078617\tAccuracy: 97.58%\n",
      "4\tValidation loss: 0.079870\tBest loss: 0.078617\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.055868\tBest loss: 0.055868\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.049507\tBest loss: 0.049507\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.061943\tBest loss: 0.049507\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.049603\tBest loss: 0.049507\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.042779\tBest loss: 0.042779\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.048514\tBest loss: 0.042779\tAccuracy: 98.48%\n",
      "11\tValidation loss: 0.066893\tBest loss: 0.042779\tAccuracy: 98.05%\n",
      "12\tValidation loss: 0.061113\tBest loss: 0.042779\tAccuracy: 98.44%\n",
      "13\tValidation loss: 0.056440\tBest loss: 0.042779\tAccuracy: 98.40%\n",
      "14\tValidation loss: 0.064005\tBest loss: 0.042779\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.072627\tBest loss: 0.042779\tAccuracy: 98.24%\n",
      "16\tValidation loss: 0.050459\tBest loss: 0.042779\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.049017\tBest loss: 0.042779\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.062369\tBest loss: 0.042779\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.068728\tBest loss: 0.042779\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.052905\tBest loss: 0.042779\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.070377\tBest loss: 0.042779\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.076648\tBest loss: 0.042779\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.071000\tBest loss: 0.042779\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.080294\tBest loss: 0.042779\tAccuracy: 98.12%\n",
      "25\tValidation loss: 0.054932\tBest loss: 0.042779\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.059327\tBest loss: 0.042779\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.064885\tBest loss: 0.042779\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.060591\tBest loss: 0.042779\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.109514\tBest loss: 0.042779\tAccuracy: 98.51%\n",
      "30\tValidation loss: 0.096918\tBest loss: 0.042779\tAccuracy: 98.05%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, learning_rate=0.1, batch_size=500, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total=  35.1s\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.432049\tBest loss: 1.432049\tAccuracy: 97.07%\n",
      "1\tValidation loss: 1.008913\tBest loss: 1.008913\tAccuracy: 96.29%\n",
      "2\tValidation loss: 1.005040\tBest loss: 1.005040\tAccuracy: 95.47%\n",
      "3\tValidation loss: 0.362375\tBest loss: 0.362375\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.300315\tBest loss: 0.300315\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.334673\tBest loss: 0.300315\tAccuracy: 97.30%\n",
      "6\tValidation loss: 0.222120\tBest loss: 0.222120\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.336035\tBest loss: 0.222120\tAccuracy: 98.01%\n",
      "8\tValidation loss: 0.194372\tBest loss: 0.194372\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.234533\tBest loss: 0.194372\tAccuracy: 97.81%\n",
      "10\tValidation loss: 0.167840\tBest loss: 0.167840\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.112731\tBest loss: 0.112731\tAccuracy: 98.79%\n",
      "12\tValidation loss: 0.268048\tBest loss: 0.112731\tAccuracy: 98.01%\n",
      "13\tValidation loss: 0.288214\tBest loss: 0.112731\tAccuracy: 97.62%\n",
      "14\tValidation loss: 0.178025\tBest loss: 0.112731\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.215611\tBest loss: 0.112731\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.193298\tBest loss: 0.112731\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.116159\tBest loss: 0.112731\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.156037\tBest loss: 0.112731\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.103455\tBest loss: 0.103455\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.106437\tBest loss: 0.103455\tAccuracy: 98.67%\n",
      "21\tValidation loss: 0.099137\tBest loss: 0.099137\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.115575\tBest loss: 0.099137\tAccuracy: 98.40%\n",
      "23\tValidation loss: 0.176366\tBest loss: 0.099137\tAccuracy: 98.51%\n",
      "24\tValidation loss: 0.139040\tBest loss: 0.099137\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.133111\tBest loss: 0.099137\tAccuracy: 98.63%\n",
      "26\tValidation loss: 0.195385\tBest loss: 0.099137\tAccuracy: 98.67%\n",
      "27\tValidation loss: 0.125305\tBest loss: 0.099137\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.218305\tBest loss: 0.099137\tAccuracy: 98.12%\n",
      "29\tValidation loss: 0.081085\tBest loss: 0.081085\tAccuracy: 99.18%\n",
      "30\tValidation loss: 0.086297\tBest loss: 0.081085\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.127995\tBest loss: 0.081085\tAccuracy: 98.44%\n",
      "32\tValidation loss: 0.128080\tBest loss: 0.081085\tAccuracy: 98.75%\n",
      "33\tValidation loss: 0.097989\tBest loss: 0.081085\tAccuracy: 98.79%\n",
      "34\tValidation loss: 0.141075\tBest loss: 0.081085\tAccuracy: 98.44%\n",
      "35\tValidation loss: 0.110292\tBest loss: 0.081085\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.142949\tBest loss: 0.081085\tAccuracy: 98.55%\n",
      "37\tValidation loss: 0.169670\tBest loss: 0.081085\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.197927\tBest loss: 0.081085\tAccuracy: 98.20%\n",
      "39\tValidation loss: 0.153773\tBest loss: 0.081085\tAccuracy: 98.67%\n",
      "40\tValidation loss: 0.130640\tBest loss: 0.081085\tAccuracy: 98.71%\n",
      "41\tValidation loss: 0.112598\tBest loss: 0.081085\tAccuracy: 98.75%\n",
      "42\tValidation loss: 0.115188\tBest loss: 0.081085\tAccuracy: 98.79%\n",
      "43\tValidation loss: 0.083010\tBest loss: 0.081085\tAccuracy: 98.83%\n",
      "44\tValidation loss: 0.124595\tBest loss: 0.081085\tAccuracy: 98.59%\n",
      "45\tValidation loss: 0.099261\tBest loss: 0.081085\tAccuracy: 98.94%\n",
      "46\tValidation loss: 0.208869\tBest loss: 0.081085\tAccuracy: 97.93%\n",
      "47\tValidation loss: 0.160391\tBest loss: 0.081085\tAccuracy: 98.36%\n",
      "48\tValidation loss: 0.117300\tBest loss: 0.081085\tAccuracy: 98.91%\n",
      "49\tValidation loss: 0.089184\tBest loss: 0.081085\tAccuracy: 99.10%\n",
      "50\tValidation loss: 0.095595\tBest loss: 0.081085\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 2.3min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.276900\tBest loss: 1.276900\tAccuracy: 97.11%\n",
      "1\tValidation loss: 0.941731\tBest loss: 0.941731\tAccuracy: 96.01%\n",
      "2\tValidation loss: 0.434864\tBest loss: 0.434864\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.301509\tBest loss: 0.301509\tAccuracy: 97.77%\n",
      "4\tValidation loss: 0.278265\tBest loss: 0.278265\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.193601\tBest loss: 0.193601\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.111129\tBest loss: 0.111129\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.167041\tBest loss: 0.111129\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.484620\tBest loss: 0.111129\tAccuracy: 96.01%\n",
      "9\tValidation loss: 0.160078\tBest loss: 0.111129\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.233647\tBest loss: 0.111129\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.168135\tBest loss: 0.111129\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.194105\tBest loss: 0.111129\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.156518\tBest loss: 0.111129\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.262872\tBest loss: 0.111129\tAccuracy: 97.65%\n",
      "15\tValidation loss: 0.143928\tBest loss: 0.111129\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.235309\tBest loss: 0.111129\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.204700\tBest loss: 0.111129\tAccuracy: 97.81%\n",
      "18\tValidation loss: 0.102894\tBest loss: 0.102894\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.144616\tBest loss: 0.102894\tAccuracy: 98.24%\n",
      "20\tValidation loss: 0.126250\tBest loss: 0.102894\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.294065\tBest loss: 0.102894\tAccuracy: 98.28%\n",
      "22\tValidation loss: 0.209462\tBest loss: 0.102894\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.154701\tBest loss: 0.102894\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.128932\tBest loss: 0.102894\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.134682\tBest loss: 0.102894\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.147553\tBest loss: 0.102894\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.111720\tBest loss: 0.102894\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.106240\tBest loss: 0.102894\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.099085\tBest loss: 0.099085\tAccuracy: 99.06%\n",
      "30\tValidation loss: 0.122247\tBest loss: 0.099085\tAccuracy: 98.55%\n",
      "31\tValidation loss: 0.173951\tBest loss: 0.099085\tAccuracy: 98.05%\n",
      "32\tValidation loss: 0.142309\tBest loss: 0.099085\tAccuracy: 98.63%\n",
      "33\tValidation loss: 0.134061\tBest loss: 0.099085\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.150193\tBest loss: 0.099085\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.125602\tBest loss: 0.099085\tAccuracy: 98.87%\n",
      "36\tValidation loss: 0.204407\tBest loss: 0.099085\tAccuracy: 98.44%\n",
      "37\tValidation loss: 0.152028\tBest loss: 0.099085\tAccuracy: 98.55%\n",
      "38\tValidation loss: 0.119147\tBest loss: 0.099085\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.152502\tBest loss: 0.099085\tAccuracy: 98.59%\n",
      "40\tValidation loss: 0.099460\tBest loss: 0.099085\tAccuracy: 98.94%\n",
      "41\tValidation loss: 0.129342\tBest loss: 0.099085\tAccuracy: 98.59%\n",
      "42\tValidation loss: 0.164715\tBest loss: 0.099085\tAccuracy: 98.40%\n",
      "43\tValidation loss: 0.142113\tBest loss: 0.099085\tAccuracy: 98.75%\n",
      "44\tValidation loss: 0.159495\tBest loss: 0.099085\tAccuracy: 98.87%\n",
      "45\tValidation loss: 0.179022\tBest loss: 0.099085\tAccuracy: 98.48%\n",
      "46\tValidation loss: 0.186551\tBest loss: 0.099085\tAccuracy: 98.67%\n",
      "47\tValidation loss: 0.129327\tBest loss: 0.099085\tAccuracy: 98.98%\n",
      "48\tValidation loss: 0.133967\tBest loss: 0.099085\tAccuracy: 98.75%\n",
      "49\tValidation loss: 0.086146\tBest loss: 0.086146\tAccuracy: 98.98%\n",
      "50\tValidation loss: 0.086942\tBest loss: 0.086146\tAccuracy: 99.14%\n",
      "51\tValidation loss: 0.127600\tBest loss: 0.086146\tAccuracy: 98.63%\n",
      "52\tValidation loss: 0.095309\tBest loss: 0.086146\tAccuracy: 98.91%\n",
      "53\tValidation loss: 0.097614\tBest loss: 0.086146\tAccuracy: 98.71%\n",
      "54\tValidation loss: 0.100393\tBest loss: 0.086146\tAccuracy: 98.67%\n",
      "55\tValidation loss: 0.085403\tBest loss: 0.085403\tAccuracy: 98.16%\n",
      "56\tValidation loss: 0.118382\tBest loss: 0.085403\tAccuracy: 98.63%\n",
      "57\tValidation loss: 0.141913\tBest loss: 0.085403\tAccuracy: 98.71%\n",
      "58\tValidation loss: 0.255288\tBest loss: 0.085403\tAccuracy: 98.20%\n",
      "59\tValidation loss: 0.212931\tBest loss: 0.085403\tAccuracy: 98.24%\n",
      "60\tValidation loss: 0.123774\tBest loss: 0.085403\tAccuracy: 99.06%\n",
      "61\tValidation loss: 0.112441\tBest loss: 0.085403\tAccuracy: 99.02%\n",
      "62\tValidation loss: 0.106548\tBest loss: 0.085403\tAccuracy: 98.98%\n",
      "63\tValidation loss: 0.083768\tBest loss: 0.083768\tAccuracy: 98.98%\n",
      "64\tValidation loss: 0.098682\tBest loss: 0.083768\tAccuracy: 98.87%\n",
      "65\tValidation loss: 0.104924\tBest loss: 0.083768\tAccuracy: 99.02%\n",
      "66\tValidation loss: 0.090733\tBest loss: 0.083768\tAccuracy: 99.06%\n",
      "67\tValidation loss: 0.118630\tBest loss: 0.083768\tAccuracy: 98.71%\n",
      "68\tValidation loss: 0.137111\tBest loss: 0.083768\tAccuracy: 98.40%\n",
      "69\tValidation loss: 0.115733\tBest loss: 0.083768\tAccuracy: 98.79%\n",
      "70\tValidation loss: 0.094939\tBest loss: 0.083768\tAccuracy: 98.91%\n",
      "71\tValidation loss: 0.067955\tBest loss: 0.067955\tAccuracy: 99.22%\n",
      "72\tValidation loss: 0.071657\tBest loss: 0.067955\tAccuracy: 99.34%\n",
      "73\tValidation loss: 0.060587\tBest loss: 0.060587\tAccuracy: 99.37%\n",
      "74\tValidation loss: 0.064389\tBest loss: 0.060587\tAccuracy: 99.02%\n",
      "75\tValidation loss: 0.063597\tBest loss: 0.060587\tAccuracy: 99.06%\n",
      "76\tValidation loss: 0.098221\tBest loss: 0.060587\tAccuracy: 98.94%\n",
      "77\tValidation loss: 0.092173\tBest loss: 0.060587\tAccuracy: 98.98%\n",
      "78\tValidation loss: 0.110476\tBest loss: 0.060587\tAccuracy: 98.87%\n",
      "79\tValidation loss: 0.102284\tBest loss: 0.060587\tAccuracy: 99.10%\n",
      "80\tValidation loss: 0.097520\tBest loss: 0.060587\tAccuracy: 98.87%\n",
      "81\tValidation loss: 0.104743\tBest loss: 0.060587\tAccuracy: 98.83%\n",
      "82\tValidation loss: 0.092600\tBest loss: 0.060587\tAccuracy: 98.91%\n",
      "83\tValidation loss: 0.094804\tBest loss: 0.060587\tAccuracy: 99.14%\n",
      "84\tValidation loss: 0.072961\tBest loss: 0.060587\tAccuracy: 99.06%\n",
      "85\tValidation loss: 0.079749\tBest loss: 0.060587\tAccuracy: 99.10%\n",
      "86\tValidation loss: 0.123088\tBest loss: 0.060587\tAccuracy: 99.06%\n",
      "87\tValidation loss: 0.079740\tBest loss: 0.060587\tAccuracy: 98.83%\n",
      "88\tValidation loss: 0.177182\tBest loss: 0.060587\tAccuracy: 98.71%\n",
      "89\tValidation loss: 0.253782\tBest loss: 0.060587\tAccuracy: 97.89%\n",
      "90\tValidation loss: 0.122710\tBest loss: 0.060587\tAccuracy: 98.83%\n",
      "91\tValidation loss: 0.176252\tBest loss: 0.060587\tAccuracy: 98.67%\n",
      "92\tValidation loss: 0.128602\tBest loss: 0.060587\tAccuracy: 98.94%\n",
      "93\tValidation loss: 0.118333\tBest loss: 0.060587\tAccuracy: 99.02%\n",
      "94\tValidation loss: 0.089145\tBest loss: 0.060587\tAccuracy: 99.10%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 4.3min\n",
      "[CV] n_neurons=140, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.493919\tBest loss: 1.493919\tAccuracy: 96.91%\n",
      "1\tValidation loss: 0.903507\tBest loss: 0.903507\tAccuracy: 96.79%\n",
      "2\tValidation loss: 0.595476\tBest loss: 0.595476\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.322415\tBest loss: 0.322415\tAccuracy: 97.77%\n",
      "4\tValidation loss: 0.191552\tBest loss: 0.191552\tAccuracy: 98.55%\n",
      "5\tValidation loss: 0.151357\tBest loss: 0.151357\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.148856\tBest loss: 0.148856\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.209701\tBest loss: 0.148856\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.318774\tBest loss: 0.148856\tAccuracy: 96.56%\n",
      "9\tValidation loss: 0.155128\tBest loss: 0.148856\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.188609\tBest loss: 0.148856\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.138746\tBest loss: 0.138746\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.109304\tBest loss: 0.109304\tAccuracy: 98.71%\n",
      "13\tValidation loss: 0.112691\tBest loss: 0.109304\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.149212\tBest loss: 0.109304\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.192088\tBest loss: 0.109304\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.228047\tBest loss: 0.109304\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.263682\tBest loss: 0.109304\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.186742\tBest loss: 0.109304\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.124288\tBest loss: 0.109304\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.114261\tBest loss: 0.109304\tAccuracy: 99.02%\n",
      "21\tValidation loss: 0.158245\tBest loss: 0.109304\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.152194\tBest loss: 0.109304\tAccuracy: 98.59%\n",
      "23\tValidation loss: 0.134837\tBest loss: 0.109304\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.080108\tBest loss: 0.080108\tAccuracy: 99.14%\n",
      "25\tValidation loss: 0.098014\tBest loss: 0.080108\tAccuracy: 98.91%\n",
      "26\tValidation loss: 0.095423\tBest loss: 0.080108\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.100383\tBest loss: 0.080108\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.145980\tBest loss: 0.080108\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.188705\tBest loss: 0.080108\tAccuracy: 98.32%\n",
      "30\tValidation loss: 0.101701\tBest loss: 0.080108\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.177704\tBest loss: 0.080108\tAccuracy: 98.32%\n",
      "32\tValidation loss: 0.105181\tBest loss: 0.080108\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.084811\tBest loss: 0.080108\tAccuracy: 99.06%\n",
      "34\tValidation loss: 0.156115\tBest loss: 0.080108\tAccuracy: 98.44%\n",
      "35\tValidation loss: 0.116062\tBest loss: 0.080108\tAccuracy: 98.79%\n",
      "36\tValidation loss: 0.139880\tBest loss: 0.080108\tAccuracy: 98.79%\n",
      "37\tValidation loss: 0.117302\tBest loss: 0.080108\tAccuracy: 98.91%\n",
      "38\tValidation loss: 0.125043\tBest loss: 0.080108\tAccuracy: 98.91%\n",
      "39\tValidation loss: 0.146965\tBest loss: 0.080108\tAccuracy: 98.32%\n",
      "40\tValidation loss: 0.072030\tBest loss: 0.072030\tAccuracy: 99.06%\n",
      "41\tValidation loss: 0.098987\tBest loss: 0.072030\tAccuracy: 98.91%\n",
      "42\tValidation loss: 0.112266\tBest loss: 0.072030\tAccuracy: 99.10%\n",
      "43\tValidation loss: 0.163645\tBest loss: 0.072030\tAccuracy: 98.20%\n",
      "44\tValidation loss: 0.082453\tBest loss: 0.072030\tAccuracy: 99.02%\n",
      "45\tValidation loss: 0.081296\tBest loss: 0.072030\tAccuracy: 99.22%\n",
      "46\tValidation loss: 0.075037\tBest loss: 0.072030\tAccuracy: 99.18%\n",
      "47\tValidation loss: 0.093118\tBest loss: 0.072030\tAccuracy: 98.94%\n",
      "48\tValidation loss: 0.122183\tBest loss: 0.072030\tAccuracy: 98.75%\n",
      "49\tValidation loss: 0.090366\tBest loss: 0.072030\tAccuracy: 98.83%\n",
      "50\tValidation loss: 0.130504\tBest loss: 0.072030\tAccuracy: 98.83%\n",
      "51\tValidation loss: 0.047487\tBest loss: 0.047487\tAccuracy: 99.30%\n",
      "52\tValidation loss: 0.046257\tBest loss: 0.046257\tAccuracy: 99.22%\n",
      "53\tValidation loss: 0.085882\tBest loss: 0.046257\tAccuracy: 98.94%\n",
      "54\tValidation loss: 0.070559\tBest loss: 0.046257\tAccuracy: 99.02%\n",
      "55\tValidation loss: 0.072281\tBest loss: 0.046257\tAccuracy: 98.94%\n",
      "56\tValidation loss: 0.078096\tBest loss: 0.046257\tAccuracy: 99.02%\n",
      "57\tValidation loss: 0.071731\tBest loss: 0.046257\tAccuracy: 98.98%\n",
      "58\tValidation loss: 0.061308\tBest loss: 0.046257\tAccuracy: 99.30%\n",
      "59\tValidation loss: 0.218196\tBest loss: 0.046257\tAccuracy: 97.97%\n",
      "60\tValidation loss: 0.118355\tBest loss: 0.046257\tAccuracy: 99.06%\n",
      "61\tValidation loss: 0.138014\tBest loss: 0.046257\tAccuracy: 99.06%\n",
      "62\tValidation loss: 0.100419\tBest loss: 0.046257\tAccuracy: 98.91%\n",
      "63\tValidation loss: 0.118755\tBest loss: 0.046257\tAccuracy: 98.98%\n",
      "64\tValidation loss: 0.074346\tBest loss: 0.046257\tAccuracy: 99.26%\n",
      "65\tValidation loss: 0.064062\tBest loss: 0.046257\tAccuracy: 99.34%\n",
      "66\tValidation loss: 0.099725\tBest loss: 0.046257\tAccuracy: 99.06%\n",
      "67\tValidation loss: 0.068981\tBest loss: 0.046257\tAccuracy: 99.10%\n",
      "68\tValidation loss: 0.053673\tBest loss: 0.046257\tAccuracy: 99.37%\n",
      "69\tValidation loss: 0.061962\tBest loss: 0.046257\tAccuracy: 99.49%\n",
      "70\tValidation loss: 0.059216\tBest loss: 0.046257\tAccuracy: 99.41%\n",
      "71\tValidation loss: 0.051771\tBest loss: 0.046257\tAccuracy: 99.34%\n",
      "72\tValidation loss: 0.091656\tBest loss: 0.046257\tAccuracy: 99.02%\n",
      "73\tValidation loss: 0.084449\tBest loss: 0.046257\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 3.4min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.642871\tBest loss: 0.642871\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.747666\tBest loss: 0.642871\tAccuracy: 96.95%\n",
      "2\tValidation loss: 0.498693\tBest loss: 0.498693\tAccuracy: 97.50%\n",
      "3\tValidation loss: 0.401848\tBest loss: 0.401848\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.217142\tBest loss: 0.217142\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.214706\tBest loss: 0.214706\tAccuracy: 98.20%\n",
      "6\tValidation loss: 0.179320\tBest loss: 0.179320\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.306413\tBest loss: 0.179320\tAccuracy: 97.22%\n",
      "8\tValidation loss: 0.107673\tBest loss: 0.107673\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.122555\tBest loss: 0.107673\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.128601\tBest loss: 0.107673\tAccuracy: 98.48%\n",
      "11\tValidation loss: 0.139690\tBest loss: 0.107673\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.134932\tBest loss: 0.107673\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.135659\tBest loss: 0.107673\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.108767\tBest loss: 0.107673\tAccuracy: 98.98%\n",
      "15\tValidation loss: 0.156079\tBest loss: 0.107673\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.182090\tBest loss: 0.107673\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.116774\tBest loss: 0.107673\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.115665\tBest loss: 0.107673\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.130289\tBest loss: 0.107673\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.269589\tBest loss: 0.107673\tAccuracy: 97.38%\n",
      "21\tValidation loss: 0.108390\tBest loss: 0.107673\tAccuracy: 98.87%\n",
      "22\tValidation loss: 0.098973\tBest loss: 0.098973\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.101375\tBest loss: 0.098973\tAccuracy: 98.36%\n",
      "24\tValidation loss: 0.132201\tBest loss: 0.098973\tAccuracy: 98.36%\n",
      "25\tValidation loss: 0.071201\tBest loss: 0.071201\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.109777\tBest loss: 0.071201\tAccuracy: 98.79%\n",
      "27\tValidation loss: 0.111807\tBest loss: 0.071201\tAccuracy: 98.87%\n",
      "28\tValidation loss: 0.096829\tBest loss: 0.071201\tAccuracy: 98.79%\n",
      "29\tValidation loss: 0.109707\tBest loss: 0.071201\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.112551\tBest loss: 0.071201\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.237399\tBest loss: 0.071201\tAccuracy: 97.73%\n",
      "32\tValidation loss: 0.132382\tBest loss: 0.071201\tAccuracy: 98.67%\n",
      "33\tValidation loss: 0.127775\tBest loss: 0.071201\tAccuracy: 98.55%\n",
      "34\tValidation loss: 0.098798\tBest loss: 0.071201\tAccuracy: 98.67%\n",
      "35\tValidation loss: 0.151016\tBest loss: 0.071201\tAccuracy: 98.20%\n",
      "36\tValidation loss: 0.137240\tBest loss: 0.071201\tAccuracy: 98.63%\n",
      "37\tValidation loss: 0.125944\tBest loss: 0.071201\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.164251\tBest loss: 0.071201\tAccuracy: 98.40%\n",
      "39\tValidation loss: 0.131476\tBest loss: 0.071201\tAccuracy: 98.55%\n",
      "40\tValidation loss: 0.103264\tBest loss: 0.071201\tAccuracy: 98.75%\n",
      "41\tValidation loss: 0.183988\tBest loss: 0.071201\tAccuracy: 98.05%\n",
      "42\tValidation loss: 0.079641\tBest loss: 0.071201\tAccuracy: 98.91%\n",
      "43\tValidation loss: 0.093434\tBest loss: 0.071201\tAccuracy: 98.98%\n",
      "44\tValidation loss: 0.103985\tBest loss: 0.071201\tAccuracy: 98.83%\n",
      "45\tValidation loss: 0.113704\tBest loss: 0.071201\tAccuracy: 98.87%\n",
      "46\tValidation loss: 0.087775\tBest loss: 0.071201\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 2.3min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.107452\tBest loss: 1.107452\tAccuracy: 96.25%\n",
      "1\tValidation loss: 0.542040\tBest loss: 0.542040\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.371537\tBest loss: 0.371537\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.371389\tBest loss: 0.371389\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.207747\tBest loss: 0.207747\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.186662\tBest loss: 0.186662\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.157975\tBest loss: 0.157975\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.148173\tBest loss: 0.148173\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.319348\tBest loss: 0.148173\tAccuracy: 96.33%\n",
      "9\tValidation loss: 0.139768\tBest loss: 0.139768\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.098236\tBest loss: 0.098236\tAccuracy: 99.14%\n",
      "11\tValidation loss: 0.105807\tBest loss: 0.098236\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.127495\tBest loss: 0.098236\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.165030\tBest loss: 0.098236\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.146987\tBest loss: 0.098236\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.301998\tBest loss: 0.098236\tAccuracy: 96.21%\n",
      "16\tValidation loss: 0.103767\tBest loss: 0.098236\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.111620\tBest loss: 0.098236\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.126205\tBest loss: 0.098236\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.094885\tBest loss: 0.094885\tAccuracy: 98.83%\n",
      "20\tValidation loss: 0.089172\tBest loss: 0.089172\tAccuracy: 98.87%\n",
      "21\tValidation loss: 0.105943\tBest loss: 0.089172\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.146213\tBest loss: 0.089172\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.161120\tBest loss: 0.089172\tAccuracy: 98.08%\n",
      "24\tValidation loss: 0.112843\tBest loss: 0.089172\tAccuracy: 98.55%\n",
      "25\tValidation loss: 0.161974\tBest loss: 0.089172\tAccuracy: 98.28%\n",
      "26\tValidation loss: 0.117956\tBest loss: 0.089172\tAccuracy: 98.79%\n",
      "27\tValidation loss: 0.151809\tBest loss: 0.089172\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.185749\tBest loss: 0.089172\tAccuracy: 97.54%\n",
      "29\tValidation loss: 0.113181\tBest loss: 0.089172\tAccuracy: 98.63%\n",
      "30\tValidation loss: 0.179706\tBest loss: 0.089172\tAccuracy: 98.20%\n",
      "31\tValidation loss: 0.126880\tBest loss: 0.089172\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.128443\tBest loss: 0.089172\tAccuracy: 98.67%\n",
      "33\tValidation loss: 0.126743\tBest loss: 0.089172\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.183607\tBest loss: 0.089172\tAccuracy: 98.12%\n",
      "35\tValidation loss: 0.099112\tBest loss: 0.089172\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.080045\tBest loss: 0.080045\tAccuracy: 99.10%\n",
      "37\tValidation loss: 0.092151\tBest loss: 0.080045\tAccuracy: 98.79%\n",
      "38\tValidation loss: 0.140790\tBest loss: 0.080045\tAccuracy: 98.51%\n",
      "39\tValidation loss: 0.117914\tBest loss: 0.080045\tAccuracy: 99.02%\n",
      "40\tValidation loss: 0.107257\tBest loss: 0.080045\tAccuracy: 98.83%\n",
      "41\tValidation loss: 0.105792\tBest loss: 0.080045\tAccuracy: 98.75%\n",
      "42\tValidation loss: 0.156774\tBest loss: 0.080045\tAccuracy: 98.32%\n",
      "43\tValidation loss: 0.144620\tBest loss: 0.080045\tAccuracy: 98.51%\n",
      "44\tValidation loss: 0.111543\tBest loss: 0.080045\tAccuracy: 98.94%\n",
      "45\tValidation loss: 0.140129\tBest loss: 0.080045\tAccuracy: 98.40%\n",
      "46\tValidation loss: 0.081628\tBest loss: 0.080045\tAccuracy: 99.18%\n",
      "47\tValidation loss: 0.105943\tBest loss: 0.080045\tAccuracy: 98.55%\n",
      "48\tValidation loss: 0.068568\tBest loss: 0.068568\tAccuracy: 99.10%\n",
      "49\tValidation loss: 0.134700\tBest loss: 0.068568\tAccuracy: 98.28%\n",
      "50\tValidation loss: 0.076554\tBest loss: 0.068568\tAccuracy: 99.02%\n",
      "51\tValidation loss: 0.097788\tBest loss: 0.068568\tAccuracy: 98.98%\n",
      "52\tValidation loss: 0.075430\tBest loss: 0.068568\tAccuracy: 99.26%\n",
      "53\tValidation loss: 0.076374\tBest loss: 0.068568\tAccuracy: 99.14%\n",
      "54\tValidation loss: 0.127306\tBest loss: 0.068568\tAccuracy: 98.71%\n",
      "55\tValidation loss: 0.084995\tBest loss: 0.068568\tAccuracy: 99.02%\n",
      "56\tValidation loss: 0.124647\tBest loss: 0.068568\tAccuracy: 98.87%\n",
      "57\tValidation loss: 0.122130\tBest loss: 0.068568\tAccuracy: 98.79%\n",
      "58\tValidation loss: 0.113526\tBest loss: 0.068568\tAccuracy: 98.67%\n",
      "59\tValidation loss: 0.078349\tBest loss: 0.068568\tAccuracy: 98.94%\n",
      "60\tValidation loss: 0.090320\tBest loss: 0.068568\tAccuracy: 98.98%\n",
      "61\tValidation loss: 0.110652\tBest loss: 0.068568\tAccuracy: 98.94%\n",
      "62\tValidation loss: 0.097831\tBest loss: 0.068568\tAccuracy: 98.94%\n",
      "63\tValidation loss: 0.071716\tBest loss: 0.068568\tAccuracy: 99.06%\n",
      "64\tValidation loss: 0.092208\tBest loss: 0.068568\tAccuracy: 98.91%\n",
      "65\tValidation loss: 0.083321\tBest loss: 0.068568\tAccuracy: 99.06%\n",
      "66\tValidation loss: 0.076573\tBest loss: 0.068568\tAccuracy: 99.14%\n",
      "67\tValidation loss: 0.062326\tBest loss: 0.062326\tAccuracy: 99.22%\n",
      "68\tValidation loss: 0.065602\tBest loss: 0.062326\tAccuracy: 98.87%\n",
      "69\tValidation loss: 0.099371\tBest loss: 0.062326\tAccuracy: 98.40%\n",
      "70\tValidation loss: 0.095819\tBest loss: 0.062326\tAccuracy: 98.51%\n",
      "71\tValidation loss: 0.066391\tBest loss: 0.062326\tAccuracy: 99.06%\n",
      "72\tValidation loss: 0.078601\tBest loss: 0.062326\tAccuracy: 99.02%\n",
      "73\tValidation loss: 0.105868\tBest loss: 0.062326\tAccuracy: 99.06%\n",
      "74\tValidation loss: 0.086414\tBest loss: 0.062326\tAccuracy: 98.75%\n",
      "75\tValidation loss: 0.084668\tBest loss: 0.062326\tAccuracy: 99.10%\n",
      "76\tValidation loss: 0.089905\tBest loss: 0.062326\tAccuracy: 98.94%\n",
      "77\tValidation loss: 0.078653\tBest loss: 0.062326\tAccuracy: 98.83%\n",
      "78\tValidation loss: 0.082464\tBest loss: 0.062326\tAccuracy: 99.02%\n",
      "79\tValidation loss: 0.091669\tBest loss: 0.062326\tAccuracy: 98.83%\n",
      "80\tValidation loss: 0.104664\tBest loss: 0.062326\tAccuracy: 98.67%\n",
      "81\tValidation loss: 0.093544\tBest loss: 0.062326\tAccuracy: 98.55%\n",
      "82\tValidation loss: 0.068937\tBest loss: 0.062326\tAccuracy: 99.22%\n",
      "83\tValidation loss: 0.088167\tBest loss: 0.062326\tAccuracy: 98.59%\n",
      "84\tValidation loss: 0.078786\tBest loss: 0.062326\tAccuracy: 98.87%\n",
      "85\tValidation loss: 0.072459\tBest loss: 0.062326\tAccuracy: 99.02%\n",
      "86\tValidation loss: 0.073325\tBest loss: 0.062326\tAccuracy: 98.98%\n",
      "87\tValidation loss: 0.101360\tBest loss: 0.062326\tAccuracy: 98.63%\n",
      "88\tValidation loss: 0.081955\tBest loss: 0.062326\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 4.3min\n",
      "[CV] n_neurons=160, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 1.027597\tBest loss: 1.027597\tAccuracy: 96.87%\n",
      "1\tValidation loss: 1.086255\tBest loss: 1.027597\tAccuracy: 95.31%\n",
      "2\tValidation loss: 0.317879\tBest loss: 0.317879\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.255131\tBest loss: 0.255131\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.355340\tBest loss: 0.255131\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.130042\tBest loss: 0.130042\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.268020\tBest loss: 0.130042\tAccuracy: 97.46%\n",
      "7\tValidation loss: 0.146265\tBest loss: 0.130042\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.188918\tBest loss: 0.130042\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.112709\tBest loss: 0.112709\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.136487\tBest loss: 0.112709\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.196904\tBest loss: 0.112709\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.120240\tBest loss: 0.112709\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.133841\tBest loss: 0.112709\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.087638\tBest loss: 0.087638\tAccuracy: 99.10%\n",
      "15\tValidation loss: 0.186581\tBest loss: 0.087638\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.094867\tBest loss: 0.087638\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.085420\tBest loss: 0.085420\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.096645\tBest loss: 0.085420\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.113721\tBest loss: 0.085420\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.060397\tBest loss: 0.060397\tAccuracy: 99.34%\n",
      "21\tValidation loss: 0.209578\tBest loss: 0.060397\tAccuracy: 97.77%\n",
      "22\tValidation loss: 0.085045\tBest loss: 0.060397\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.071577\tBest loss: 0.060397\tAccuracy: 99.34%\n",
      "24\tValidation loss: 0.179529\tBest loss: 0.060397\tAccuracy: 98.08%\n",
      "25\tValidation loss: 0.109586\tBest loss: 0.060397\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.176637\tBest loss: 0.060397\tAccuracy: 98.51%\n",
      "27\tValidation loss: 0.099666\tBest loss: 0.060397\tAccuracy: 98.91%\n",
      "28\tValidation loss: 0.074724\tBest loss: 0.060397\tAccuracy: 99.02%\n",
      "29\tValidation loss: 0.071503\tBest loss: 0.060397\tAccuracy: 99.06%\n",
      "30\tValidation loss: 0.072247\tBest loss: 0.060397\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.064780\tBest loss: 0.060397\tAccuracy: 99.14%\n",
      "32\tValidation loss: 0.080492\tBest loss: 0.060397\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.065036\tBest loss: 0.060397\tAccuracy: 99.10%\n",
      "34\tValidation loss: 0.191284\tBest loss: 0.060397\tAccuracy: 97.62%\n",
      "35\tValidation loss: 0.084959\tBest loss: 0.060397\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.203467\tBest loss: 0.060397\tAccuracy: 98.40%\n",
      "37\tValidation loss: 0.109308\tBest loss: 0.060397\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.061105\tBest loss: 0.060397\tAccuracy: 99.18%\n",
      "39\tValidation loss: 0.052946\tBest loss: 0.052946\tAccuracy: 99.26%\n",
      "40\tValidation loss: 0.055401\tBest loss: 0.052946\tAccuracy: 99.30%\n",
      "41\tValidation loss: 0.105466\tBest loss: 0.052946\tAccuracy: 98.63%\n",
      "42\tValidation loss: 0.099236\tBest loss: 0.052946\tAccuracy: 98.59%\n",
      "43\tValidation loss: 0.108613\tBest loss: 0.052946\tAccuracy: 98.94%\n",
      "44\tValidation loss: 0.081450\tBest loss: 0.052946\tAccuracy: 99.10%\n",
      "45\tValidation loss: 0.076454\tBest loss: 0.052946\tAccuracy: 99.26%\n",
      "46\tValidation loss: 0.082152\tBest loss: 0.052946\tAccuracy: 98.91%\n",
      "47\tValidation loss: 0.087359\tBest loss: 0.052946\tAccuracy: 99.10%\n",
      "48\tValidation loss: 0.099282\tBest loss: 0.052946\tAccuracy: 98.91%\n",
      "49\tValidation loss: 0.053992\tBest loss: 0.052946\tAccuracy: 99.18%\n",
      "50\tValidation loss: 0.044918\tBest loss: 0.044918\tAccuracy: 99.22%\n",
      "51\tValidation loss: 0.107651\tBest loss: 0.044918\tAccuracy: 98.51%\n",
      "52\tValidation loss: 0.070694\tBest loss: 0.044918\tAccuracy: 99.22%\n",
      "53\tValidation loss: 0.096964\tBest loss: 0.044918\tAccuracy: 98.63%\n",
      "54\tValidation loss: 0.090264\tBest loss: 0.044918\tAccuracy: 98.94%\n",
      "55\tValidation loss: 0.065135\tBest loss: 0.044918\tAccuracy: 99.14%\n",
      "56\tValidation loss: 0.079393\tBest loss: 0.044918\tAccuracy: 98.91%\n",
      "57\tValidation loss: 0.083395\tBest loss: 0.044918\tAccuracy: 98.79%\n",
      "58\tValidation loss: 0.066411\tBest loss: 0.044918\tAccuracy: 99.02%\n",
      "59\tValidation loss: 0.104267\tBest loss: 0.044918\tAccuracy: 98.75%\n",
      "60\tValidation loss: 0.078658\tBest loss: 0.044918\tAccuracy: 99.02%\n",
      "61\tValidation loss: 0.069272\tBest loss: 0.044918\tAccuracy: 99.02%\n",
      "62\tValidation loss: 0.073003\tBest loss: 0.044918\tAccuracy: 99.02%\n",
      "63\tValidation loss: 0.141570\tBest loss: 0.044918\tAccuracy: 98.24%\n",
      "64\tValidation loss: 0.095545\tBest loss: 0.044918\tAccuracy: 98.87%\n",
      "65\tValidation loss: 0.069046\tBest loss: 0.044918\tAccuracy: 99.18%\n",
      "66\tValidation loss: 0.080267\tBest loss: 0.044918\tAccuracy: 98.94%\n",
      "67\tValidation loss: 0.110408\tBest loss: 0.044918\tAccuracy: 98.67%\n",
      "68\tValidation loss: 0.062917\tBest loss: 0.044918\tAccuracy: 99.06%\n",
      "69\tValidation loss: 0.056876\tBest loss: 0.044918\tAccuracy: 99.18%\n",
      "70\tValidation loss: 0.069778\tBest loss: 0.044918\tAccuracy: 99.26%\n",
      "71\tValidation loss: 0.092246\tBest loss: 0.044918\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.999, activation=<function elu at 0x7fabf3fc68b0>, total= 3.5min\n",
      "[CV] n_neurons=10, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.169170\tBest loss: 0.169170\tAccuracy: 94.68%\n",
      "1\tValidation loss: 0.111733\tBest loss: 0.111733\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.083100\tBest loss: 0.083100\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.061405\tBest loss: 0.061405\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.083046\tBest loss: 0.061405\tAccuracy: 97.42%\n",
      "5\tValidation loss: 0.068012\tBest loss: 0.061405\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.066192\tBest loss: 0.061405\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.110199\tBest loss: 0.061405\tAccuracy: 97.30%\n",
      "8\tValidation loss: 0.070692\tBest loss: 0.061405\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.063736\tBest loss: 0.061405\tAccuracy: 98.12%\n",
      "10\tValidation loss: 0.060193\tBest loss: 0.060193\tAccuracy: 98.05%\n",
      "11\tValidation loss: 0.069878\tBest loss: 0.060193\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.062317\tBest loss: 0.060193\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.082524\tBest loss: 0.060193\tAccuracy: 97.69%\n",
      "14\tValidation loss: 0.069162\tBest loss: 0.060193\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.067003\tBest loss: 0.060193\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.073343\tBest loss: 0.060193\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.086287\tBest loss: 0.060193\tAccuracy: 97.65%\n",
      "18\tValidation loss: 0.076385\tBest loss: 0.060193\tAccuracy: 98.08%\n",
      "19\tValidation loss: 0.072271\tBest loss: 0.060193\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.067566\tBest loss: 0.060193\tAccuracy: 98.20%\n",
      "21\tValidation loss: 0.074297\tBest loss: 0.060193\tAccuracy: 97.97%\n",
      "22\tValidation loss: 0.128424\tBest loss: 0.060193\tAccuracy: 97.22%\n",
      "23\tValidation loss: 0.076284\tBest loss: 0.060193\tAccuracy: 97.77%\n",
      "24\tValidation loss: 0.084812\tBest loss: 0.060193\tAccuracy: 98.08%\n",
      "25\tValidation loss: 0.062517\tBest loss: 0.060193\tAccuracy: 98.36%\n",
      "26\tValidation loss: 0.067681\tBest loss: 0.060193\tAccuracy: 98.12%\n",
      "27\tValidation loss: 0.068765\tBest loss: 0.060193\tAccuracy: 98.20%\n",
      "28\tValidation loss: 0.071678\tBest loss: 0.060193\tAccuracy: 98.20%\n",
      "29\tValidation loss: 0.066903\tBest loss: 0.060193\tAccuracy: 98.32%\n",
      "30\tValidation loss: 0.075026\tBest loss: 0.060193\tAccuracy: 97.89%\n",
      "31\tValidation loss: 0.081656\tBest loss: 0.060193\tAccuracy: 97.93%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0>, total=  39.8s\n",
      "[CV] n_neurons=10, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.092320\tBest loss: 0.092320\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.073430\tBest loss: 0.073430\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.061293\tBest loss: 0.061293\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.070818\tBest loss: 0.061293\tAccuracy: 97.69%\n",
      "4\tValidation loss: 0.065335\tBest loss: 0.061293\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.069645\tBest loss: 0.061293\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.057066\tBest loss: 0.057066\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.063909\tBest loss: 0.057066\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.053417\tBest loss: 0.053417\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.061246\tBest loss: 0.053417\tAccuracy: 98.12%\n",
      "10\tValidation loss: 0.061465\tBest loss: 0.053417\tAccuracy: 98.08%\n",
      "11\tValidation loss: 0.074437\tBest loss: 0.053417\tAccuracy: 97.73%\n",
      "12\tValidation loss: 0.061398\tBest loss: 0.053417\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.073076\tBest loss: 0.053417\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.069688\tBest loss: 0.053417\tAccuracy: 98.08%\n",
      "15\tValidation loss: 0.089144\tBest loss: 0.053417\tAccuracy: 97.62%\n",
      "16\tValidation loss: 0.080051\tBest loss: 0.053417\tAccuracy: 97.85%\n",
      "17\tValidation loss: 0.057460\tBest loss: 0.053417\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.068177\tBest loss: 0.053417\tAccuracy: 98.12%\n",
      "19\tValidation loss: 0.080811\tBest loss: 0.053417\tAccuracy: 97.93%\n",
      "20\tValidation loss: 0.058916\tBest loss: 0.053417\tAccuracy: 98.16%\n",
      "21\tValidation loss: 0.075143\tBest loss: 0.053417\tAccuracy: 98.01%\n",
      "22\tValidation loss: 0.061798\tBest loss: 0.053417\tAccuracy: 98.24%\n",
      "23\tValidation loss: 0.066495\tBest loss: 0.053417\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.057809\tBest loss: 0.053417\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.066024\tBest loss: 0.053417\tAccuracy: 98.32%\n",
      "26\tValidation loss: 0.070893\tBest loss: 0.053417\tAccuracy: 98.16%\n",
      "27\tValidation loss: 0.089461\tBest loss: 0.053417\tAccuracy: 98.16%\n",
      "28\tValidation loss: 0.075526\tBest loss: 0.053417\tAccuracy: 97.81%\n",
      "29\tValidation loss: 0.077747\tBest loss: 0.053417\tAccuracy: 98.08%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0>, total=  37.0s\n",
      "[CV] n_neurons=10, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.150758\tBest loss: 0.150758\tAccuracy: 95.82%\n",
      "1\tValidation loss: 0.095702\tBest loss: 0.095702\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.084047\tBest loss: 0.084047\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.083323\tBest loss: 0.083323\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.063850\tBest loss: 0.063850\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.067876\tBest loss: 0.063850\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.062329\tBest loss: 0.062329\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.063711\tBest loss: 0.062329\tAccuracy: 98.32%\n",
      "8\tValidation loss: 0.069989\tBest loss: 0.062329\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.064879\tBest loss: 0.062329\tAccuracy: 98.20%\n",
      "10\tValidation loss: 0.056104\tBest loss: 0.056104\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.070640\tBest loss: 0.056104\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.065331\tBest loss: 0.056104\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.065978\tBest loss: 0.056104\tAccuracy: 98.12%\n",
      "14\tValidation loss: 0.063934\tBest loss: 0.056104\tAccuracy: 98.32%\n",
      "15\tValidation loss: 0.070939\tBest loss: 0.056104\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.062711\tBest loss: 0.056104\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.068024\tBest loss: 0.056104\tAccuracy: 98.24%\n",
      "18\tValidation loss: 0.057957\tBest loss: 0.056104\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.062979\tBest loss: 0.056104\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.070341\tBest loss: 0.056104\tAccuracy: 97.93%\n",
      "21\tValidation loss: 0.069244\tBest loss: 0.056104\tAccuracy: 98.16%\n",
      "22\tValidation loss: 0.079729\tBest loss: 0.056104\tAccuracy: 97.73%\n",
      "23\tValidation loss: 0.058744\tBest loss: 0.056104\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.067581\tBest loss: 0.056104\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.065243\tBest loss: 0.056104\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.063379\tBest loss: 0.056104\tAccuracy: 98.40%\n",
      "27\tValidation loss: 0.063830\tBest loss: 0.056104\tAccuracy: 98.40%\n",
      "28\tValidation loss: 0.067575\tBest loss: 0.056104\tAccuracy: 98.48%\n",
      "29\tValidation loss: 0.065485\tBest loss: 0.056104\tAccuracy: 98.20%\n",
      "30\tValidation loss: 0.065646\tBest loss: 0.056104\tAccuracy: 98.24%\n",
      "31\tValidation loss: 0.062697\tBest loss: 0.056104\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.02, batch_size=100, batch_norm_momentum=0.98, activation=<function relu at 0x7fabf3f8d0d0>, total=  39.7s\n",
      "[CV] n_neurons=120, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.084585\tBest loss: 0.084585\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.089486\tBest loss: 0.084585\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.056409\tBest loss: 0.056409\tAccuracy: 98.40%\n",
      "3\tValidation loss: 0.076732\tBest loss: 0.056409\tAccuracy: 97.69%\n",
      "4\tValidation loss: 0.044868\tBest loss: 0.044868\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.048949\tBest loss: 0.044868\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.063975\tBest loss: 0.044868\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.044464\tBest loss: 0.044464\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.044009\tBest loss: 0.044009\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.093289\tBest loss: 0.044009\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.049564\tBest loss: 0.044009\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.038198\tBest loss: 0.038198\tAccuracy: 98.94%\n",
      "12\tValidation loss: 0.032235\tBest loss: 0.032235\tAccuracy: 99.14%\n",
      "13\tValidation loss: 0.039589\tBest loss: 0.032235\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.037230\tBest loss: 0.032235\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.074043\tBest loss: 0.032235\tAccuracy: 97.97%\n",
      "16\tValidation loss: 0.041185\tBest loss: 0.032235\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.036192\tBest loss: 0.032235\tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.038737\tBest loss: 0.032235\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.052090\tBest loss: 0.032235\tAccuracy: 98.51%\n",
      "20\tValidation loss: 0.042241\tBest loss: 0.032235\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.055929\tBest loss: 0.032235\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.042407\tBest loss: 0.032235\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.073141\tBest loss: 0.032235\tAccuracy: 98.20%\n",
      "24\tValidation loss: 0.044208\tBest loss: 0.032235\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.038091\tBest loss: 0.032235\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.041545\tBest loss: 0.032235\tAccuracy: 99.06%\n",
      "27\tValidation loss: 0.039323\tBest loss: 0.032235\tAccuracy: 99.02%\n",
      "28\tValidation loss: 0.062158\tBest loss: 0.032235\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.048550\tBest loss: 0.032235\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.047729\tBest loss: 0.032235\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.045842\tBest loss: 0.032235\tAccuracy: 98.91%\n",
      "32\tValidation loss: 0.034300\tBest loss: 0.032235\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.050718\tBest loss: 0.032235\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 7.3min\n",
      "[CV] n_neurons=120, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.098711\tBest loss: 0.098711\tAccuracy: 96.60%\n",
      "1\tValidation loss: 0.080079\tBest loss: 0.080079\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.063808\tBest loss: 0.063808\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.065699\tBest loss: 0.063808\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.044493\tBest loss: 0.044493\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.051919\tBest loss: 0.044493\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.042548\tBest loss: 0.042548\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.042108\tBest loss: 0.042108\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.053093\tBest loss: 0.042108\tAccuracy: 98.44%\n",
      "9\tValidation loss: 0.051413\tBest loss: 0.042108\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.031786\tBest loss: 0.031786\tAccuracy: 98.91%\n",
      "11\tValidation loss: 0.032440\tBest loss: 0.031786\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.029487\tBest loss: 0.029487\tAccuracy: 99.22%\n",
      "13\tValidation loss: 0.042720\tBest loss: 0.029487\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.037849\tBest loss: 0.029487\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.041070\tBest loss: 0.029487\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.045916\tBest loss: 0.029487\tAccuracy: 98.55%\n",
      "17\tValidation loss: 0.046056\tBest loss: 0.029487\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.036901\tBest loss: 0.029487\tAccuracy: 98.98%\n",
      "19\tValidation loss: 0.040571\tBest loss: 0.029487\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.040100\tBest loss: 0.029487\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.038527\tBest loss: 0.029487\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.060302\tBest loss: 0.029487\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.037693\tBest loss: 0.029487\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.032656\tBest loss: 0.029487\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.041701\tBest loss: 0.029487\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.033181\tBest loss: 0.029487\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.053121\tBest loss: 0.029487\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.050179\tBest loss: 0.029487\tAccuracy: 98.67%\n",
      "29\tValidation loss: 0.043020\tBest loss: 0.029487\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.047716\tBest loss: 0.029487\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.043266\tBest loss: 0.029487\tAccuracy: 98.91%\n",
      "32\tValidation loss: 0.052690\tBest loss: 0.029487\tAccuracy: 98.55%\n",
      "33\tValidation loss: 0.039401\tBest loss: 0.029487\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 7.2min\n",
      "[CV] n_neurons=120, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.111456\tBest loss: 0.111456\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.071432\tBest loss: 0.071432\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.073484\tBest loss: 0.071432\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.066135\tBest loss: 0.066135\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.054729\tBest loss: 0.054729\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.055981\tBest loss: 0.054729\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.040672\tBest loss: 0.040672\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.045428\tBest loss: 0.040672\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.046836\tBest loss: 0.040672\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.034132\tBest loss: 0.034132\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.034766\tBest loss: 0.034132\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.082535\tBest loss: 0.034132\tAccuracy: 97.50%\n",
      "12\tValidation loss: 0.028503\tBest loss: 0.028503\tAccuracy: 99.18%\n",
      "13\tValidation loss: 0.045653\tBest loss: 0.028503\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.035804\tBest loss: 0.028503\tAccuracy: 99.02%\n",
      "15\tValidation loss: 0.043328\tBest loss: 0.028503\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.043339\tBest loss: 0.028503\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.052285\tBest loss: 0.028503\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.068773\tBest loss: 0.028503\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.039370\tBest loss: 0.028503\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.039025\tBest loss: 0.028503\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.054633\tBest loss: 0.028503\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.036862\tBest loss: 0.028503\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.041729\tBest loss: 0.028503\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.041332\tBest loss: 0.028503\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.029128\tBest loss: 0.028503\tAccuracy: 99.14%\n",
      "26\tValidation loss: 0.035268\tBest loss: 0.028503\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.033193\tBest loss: 0.028503\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.032950\tBest loss: 0.028503\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.038107\tBest loss: 0.028503\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.032704\tBest loss: 0.028503\tAccuracy: 99.22%\n",
      "31\tValidation loss: 0.047558\tBest loss: 0.028503\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.036829\tBest loss: 0.028503\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.036157\tBest loss: 0.028503\tAccuracy: 99.14%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.02, batch_size=10, batch_norm_momentum=0.95, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total= 7.2min\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.181308\tBest loss: 0.181308\tAccuracy: 95.82%\n",
      "1\tValidation loss: 0.111516\tBest loss: 0.111516\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.087929\tBest loss: 0.087929\tAccuracy: 97.30%\n",
      "3\tValidation loss: 0.085471\tBest loss: 0.085471\tAccuracy: 97.54%\n",
      "4\tValidation loss: 0.093056\tBest loss: 0.085471\tAccuracy: 97.26%\n",
      "5\tValidation loss: 0.097479\tBest loss: 0.085471\tAccuracy: 97.15%\n",
      "6\tValidation loss: 0.082581\tBest loss: 0.082581\tAccuracy: 97.77%\n",
      "7\tValidation loss: 0.068278\tBest loss: 0.068278\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.086134\tBest loss: 0.068278\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.088461\tBest loss: 0.068278\tAccuracy: 97.50%\n",
      "10\tValidation loss: 0.077059\tBest loss: 0.068278\tAccuracy: 97.62%\n",
      "11\tValidation loss: 0.088957\tBest loss: 0.068278\tAccuracy: 97.22%\n",
      "12\tValidation loss: 0.071569\tBest loss: 0.068278\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.085408\tBest loss: 0.068278\tAccuracy: 97.65%\n",
      "14\tValidation loss: 0.085151\tBest loss: 0.068278\tAccuracy: 97.73%\n",
      "15\tValidation loss: 0.090564\tBest loss: 0.068278\tAccuracy: 97.62%\n",
      "16\tValidation loss: 0.100597\tBest loss: 0.068278\tAccuracy: 97.34%\n",
      "17\tValidation loss: 0.089265\tBest loss: 0.068278\tAccuracy: 97.69%\n",
      "18\tValidation loss: 0.090937\tBest loss: 0.068278\tAccuracy: 97.58%\n",
      "19\tValidation loss: 0.084154\tBest loss: 0.068278\tAccuracy: 97.77%\n",
      "20\tValidation loss: 0.080954\tBest loss: 0.068278\tAccuracy: 97.81%\n",
      "21\tValidation loss: 0.090080\tBest loss: 0.068278\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.085838\tBest loss: 0.068278\tAccuracy: 97.34%\n",
      "23\tValidation loss: 0.083561\tBest loss: 0.068278\tAccuracy: 97.81%\n",
      "24\tValidation loss: 0.108223\tBest loss: 0.068278\tAccuracy: 97.30%\n",
      "25\tValidation loss: 0.086758\tBest loss: 0.068278\tAccuracy: 97.77%\n",
      "26\tValidation loss: 0.082765\tBest loss: 0.068278\tAccuracy: 97.93%\n",
      "27\tValidation loss: 0.085860\tBest loss: 0.068278\tAccuracy: 97.89%\n",
      "28\tValidation loss: 0.086045\tBest loss: 0.068278\tAccuracy: 97.89%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=  14.7s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.182125\tBest loss: 0.182125\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.090230\tBest loss: 0.090230\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.082380\tBest loss: 0.082380\tAccuracy: 97.34%\n",
      "3\tValidation loss: 0.066109\tBest loss: 0.066109\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.071032\tBest loss: 0.066109\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.055961\tBest loss: 0.055961\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.059032\tBest loss: 0.055961\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.056989\tBest loss: 0.055961\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.067783\tBest loss: 0.055961\tAccuracy: 97.93%\n",
      "9\tValidation loss: 0.070110\tBest loss: 0.055961\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.061292\tBest loss: 0.055961\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.078609\tBest loss: 0.055961\tAccuracy: 97.81%\n",
      "12\tValidation loss: 0.058139\tBest loss: 0.055961\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.070671\tBest loss: 0.055961\tAccuracy: 97.93%\n",
      "14\tValidation loss: 0.063029\tBest loss: 0.055961\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.058568\tBest loss: 0.055961\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.067571\tBest loss: 0.055961\tAccuracy: 98.51%\n",
      "17\tValidation loss: 0.076597\tBest loss: 0.055961\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.063265\tBest loss: 0.055961\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.068175\tBest loss: 0.055961\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.063983\tBest loss: 0.055961\tAccuracy: 98.24%\n",
      "21\tValidation loss: 0.062692\tBest loss: 0.055961\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.076178\tBest loss: 0.055961\tAccuracy: 98.28%\n",
      "23\tValidation loss: 0.071895\tBest loss: 0.055961\tAccuracy: 98.28%\n",
      "24\tValidation loss: 0.070808\tBest loss: 0.055961\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.063494\tBest loss: 0.055961\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.069175\tBest loss: 0.055961\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=  13.9s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70> \n",
      "0\tValidation loss: 0.152011\tBest loss: 0.152011\tAccuracy: 96.09%\n",
      "1\tValidation loss: 0.084565\tBest loss: 0.084565\tAccuracy: 97.26%\n",
      "2\tValidation loss: 0.069341\tBest loss: 0.069341\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.069059\tBest loss: 0.069059\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.062458\tBest loss: 0.062458\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.060354\tBest loss: 0.060354\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.059299\tBest loss: 0.059299\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.060066\tBest loss: 0.059299\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.059718\tBest loss: 0.059299\tAccuracy: 98.40%\n",
      "9\tValidation loss: 0.058699\tBest loss: 0.058699\tAccuracy: 98.08%\n",
      "10\tValidation loss: 0.062601\tBest loss: 0.058699\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.066449\tBest loss: 0.058699\tAccuracy: 98.16%\n",
      "12\tValidation loss: 0.073616\tBest loss: 0.058699\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.075694\tBest loss: 0.058699\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.071956\tBest loss: 0.058699\tAccuracy: 98.20%\n",
      "15\tValidation loss: 0.074217\tBest loss: 0.058699\tAccuracy: 98.16%\n",
      "16\tValidation loss: 0.094252\tBest loss: 0.058699\tAccuracy: 97.73%\n",
      "17\tValidation loss: 0.072090\tBest loss: 0.058699\tAccuracy: 98.24%\n",
      "18\tValidation loss: 0.083199\tBest loss: 0.058699\tAccuracy: 98.01%\n",
      "19\tValidation loss: 0.080390\tBest loss: 0.058699\tAccuracy: 98.08%\n",
      "20\tValidation loss: 0.076492\tBest loss: 0.058699\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.082391\tBest loss: 0.058699\tAccuracy: 98.36%\n",
      "22\tValidation loss: 0.091396\tBest loss: 0.058699\tAccuracy: 98.01%\n",
      "23\tValidation loss: 0.081707\tBest loss: 0.058699\tAccuracy: 98.05%\n",
      "24\tValidation loss: 0.086028\tBest loss: 0.058699\tAccuracy: 98.12%\n",
      "25\tValidation loss: 0.086033\tBest loss: 0.058699\tAccuracy: 98.20%\n",
      "26\tValidation loss: 0.079395\tBest loss: 0.058699\tAccuracy: 98.24%\n",
      "27\tValidation loss: 0.095925\tBest loss: 0.058699\tAccuracy: 98.28%\n",
      "28\tValidation loss: 0.081316\tBest loss: 0.058699\tAccuracy: 98.20%\n",
      "29\tValidation loss: 0.084960\tBest loss: 0.058699\tAccuracy: 98.12%\n",
      "30\tValidation loss: 0.098609\tBest loss: 0.058699\tAccuracy: 98.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=500, batch_norm_momentum=0.9, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>, total=  15.8s\n",
      "[CV] n_neurons=120, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 2.312047\tBest loss: 2.312047\tAccuracy: 87.65%\n",
      "1\tValidation loss: 2.314633\tBest loss: 2.312047\tAccuracy: 78.46%\n",
      "2\tValidation loss: 0.301836\tBest loss: 0.301836\tAccuracy: 96.40%\n",
      "3\tValidation loss: 0.300262\tBest loss: 0.300262\tAccuracy: 95.23%\n",
      "4\tValidation loss: 0.133692\tBest loss: 0.133692\tAccuracy: 97.50%\n",
      "5\tValidation loss: 0.230741\tBest loss: 0.133692\tAccuracy: 95.23%\n",
      "6\tValidation loss: 0.094630\tBest loss: 0.094630\tAccuracy: 98.08%\n",
      "7\tValidation loss: 0.133836\tBest loss: 0.094630\tAccuracy: 95.97%\n",
      "8\tValidation loss: 0.140788\tBest loss: 0.094630\tAccuracy: 96.44%\n",
      "9\tValidation loss: 0.096584\tBest loss: 0.094630\tAccuracy: 97.89%\n",
      "10\tValidation loss: 0.131309\tBest loss: 0.094630\tAccuracy: 96.44%\n",
      "11\tValidation loss: 0.096531\tBest loss: 0.094630\tAccuracy: 97.22%\n",
      "12\tValidation loss: 0.061236\tBest loss: 0.061236\tAccuracy: 98.28%\n",
      "13\tValidation loss: 0.090262\tBest loss: 0.061236\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.369879\tBest loss: 0.061236\tAccuracy: 92.30%\n",
      "15\tValidation loss: 0.085462\tBest loss: 0.061236\tAccuracy: 98.01%\n",
      "16\tValidation loss: 0.059931\tBest loss: 0.059931\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.115660\tBest loss: 0.059931\tAccuracy: 97.65%\n",
      "18\tValidation loss: 0.145279\tBest loss: 0.059931\tAccuracy: 97.77%\n",
      "19\tValidation loss: 0.109391\tBest loss: 0.059931\tAccuracy: 96.91%\n",
      "20\tValidation loss: 0.078902\tBest loss: 0.059931\tAccuracy: 98.24%\n",
      "21\tValidation loss: 0.049136\tBest loss: 0.049136\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.097519\tBest loss: 0.049136\tAccuracy: 98.24%\n",
      "23\tValidation loss: 0.100607\tBest loss: 0.049136\tAccuracy: 97.50%\n",
      "24\tValidation loss: 0.053719\tBest loss: 0.049136\tAccuracy: 98.55%\n",
      "25\tValidation loss: 0.189242\tBest loss: 0.049136\tAccuracy: 96.29%\n",
      "26\tValidation loss: 0.124994\tBest loss: 0.049136\tAccuracy: 96.91%\n",
      "27\tValidation loss: 0.048272\tBest loss: 0.048272\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.085491\tBest loss: 0.048272\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.076526\tBest loss: 0.048272\tAccuracy: 98.16%\n",
      "30\tValidation loss: 0.110047\tBest loss: 0.048272\tAccuracy: 97.38%\n",
      "31\tValidation loss: 0.110641\tBest loss: 0.048272\tAccuracy: 97.19%\n",
      "32\tValidation loss: 0.075070\tBest loss: 0.048272\tAccuracy: 98.87%\n",
      "33\tValidation loss: 0.080984\tBest loss: 0.048272\tAccuracy: 98.75%\n",
      "34\tValidation loss: 0.053733\tBest loss: 0.048272\tAccuracy: 98.59%\n",
      "35\tValidation loss: 0.070418\tBest loss: 0.048272\tAccuracy: 98.71%\n",
      "36\tValidation loss: 0.078960\tBest loss: 0.048272\tAccuracy: 98.63%\n",
      "37\tValidation loss: 0.068469\tBest loss: 0.048272\tAccuracy: 98.79%\n",
      "38\tValidation loss: 0.066070\tBest loss: 0.048272\tAccuracy: 98.83%\n",
      "39\tValidation loss: 0.066567\tBest loss: 0.048272\tAccuracy: 98.75%\n",
      "40\tValidation loss: 0.098252\tBest loss: 0.048272\tAccuracy: 98.20%\n",
      "41\tValidation loss: 0.048379\tBest loss: 0.048272\tAccuracy: 98.94%\n",
      "42\tValidation loss: 0.152777\tBest loss: 0.048272\tAccuracy: 98.24%\n",
      "43\tValidation loss: 0.097927\tBest loss: 0.048272\tAccuracy: 98.24%\n",
      "44\tValidation loss: 0.136904\tBest loss: 0.048272\tAccuracy: 97.73%\n",
      "45\tValidation loss: 0.063494\tBest loss: 0.048272\tAccuracy: 98.16%\n",
      "46\tValidation loss: 0.059237\tBest loss: 0.048272\tAccuracy: 98.91%\n",
      "47\tValidation loss: 0.063171\tBest loss: 0.048272\tAccuracy: 98.71%\n",
      "48\tValidation loss: 0.203382\tBest loss: 0.048272\tAccuracy: 96.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total= 9.7min\n",
      "[CV] n_neurons=120, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.033921\tBest loss: 1.033921\tAccuracy: 90.81%\n",
      "1\tValidation loss: 0.754098\tBest loss: 0.754098\tAccuracy: 92.14%\n",
      "2\tValidation loss: 0.478571\tBest loss: 0.478571\tAccuracy: 89.05%\n",
      "3\tValidation loss: 0.750373\tBest loss: 0.478571\tAccuracy: 85.97%\n",
      "4\tValidation loss: 0.274036\tBest loss: 0.274036\tAccuracy: 92.65%\n",
      "5\tValidation loss: 0.527935\tBest loss: 0.274036\tAccuracy: 86.98%\n",
      "6\tValidation loss: 0.199624\tBest loss: 0.199624\tAccuracy: 95.35%\n",
      "7\tValidation loss: 0.070916\tBest loss: 0.070916\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.148805\tBest loss: 0.070916\tAccuracy: 96.79%\n",
      "9\tValidation loss: 0.171842\tBest loss: 0.070916\tAccuracy: 96.33%\n",
      "10\tValidation loss: 0.543855\tBest loss: 0.070916\tAccuracy: 87.02%\n",
      "11\tValidation loss: 0.073073\tBest loss: 0.070916\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.098310\tBest loss: 0.070916\tAccuracy: 97.46%\n",
      "13\tValidation loss: 0.210995\tBest loss: 0.070916\tAccuracy: 95.66%\n",
      "14\tValidation loss: 0.139189\tBest loss: 0.070916\tAccuracy: 97.03%\n",
      "15\tValidation loss: 0.147141\tBest loss: 0.070916\tAccuracy: 96.01%\n",
      "16\tValidation loss: 0.062600\tBest loss: 0.062600\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.219017\tBest loss: 0.062600\tAccuracy: 95.86%\n",
      "18\tValidation loss: 0.060870\tBest loss: 0.060870\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.104330\tBest loss: 0.060870\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.048868\tBest loss: 0.048868\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.080685\tBest loss: 0.048868\tAccuracy: 98.08%\n",
      "22\tValidation loss: 0.057861\tBest loss: 0.048868\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.051219\tBest loss: 0.048868\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.069435\tBest loss: 0.048868\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.061411\tBest loss: 0.048868\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.085682\tBest loss: 0.048868\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.077466\tBest loss: 0.048868\tAccuracy: 98.20%\n",
      "28\tValidation loss: 0.051970\tBest loss: 0.048868\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.071576\tBest loss: 0.048868\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.072868\tBest loss: 0.048868\tAccuracy: 98.55%\n",
      "31\tValidation loss: 0.049224\tBest loss: 0.048868\tAccuracy: 98.51%\n",
      "32\tValidation loss: 0.097889\tBest loss: 0.048868\tAccuracy: 98.28%\n",
      "33\tValidation loss: 0.043356\tBest loss: 0.043356\tAccuracy: 98.98%\n",
      "34\tValidation loss: 0.047268\tBest loss: 0.043356\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.097183\tBest loss: 0.043356\tAccuracy: 98.59%\n",
      "36\tValidation loss: 0.066695\tBest loss: 0.043356\tAccuracy: 98.59%\n",
      "37\tValidation loss: 0.067301\tBest loss: 0.043356\tAccuracy: 98.55%\n",
      "38\tValidation loss: 0.121331\tBest loss: 0.043356\tAccuracy: 98.16%\n",
      "39\tValidation loss: 0.207534\tBest loss: 0.043356\tAccuracy: 96.91%\n",
      "40\tValidation loss: 0.147535\tBest loss: 0.043356\tAccuracy: 96.99%\n",
      "41\tValidation loss: 0.403042\tBest loss: 0.043356\tAccuracy: 93.90%\n",
      "42\tValidation loss: 0.070633\tBest loss: 0.043356\tAccuracy: 98.55%\n",
      "43\tValidation loss: 0.067639\tBest loss: 0.043356\tAccuracy: 98.71%\n",
      "44\tValidation loss: 0.066527\tBest loss: 0.043356\tAccuracy: 98.79%\n",
      "45\tValidation loss: 0.060230\tBest loss: 0.043356\tAccuracy: 98.91%\n",
      "46\tValidation loss: 0.176773\tBest loss: 0.043356\tAccuracy: 96.64%\n",
      "47\tValidation loss: 0.052722\tBest loss: 0.043356\tAccuracy: 98.87%\n",
      "48\tValidation loss: 0.109852\tBest loss: 0.043356\tAccuracy: 97.89%\n",
      "49\tValidation loss: 0.111078\tBest loss: 0.043356\tAccuracy: 98.51%\n",
      "50\tValidation loss: 0.056163\tBest loss: 0.043356\tAccuracy: 98.94%\n",
      "51\tValidation loss: 0.073884\tBest loss: 0.043356\tAccuracy: 98.71%\n",
      "52\tValidation loss: 0.077450\tBest loss: 0.043356\tAccuracy: 98.87%\n",
      "53\tValidation loss: 0.063116\tBest loss: 0.043356\tAccuracy: 98.51%\n",
      "54\tValidation loss: 0.070394\tBest loss: 0.043356\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total=10.8min\n",
      "[CV] n_neurons=120, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 1.922357\tBest loss: 1.922357\tAccuracy: 83.23%\n",
      "1\tValidation loss: 0.587778\tBest loss: 0.587778\tAccuracy: 94.41%\n",
      "2\tValidation loss: 0.408412\tBest loss: 0.408412\tAccuracy: 92.18%\n",
      "3\tValidation loss: 0.374457\tBest loss: 0.374457\tAccuracy: 91.24%\n",
      "4\tValidation loss: 0.628030\tBest loss: 0.374457\tAccuracy: 89.37%\n",
      "5\tValidation loss: 0.167434\tBest loss: 0.167434\tAccuracy: 94.80%\n",
      "6\tValidation loss: 0.101236\tBest loss: 0.101236\tAccuracy: 97.46%\n",
      "7\tValidation loss: 0.141250\tBest loss: 0.101236\tAccuracy: 97.03%\n",
      "8\tValidation loss: 0.162977\tBest loss: 0.101236\tAccuracy: 95.27%\n",
      "9\tValidation loss: 0.055258\tBest loss: 0.055258\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.074277\tBest loss: 0.055258\tAccuracy: 97.65%\n",
      "11\tValidation loss: 0.115423\tBest loss: 0.055258\tAccuracy: 97.11%\n",
      "12\tValidation loss: 0.088581\tBest loss: 0.055258\tAccuracy: 97.69%\n",
      "13\tValidation loss: 0.055169\tBest loss: 0.055169\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.065101\tBest loss: 0.055169\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.179866\tBest loss: 0.055169\tAccuracy: 95.35%\n",
      "16\tValidation loss: 0.155548\tBest loss: 0.055169\tAccuracy: 96.91%\n",
      "17\tValidation loss: 0.181977\tBest loss: 0.055169\tAccuracy: 96.09%\n",
      "18\tValidation loss: 0.099686\tBest loss: 0.055169\tAccuracy: 97.93%\n",
      "19\tValidation loss: 0.108261\tBest loss: 0.055169\tAccuracy: 97.46%\n",
      "20\tValidation loss: 0.082565\tBest loss: 0.055169\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.066535\tBest loss: 0.055169\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.070905\tBest loss: 0.055169\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.088062\tBest loss: 0.055169\tAccuracy: 97.73%\n",
      "24\tValidation loss: 0.097386\tBest loss: 0.055169\tAccuracy: 98.48%\n",
      "25\tValidation loss: 0.063174\tBest loss: 0.055169\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.044608\tBest loss: 0.044608\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.174448\tBest loss: 0.044608\tAccuracy: 94.68%\n",
      "28\tValidation loss: 0.069635\tBest loss: 0.044608\tAccuracy: 98.08%\n",
      "29\tValidation loss: 0.092118\tBest loss: 0.044608\tAccuracy: 98.40%\n",
      "30\tValidation loss: 0.058033\tBest loss: 0.044608\tAccuracy: 98.59%\n",
      "31\tValidation loss: 0.050345\tBest loss: 0.044608\tAccuracy: 98.87%\n",
      "32\tValidation loss: 0.068791\tBest loss: 0.044608\tAccuracy: 98.63%\n",
      "33\tValidation loss: 0.075448\tBest loss: 0.044608\tAccuracy: 98.48%\n",
      "34\tValidation loss: 0.089130\tBest loss: 0.044608\tAccuracy: 98.08%\n",
      "35\tValidation loss: 0.094860\tBest loss: 0.044608\tAccuracy: 97.85%\n",
      "36\tValidation loss: 0.049847\tBest loss: 0.044608\tAccuracy: 98.59%\n",
      "37\tValidation loss: 0.061107\tBest loss: 0.044608\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.064857\tBest loss: 0.044608\tAccuracy: 98.59%\n",
      "39\tValidation loss: 0.129789\tBest loss: 0.044608\tAccuracy: 97.19%\n",
      "40\tValidation loss: 0.067736\tBest loss: 0.044608\tAccuracy: 98.67%\n",
      "41\tValidation loss: 0.101401\tBest loss: 0.044608\tAccuracy: 97.97%\n",
      "42\tValidation loss: 0.043330\tBest loss: 0.043330\tAccuracy: 98.94%\n",
      "43\tValidation loss: 0.086136\tBest loss: 0.043330\tAccuracy: 97.97%\n",
      "44\tValidation loss: 0.069378\tBest loss: 0.043330\tAccuracy: 98.44%\n",
      "45\tValidation loss: 0.125931\tBest loss: 0.043330\tAccuracy: 98.12%\n",
      "46\tValidation loss: 0.054975\tBest loss: 0.043330\tAccuracy: 99.10%\n",
      "47\tValidation loss: 0.090178\tBest loss: 0.043330\tAccuracy: 98.28%\n",
      "48\tValidation loss: 0.089767\tBest loss: 0.043330\tAccuracy: 98.05%\n",
      "49\tValidation loss: 0.062525\tBest loss: 0.043330\tAccuracy: 98.83%\n",
      "50\tValidation loss: 0.062046\tBest loss: 0.043330\tAccuracy: 98.87%\n",
      "51\tValidation loss: 0.055128\tBest loss: 0.043330\tAccuracy: 98.98%\n",
      "52\tValidation loss: 0.077360\tBest loss: 0.043330\tAccuracy: 98.24%\n",
      "53\tValidation loss: 0.083314\tBest loss: 0.043330\tAccuracy: 98.20%\n",
      "54\tValidation loss: 0.040688\tBest loss: 0.040688\tAccuracy: 98.83%\n",
      "55\tValidation loss: 0.119533\tBest loss: 0.040688\tAccuracy: 96.83%\n",
      "56\tValidation loss: 0.055570\tBest loss: 0.040688\tAccuracy: 98.87%\n",
      "57\tValidation loss: 0.091866\tBest loss: 0.040688\tAccuracy: 98.51%\n",
      "58\tValidation loss: 0.066875\tBest loss: 0.040688\tAccuracy: 98.44%\n",
      "59\tValidation loss: 0.202778\tBest loss: 0.040688\tAccuracy: 96.99%\n",
      "60\tValidation loss: 0.085746\tBest loss: 0.040688\tAccuracy: 98.01%\n",
      "61\tValidation loss: 0.056620\tBest loss: 0.040688\tAccuracy: 98.71%\n",
      "62\tValidation loss: 0.046567\tBest loss: 0.040688\tAccuracy: 98.94%\n",
      "63\tValidation loss: 0.066198\tBest loss: 0.040688\tAccuracy: 98.91%\n",
      "64\tValidation loss: 0.051974\tBest loss: 0.040688\tAccuracy: 98.91%\n",
      "65\tValidation loss: 0.112089\tBest loss: 0.040688\tAccuracy: 98.01%\n",
      "66\tValidation loss: 0.064961\tBest loss: 0.040688\tAccuracy: 98.83%\n",
      "67\tValidation loss: 0.080502\tBest loss: 0.040688\tAccuracy: 98.63%\n",
      "68\tValidation loss: 0.045813\tBest loss: 0.040688\tAccuracy: 98.67%\n",
      "69\tValidation loss: 0.114004\tBest loss: 0.040688\tAccuracy: 98.48%\n",
      "70\tValidation loss: 0.068523\tBest loss: 0.040688\tAccuracy: 98.71%\n",
      "71\tValidation loss: 0.065225\tBest loss: 0.040688\tAccuracy: 98.79%\n",
      "72\tValidation loss: 0.054857\tBest loss: 0.040688\tAccuracy: 98.48%\n",
      "73\tValidation loss: 0.087524\tBest loss: 0.040688\tAccuracy: 98.55%\n",
      "74\tValidation loss: 0.090232\tBest loss: 0.040688\tAccuracy: 98.83%\n",
      "75\tValidation loss: 0.113751\tBest loss: 0.040688\tAccuracy: 98.12%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.1, batch_size=10, batch_norm_momentum=0.999, activation=<function relu at 0x7fabf3f8d0d0>, total=15.0min\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.144134\tBest loss: 0.144134\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.131415\tBest loss: 0.131415\tAccuracy: 96.05%\n",
      "2\tValidation loss: 0.121702\tBest loss: 0.121702\tAccuracy: 96.68%\n",
      "3\tValidation loss: 0.084363\tBest loss: 0.084363\tAccuracy: 97.26%\n",
      "4\tValidation loss: 0.080780\tBest loss: 0.080780\tAccuracy: 97.50%\n",
      "5\tValidation loss: 0.132724\tBest loss: 0.080780\tAccuracy: 96.91%\n",
      "6\tValidation loss: 0.096943\tBest loss: 0.080780\tAccuracy: 97.15%\n",
      "7\tValidation loss: 0.109800\tBest loss: 0.080780\tAccuracy: 96.56%\n",
      "8\tValidation loss: 0.081767\tBest loss: 0.080780\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.103585\tBest loss: 0.080780\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.083135\tBest loss: 0.080780\tAccuracy: 97.42%\n",
      "11\tValidation loss: 0.105719\tBest loss: 0.080780\tAccuracy: 97.38%\n",
      "12\tValidation loss: 0.096871\tBest loss: 0.080780\tAccuracy: 97.22%\n",
      "13\tValidation loss: 0.079330\tBest loss: 0.079330\tAccuracy: 98.01%\n",
      "14\tValidation loss: 0.141200\tBest loss: 0.079330\tAccuracy: 96.60%\n",
      "15\tValidation loss: 0.101725\tBest loss: 0.079330\tAccuracy: 97.54%\n",
      "16\tValidation loss: 0.087269\tBest loss: 0.079330\tAccuracy: 97.42%\n",
      "17\tValidation loss: 0.087318\tBest loss: 0.079330\tAccuracy: 97.38%\n",
      "18\tValidation loss: 0.091526\tBest loss: 0.079330\tAccuracy: 97.89%\n",
      "19\tValidation loss: 0.159419\tBest loss: 0.079330\tAccuracy: 96.99%\n",
      "20\tValidation loss: 0.114294\tBest loss: 0.079330\tAccuracy: 97.62%\n",
      "21\tValidation loss: 0.088347\tBest loss: 0.079330\tAccuracy: 97.58%\n",
      "22\tValidation loss: 0.102182\tBest loss: 0.079330\tAccuracy: 97.46%\n",
      "23\tValidation loss: 0.097980\tBest loss: 0.079330\tAccuracy: 97.50%\n",
      "24\tValidation loss: 0.139656\tBest loss: 0.079330\tAccuracy: 97.22%\n",
      "25\tValidation loss: 0.106786\tBest loss: 0.079330\tAccuracy: 97.42%\n",
      "26\tValidation loss: 0.074046\tBest loss: 0.074046\tAccuracy: 98.12%\n",
      "27\tValidation loss: 0.093856\tBest loss: 0.074046\tAccuracy: 97.50%\n",
      "28\tValidation loss: 0.080450\tBest loss: 0.074046\tAccuracy: 97.50%\n",
      "29\tValidation loss: 0.092457\tBest loss: 0.074046\tAccuracy: 97.73%\n",
      "30\tValidation loss: 0.094668\tBest loss: 0.074046\tAccuracy: 97.62%\n",
      "31\tValidation loss: 0.148206\tBest loss: 0.074046\tAccuracy: 96.68%\n",
      "32\tValidation loss: 0.118165\tBest loss: 0.074046\tAccuracy: 97.07%\n",
      "33\tValidation loss: 0.094071\tBest loss: 0.074046\tAccuracy: 97.65%\n",
      "34\tValidation loss: 0.098459\tBest loss: 0.074046\tAccuracy: 97.62%\n",
      "35\tValidation loss: 0.110558\tBest loss: 0.074046\tAccuracy: 97.50%\n",
      "36\tValidation loss: 0.174501\tBest loss: 0.074046\tAccuracy: 96.48%\n",
      "37\tValidation loss: 0.109449\tBest loss: 0.074046\tAccuracy: 97.69%\n",
      "38\tValidation loss: 0.100280\tBest loss: 0.074046\tAccuracy: 97.69%\n",
      "39\tValidation loss: 0.128477\tBest loss: 0.074046\tAccuracy: 97.69%\n",
      "40\tValidation loss: 0.126533\tBest loss: 0.074046\tAccuracy: 97.46%\n",
      "41\tValidation loss: 0.097013\tBest loss: 0.074046\tAccuracy: 97.50%\n",
      "42\tValidation loss: 0.130816\tBest loss: 0.074046\tAccuracy: 97.62%\n",
      "43\tValidation loss: 0.148104\tBest loss: 0.074046\tAccuracy: 96.91%\n",
      "44\tValidation loss: 0.096941\tBest loss: 0.074046\tAccuracy: 97.89%\n",
      "45\tValidation loss: 0.097626\tBest loss: 0.074046\tAccuracy: 97.77%\n",
      "46\tValidation loss: 0.125343\tBest loss: 0.074046\tAccuracy: 96.99%\n",
      "47\tValidation loss: 0.088753\tBest loss: 0.074046\tAccuracy: 97.69%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 1.6min\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.143730\tBest loss: 0.143730\tAccuracy: 95.50%\n",
      "1\tValidation loss: 0.114134\tBest loss: 0.114134\tAccuracy: 96.44%\n",
      "2\tValidation loss: 0.114318\tBest loss: 0.114134\tAccuracy: 96.76%\n",
      "3\tValidation loss: 0.136696\tBest loss: 0.114134\tAccuracy: 96.44%\n",
      "4\tValidation loss: 0.132703\tBest loss: 0.114134\tAccuracy: 96.17%\n",
      "5\tValidation loss: 0.109227\tBest loss: 0.109227\tAccuracy: 96.60%\n",
      "6\tValidation loss: 0.098128\tBest loss: 0.098128\tAccuracy: 97.22%\n",
      "7\tValidation loss: 0.093112\tBest loss: 0.093112\tAccuracy: 97.19%\n",
      "8\tValidation loss: 0.096477\tBest loss: 0.093112\tAccuracy: 97.19%\n",
      "9\tValidation loss: 0.083929\tBest loss: 0.083929\tAccuracy: 97.42%\n",
      "10\tValidation loss: 0.092870\tBest loss: 0.083929\tAccuracy: 97.42%\n",
      "11\tValidation loss: 0.093621\tBest loss: 0.083929\tAccuracy: 97.30%\n",
      "12\tValidation loss: 0.092380\tBest loss: 0.083929\tAccuracy: 97.30%\n",
      "13\tValidation loss: 0.083638\tBest loss: 0.083638\tAccuracy: 97.46%\n",
      "14\tValidation loss: 0.076792\tBest loss: 0.076792\tAccuracy: 97.62%\n",
      "15\tValidation loss: 0.120212\tBest loss: 0.076792\tAccuracy: 96.29%\n",
      "16\tValidation loss: 0.085519\tBest loss: 0.076792\tAccuracy: 97.42%\n",
      "17\tValidation loss: 0.083637\tBest loss: 0.076792\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.092202\tBest loss: 0.076792\tAccuracy: 97.81%\n",
      "19\tValidation loss: 0.097270\tBest loss: 0.076792\tAccuracy: 97.34%\n",
      "20\tValidation loss: 0.067637\tBest loss: 0.067637\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.075478\tBest loss: 0.067637\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.079908\tBest loss: 0.067637\tAccuracy: 97.93%\n",
      "23\tValidation loss: 0.081836\tBest loss: 0.067637\tAccuracy: 97.97%\n",
      "24\tValidation loss: 0.086530\tBest loss: 0.067637\tAccuracy: 97.77%\n",
      "25\tValidation loss: 0.092420\tBest loss: 0.067637\tAccuracy: 98.05%\n",
      "26\tValidation loss: 0.103299\tBest loss: 0.067637\tAccuracy: 97.46%\n",
      "27\tValidation loss: 0.086293\tBest loss: 0.067637\tAccuracy: 97.89%\n",
      "28\tValidation loss: 0.119274\tBest loss: 0.067637\tAccuracy: 97.69%\n",
      "29\tValidation loss: 0.087473\tBest loss: 0.067637\tAccuracy: 97.85%\n",
      "30\tValidation loss: 0.093761\tBest loss: 0.067637\tAccuracy: 97.65%\n",
      "31\tValidation loss: 0.096793\tBest loss: 0.067637\tAccuracy: 97.65%\n",
      "32\tValidation loss: 0.108352\tBest loss: 0.067637\tAccuracy: 97.58%\n",
      "33\tValidation loss: 0.090039\tBest loss: 0.067637\tAccuracy: 97.73%\n",
      "34\tValidation loss: 0.083750\tBest loss: 0.067637\tAccuracy: 98.01%\n",
      "35\tValidation loss: 0.083482\tBest loss: 0.067637\tAccuracy: 98.28%\n",
      "36\tValidation loss: 0.094832\tBest loss: 0.067637\tAccuracy: 97.89%\n",
      "37\tValidation loss: 0.092387\tBest loss: 0.067637\tAccuracy: 97.77%\n",
      "38\tValidation loss: 0.095722\tBest loss: 0.067637\tAccuracy: 97.54%\n",
      "39\tValidation loss: 0.136265\tBest loss: 0.067637\tAccuracy: 97.11%\n",
      "40\tValidation loss: 0.139299\tBest loss: 0.067637\tAccuracy: 96.87%\n",
      "41\tValidation loss: 0.143212\tBest loss: 0.067637\tAccuracy: 96.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 1.4min\n",
      "[CV] n_neurons=10, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0> \n",
      "0\tValidation loss: 0.105162\tBest loss: 0.105162\tAccuracy: 96.76%\n",
      "1\tValidation loss: 0.129578\tBest loss: 0.105162\tAccuracy: 95.97%\n",
      "2\tValidation loss: 0.098599\tBest loss: 0.098599\tAccuracy: 96.87%\n",
      "3\tValidation loss: 0.082235\tBest loss: 0.082235\tAccuracy: 97.42%\n",
      "4\tValidation loss: 0.099889\tBest loss: 0.082235\tAccuracy: 97.26%\n",
      "5\tValidation loss: 0.088941\tBest loss: 0.082235\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.098324\tBest loss: 0.082235\tAccuracy: 97.42%\n",
      "7\tValidation loss: 0.080812\tBest loss: 0.080812\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.098872\tBest loss: 0.080812\tAccuracy: 97.19%\n",
      "9\tValidation loss: 0.071233\tBest loss: 0.071233\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.142755\tBest loss: 0.071233\tAccuracy: 96.01%\n",
      "11\tValidation loss: 0.110952\tBest loss: 0.071233\tAccuracy: 96.83%\n",
      "12\tValidation loss: 0.078884\tBest loss: 0.071233\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.078707\tBest loss: 0.071233\tAccuracy: 97.65%\n",
      "14\tValidation loss: 0.108338\tBest loss: 0.071233\tAccuracy: 97.07%\n",
      "15\tValidation loss: 0.099597\tBest loss: 0.071233\tAccuracy: 97.15%\n",
      "16\tValidation loss: 0.076180\tBest loss: 0.071233\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.097505\tBest loss: 0.071233\tAccuracy: 97.19%\n",
      "18\tValidation loss: 0.081087\tBest loss: 0.071233\tAccuracy: 97.77%\n",
      "19\tValidation loss: 0.075626\tBest loss: 0.071233\tAccuracy: 97.81%\n",
      "20\tValidation loss: 0.075276\tBest loss: 0.071233\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.114220\tBest loss: 0.071233\tAccuracy: 97.19%\n",
      "22\tValidation loss: 0.075319\tBest loss: 0.071233\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.083363\tBest loss: 0.071233\tAccuracy: 97.85%\n",
      "24\tValidation loss: 0.091899\tBest loss: 0.071233\tAccuracy: 97.89%\n",
      "25\tValidation loss: 0.088091\tBest loss: 0.071233\tAccuracy: 97.77%\n",
      "26\tValidation loss: 0.105121\tBest loss: 0.071233\tAccuracy: 97.46%\n",
      "27\tValidation loss: 0.076426\tBest loss: 0.071233\tAccuracy: 98.08%\n",
      "28\tValidation loss: 0.107967\tBest loss: 0.071233\tAccuracy: 97.54%\n",
      "29\tValidation loss: 0.082183\tBest loss: 0.071233\tAccuracy: 98.05%\n",
      "30\tValidation loss: 0.107202\tBest loss: 0.071233\tAccuracy: 97.30%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.1, batch_size=50, batch_norm_momentum=0.9, activation=<function elu at 0x7fabf3fc68b0>, total= 1.1min\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.061137\tBest loss: 0.061137\tAccuracy: 98.36%\n",
      "1\tValidation loss: 0.055409\tBest loss: 0.055409\tAccuracy: 98.44%\n",
      "2\tValidation loss: 0.041492\tBest loss: 0.041492\tAccuracy: 98.79%\n",
      "3\tValidation loss: 0.055522\tBest loss: 0.041492\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.042415\tBest loss: 0.041492\tAccuracy: 98.55%\n",
      "5\tValidation loss: 0.050421\tBest loss: 0.041492\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.044510\tBest loss: 0.041492\tAccuracy: 98.83%\n",
      "7\tValidation loss: 0.039607\tBest loss: 0.039607\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.044539\tBest loss: 0.039607\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.042187\tBest loss: 0.039607\tAccuracy: 99.06%\n",
      "10\tValidation loss: 0.040517\tBest loss: 0.039607\tAccuracy: 99.02%\n",
      "11\tValidation loss: 0.030271\tBest loss: 0.030271\tAccuracy: 99.14%\n",
      "12\tValidation loss: 0.042318\tBest loss: 0.030271\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.038301\tBest loss: 0.030271\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.042846\tBest loss: 0.030271\tAccuracy: 98.98%\n",
      "15\tValidation loss: 0.037774\tBest loss: 0.030271\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.045095\tBest loss: 0.030271\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.042607\tBest loss: 0.030271\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.036484\tBest loss: 0.030271\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.049917\tBest loss: 0.030271\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.038079\tBest loss: 0.030271\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.035607\tBest loss: 0.030271\tAccuracy: 99.26%\n",
      "22\tValidation loss: 0.044610\tBest loss: 0.030271\tAccuracy: 98.83%\n",
      "23\tValidation loss: 0.042693\tBest loss: 0.030271\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.042175\tBest loss: 0.030271\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.055877\tBest loss: 0.030271\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.045200\tBest loss: 0.030271\tAccuracy: 98.91%\n",
      "27\tValidation loss: 0.059028\tBest loss: 0.030271\tAccuracy: 98.63%\n",
      "28\tValidation loss: 0.041274\tBest loss: 0.030271\tAccuracy: 99.14%\n",
      "29\tValidation loss: 0.036096\tBest loss: 0.030271\tAccuracy: 99.26%\n",
      "30\tValidation loss: 0.032298\tBest loss: 0.030271\tAccuracy: 99.26%\n",
      "31\tValidation loss: 0.043744\tBest loss: 0.030271\tAccuracy: 99.14%\n",
      "32\tValidation loss: 0.049129\tBest loss: 0.030271\tAccuracy: 99.10%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  57.3s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.064486\tBest loss: 0.064486\tAccuracy: 98.20%\n",
      "1\tValidation loss: 0.065394\tBest loss: 0.064486\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.038554\tBest loss: 0.038554\tAccuracy: 98.87%\n",
      "3\tValidation loss: 0.063711\tBest loss: 0.038554\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.030787\tBest loss: 0.030787\tAccuracy: 99.02%\n",
      "5\tValidation loss: 0.050122\tBest loss: 0.030787\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.031976\tBest loss: 0.030787\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.042295\tBest loss: 0.030787\tAccuracy: 98.83%\n",
      "8\tValidation loss: 0.045190\tBest loss: 0.030787\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.040823\tBest loss: 0.030787\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.039669\tBest loss: 0.030787\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.060261\tBest loss: 0.030787\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.040190\tBest loss: 0.030787\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.043358\tBest loss: 0.030787\tAccuracy: 99.14%\n",
      "14\tValidation loss: 0.041401\tBest loss: 0.030787\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.033874\tBest loss: 0.030787\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.035533\tBest loss: 0.030787\tAccuracy: 99.22%\n",
      "17\tValidation loss: 0.051334\tBest loss: 0.030787\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.052532\tBest loss: 0.030787\tAccuracy: 98.67%\n",
      "19\tValidation loss: 0.053924\tBest loss: 0.030787\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.041931\tBest loss: 0.030787\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.047123\tBest loss: 0.030787\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.050497\tBest loss: 0.030787\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.041741\tBest loss: 0.030787\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.054404\tBest loss: 0.030787\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.043873\tBest loss: 0.030787\tAccuracy: 99.10%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  45.9s\n",
      "[CV] n_neurons=70, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0> \n",
      "0\tValidation loss: 0.080640\tBest loss: 0.080640\tAccuracy: 97.50%\n",
      "1\tValidation loss: 0.060680\tBest loss: 0.060680\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.042163\tBest loss: 0.042163\tAccuracy: 98.71%\n",
      "3\tValidation loss: 0.048223\tBest loss: 0.042163\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.032752\tBest loss: 0.032752\tAccuracy: 99.02%\n",
      "5\tValidation loss: 0.056164\tBest loss: 0.032752\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.041681\tBest loss: 0.032752\tAccuracy: 98.83%\n",
      "7\tValidation loss: 0.052438\tBest loss: 0.032752\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.054329\tBest loss: 0.032752\tAccuracy: 98.40%\n",
      "9\tValidation loss: 0.033926\tBest loss: 0.032752\tAccuracy: 99.02%\n",
      "10\tValidation loss: 0.031551\tBest loss: 0.031551\tAccuracy: 99.10%\n",
      "11\tValidation loss: 0.036456\tBest loss: 0.031551\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.036644\tBest loss: 0.031551\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.052171\tBest loss: 0.031551\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.038467\tBest loss: 0.031551\tAccuracy: 99.06%\n",
      "15\tValidation loss: 0.043244\tBest loss: 0.031551\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.035302\tBest loss: 0.031551\tAccuracy: 99.18%\n",
      "17\tValidation loss: 0.049303\tBest loss: 0.031551\tAccuracy: 98.94%\n",
      "18\tValidation loss: 0.038865\tBest loss: 0.031551\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.047505\tBest loss: 0.031551\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.041854\tBest loss: 0.031551\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.039858\tBest loss: 0.031551\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.032754\tBest loss: 0.031551\tAccuracy: 99.22%\n",
      "23\tValidation loss: 0.038630\tBest loss: 0.031551\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.040695\tBest loss: 0.031551\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.053651\tBest loss: 0.031551\tAccuracy: 98.71%\n",
      "26\tValidation loss: 0.051369\tBest loss: 0.031551\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.046424\tBest loss: 0.031551\tAccuracy: 98.94%\n",
      "28\tValidation loss: 0.038754\tBest loss: 0.031551\tAccuracy: 99.30%\n",
      "29\tValidation loss: 0.041443\tBest loss: 0.031551\tAccuracy: 99.18%\n",
      "30\tValidation loss: 0.037324\tBest loss: 0.031551\tAccuracy: 99.02%\n",
      "31\tValidation loss: 0.037857\tBest loss: 0.031551\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.01, batch_size=100, batch_norm_momentum=0.9, activation=<function relu at 0x7fabf3f8d0d0>, total=  55.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 537.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.259817\tBest loss: 4.259817\tAccuracy: 96.21%\n",
      "1\tValidation loss: 2.562983\tBest loss: 2.562983\tAccuracy: 95.39%\n",
      "2\tValidation loss: 0.998027\tBest loss: 0.998027\tAccuracy: 97.77%\n",
      "3\tValidation loss: 1.092979\tBest loss: 0.998027\tAccuracy: 96.09%\n",
      "4\tValidation loss: 0.417426\tBest loss: 0.417426\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.835319\tBest loss: 0.417426\tAccuracy: 97.42%\n",
      "6\tValidation loss: 0.486228\tBest loss: 0.417426\tAccuracy: 97.11%\n",
      "7\tValidation loss: 0.348165\tBest loss: 0.348165\tAccuracy: 98.44%\n",
      "8\tValidation loss: 0.977283\tBest loss: 0.348165\tAccuracy: 94.88%\n",
      "9\tValidation loss: 0.179964\tBest loss: 0.179964\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.293253\tBest loss: 0.179964\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.210867\tBest loss: 0.179964\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.262691\tBest loss: 0.179964\tAccuracy: 98.36%\n",
      "13\tValidation loss: 0.186863\tBest loss: 0.179964\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.088223\tBest loss: 0.088223\tAccuracy: 99.18%\n",
      "15\tValidation loss: 0.145115\tBest loss: 0.088223\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.187094\tBest loss: 0.088223\tAccuracy: 98.44%\n",
      "17\tValidation loss: 0.122010\tBest loss: 0.088223\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.127091\tBest loss: 0.088223\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.170421\tBest loss: 0.088223\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.250627\tBest loss: 0.088223\tAccuracy: 97.77%\n",
      "21\tValidation loss: 0.160864\tBest loss: 0.088223\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.081966\tBest loss: 0.081966\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.114935\tBest loss: 0.081966\tAccuracy: 98.71%\n",
      "24\tValidation loss: 0.120269\tBest loss: 0.081966\tAccuracy: 98.51%\n",
      "25\tValidation loss: 0.133010\tBest loss: 0.081966\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.175334\tBest loss: 0.081966\tAccuracy: 97.85%\n",
      "27\tValidation loss: 0.063326\tBest loss: 0.063326\tAccuracy: 98.98%\n",
      "28\tValidation loss: 6.478941\tBest loss: 0.063326\tAccuracy: 74.55%\n",
      "29\tValidation loss: 0.085486\tBest loss: 0.063326\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.103890\tBest loss: 0.063326\tAccuracy: 98.83%\n",
      "31\tValidation loss: 0.112809\tBest loss: 0.063326\tAccuracy: 98.75%\n",
      "32\tValidation loss: 0.120169\tBest loss: 0.063326\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.194672\tBest loss: 0.063326\tAccuracy: 98.63%\n",
      "34\tValidation loss: 0.123234\tBest loss: 0.063326\tAccuracy: 98.75%\n",
      "35\tValidation loss: 0.148962\tBest loss: 0.063326\tAccuracy: 98.59%\n",
      "36\tValidation loss: 0.150137\tBest loss: 0.063326\tAccuracy: 98.36%\n",
      "37\tValidation loss: 0.086472\tBest loss: 0.063326\tAccuracy: 98.94%\n",
      "38\tValidation loss: 0.117121\tBest loss: 0.063326\tAccuracy: 98.94%\n",
      "39\tValidation loss: 0.123272\tBest loss: 0.063326\tAccuracy: 98.87%\n",
      "40\tValidation loss: 0.106890\tBest loss: 0.063326\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.084543\tBest loss: 0.063326\tAccuracy: 98.91%\n",
      "42\tValidation loss: 0.068346\tBest loss: 0.063326\tAccuracy: 98.98%\n",
      "43\tValidation loss: 0.051877\tBest loss: 0.051877\tAccuracy: 99.26%\n",
      "44\tValidation loss: 0.073477\tBest loss: 0.051877\tAccuracy: 99.06%\n",
      "45\tValidation loss: 0.063954\tBest loss: 0.051877\tAccuracy: 99.10%\n",
      "46\tValidation loss: 0.052227\tBest loss: 0.051877\tAccuracy: 99.14%\n",
      "47\tValidation loss: 0.099568\tBest loss: 0.051877\tAccuracy: 98.71%\n",
      "48\tValidation loss: 0.077955\tBest loss: 0.051877\tAccuracy: 98.94%\n",
      "49\tValidation loss: 0.062335\tBest loss: 0.051877\tAccuracy: 99.02%\n",
      "50\tValidation loss: 0.044190\tBest loss: 0.044190\tAccuracy: 99.14%\n",
      "51\tValidation loss: 0.070731\tBest loss: 0.044190\tAccuracy: 99.14%\n",
      "52\tValidation loss: 0.288970\tBest loss: 0.044190\tAccuracy: 95.90%\n",
      "53\tValidation loss: 0.089037\tBest loss: 0.044190\tAccuracy: 98.87%\n",
      "54\tValidation loss: 0.069872\tBest loss: 0.044190\tAccuracy: 99.26%\n",
      "55\tValidation loss: 0.181174\tBest loss: 0.044190\tAccuracy: 98.36%\n",
      "56\tValidation loss: 0.054083\tBest loss: 0.044190\tAccuracy: 99.45%\n",
      "57\tValidation loss: 0.084316\tBest loss: 0.044190\tAccuracy: 98.87%\n",
      "58\tValidation loss: 0.055552\tBest loss: 0.044190\tAccuracy: 98.98%\n",
      "59\tValidation loss: 0.083938\tBest loss: 0.044190\tAccuracy: 98.87%\n",
      "60\tValidation loss: 0.098163\tBest loss: 0.044190\tAccuracy: 99.02%\n",
      "61\tValidation loss: 0.074819\tBest loss: 0.044190\tAccuracy: 98.98%\n",
      "62\tValidation loss: 0.074706\tBest loss: 0.044190\tAccuracy: 99.22%\n",
      "63\tValidation loss: 0.152256\tBest loss: 0.044190\tAccuracy: 98.44%\n",
      "64\tValidation loss: 0.069897\tBest loss: 0.044190\tAccuracy: 98.91%\n",
      "65\tValidation loss: 0.069826\tBest loss: 0.044190\tAccuracy: 99.10%\n",
      "66\tValidation loss: 0.097748\tBest loss: 0.044190\tAccuracy: 98.67%\n",
      "67\tValidation loss: 0.051820\tBest loss: 0.044190\tAccuracy: 99.02%\n",
      "68\tValidation loss: 0.236093\tBest loss: 0.044190\tAccuracy: 96.72%\n",
      "69\tValidation loss: 0.057716\tBest loss: 0.044190\tAccuracy: 99.18%\n",
      "70\tValidation loss: 0.057092\tBest loss: 0.044190\tAccuracy: 99.18%\n",
      "71\tValidation loss: 0.058638\tBest loss: 0.044190\tAccuracy: 99.14%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DNNClassifier(random_state=55), n_iter=50,\n",
       "                   param_distributions={'activation': [<function relu at 0x7fabf3f8d0d0>,\n",
       "                                                       <function elu at 0x7fabf3fc68b0>,\n",
       "                                                       <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be12f70>,\n",
       "                                                       <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7be128b0>],\n",
       "                                        'batch_norm_momentum': [0.9, 0.95, 0.98,\n",
       "                                                                0.99, 0.999],\n",
       "                                        'batch_size': [10, 50, 100, 500],\n",
       "                                        'learning_rate': [0.01, 0.02, 0.05,\n",
       "                                                          0.1],\n",
       "                                        'n_neurons': [10, 30, 50, 70, 90, 100,\n",
       "                                                      120, 140, 160]},\n",
       "                   random_state=55, verbose=2)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "    \"batch_norm_momentum\": [0.9, 0.95, 0.98, 0.99, 0.999],\n",
    "}\n",
    "\n",
    "rnd_search_bn = RandomizedSearchCV(DNNClassifier(random_state=55), param_distribs, n_iter=50, cv=3,\n",
    "                                   random_state=55, verbose=2, n_jobs=-1)\n",
    "rnd_search_bn.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "\n",
    "# If you have Scikit-Learn 0.18 or earlier, you should upgrade, or use the fit_params argument:\n",
    "# fit_params = dict(X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "# rnd_search_bn = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "#                                    fit_params=fit_params, random_state=42, verbose=2)\n",
    "# rnd_search_bn.fit(X_train1, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 120,\n",
       " 'learning_rate': 0.05,\n",
       " 'batch_size': 100,\n",
       " 'batch_norm_momentum': 0.999,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_bn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922163845106052"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_bn.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.模型是否过度拟合训练集？给每一层加dropout再试一次，看看是否有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980027106070333"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_train1)\n",
    "accuracy_score(y_train1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs significantly better on the training set than on the test set (99.8% vs 99.2%), which means it is overfitting the training set. A bit of regularization may help. Let's try adding dropout with a 50% dropout rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.128183\tBest loss: 0.128183\tAccuracy: 96.60%\n",
      "1\tValidation loss: 0.098271\tBest loss: 0.098271\tAccuracy: 97.22%\n",
      "2\tValidation loss: 0.100068\tBest loss: 0.098271\tAccuracy: 97.46%\n",
      "3\tValidation loss: 0.086596\tBest loss: 0.086596\tAccuracy: 97.85%\n",
      "4\tValidation loss: 0.090082\tBest loss: 0.086596\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.077057\tBest loss: 0.077057\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.073766\tBest loss: 0.073766\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.076948\tBest loss: 0.073766\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.072577\tBest loss: 0.072577\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.068553\tBest loss: 0.068553\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.076684\tBest loss: 0.068553\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.064740\tBest loss: 0.064740\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.073593\tBest loss: 0.064740\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.073456\tBest loss: 0.064740\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.074464\tBest loss: 0.064740\tAccuracy: 98.20%\n",
      "15\tValidation loss: 0.072272\tBest loss: 0.064740\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.063642\tBest loss: 0.063642\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.061025\tBest loss: 0.061025\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.075616\tBest loss: 0.061025\tAccuracy: 97.93%\n",
      "19\tValidation loss: 0.061952\tBest loss: 0.061025\tAccuracy: 98.48%\n",
      "20\tValidation loss: 0.068112\tBest loss: 0.061025\tAccuracy: 98.28%\n",
      "21\tValidation loss: 0.062787\tBest loss: 0.061025\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.066614\tBest loss: 0.061025\tAccuracy: 98.16%\n",
      "23\tValidation loss: 0.076605\tBest loss: 0.061025\tAccuracy: 98.20%\n",
      "24\tValidation loss: 0.066317\tBest loss: 0.061025\tAccuracy: 98.36%\n",
      "25\tValidation loss: 0.071392\tBest loss: 0.061025\tAccuracy: 98.28%\n",
      "26\tValidation loss: 0.062707\tBest loss: 0.061025\tAccuracy: 98.32%\n",
      "27\tValidation loss: 0.064112\tBest loss: 0.061025\tAccuracy: 98.40%\n",
      "28\tValidation loss: 0.061054\tBest loss: 0.061025\tAccuracy: 98.32%\n",
      "29\tValidation loss: 0.060051\tBest loss: 0.060051\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.063352\tBest loss: 0.060051\tAccuracy: 98.36%\n",
      "31\tValidation loss: 0.062187\tBest loss: 0.060051\tAccuracy: 98.36%\n",
      "32\tValidation loss: 0.067269\tBest loss: 0.060051\tAccuracy: 98.28%\n",
      "33\tValidation loss: 0.060683\tBest loss: 0.060051\tAccuracy: 98.63%\n",
      "34\tValidation loss: 0.073253\tBest loss: 0.060051\tAccuracy: 98.28%\n",
      "35\tValidation loss: 0.091152\tBest loss: 0.060051\tAccuracy: 97.69%\n",
      "36\tValidation loss: 0.084634\tBest loss: 0.060051\tAccuracy: 97.62%\n",
      "37\tValidation loss: 0.128281\tBest loss: 0.060051\tAccuracy: 97.42%\n",
      "38\tValidation loss: 0.409235\tBest loss: 0.060051\tAccuracy: 83.78%\n",
      "39\tValidation loss: 0.161333\tBest loss: 0.060051\tAccuracy: 95.50%\n",
      "40\tValidation loss: 0.135888\tBest loss: 0.060051\tAccuracy: 96.87%\n",
      "41\tValidation loss: 0.132050\tBest loss: 0.060051\tAccuracy: 96.56%\n",
      "42\tValidation loss: 0.117845\tBest loss: 0.060051\tAccuracy: 96.79%\n",
      "43\tValidation loss: 0.130596\tBest loss: 0.060051\tAccuracy: 96.64%\n",
      "44\tValidation loss: 0.110234\tBest loss: 0.060051\tAccuracy: 96.95%\n",
      "45\tValidation loss: 0.115932\tBest loss: 0.060051\tAccuracy: 97.50%\n",
      "46\tValidation loss: 0.105098\tBest loss: 0.060051\tAccuracy: 97.65%\n",
      "47\tValidation loss: 0.093801\tBest loss: 0.060051\tAccuracy: 97.89%\n",
      "48\tValidation loss: 0.154915\tBest loss: 0.060051\tAccuracy: 96.95%\n",
      "49\tValidation loss: 0.242813\tBest loss: 0.060051\tAccuracy: 94.57%\n",
      "50\tValidation loss: 0.242475\tBest loss: 0.060051\tAccuracy: 91.13%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7faa7839fd30>,\n",
       "              batch_size=500, dropout_rate=0.5, n_neurons=90, random_state=55)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_dropout = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                                n_neurons=90, random_state=55,\n",
    "                                dropout_rate=0.5)\n",
    "dnn_clf_dropout.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857949017318545"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_dropout.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "    \"dropout_rate\": [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "}\n",
    "\n",
    "rnd_search_dropout = RandomizedSearchCV(DNNClassifier(random_state=55), param_distribs, n_iter=50,\n",
    "                                        cv=3, random_state=55, verbose=2, n_jobs=-1)\n",
    "rnd_search_dropout.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "\n",
    "# If you have Scikit-Learn 0.18 or earlier, you should upgrade, or use the fit_params argument:\n",
    "# fit_params = dict(X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "# rnd_search_dropout = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "#                                         fit_params=fit_params, random_state=42, verbose=2)\n",
    "# rnd_search_dropout.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_dropout.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rnd_search_dropout.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.迁移学习。\n",
    "\n",
    "a.重用预训练的隐藏层和之前的模型构建一个新的DNN，冻结它，同时用新的DNN代替softmax输出层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./models/my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.对数字5～9训练这个新的DNN，一个数字只用100张图，会花多长时间。除去这个小个数样本，你还可以达到更高的精度吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_full = X_train[y_train >= 5]\n",
    "y_train2_full = y_train[y_train >= 5] - 5\n",
    "X_valid2_full = X_valid[y_valid >= 5]\n",
    "y_valid2_full = y_valid[y_valid >= 5] - 5\n",
    "X_test2 = X_test[y_test >= 5]\n",
    "y_test2 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_best_mnist_model_0_to_4\n",
      "5\tValidation loss: 1.023635\tBest loss: 1.023635\tAccuracy: 64.67%\n",
      "15\tValidation loss: 1.062819\tBest loss: 1.023635\tAccuracy: 66.00%\n",
      "25\tValidation loss: 1.100936\tBest loss: 1.023635\tAccuracy: 65.33%\n",
      "Early stopping!\n",
      "Total training time: 1.8s\n",
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 62.39%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./models/my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        if epoch % 10 == 5:\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.尝试缓冲冻结层，重新训练模型：这次会花多长时间？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_best_mnist_model_0_to_4\n",
      "5\tValidation loss: 1.063888\tBest loss: 1.038225\tAccuracy: 64.67%\n",
      "15\tValidation loss: 1.066690\tBest loss: 1.032913\tAccuracy: 65.33%\n",
      "25\tValidation loss: 1.104476\tBest loss: 1.032913\tAccuracy: 63.33%\n",
      "Early stopping!\n",
      "Total training time: 1.4s\n",
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 62.70%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./models/my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        if epoch % 10 == 5:\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.只用4个隐藏层再试一次，能获得更高的精度吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./models/my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_best_mnist_model_0_to_4\n",
      "5\tValidation loss: 1.011672\tBest loss: 1.011672\tAccuracy: 63.33%\n",
      "15\tValidation loss: 1.005564\tBest loss: 0.997342\tAccuracy: 65.33%\n",
      "25\tValidation loss: 1.011413\tBest loss: 0.996033\tAccuracy: 65.33%\n",
      "35\tValidation loss: 0.998333\tBest loss: 0.996033\tAccuracy: 65.33%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_four_frozen\n",
      "Final test accuracy: 67.00%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_best_mnist_model_0_to_4\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./models/my_mnist_model_5_to_9_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        if (epoch % 10 == 5):\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.将最上面的两个隐藏层解冻继续训练：你能让模型表现得更好吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_four_frozen\n",
      "5\tValidation loss: 0.850117\tBest loss: 0.820509\tAccuracy: 76.00%\n",
      "15\tValidation loss: 0.951028\tBest loss: 0.796047\tAccuracy: 72.67%\n",
      "25\tValidation loss: 1.240465\tBest loss: 0.796047\tAccuracy: 78.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_two_frozen\n",
      "Final test accuracy: 71.98%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_four_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./models/my_mnist_model_5_to_9_two_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        if (epoch % 10 == 5):\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_two_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam4\")\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "no_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_two_frozen\n",
      "5\tValidation loss: 0.525271\tBest loss: 0.418923\tAccuracy: 86.67%\n",
      "15\tValidation loss: 0.614855\tBest loss: 0.380107\tAccuracy: 90.67%\n",
      "25\tValidation loss: 0.365112\tBest loss: 0.253128\tAccuracy: 92.00%\n",
      "35\tValidation loss: 0.356685\tBest loss: 0.253128\tAccuracy: 92.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./models/my_mnist_model_5_to_9_no_frozen\n",
      "Final test accuracy: 90.66%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    two_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_two_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = no_frozen_saver.save(sess, \"./models/my_mnist_model_5_to_9_no_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        if epoch % 10 == 5:\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    no_frozen_saver.restore(sess, \"./models/my_mnist_model_5_to_9_no_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.578121\tBest loss: 0.578121\tAccuracy: 80.67%\n",
      "10\tValidation loss: 0.798676\tBest loss: 0.333337\tAccuracy: 90.00%\n",
      "20\tValidation loss: 0.854038\tBest loss: 0.333337\tAccuracy: 92.00%\n",
      "30\tValidation loss: 0.912169\tBest loss: 0.333337\tAccuracy: 92.00%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(n_hidden_layers=4, random_state=55)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_5_to_9 = DNNClassifier(n_hidden_layers=4, random_state=55)\n",
    "dnn_clf_5_to_9.fit(X_train2, y_train2, n_epochs=1000, X_valid=X_valid2, y_valid=y_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668998148529109"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_5_to_9.predict(X_test2)\n",
    "accuracy_score(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.在辅助任务上进行预训练。\n",
    "\n",
    "a.在这个练习中，你要构建一个DNN，对比两个MNIST数字图片并预测它们是否代表同一个数字。然后，重用这个网络的低层，用很少的训练数据来训练一个MNIST分类器。首先构建两个DNN（我们称之为DNN A和DNN B），它们都和你之前构建的DNN一样，只是没有输出层：每个DNN要保证每100个神经元有5个隐藏层，He初始化和ELU激活。接着，在两个DNN的顶部添加一个输出层。你要调用TensorFlow的`concat()`函数，并且设置`axis=1`，用函数将两个DNN沿着水平轴连接起来，然后将结果传给输出层。这个输出层应包含一个使用逻辑激活函数的单个神经元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
    "X1, X2 = tf.unstack(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1 = dnn(X1, name=\"DNN_A\")\n",
    "dnn2 = dnn(X2, name=\"DNN_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_outputs = tf.concat([dnn1, dnn2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(100)]),\n",
       " TensorShape([Dimension(None), Dimension(100)]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn1.shape, dnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(200)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.layers.dense(dnn_outputs, units=10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "logits = tf.layers.dense(hidden, units=1, kernel_initializer=he_init)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_as_float = tf.cast(y, tf.float32)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.95\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_correct = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.将MNIST训练集一分为二：分组1包55000张图片，分组2包含5000张图片。构建一个生成训练批量的函数，其中每个实例都是从分组1中选择的一对MNIST图片。一半的训练实例应该是属于同一类型的图片对，而另一半属于不同类型。对每一个图片对，如果来自同一类型则训练标签标记为0，如果来自不同类型则标记为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train\n",
    "y_train1 = y_train\n",
    "\n",
    "X_train2 = X_valid\n",
    "y_train2 = y_valid\n",
    "\n",
    "X_test = X_test\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, 784), dtype('float32'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.在这个训练集上训练DNN。对每一个图片对，你都可以同时将第一张图片传给DNN A，第二张图片传给DNN B。整个网络慢慢就可以分辨出两张图片是否属于同一种类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss: 0.69048864\n",
      "0 Test accuracy: 0.5061\n",
      "1 Train loss: 0.6667586\n",
      "2 Train loss: 0.54621285\n",
      "3 Train loss: 0.5051319\n",
      "4 Train loss: 0.43973455\n",
      "5 Train loss: 0.39108807\n",
      "5 Test accuracy: 0.8115\n",
      "6 Train loss: 0.3134558\n",
      "7 Train loss: 0.32826358\n",
      "8 Train loss: 0.30579954\n",
      "9 Train loss: 0.2897354\n",
      "10 Train loss: 0.27892146\n",
      "10 Test accuracy: 0.8822\n",
      "11 Train loss: 0.29858002\n",
      "12 Train loss: 0.2842432\n",
      "13 Train loss: 0.25327113\n",
      "14 Train loss: 0.22505374\n",
      "15 Train loss: 0.22724876\n",
      "15 Test accuracy: 0.9097\n",
      "16 Train loss: 0.21990876\n",
      "17 Train loss: 0.22201169\n",
      "18 Train loss: 0.17837317\n",
      "19 Train loss: 0.15718915\n",
      "20 Train loss: 0.14760444\n",
      "20 Test accuracy: 0.9367\n",
      "21 Train loss: 0.17063677\n",
      "22 Train loss: 0.17549153\n",
      "23 Train loss: 0.1394681\n",
      "24 Train loss: 0.12949528\n",
      "25 Train loss: 0.14707483\n",
      "25 Test accuracy: 0.9478\n",
      "26 Train loss: 0.12104422\n",
      "27 Train loss: 0.08231911\n",
      "28 Train loss: 0.11367395\n",
      "29 Train loss: 0.119283594\n",
      "30 Train loss: 0.12600785\n",
      "30 Test accuracy: 0.9564\n",
      "31 Train loss: 0.14141203\n",
      "32 Train loss: 0.10140592\n",
      "33 Train loss: 0.10687157\n",
      "34 Train loss: 0.120394856\n",
      "35 Train loss: 0.10073631\n",
      "35 Test accuracy: 0.9615\n",
      "36 Train loss: 0.09530073\n",
      "37 Train loss: 0.07816943\n",
      "38 Train loss: 0.06705389\n",
      "39 Train loss: 0.10988103\n",
      "40 Train loss: 0.0931921\n",
      "40 Test accuracy: 0.9645\n",
      "41 Train loss: 0.09542428\n",
      "42 Train loss: 0.071554504\n",
      "43 Train loss: 0.083228625\n",
      "44 Train loss: 0.062468033\n",
      "45 Train loss: 0.092330106\n",
      "45 Test accuracy: 0.9702\n",
      "46 Train loss: 0.056503814\n",
      "47 Train loss: 0.061391722\n",
      "48 Train loss: 0.05966626\n",
      "49 Train loss: 0.05681319\n",
      "50 Train loss: 0.061694864\n",
      "50 Test accuracy: 0.9714\n",
      "51 Train loss: 0.052886464\n",
      "52 Train loss: 0.07414904\n",
      "53 Train loss: 0.04967873\n",
      "54 Train loss: 0.09230027\n",
      "55 Train loss: 0.048095472\n",
      "55 Test accuracy: 0.9726\n",
      "56 Train loss: 0.037087683\n",
      "57 Train loss: 0.084204316\n",
      "58 Train loss: 0.07706146\n",
      "59 Train loss: 0.056927666\n",
      "60 Train loss: 0.03954575\n",
      "60 Test accuracy: 0.9735\n",
      "61 Train loss: 0.051148117\n",
      "62 Train loss: 0.07474898\n",
      "63 Train loss: 0.036958944\n",
      "64 Train loss: 0.03138796\n",
      "65 Train loss: 0.06669835\n",
      "65 Test accuracy: 0.9733\n",
      "66 Train loss: 0.026532626\n",
      "67 Train loss: 0.064011514\n",
      "68 Train loss: 0.048144005\n",
      "69 Train loss: 0.044639245\n",
      "70 Train loss: 0.018387921\n",
      "70 Test accuracy: 0.974\n",
      "71 Train loss: 0.07008665\n",
      "72 Train loss: 0.04996928\n",
      "73 Train loss: 0.042957768\n",
      "74 Train loss: 0.036499474\n",
      "75 Train loss: 0.0521563\n",
      "75 Test accuracy: 0.9759\n",
      "76 Train loss: 0.034587298\n",
      "77 Train loss: 0.07468747\n",
      "78 Train loss: 0.038851514\n",
      "79 Train loss: 0.028718973\n",
      "80 Train loss: 0.029475065\n",
      "80 Test accuracy: 0.977\n",
      "81 Train loss: 0.031431567\n",
      "82 Train loss: 0.045749724\n",
      "83 Train loss: 0.054301824\n",
      "84 Train loss: 0.019578343\n",
      "85 Train loss: 0.027450282\n",
      "85 Test accuracy: 0.9762\n",
      "86 Train loss: 0.037972815\n",
      "87 Train loss: 0.05772395\n",
      "88 Train loss: 0.019148406\n",
      "89 Train loss: 0.03437062\n",
      "90 Train loss: 0.027838388\n",
      "90 Test accuracy: 0.9776\n",
      "91 Train loss: 0.020518955\n",
      "92 Train loss: 0.024559947\n",
      "93 Train loss: 0.0232796\n",
      "94 Train loss: 0.061095852\n",
      "95 Train loss: 0.012446473\n",
      "95 Test accuracy: 0.979\n",
      "96 Train loss: 0.029984415\n",
      "97 Train loss: 0.027678084\n",
      "98 Train loss: 0.0208357\n",
      "99 Train loss: 0.037535917\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train loss:\", loss_val)\n",
    "        if epoch % 5 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_digit_comparison_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.现在通过重用和冻结DNN的隐藏层，同时在10个神经元上添加一个softmax输出的方法构建一个新的DNN。在分组2上训练这个网络，看看在每一类只有500张图片的情况下能不能获得比较高的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
    "frozen_outputs = tf.stop_gradient(dnn_outputs)\n",
    "\n",
    "logits = tf.layers.dense(frozen_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_digit_comparison_model.ckpt\n",
      "0 Test accuracy: 0.9724\n",
      "10 Test accuracy: 0.9723\n",
      "20 Test accuracy: 0.9744\n",
      "30 Test accuracy: 0.9732\n",
      "40 Test accuracy: 0.9743\n",
      "50 Test accuracy: 0.9738\n",
      "60 Test accuracy: 0.9732\n",
      "70 Test accuracy: 0.973\n",
      "80 Test accuracy: 0.9728\n",
      "90 Test accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./models/my_digit_comparison_model.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8798\n",
      "10 Test accuracy: 0.9294\n",
      "20 Test accuracy: 0.9319\n",
      "30 Test accuracy: 0.9431\n",
      "40 Test accuracy: 0.9429\n",
      "50 Test accuracy: 0.9431\n",
      "60 Test accuracy: 0.9428\n",
      "70 Test accuracy: 0.9424\n",
      "80 Test accuracy: 0.9426\n",
      "90 Test accuracy: 0.9424\n",
      "100 Test accuracy: 0.9424\n",
      "110 Test accuracy: 0.9426\n",
      "120 Test accuracy: 0.9425\n",
      "130 Test accuracy: 0.9424\n",
      "140 Test accuracy: 0.9424\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 150\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
