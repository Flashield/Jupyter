{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=55):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_no = '0' # or '1'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_no\n",
    "\n",
    "# 定义TensorFlow配置\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# 配置GPU内存分配方式，按需增长，很关键\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# 配置可使用的显存比例\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# 在创建session的时候把config作为参数传进去\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从生物神经元到人工神经元\n",
    "\n",
    "令人惊讶的是，ANN已经存在了好长时间了：最早在1943年由神经学家Warren McCulloch和数学家Walter Pitts提出。在他们著名的论文“A Logical Calculus of Ideas Immanent in Nervous Activity”（ https://goo.gl/Ul4mxW ） [1] 中，McCulloch和Pitts展示了一个简化过的计算模型来描述在动物的大脑中，神经元如何通过命题逻辑来实现复杂的计算。这是第一个人工神经网络架构，正如我们将要看到的，从那之后还有很多其他类型的架构被发明出来。\n",
    "\n",
    "直到20世纪60年代，ANN的早期成功让人们普遍认为，我们很快将会与真正智能的机器对话。当明确表示这一承诺（至少在一段时间内）将不会实现时，资金就投向了其他地方，ANN进入了漫长的黑暗时期。在20世纪80年代初，随着新网络架构的发明和更好的培训技术的发展，人们对ANN的兴趣又重新变得浓厚。不过到了20世纪90年代，更强大的机器学习技术如支持向量机（见第5章）成为大部分研究者的新宠，因为它们似乎提供了更好的结果和更强大的理论基础。最终，见证了另一波对ANN兴趣的高潮。这次高潮会像上一次那样归于沉寂吗？有很多的原因可以相信这一次会不同，而且会给生活带来很多的影响：\n",
    "\n",
    "* 现在有了海量的可用数据来训练神经网络，而且在超大超复杂问题上ANN比其他的ML技术性能更佳。\n",
    "* 自20世纪90年代以来，飞速增长的计算能力使得在合理时间内训练大型神经网络成为可能。部分原因是摩尔定律在生效，不过也要感谢游戏产业，它们制造了数以百万计的强大的GPU。\n",
    "* 训练算法也得到了很大的提升。坦白说与20世纪90年代相比，算法只有一点点不同，但是这些小的调整产生了巨大的正面影响。\n",
    "* ANN的一些理论限制在实践中被证明是可以接受的。比如，很多人认为训练算法是注定要失败的，因为算法在局部优化时很可能被卡住，不过这种情况在实践中非常少见（或者即使出现了，它们往往和全局优化值已经非常接近）。\n",
    "* ANN似乎进入了资金和技术进步的良性循环。基于ANN的惊人产品不断地出现在头条，从而吸引更多的关注和资金投入，这又会使其产生新的进步，然后产生更多令人惊讶的产品。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生物神经元\n",
    "\n",
    "在讨论人工神经元之前，先来快速看一下生物神经元（如图10-1所示）。这是一种通常会出现在动物的大脑皮层中的非凡细胞（比如在你的大脑中），由包含细胞核和大部分细胞复合成分的细胞体组成，有许多分枝延伸的部分称为树突，一个非常长的延伸称为轴突。轴突的长度可能比细胞体长几倍，或者长达几万倍。在其极端附近，轴突分裂成许多被称为终树突的分支，在这些分支的尖端是称为突触终端（或简单的突触）的微小结构，它会连接到其他神经元的树突（或直接连接到细胞体）。生物神经元通过这些突触接受从其他细胞发来的很短的电脉冲，这种脉冲被称为信号。当一个神经元在一定的时间内收到足够多的信号，就会出发它自己的信号。\n",
    "\n",
    "![图10-1：生物神经元](images/VNote/20201224170130664_15304.png)\n",
    "\n",
    "图10-1：生物神经元 [2]\n",
    "\n",
    "单个的生物神经元看起来非常简单，但是数以亿计的神经元组成了一个巨大的网络，每个神经元都会与数千个其他的神经元链接。超级复杂的计算也可以通过这些简单的神经元来完成。生物神经网络架构 [3] 仍然是一个非常活跃的研究主题，不过大脑的部分区域已经被映射好了，神经元往往会按照连续的层次来组织，如图10-2所示。\n",
    "\n",
    "![图10-2：生物神经网络的多个层次（人类大脑皮层）](images/VNote/20201224173421868_6121.png)\n",
    "\n",
    "图10-2：生物神经网络的多个层次（人类大脑皮层） [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具有神经元的逻辑计算\n",
    "\n",
    "Warren McCulloch和Walter Pitts提出了一个生物神经元的简化模型，这种模型后来被称为人工神经元：它有一个或多个二进制（开/关）的输入和一个二进制输出。当一定数量的输入都是激活状态时，人工神经元就会激活其输出。McCulloch和Pitts展示了即使用如此简单的模型，也可能构建一个可以计算任意复杂逻辑的网络出来。举个例子，来构建一个执行多种逻辑计算的人工神经网络（见图10-3），假设当一个神经元的至少两个输入是激活状态时它自身就会处于激活状态。\n",
    "\n",
    "![图10-3：计算简单逻辑计算的人工神经网络](images/VNote/20201224173551911_9920.png)\n",
    "\n",
    "图10-3：计算简单逻辑计算的人工神经网络\n",
    "\n",
    "* 左侧的第一个网络是一个简单的等同函数：如果神经元A是激活的，那么C就是激活的（它从A接受了两个输入信号），如果A是非激活的，则C也是非激活的。\n",
    "* 第二个网络计算逻辑与：只有当A和B都处于激活状态，C才会激活（单独的一个输入并不足以激活C）。\n",
    "* 第三个网络计算逻辑或：A和B中有一个（或者两者都）处于激活时，C就会被激活。\n",
    "* 最后，假设输入可以抑制神经元的激活状态（正如生物神经网络中那样），那么第四个网络计算的就是一个比较复杂的逻辑操作：只有在A是激活而且B是非激活时，神经元C才会处于激活状态。如果A一直处于激活，那你就得到了逻辑非：当B非激活时，C激活，反之亦然。\n",
    "\n",
    "想象用这些网络如何组合出更复杂的逻辑计算（练习见章节末尾处）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感知器\n",
    "\n",
    "感知器是最简单的ANN架构之一，于1957年由Frank Rosenblatt发明。它基于一个稍微不同的被称为线性阈值单元（LTU）的人工神经元（见图10-4）：输入和输出都是数字（而不是二进制的开关状态），每个输入的连接都有一个对应的权重。LTU会加权求和所有的输入（$z=w_1x_1 + w_2x_2 + \\dots +w_nx_n = w^T \\cdot x$），然后对求值结果应用一个阶跃函数（step funciton）并产生最后的输出：$h_w(x) = step(z) = step(w^T \\cdot x)$。\n",
    "\n",
    "感知器中最常见的阶跃函数叫作Heaviside阶跃函数（见公式10-1），有时候会使用带符号的函数。\n",
    "\n",
    "![图10-4：线性阈值单元](images/VNote/20201225101922344_25536.png)\n",
    "\n",
    "图10-4：线性阈值单元\n",
    "\n",
    "$$\n",
    "heaviside(z) = \\begin{cases}\n",
    "    0 & (z < 0) \\\\\n",
    "    1 & (z \\geq 0)\n",
    "\\end{cases} \\\\\n",
    "sgn(z) = \\begin{cases}\n",
    "    -1 & (z<0) \\\\\n",
    "    0 & (z=0) \\\\\n",
    "    1 & (z>0)\n",
    "\\end{cases} \\tag{10-1} \\label{10-1}\n",
    "$$\n",
    "公式10-1：感知器中常见的阶跃函数\n",
    "\n",
    "单个LTU可以用来做简单的线性二值分类。它计算输入的线性组合，如果结果超出了阈值，输出就是正否则为负（与逻辑回归分类器或者线性支持向量机一样）。举个例子，可以用一个LTU来根据花瓣的长度和宽度分类鸢尾花（正如我们在上一章做的，添加一个$x_0 =1$偏差）。训练LTU的意思是寻找$w_0$ 、$w_1$ 和$w_2$ 的正确值（训练算法待会讨论）。 \n",
    "\n",
    "感知器就是个单层的LTU [5] ，每个神经元都与所有输入相连。这些连接通常使用称为输入神经元的特殊传递神经元来表示：输入什么就输出什么。此外，还会加上一个额外的偏差特征（$x_0 =1$）。偏差特征通常用偏差神经元来表示，它永远都只输出1。\n",
    "\n",
    "图10-5展示了一个有两个输入和三个输出的感知器。这个感知器可以将实例同时分为三个不同的二进制类，因此它被称为多输出分类器。\n",
    "\n",
    "![图10-5：感知器图](images/VNote/20201225103530204_2459.png)\n",
    "\n",
    "图10-5：感知器图\n",
    "\n",
    "那么感知器是如何被训练的呢？Frank Rosenblatt提出的感知器训练算法很大程度上受到Hebb’s定律的启发。在他1949年出版的著作《行为的组织》中，Donald Hebb提到如果一个生物神经元总是触发另外的神经元，那么这两个神经元之间的连接就会变得更强。这个想法后来被Siegrid Lowel总结为：同时处于激活状态的细胞是会连在一起的。这个规律后来变成了著名的Hebb定律（又叫Hebbian学习）：当两个神经元有相同的输出时，它们之间的连接权重就会增强。感知器就是使用这个规则的变体进行训练，该变种还考虑了网络错误，对于导致错误输出的连接，它不会加强该连接的权重。更具体地说，感知器一次供给一个训练实例，并且对于每个实例它都会进行预测。对于产生错误预测的每个输出神经元，它加强了来自输入的连接权重，这将对正确的预测做出贡献。规则见公式10-2。\n",
    "\n",
    "公式10-2：感知器学习规则（权重更新）\n",
    "\n",
    "$$\n",
    "w_{i,j}^{(next\\_step)} = w_{i,j} + \\eta(\\hat y_j -y_j)x_i \\tag{10-2} \\label{10-2}\n",
    "$$\n",
    "\n",
    "* $w_{i，j}$是第$i$个输入神经元和第$j$个输出神经元的连接权重。\n",
    "* $x_i$ 是当前训练实例的第$i$个输入值。\n",
    "* $\\hat y_j$ 是当前训练实例的第$j$个输出神经元的输出。\n",
    "* $y_j$ 是当前训练实例的第j个输出神经元的目标输出。\n",
    "* $\\eta$是学习速率。\n",
    "\n",
    "每个输出神经元的决策边界是线性的，所以感知器无法学习复杂的模式（这点和逻辑回归分类器一样）。Rosenblatt证明如果训练实例是线性可分的，这个算法会收敛到一个解 [6] 。这被称为`感知器收敛定理`。\n",
    "\n",
    "Scikit-Learn提供了一个实现单一LTU网络的Perceptron类。它基本可以在鸢尾花数据集上如期工作（见第4章）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(max_iter=100, random_state=42, tol=-inf)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=100, tol=-np.infty, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_state改成55就会出现不同的预测结果。\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可能已经注意到感知器学习算法酷似随机梯度下降法。事实上，在Scikit-Learn里，Perceptron类的行为等同于使用以下超参数的`SGDClassifier`：`loss=\"perceptron\"`，`learning_rate=\"constant\"`，`eta0=1`（学习速率），以及`penalty=None`（不做正则化）。\n",
    "\n",
    "> 和逻辑回归分类器相反，感知器不输出某个类概率。它只能根据一个固定的阈值来做预测。这也是更应该使用逻辑回归而不是感知器的一个原因。\n",
    "\n",
    "在1969年的名为《感知器》的专著中，Marvin Minsky和Seymour Papert强调了感知器的一系列缺点，特别是它无法处理的一些很微小的问题，比如异或分类问题（XOR），见图10-6左侧。当然这个问题在其他任何的线性分类模型中一样存在，只不过研究者对感知器的期望太高，因此失望也更大：结果就是，很多研究者完全放弃连接机制（connectionism，即神经网络的研究），而倾向于更高层次的问题，如逻辑、问题解决和搜索。\n",
    "\n",
    "不过，事实证明感知器的一些限制可以通过将多个感知器堆叠起来的方式来消除，这种形式的ANN就是多层感知器（Multi-Layer Perceptron）。实践中，MLP可以解决异或问题，比如可以计算一下图10-6中的MLP的结果来验证：对于输入的不同组合，（0，0）或者（1，1）会产生0，而（0，1）或者则产生1。\n",
    "\n",
    "![图10-6：异或分类问题和用来解决它的MLP](images/VNote/20201225111431021_3265.png)\n",
    "\n",
    "图10-6：异或分类问题和用来解决它的MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x288 with 0 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x7f75d8f36850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8c8e970>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8c8ee50>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Activation function: heaviside')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x7f75d8c8efd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8c70340>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8c707f0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Activation function: sigmoid')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层感知器和反向传播\n",
    "\n",
    "一个MLP包含一个（透传）输入层，一个或者多个被称为隐藏层的LTU层，以及一个被称为输出层的LTU组成的最终层（见图10-7）。除了输出层之外，每层都包含了一个偏移神经元，并且与下一层完全相连。如果一个ANN有2个以及2个以上的隐藏层，则被称为`深度神经网络`（DNN）。\n",
    "\n",
    "![图10-7：多层感知器](images/VNote/20201225111808554_27357.png)\n",
    "\n",
    "图10-7：多层感知器\n",
    "\n",
    "多年来，研究者都为如何训练MLP而头疼不已，一直没有进展。直到1986年，D.E.Rumelhart发表了一篇介绍`反向传播训练算法` [7] 的开创性论文（ https://goo.gl/Wl7Xyc ） [8] 。今天称其为使用了反向自动微分的梯度下降法（梯度下降在第4章介绍过，自动微分在第9章介绍过）。\n",
    "\n",
    "对于每一个训练实例，算法将其发送到网络中并计算每个连续层中的每个神经元的输出（这是正向过程，与做预测的过程一样）。然后它会度量网络的输出误差（对比期望值和实际的网络输出），然后它会计算最后一个隐藏层中的每个神经元对输出神经元的误差的贡献度。之后它继续测量这些误差贡献中有多少来自前一个隐藏层中的每个神经元，这个过程一直持续到输入层（也就是第一层）。这个反向传递过程通过在网络中向后传播误差梯度有效地测量网络中所有连接权重的误差梯度（这也是它名字的来源）。如果看一下附录D中的反向自动微分算法，会发现反向传播的正向和反向传递都只是简单地执行反向模式的自动微分。反向传播算法的最后一步是对网络中所有连接权重执行梯度下降法，使用之前度量的误差梯度。\n",
    "\n",
    "简而言之：对于每个训练实例，反向传播算法先做一次预测（正向过程），度量误差，然后反向的遍历每个层次来度量每个连接的误差贡献度（反向过程），最后再微调每个连接的权重来降低误差（梯度下降）。\n",
    "\n",
    "为了让这个算法正常工作，作者对MLP架构做了一个关键的调整：把阶跃函数改成了逻辑函数：$\\theta(z) = 1/(1 + \\exp(-z))$。这是非常关键的一步，因为阶跃函数只包含平面，所以没有梯度（梯度下降在平面上无法移动），但是逻辑函数则有着定义良好的偏导，梯度下降可以在每一步都做调整。除了逻辑函数，反向传播算法还可以和其他激活函数一起使用。最流行的两个`激活函数`是：\n",
    "\n",
    "*双曲正切函数*：$\\tanh(z)=\\frac{\\exp(z) - \\exp(-z)}{\\exp(z) + \\exp(-z)}$\n",
    "\n",
    "与逻辑函数类似，它是一个S形曲线，连续且可微分，不过它的输出是-1到1之间的值（逻辑是0到1之间的值），这会让每层的输出在训练开始时或多或少地标准化（以0为中心）。这通常有助于快速融合。\n",
    "\n",
    "*ReLU函数*（在第9章介绍过）:$ReLU(z) = \\max(0,z)$。\n",
    "\n",
    "这个函数也是连续的，不过在$z=0$时不可微分（坡度的突然变化可以使梯度下降反弹）。不过实践中它工作良好，而且计算速度很快。最重要的是，由于它没有最大输出值，对于消除梯度下降的一些问题很有帮助（将在第11章详细讨论）\n",
    "\n",
    "这些常见激活函数和它们的导数如图10-8所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 792x288 with 0 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b68970>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b68cd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b73070>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b733d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f75d8b735e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Activation functions')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -1.2, 1.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b3b6d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b3bbb0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8b3bdf0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8ad5160>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8ad53a0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d8ad59a0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Derivatives')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.2, 1.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "# save_fig(\"activation_functions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图10-8：激活函数和它们的导数\n",
    "\n",
    "MLP常常被用来做分类，每个输出对应一个不同的二进制分类（比如，垃圾邮件/正常邮件、紧急/非紧急，等等）。当每个分类是互斥的情况下（比如将图片分类为数字0～9的场景），输出层通常被修改成一个共享的softmax函数（见图10-9）。softmax函数在第3章介绍过。每个神经元的输出对应于相应分类的估计概率。注意信号是单向流动的（从输入流向输出），所以这种架构是前馈神经网络（FNN）的一个范例。\n",
    "\n",
    "> 生物神经元貌似实现了一个粗糙的S形激活函数，所以研究者花了很长时间在S形函数上。但事实证明，ReLU激活函数通常在ANN中工作得更好，这是被生物类比误导的案例之一。\n",
    "\n",
    "![图10-9：用以分类的现代MLP（包含ReLU和softmax）](images/VNote/20201225133806396_31080.png)\n",
    "\n",
    "图10-9：用以分类的现代MLP（包含ReLU和softmax）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] “神经活动中内在思想的逻辑演算”，W.McCulloch和W.Pitts（1943）。\n",
    "\n",
    "[2] 图片由Bruce Blaus拍摄（知识共享3.0，https://creativecommons.org/licenses/by/3.0/），转载自https://en.wikipedia.org/wiki/Neuron。\n",
    "\n",
    "[3] 在机器学习的上下文中，“神经网络”一般指的是人工神经网络，而不是生物神经网络。\n",
    "\n",
    "[4] 由S.Ramon y Caja（l公共领域）绘制大脑皮质层。转载自https://en.wikipedia.org/wiki/Cerebral_cortex。\n",
    "\n",
    "[5] Perceptron有时用来表示具有单个LTU的小型网络。\n",
    "\n",
    "[6] 注意答案往往不唯一，通常来说，如果数据是线性可分的，那么总有一个无线的超平面可以划分它们。\n",
    "\n",
    "[7] “通过错误传播学习内部表示”，D.Rumelhart、G.Hinton和R.Williams（1986）。\n",
    "\n",
    "[8] 该算法实际由不同领域的多个研究人员发明，从1974年，P.Werbos的研究开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用TensorFlow的高级API来训练MLP\n",
    "\n",
    "用TensorFlow训练MLP的最简单方式是使用它的高级API TF.Learn，这和Scikit-learn的API非常类似。用DNNClassifier类来训练一个有着任意数量隐藏层，并包含一个用来计算类别概率的softmax输出层的深度神经网络都易如反掌。比如，下面的代码训练一个用于分类有两个隐藏层（一个有300个神经元，另一个有100个），以及一个softmax输出层的具有10个神经元的DNN："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptq2ehbvi\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmptq2ehbvi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmptq2ehbvi/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 119.90719, step = 1\n",
      "INFO:tensorflow:global_step/sec: 182.232\n",
      "INFO:tensorflow:loss = 26.023655, step = 101 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.79\n",
      "INFO:tensorflow:loss = 5.657491, step = 201 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.585\n",
      "INFO:tensorflow:loss = 12.40954, step = 301 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.19\n",
      "INFO:tensorflow:loss = 6.722644, step = 401 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.077\n",
      "INFO:tensorflow:loss = 6.8919406, step = 501 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.619\n",
      "INFO:tensorflow:loss = 10.305245, step = 601 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.409\n",
      "INFO:tensorflow:loss = 2.9711938, step = 701 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.917\n",
      "INFO:tensorflow:loss = 6.8107924, step = 801 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.731\n",
      "INFO:tensorflow:loss = 1.2288294, step = 901 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.654\n",
      "INFO:tensorflow:loss = 10.582087, step = 1001 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.17\n",
      "INFO:tensorflow:loss = 11.902342, step = 1101 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.779\n",
      "INFO:tensorflow:loss = 6.040826, step = 1201 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.897\n",
      "INFO:tensorflow:loss = 1.3617094, step = 1301 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.562\n",
      "INFO:tensorflow:loss = 9.083714, step = 1401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.887\n",
      "INFO:tensorflow:loss = 1.9457719, step = 1501 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.951\n",
      "INFO:tensorflow:loss = 1.4530289, step = 1601 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.362\n",
      "INFO:tensorflow:loss = 2.0834124, step = 1701 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.977\n",
      "INFO:tensorflow:loss = 15.135464, step = 1801 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.972\n",
      "INFO:tensorflow:loss = 3.3838525, step = 1901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.171\n",
      "INFO:tensorflow:loss = 8.373618, step = 2001 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.435\n",
      "INFO:tensorflow:loss = 0.40409005, step = 2101 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.39\n",
      "INFO:tensorflow:loss = 0.34337097, step = 2201 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.118\n",
      "INFO:tensorflow:loss = 2.2361856, step = 2301 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.765\n",
      "INFO:tensorflow:loss = 0.84223783, step = 2401 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.101\n",
      "INFO:tensorflow:loss = 4.6640244, step = 2501 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.601\n",
      "INFO:tensorflow:loss = 0.7181871, step = 2601 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.45\n",
      "INFO:tensorflow:loss = 4.426924, step = 2701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.637\n",
      "INFO:tensorflow:loss = 6.100838, step = 2801 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.402\n",
      "INFO:tensorflow:loss = 1.503288, step = 2901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.83\n",
      "INFO:tensorflow:loss = 0.67857456, step = 3001 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.924\n",
      "INFO:tensorflow:loss = 1.3580016, step = 3101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.925\n",
      "INFO:tensorflow:loss = 4.1447563, step = 3201 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.772\n",
      "INFO:tensorflow:loss = 1.5158881, step = 3301 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.332\n",
      "INFO:tensorflow:loss = 1.4975138, step = 3401 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.339\n",
      "INFO:tensorflow:loss = 2.0574694, step = 3501 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.842\n",
      "INFO:tensorflow:loss = 1.3078237, step = 3601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.68\n",
      "INFO:tensorflow:loss = 1.4942781, step = 3701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.345\n",
      "INFO:tensorflow:loss = 0.4294421, step = 3801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.86\n",
      "INFO:tensorflow:loss = 4.6545477, step = 3901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.809\n",
      "INFO:tensorflow:loss = 3.3268738, step = 4001 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.99\n",
      "INFO:tensorflow:loss = 0.2701024, step = 4101 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.025\n",
      "INFO:tensorflow:loss = 1.5233532, step = 4201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.791\n",
      "INFO:tensorflow:loss = 1.589758, step = 4301 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.944\n",
      "INFO:tensorflow:loss = 1.6735287, step = 4401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.068\n",
      "INFO:tensorflow:loss = 4.78852, step = 4501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.375\n",
      "INFO:tensorflow:loss = 0.18773896, step = 4601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.547\n",
      "INFO:tensorflow:loss = 3.183665, step = 4701 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.718\n",
      "INFO:tensorflow:loss = 0.6364289, step = 4801 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.923\n",
      "INFO:tensorflow:loss = 0.38071597, step = 4901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.297\n",
      "INFO:tensorflow:loss = 3.8745778, step = 5001 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.768\n",
      "INFO:tensorflow:loss = 2.0737925, step = 5101 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.44\n",
      "INFO:tensorflow:loss = 0.60523653, step = 5201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.806\n",
      "INFO:tensorflow:loss = 1.1743891, step = 5301 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.867\n",
      "INFO:tensorflow:loss = 0.63938665, step = 5401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.58\n",
      "INFO:tensorflow:loss = 1.193684, step = 5501 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.282\n",
      "INFO:tensorflow:loss = 0.17516252, step = 5601 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.324\n",
      "INFO:tensorflow:loss = 6.956086, step = 5701 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.029\n",
      "INFO:tensorflow:loss = 1.9075593, step = 5801 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.835\n",
      "INFO:tensorflow:loss = 1.4378647, step = 5901 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.947\n",
      "INFO:tensorflow:loss = 0.87478673, step = 6001 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.535\n",
      "INFO:tensorflow:loss = 2.7510476, step = 6101 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.439\n",
      "INFO:tensorflow:loss = 0.3533257, step = 6201 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.842\n",
      "INFO:tensorflow:loss = 1.2233163, step = 6301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.335\n",
      "INFO:tensorflow:loss = 0.21135451, step = 6401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.126\n",
      "INFO:tensorflow:loss = 0.87269825, step = 6501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.357\n",
      "INFO:tensorflow:loss = 1.7316959, step = 6601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.809\n",
      "INFO:tensorflow:loss = 1.594207, step = 6701 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.818\n",
      "INFO:tensorflow:loss = 0.48153216, step = 6801 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.362\n",
      "INFO:tensorflow:loss = 1.2063023, step = 6901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.786\n",
      "INFO:tensorflow:loss = 0.7222551, step = 7001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.135\n",
      "INFO:tensorflow:loss = 1.1835383, step = 7101 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.77\n",
      "INFO:tensorflow:loss = 1.2003517, step = 7201 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.326\n",
      "INFO:tensorflow:loss = 0.11348795, step = 7301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.183\n",
      "INFO:tensorflow:loss = 1.2702916, step = 7401 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.539\n",
      "INFO:tensorflow:loss = 0.7542242, step = 7501 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.221\n",
      "INFO:tensorflow:loss = 1.5888662, step = 7601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.998\n",
      "INFO:tensorflow:loss = 1.0607804, step = 7701 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.271\n",
      "INFO:tensorflow:loss = 0.36209625, step = 7801 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.939\n",
      "INFO:tensorflow:loss = 1.9501828, step = 7901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.984\n",
      "INFO:tensorflow:loss = 1.9548733, step = 8001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.939\n",
      "INFO:tensorflow:loss = 0.18690047, step = 8101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.086\n",
      "INFO:tensorflow:loss = 0.23126332, step = 8201 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.897\n",
      "INFO:tensorflow:loss = 1.5862814, step = 8301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.404\n",
      "INFO:tensorflow:loss = 1.3137321, step = 8401 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.053\n",
      "INFO:tensorflow:loss = 0.33268845, step = 8501 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 214\n",
      "INFO:tensorflow:loss = 1.0030164, step = 8601 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.601\n",
      "INFO:tensorflow:loss = 0.29836887, step = 8701 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.906\n",
      "INFO:tensorflow:loss = 0.2037565, step = 8801 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.574\n",
      "INFO:tensorflow:loss = 0.1749366, step = 8901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.41\n",
      "INFO:tensorflow:loss = 0.41781926, step = 9001 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.387\n",
      "INFO:tensorflow:loss = 0.92863935, step = 9101 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.415\n",
      "INFO:tensorflow:loss = 0.5347788, step = 9201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.375\n",
      "INFO:tensorflow:loss = 0.23139873, step = 9301 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.569\n",
      "INFO:tensorflow:loss = 2.1293406, step = 9401 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.38\n",
      "INFO:tensorflow:loss = 0.9831323, step = 9501 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.385\n",
      "INFO:tensorflow:loss = 0.40961766, step = 9601 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.398\n",
      "INFO:tensorflow:loss = 0.18705595, step = 9701 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.554\n",
      "INFO:tensorflow:loss = 0.40741968, step = 9801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.389\n",
      "INFO:tensorflow:loss = 0.31057218, step = 9901 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.986\n",
      "INFO:tensorflow:loss = 0.35776234, step = 10001 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.215\n",
      "INFO:tensorflow:loss = 0.35484928, step = 10101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.99\n",
      "INFO:tensorflow:loss = 0.15593873, step = 10201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.039\n",
      "INFO:tensorflow:loss = 0.13475488, step = 10301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.461\n",
      "INFO:tensorflow:loss = 0.16121611, step = 10401 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.545\n",
      "INFO:tensorflow:loss = 0.6130457, step = 10501 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.1\n",
      "INFO:tensorflow:loss = 0.24057661, step = 10601 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.215\n",
      "INFO:tensorflow:loss = 4.958924, step = 10701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.367\n",
      "INFO:tensorflow:loss = 1.864202, step = 10801 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.274\n",
      "INFO:tensorflow:loss = 0.0764273, step = 10901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.949\n",
      "INFO:tensorflow:loss = 0.2722181, step = 11001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.011\n",
      "INFO:tensorflow:loss = 0.29180953, step = 11101 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.396\n",
      "INFO:tensorflow:loss = 0.42286277, step = 11201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.569\n",
      "INFO:tensorflow:loss = 0.5935745, step = 11301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.639\n",
      "INFO:tensorflow:loss = 0.98451614, step = 11401 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.814\n",
      "INFO:tensorflow:loss = 0.025866784, step = 11501 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.761\n",
      "INFO:tensorflow:loss = 0.30471092, step = 11601 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.138\n",
      "INFO:tensorflow:loss = 4.091071, step = 11701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.085\n",
      "INFO:tensorflow:loss = 0.1446394, step = 11801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.982\n",
      "INFO:tensorflow:loss = 0.07147578, step = 11901 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.8\n",
      "INFO:tensorflow:loss = 0.5186671, step = 12001 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.3\n",
      "INFO:tensorflow:loss = 0.119418636, step = 12101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.217\n",
      "INFO:tensorflow:loss = 0.47761387, step = 12201 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.008\n",
      "INFO:tensorflow:loss = 1.4472662, step = 12301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.201\n",
      "INFO:tensorflow:loss = 0.1461629, step = 12401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.56\n",
      "INFO:tensorflow:loss = 0.14388214, step = 12501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.231\n",
      "INFO:tensorflow:loss = 0.20260283, step = 12601 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.45\n",
      "INFO:tensorflow:loss = 1.4959838, step = 12701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.084\n",
      "INFO:tensorflow:loss = 0.04908217, step = 12801 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.889\n",
      "INFO:tensorflow:loss = 0.04630979, step = 12901 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.699\n",
      "INFO:tensorflow:loss = 0.42033857, step = 13001 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.437\n",
      "INFO:tensorflow:loss = 0.05781596, step = 13101 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.945\n",
      "INFO:tensorflow:loss = 0.20748101, step = 13201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.505\n",
      "INFO:tensorflow:loss = 0.5550399, step = 13301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.023\n",
      "INFO:tensorflow:loss = 0.061745267, step = 13401 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.135\n",
      "INFO:tensorflow:loss = 0.118419364, step = 13501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.062\n",
      "INFO:tensorflow:loss = 0.112142, step = 13601 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.716\n",
      "INFO:tensorflow:loss = 0.60306084, step = 13701 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.74\n",
      "INFO:tensorflow:loss = 0.21648589, step = 13801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.333\n",
      "INFO:tensorflow:loss = 0.22426972, step = 13901 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.207\n",
      "INFO:tensorflow:loss = 0.3399797, step = 14001 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.184\n",
      "INFO:tensorflow:loss = 0.13043173, step = 14101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.579\n",
      "INFO:tensorflow:loss = 0.14633472, step = 14201 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.291\n",
      "INFO:tensorflow:loss = 0.052173126, step = 14301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.665\n",
      "INFO:tensorflow:loss = 0.11882734, step = 14401 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.856\n",
      "INFO:tensorflow:loss = 0.061299503, step = 14501 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.601\n",
      "INFO:tensorflow:loss = 0.052749783, step = 14601 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.654\n",
      "INFO:tensorflow:loss = 0.07516726, step = 14701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.365\n",
      "INFO:tensorflow:loss = 0.26262197, step = 14801 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.236\n",
      "INFO:tensorflow:loss = 0.0515284, step = 14901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.482\n",
      "INFO:tensorflow:loss = 0.11800368, step = 15001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.612\n",
      "INFO:tensorflow:loss = 0.05066301, step = 15101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.428\n",
      "INFO:tensorflow:loss = 0.010987412, step = 15201 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.338\n",
      "INFO:tensorflow:loss = 0.39524314, step = 15301 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.773\n",
      "INFO:tensorflow:loss = 0.08054689, step = 15401 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.355\n",
      "INFO:tensorflow:loss = 0.28787592, step = 15501 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.047\n",
      "INFO:tensorflow:loss = 0.27957556, step = 15601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.299\n",
      "INFO:tensorflow:loss = 0.06442652, step = 15701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.665\n",
      "INFO:tensorflow:loss = 0.052463315, step = 15801 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.482\n",
      "INFO:tensorflow:loss = 0.07699101, step = 15901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.183\n",
      "INFO:tensorflow:loss = 0.17294437, step = 16001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.14\n",
      "INFO:tensorflow:loss = 0.24461576, step = 16101 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.691\n",
      "INFO:tensorflow:loss = 0.07466468, step = 16201 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.834\n",
      "INFO:tensorflow:loss = 0.0605985, step = 16301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.617\n",
      "INFO:tensorflow:loss = 5.607206, step = 16401 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.368\n",
      "INFO:tensorflow:loss = 0.06669396, step = 16501 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.928\n",
      "INFO:tensorflow:loss = 0.23522827, step = 16601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.217\n",
      "INFO:tensorflow:loss = 0.02576522, step = 16701 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.962\n",
      "INFO:tensorflow:loss = 0.043395597, step = 16801 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.207\n",
      "INFO:tensorflow:loss = 0.16840033, step = 16901 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.774\n",
      "INFO:tensorflow:loss = 0.1578923, step = 17001 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.543\n",
      "INFO:tensorflow:loss = 0.08563474, step = 17101 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.428\n",
      "INFO:tensorflow:loss = 0.11211713, step = 17201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.143\n",
      "INFO:tensorflow:loss = 0.019420745, step = 17301 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.821\n",
      "INFO:tensorflow:loss = 0.20051903, step = 17401 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.744\n",
      "INFO:tensorflow:loss = 0.105437145, step = 17501 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.834\n",
      "INFO:tensorflow:loss = 0.022592913, step = 17601 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.498\n",
      "INFO:tensorflow:loss = 0.06598082, step = 17701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.094\n",
      "INFO:tensorflow:loss = 0.048953906, step = 17801 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.357\n",
      "INFO:tensorflow:loss = 0.56859577, step = 17901 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.854\n",
      "INFO:tensorflow:loss = 0.05787664, step = 18001 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.003\n",
      "INFO:tensorflow:loss = 0.040760856, step = 18101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.273\n",
      "INFO:tensorflow:loss = 0.074875094, step = 18201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.125\n",
      "INFO:tensorflow:loss = 0.030051677, step = 18301 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.462\n",
      "INFO:tensorflow:loss = 0.33692217, step = 18401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.147\n",
      "INFO:tensorflow:loss = 0.0066692317, step = 18501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.2\n",
      "INFO:tensorflow:loss = 0.046634078, step = 18601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.449\n",
      "INFO:tensorflow:loss = 0.0049176444, step = 18701 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.632\n",
      "INFO:tensorflow:loss = 0.113278404, step = 18801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.516\n",
      "INFO:tensorflow:loss = 0.13996108, step = 18901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.292\n",
      "INFO:tensorflow:loss = 0.027929418, step = 19001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.431\n",
      "INFO:tensorflow:loss = 0.12852365, step = 19101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.408\n",
      "INFO:tensorflow:loss = 0.07249067, step = 19201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.062\n",
      "INFO:tensorflow:loss = 0.16358992, step = 19301 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.032\n",
      "INFO:tensorflow:loss = 0.040547065, step = 19401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.518\n",
      "INFO:tensorflow:loss = 0.03316153, step = 19501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.87\n",
      "INFO:tensorflow:loss = 0.027299553, step = 19601 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.472\n",
      "INFO:tensorflow:loss = 0.052585874, step = 19701 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.153\n",
      "INFO:tensorflow:loss = 0.13629383, step = 19801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.239\n",
      "INFO:tensorflow:loss = 0.090799116, step = 19901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.824\n",
      "INFO:tensorflow:loss = 0.0034897446, step = 20001 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.286\n",
      "INFO:tensorflow:loss = 0.06661832, step = 20101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.275\n",
      "INFO:tensorflow:loss = 0.040124506, step = 20201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.32\n",
      "INFO:tensorflow:loss = 0.06497167, step = 20301 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.542\n",
      "INFO:tensorflow:loss = 0.05073671, step = 20401 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.107\n",
      "INFO:tensorflow:loss = 0.077477016, step = 20501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.181\n",
      "INFO:tensorflow:loss = 0.06652965, step = 20601 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.212\n",
      "INFO:tensorflow:loss = 0.24175486, step = 20701 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.704\n",
      "INFO:tensorflow:loss = 0.22728111, step = 20801 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.226\n",
      "INFO:tensorflow:loss = 1.0762469, step = 20901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.086\n",
      "INFO:tensorflow:loss = 0.022185544, step = 21001 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.271\n",
      "INFO:tensorflow:loss = 0.12632819, step = 21101 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.916\n",
      "INFO:tensorflow:loss = 0.19491637, step = 21201 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.647\n",
      "INFO:tensorflow:loss = 0.09650138, step = 21301 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.329\n",
      "INFO:tensorflow:loss = 0.18044508, step = 21401 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.068\n",
      "INFO:tensorflow:loss = 0.025960369, step = 21501 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.474\n",
      "INFO:tensorflow:loss = 0.09402433, step = 21601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.69\n",
      "INFO:tensorflow:loss = 0.055789966, step = 21701 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.908\n",
      "INFO:tensorflow:loss = 0.07851806, step = 21801 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.504\n",
      "INFO:tensorflow:loss = 0.0034924601, step = 21901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.747\n",
      "INFO:tensorflow:loss = 0.04258674, step = 22001 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.972\n",
      "INFO:tensorflow:loss = 0.013157273, step = 22101 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.686\n",
      "INFO:tensorflow:loss = 0.04670424, step = 22201 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.396\n",
      "INFO:tensorflow:loss = 0.1346537, step = 22301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.953\n",
      "INFO:tensorflow:loss = 0.036278345, step = 22401 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.818\n",
      "INFO:tensorflow:loss = 0.015566868, step = 22501 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.141\n",
      "INFO:tensorflow:loss = 0.043941244, step = 22601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.727\n",
      "INFO:tensorflow:loss = 0.006353903, step = 22701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.152\n",
      "INFO:tensorflow:loss = 0.031949364, step = 22801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.762\n",
      "INFO:tensorflow:loss = 0.07707614, step = 22901 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.771\n",
      "INFO:tensorflow:loss = 0.059237227, step = 23001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.976\n",
      "INFO:tensorflow:loss = 0.0052294545, step = 23101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.573\n",
      "INFO:tensorflow:loss = 0.12484203, step = 23201 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.353\n",
      "INFO:tensorflow:loss = 0.078142546, step = 23301 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.067\n",
      "INFO:tensorflow:loss = 0.025358135, step = 23401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.564\n",
      "INFO:tensorflow:loss = 0.020566264, step = 23501 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.697\n",
      "INFO:tensorflow:loss = 0.009130599, step = 23601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.631\n",
      "INFO:tensorflow:loss = 0.06310786, step = 23701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.621\n",
      "INFO:tensorflow:loss = 0.02891127, step = 23801 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.774\n",
      "INFO:tensorflow:loss = 0.020295179, step = 23901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.894\n",
      "INFO:tensorflow:loss = 0.07434863, step = 24001 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.547\n",
      "INFO:tensorflow:loss = 0.038586676, step = 24101 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.889\n",
      "INFO:tensorflow:loss = 0.006179811, step = 24201 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.278\n",
      "INFO:tensorflow:loss = 0.0072069215, step = 24301 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.585\n",
      "INFO:tensorflow:loss = 0.050695527, step = 24401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.187\n",
      "INFO:tensorflow:loss = 0.053991627, step = 24501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.932\n",
      "INFO:tensorflow:loss = 0.0085423, step = 24601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.161\n",
      "INFO:tensorflow:loss = 0.027600871, step = 24701 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.016\n",
      "INFO:tensorflow:loss = 0.051257152, step = 24801 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.039\n",
      "INFO:tensorflow:loss = 0.023593603, step = 24901 (0.479 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 24988 vs previous value: 24988. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 209.688\n",
      "INFO:tensorflow:loss = 0.03359803, step = 25001 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.177\n",
      "INFO:tensorflow:loss = 0.052578077, step = 25101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.347\n",
      "INFO:tensorflow:loss = 0.41367963, step = 25201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.48\n",
      "INFO:tensorflow:loss = 0.04504279, step = 25301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.246\n",
      "INFO:tensorflow:loss = 0.019292163, step = 25401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.908\n",
      "INFO:tensorflow:loss = 0.013918108, step = 25501 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.008\n",
      "INFO:tensorflow:loss = 0.09409381, step = 25601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.055\n",
      "INFO:tensorflow:loss = 0.038232468, step = 25701 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.768\n",
      "INFO:tensorflow:loss = 0.042652488, step = 25801 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.046\n",
      "INFO:tensorflow:loss = 0.052006174, step = 25901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.257\n",
      "INFO:tensorflow:loss = 0.13643526, step = 26001 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.505\n",
      "INFO:tensorflow:loss = 0.04652356, step = 26101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.715\n",
      "INFO:tensorflow:loss = 0.005378864, step = 26201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.566\n",
      "INFO:tensorflow:loss = 0.040206797, step = 26301 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.49\n",
      "INFO:tensorflow:loss = 0.047640912, step = 26401 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.535\n",
      "INFO:tensorflow:loss = 0.018888867, step = 26501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.556\n",
      "INFO:tensorflow:loss = 0.018398209, step = 26601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.451\n",
      "INFO:tensorflow:loss = 0.034406994, step = 26701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.877\n",
      "INFO:tensorflow:loss = 0.039980143, step = 26801 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.63\n",
      "INFO:tensorflow:loss = 0.1616072, step = 26901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.746\n",
      "INFO:tensorflow:loss = 0.07318392, step = 27001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.399\n",
      "INFO:tensorflow:loss = 0.026611714, step = 27101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.426\n",
      "INFO:tensorflow:loss = 0.0019843332, step = 27201 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.605\n",
      "INFO:tensorflow:loss = 0.07189703, step = 27301 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.098\n",
      "INFO:tensorflow:loss = 0.036904838, step = 27401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.335\n",
      "INFO:tensorflow:loss = 0.02367474, step = 27501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.969\n",
      "INFO:tensorflow:loss = 0.079331934, step = 27601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.977\n",
      "INFO:tensorflow:loss = 0.06327937, step = 27701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.517\n",
      "INFO:tensorflow:loss = 0.019636799, step = 27801 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.274\n",
      "INFO:tensorflow:loss = 0.0518241, step = 27901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.179\n",
      "INFO:tensorflow:loss = 0.11337731, step = 28001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.197\n",
      "INFO:tensorflow:loss = 0.02570027, step = 28101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.7\n",
      "INFO:tensorflow:loss = 0.104124434, step = 28201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.148\n",
      "INFO:tensorflow:loss = 0.016241293, step = 28301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.011\n",
      "INFO:tensorflow:loss = 0.009332668, step = 28401 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.847\n",
      "INFO:tensorflow:loss = 0.00085913885, step = 28501 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.806\n",
      "INFO:tensorflow:loss = 0.014666224, step = 28601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.155\n",
      "INFO:tensorflow:loss = 0.005986673, step = 28701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.337\n",
      "INFO:tensorflow:loss = 0.008922135, step = 28801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.276\n",
      "INFO:tensorflow:loss = 0.011059775, step = 28901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.508\n",
      "INFO:tensorflow:loss = 0.027939372, step = 29001 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.199\n",
      "INFO:tensorflow:loss = 0.01802686, step = 29101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.92\n",
      "INFO:tensorflow:loss = 0.07125522, step = 29201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.408\n",
      "INFO:tensorflow:loss = 0.010750934, step = 29301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.409\n",
      "INFO:tensorflow:loss = 0.07172806, step = 29401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.155\n",
      "INFO:tensorflow:loss = 0.015833238, step = 29501 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.661\n",
      "INFO:tensorflow:loss = 0.04909352, step = 29601 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.815\n",
      "INFO:tensorflow:loss = 0.0055267625, step = 29701 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.223\n",
      "INFO:tensorflow:loss = 0.073322386, step = 29801 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.995\n",
      "INFO:tensorflow:loss = 0.048161138, step = 29901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.484\n",
      "INFO:tensorflow:loss = 0.05551178, step = 30001 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.248\n",
      "INFO:tensorflow:loss = 0.0275888, step = 30101 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.252\n",
      "INFO:tensorflow:loss = 0.060400262, step = 30201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.824\n",
      "INFO:tensorflow:loss = 0.008706604, step = 30301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.11\n",
      "INFO:tensorflow:loss = 0.12551612, step = 30401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.531\n",
      "INFO:tensorflow:loss = 0.017043972, step = 30501 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.762\n",
      "INFO:tensorflow:loss = 0.03821468, step = 30601 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.413\n",
      "INFO:tensorflow:loss = 0.026856393, step = 30701 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.814\n",
      "INFO:tensorflow:loss = 0.074536845, step = 30801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.34\n",
      "INFO:tensorflow:loss = 0.04214218, step = 30901 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.758\n",
      "INFO:tensorflow:loss = 0.007869353, step = 31001 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.02\n",
      "INFO:tensorflow:loss = 0.0077169645, step = 31101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.123\n",
      "INFO:tensorflow:loss = 0.016355516, step = 31201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.814\n",
      "INFO:tensorflow:loss = 0.045051448, step = 31301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.928\n",
      "INFO:tensorflow:loss = 0.0075212354, step = 31401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.73\n",
      "INFO:tensorflow:loss = 0.04578748, step = 31501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.344\n",
      "INFO:tensorflow:loss = 0.049269885, step = 31601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.943\n",
      "INFO:tensorflow:loss = 0.008719005, step = 31701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.131\n",
      "INFO:tensorflow:loss = 0.00951997, step = 31801 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.544\n",
      "INFO:tensorflow:loss = 0.012715323, step = 31901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.466\n",
      "INFO:tensorflow:loss = 0.018875461, step = 32001 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.547\n",
      "INFO:tensorflow:loss = 0.0029846332, step = 32101 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.421\n",
      "INFO:tensorflow:loss = 0.0065387688, step = 32201 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.639\n",
      "INFO:tensorflow:loss = 0.010239121, step = 32301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.683\n",
      "INFO:tensorflow:loss = 0.098388776, step = 32401 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.559\n",
      "INFO:tensorflow:loss = 0.044457965, step = 32501 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.856\n",
      "INFO:tensorflow:loss = 0.0012638995, step = 32601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.54\n",
      "INFO:tensorflow:loss = 0.009546839, step = 32701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.765\n",
      "INFO:tensorflow:loss = 0.029022565, step = 32801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.156\n",
      "INFO:tensorflow:loss = 0.012465674, step = 32901 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.702\n",
      "INFO:tensorflow:loss = 0.018160777, step = 33001 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.695\n",
      "INFO:tensorflow:loss = 0.0037535815, step = 33101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.83\n",
      "INFO:tensorflow:loss = 0.011909153, step = 33201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.448\n",
      "INFO:tensorflow:loss = 0.02691739, step = 33301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.459\n",
      "INFO:tensorflow:loss = 0.032420635, step = 33401 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.8\n",
      "INFO:tensorflow:loss = 0.013086839, step = 33501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.914\n",
      "INFO:tensorflow:loss = 0.019527033, step = 33601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.579\n",
      "INFO:tensorflow:loss = 0.015368186, step = 33701 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.2\n",
      "INFO:tensorflow:loss = 0.048077434, step = 33801 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.274\n",
      "INFO:tensorflow:loss = 0.007414695, step = 33901 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.462\n",
      "INFO:tensorflow:loss = 0.02902521, step = 34001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.627\n",
      "INFO:tensorflow:loss = 0.013397302, step = 34101 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.306\n",
      "INFO:tensorflow:loss = 0.020850256, step = 34201 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.731\n",
      "INFO:tensorflow:loss = 0.0020066043, step = 34301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.883\n",
      "INFO:tensorflow:loss = 0.018959463, step = 34401 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.891\n",
      "INFO:tensorflow:loss = 0.024383675, step = 34501 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.497\n",
      "INFO:tensorflow:loss = 0.023053782, step = 34601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.283\n",
      "INFO:tensorflow:loss = 0.057883337, step = 34701 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.128\n",
      "INFO:tensorflow:loss = 0.018889287, step = 34801 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.218\n",
      "INFO:tensorflow:loss = 0.021817781, step = 34901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.528\n",
      "INFO:tensorflow:loss = 0.00514834, step = 35001 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.241\n",
      "INFO:tensorflow:loss = 0.0018903629, step = 35101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.303\n",
      "INFO:tensorflow:loss = 0.008288233, step = 35201 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.95\n",
      "INFO:tensorflow:loss = 0.0030936343, step = 35301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.723\n",
      "INFO:tensorflow:loss = 0.0038541427, step = 35401 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.635\n",
      "INFO:tensorflow:loss = 0.042888574, step = 35501 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.164\n",
      "INFO:tensorflow:loss = 0.009790234, step = 35601 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.111\n",
      "INFO:tensorflow:loss = 0.031846374, step = 35701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.23\n",
      "INFO:tensorflow:loss = 0.015607237, step = 35801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.796\n",
      "INFO:tensorflow:loss = 0.025032267, step = 35901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.98\n",
      "INFO:tensorflow:loss = 0.008294473, step = 36001 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.286\n",
      "INFO:tensorflow:loss = 0.003194871, step = 36101 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.919\n",
      "INFO:tensorflow:loss = 0.036811955, step = 36201 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.434\n",
      "INFO:tensorflow:loss = 0.032623176, step = 36301 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.47\n",
      "INFO:tensorflow:loss = 0.013192879, step = 36401 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.962\n",
      "INFO:tensorflow:loss = 0.010698695, step = 36501 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.532\n",
      "INFO:tensorflow:loss = 0.04288373, step = 36601 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.789\n",
      "INFO:tensorflow:loss = 0.06921467, step = 36701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.622\n",
      "INFO:tensorflow:loss = 0.012129337, step = 36801 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.318\n",
      "INFO:tensorflow:loss = 0.01606191, step = 36901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.432\n",
      "INFO:tensorflow:loss = 0.037712883, step = 37001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.644\n",
      "INFO:tensorflow:loss = 0.002148826, step = 37101 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.457\n",
      "INFO:tensorflow:loss = 0.0077980952, step = 37201 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.439\n",
      "INFO:tensorflow:loss = 0.016318368, step = 37301 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.064\n",
      "INFO:tensorflow:loss = 0.01929934, step = 37401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.45\n",
      "INFO:tensorflow:loss = 0.010865418, step = 37501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.924\n",
      "INFO:tensorflow:loss = 0.04036405, step = 37601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.583\n",
      "INFO:tensorflow:loss = 0.009787491, step = 37701 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.474\n",
      "INFO:tensorflow:loss = 0.008304817, step = 37801 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.451\n",
      "INFO:tensorflow:loss = 0.015561462, step = 37901 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.275\n",
      "INFO:tensorflow:loss = 0.00307162, step = 38001 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.663\n",
      "INFO:tensorflow:loss = 0.02953155, step = 38101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.047\n",
      "INFO:tensorflow:loss = 0.027197585, step = 38201 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.945\n",
      "INFO:tensorflow:loss = 0.024120105, step = 38301 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.517\n",
      "INFO:tensorflow:loss = 0.009039064, step = 38401 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.697\n",
      "INFO:tensorflow:loss = 0.045402467, step = 38501 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.032\n",
      "INFO:tensorflow:loss = 0.009821899, step = 38601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.707\n",
      "INFO:tensorflow:loss = 0.015244309, step = 38701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.726\n",
      "INFO:tensorflow:loss = 0.016398884, step = 38801 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.562\n",
      "INFO:tensorflow:loss = 0.033170566, step = 38901 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.687\n",
      "INFO:tensorflow:loss = 0.026103947, step = 39001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.875\n",
      "INFO:tensorflow:loss = 0.070006266, step = 39101 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.56\n",
      "INFO:tensorflow:loss = 0.018743278, step = 39201 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.356\n",
      "INFO:tensorflow:loss = 0.006827538, step = 39301 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.559\n",
      "INFO:tensorflow:loss = 0.007749922, step = 39401 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.748\n",
      "INFO:tensorflow:loss = 0.03071357, step = 39501 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.065\n",
      "INFO:tensorflow:loss = 0.01354836, step = 39601 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.032\n",
      "INFO:tensorflow:loss = 0.016161464, step = 39701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.194\n",
      "INFO:tensorflow:loss = 0.016140044, step = 39801 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.185\n",
      "INFO:tensorflow:loss = 0.016743455, step = 39901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.367\n",
      "INFO:tensorflow:loss = 0.021469232, step = 40001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.013\n",
      "INFO:tensorflow:loss = 0.03984704, step = 40101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.571\n",
      "INFO:tensorflow:loss = 0.021596663, step = 40201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.128\n",
      "INFO:tensorflow:loss = 0.011805878, step = 40301 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.07\n",
      "INFO:tensorflow:loss = 0.023209251, step = 40401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.429\n",
      "INFO:tensorflow:loss = 0.026297107, step = 40501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.89\n",
      "INFO:tensorflow:loss = 0.029771581, step = 40601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.92\n",
      "INFO:tensorflow:loss = 0.019926544, step = 40701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.003\n",
      "INFO:tensorflow:loss = 0.015652727, step = 40801 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.799\n",
      "INFO:tensorflow:loss = 0.026210159, step = 40901 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.787\n",
      "INFO:tensorflow:loss = 0.014544935, step = 41001 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.397\n",
      "INFO:tensorflow:loss = 0.020383824, step = 41101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.701\n",
      "INFO:tensorflow:loss = 0.054510184, step = 41201 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.733\n",
      "INFO:tensorflow:loss = 0.010053944, step = 41301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.783\n",
      "INFO:tensorflow:loss = 0.0072037764, step = 41401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.466\n",
      "INFO:tensorflow:loss = 0.006877206, step = 41501 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.405\n",
      "INFO:tensorflow:loss = 0.022222828, step = 41601 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.813\n",
      "INFO:tensorflow:loss = 0.0016931151, step = 41701 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.17\n",
      "INFO:tensorflow:loss = 0.00444625, step = 41801 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.329\n",
      "INFO:tensorflow:loss = 0.006239623, step = 41901 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.616\n",
      "INFO:tensorflow:loss = 0.01605495, step = 42001 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.847\n",
      "INFO:tensorflow:loss = 0.002973908, step = 42101 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.952\n",
      "INFO:tensorflow:loss = 0.031896107, step = 42201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.765\n",
      "INFO:tensorflow:loss = 0.04772485, step = 42301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.182\n",
      "INFO:tensorflow:loss = 0.022895005, step = 42401 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.271\n",
      "INFO:tensorflow:loss = 0.03438773, step = 42501 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.986\n",
      "INFO:tensorflow:loss = 0.015930148, step = 42601 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.338\n",
      "INFO:tensorflow:loss = 0.0022601148, step = 42701 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.738\n",
      "INFO:tensorflow:loss = 0.00849857, step = 42801 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.873\n",
      "INFO:tensorflow:loss = 0.09023627, step = 42901 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.97\n",
      "INFO:tensorflow:loss = 0.0043201162, step = 43001 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.35\n",
      "INFO:tensorflow:loss = 0.0026497182, step = 43101 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.771\n",
      "INFO:tensorflow:loss = 0.097257935, step = 43201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.856\n",
      "INFO:tensorflow:loss = 0.015417979, step = 43301 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.552\n",
      "INFO:tensorflow:loss = 0.03674292, step = 43401 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.675\n",
      "INFO:tensorflow:loss = 0.016126681, step = 43501 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.325\n",
      "INFO:tensorflow:loss = 0.029761776, step = 43601 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.885\n",
      "INFO:tensorflow:loss = 0.02355974, step = 43701 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.095\n",
      "INFO:tensorflow:loss = 0.0059540705, step = 43801 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.85\n",
      "INFO:tensorflow:loss = 0.02819964, step = 43901 (0.472 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 44000...\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into /tmp/tmptq2ehbvi/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 44000...\n",
      "INFO:tensorflow:Loss for final step: 0.0058124745.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f75d8b3be20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果在MNIST数据集来执行上面的代码（缩放之后，例如使用Scikit-Learn的StandardScaler来缩放），你可以得到一个在测试集上的准确率达到98.1%的模型！这比第3章里最好的模型还要好："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-12-29T20:16:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptq2ehbvi/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.55227s\n",
      "INFO:tensorflow:Finished evaluation at 2020-12-29-20:16:51\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.9801, average_loss = 0.097413175, global_step = 44000, loss = 12.330782\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44000: /tmp/tmptq2ehbvi/model.ckpt-44000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9801,\n",
       " 'average_loss': 0.097413175,\n",
       " 'loss': 12.330782,\n",
       " 'global_step': 44000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在幕后，`DNNClassifier`类基于ReLU激活函数（可以通过设置`activation_fn`超参数来调整）创建所有的神经元层次。输出层依赖于softmax函数，成本函数是交叉熵（详见第4章）。\n",
    "\n",
    "> TF.Learn API还是比较新的，所以在阅读本书时，例子中使用的名称和函数可能会有所发展，不过基本的理念是不变的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用纯TensorFlow训练DNN\n",
    "\n",
    "如果想对网络的架构有更多的控制，可以使用TensorFlow的低级Python API（见第9章）。在本节用低级API构建一个和上一节相同的模型，实现一个小批次梯度下降来训练MNIST数据集。首先是构建阶段，建立TensorFlow的计算图，第二步是执行阶段，具体运行这个图来训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建阶段\n",
    "\n",
    "首先需要引入TensorFlow库，然后是指定输入和输出的个数，并设置每层的隐藏神经元的个数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，与第9章一样，可以使用占位符节点来表示训练数据和目标。X的形状只做了部分定义。它是一个二维的张量（一个矩阵），一个维度是实例，另一个维度是特征，还知道特征的数量为28×28（每个像素一个特征），但是还不知道每个训练批次将包含多少个实例。因此X的形状为（None，n_inputs）。类似y是一个一维的张量，每个实例都有一个入口，但是我们现在还不知道训练批次的大小，所以形状是None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在创建神经网络。占位符节点X将用作输入层；在执行期，它每次都会被训练批次替换（注意训练批次中的所有实例将由神经网络同时处理）。然后创建两个隐藏层和一个输出层。两个隐藏层基本上是一样的：唯一的区别是它们和谁链接，以及每层中包含的神经元数量。输出层也一样，不过它会用softmax而不是ReLU作为激活函数。创建一个`neuron_layer()`函数来每次创建一个层。它需要的参数包括：输入、神经元数量、激活函数、层次的名字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逐行看一下这段代码：\n",
    "\n",
    "1. 首先通过层的名称来创建一个作用域：它将包含该层的所有计算机节点。这是可选的，不过如果节点组织得很好，在TensorBoard上图看起来会好看一些。\n",
    "2. 通过查看输入矩阵的形状并获取第二个维度（第一个维度对应的是实例）的尺寸来决定输入的数量。\n",
    "3. 接下来的三行创建了一个保存权重矩阵的变量W。它是一个二维张量包含了每个输入和每个神经元间连接的权重；因此，它的形状是`(n_inputs，n_neurons)`。使用标准偏差为$2/\\sqrt{n_{inputs}}$的截断 [1] 正态（高斯）分布进行随机初始化。使用一个指定的标准偏差会让算法收敛得更快（在第11章会进一步讨论，这种通过微小调整就会获得巨大收益的做法）。为所有隐藏层随机地初始化连接权重值是非常重要的，这可以避免任何可能导致梯度下降出现无法终止的对称性。 [2]\n",
    "4. 下一行创建了变量b来表示偏差，初始化为0（这里没有对称性问题），每个神经元有一个偏差参数。\n",
    "5. 创建一个子图$z=X \\cdot W+b$。对于批次中的所有实例，该向量实现仅通过一次计算，就能够有效计算每层的每个神经元的输入加上偏差项的权重之和。\n",
    "6. 最后，如果激活参数设置了`\"relu\"`，代码会返回$relu(z)$（即，$\\max(0，z)$），否则会直接返回$z$。\n",
    "\n",
    "好了，现在有了一个很棒的创建神经元的函数了。我们来用它创建一个深度神经网络吧！第一个隐藏层需要X作为其输入。第二层则以第一层的输出作为输入。最后，输出层以第二层的输出作为输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.96 Val accuracy: 0.9166\n",
      "1 Batch accuracy: 0.96 Val accuracy: 0.934\n",
      "2 Batch accuracy: 0.96 Val accuracy: 0.9434\n",
      "3 Batch accuracy: 1.0 Val accuracy: 0.9454\n",
      "4 Batch accuracy: 0.96 Val accuracy: 0.9504\n",
      "5 Batch accuracy: 0.92 Val accuracy: 0.953\n",
      "6 Batch accuracy: 0.96 Val accuracy: 0.9588\n",
      "7 Batch accuracy: 0.96 Val accuracy: 0.9594\n",
      "8 Batch accuracy: 0.98 Val accuracy: 0.9632\n",
      "9 Batch accuracy: 0.96 Val accuracy: 0.9654\n",
      "10 Batch accuracy: 0.98 Val accuracy: 0.967\n",
      "11 Batch accuracy: 0.94 Val accuracy: 0.9676\n",
      "12 Batch accuracy: 1.0 Val accuracy: 0.9698\n",
      "13 Batch accuracy: 0.98 Val accuracy: 0.9694\n",
      "14 Batch accuracy: 0.98 Val accuracy: 0.9704\n",
      "15 Batch accuracy: 1.0 Val accuracy: 0.971\n",
      "16 Batch accuracy: 0.98 Val accuracy: 0.973\n",
      "17 Batch accuracy: 0.98 Val accuracy: 0.9722\n",
      "18 Batch accuracy: 1.0 Val accuracy: 0.9736\n",
      "19 Batch accuracy: 0.98 Val accuracy: 0.9744\n",
      "20 Batch accuracy: 1.0 Val accuracy: 0.9752\n",
      "21 Batch accuracy: 1.0 Val accuracy: 0.9744\n",
      "22 Batch accuracy: 1.0 Val accuracy: 0.9742\n",
      "23 Batch accuracy: 1.0 Val accuracy: 0.9748\n",
      "24 Batch accuracy: 0.98 Val accuracy: 0.9748\n",
      "25 Batch accuracy: 1.0 Val accuracy: 0.9758\n",
      "26 Batch accuracy: 1.0 Val accuracy: 0.9756\n",
      "27 Batch accuracy: 1.0 Val accuracy: 0.9756\n",
      "28 Batch accuracy: 1.0 Val accuracy: 0.975\n",
      "29 Batch accuracy: 1.0 Val accuracy: 0.9766\n",
      "30 Batch accuracy: 1.0 Val accuracy: 0.9756\n",
      "31 Batch accuracy: 1.0 Val accuracy: 0.977\n",
      "32 Batch accuracy: 0.98 Val accuracy: 0.9768\n",
      "33 Batch accuracy: 1.0 Val accuracy: 0.9766\n",
      "34 Batch accuracy: 1.0 Val accuracy: 0.9766\n",
      "35 Batch accuracy: 1.0 Val accuracy: 0.978\n",
      "36 Batch accuracy: 1.0 Val accuracy: 0.9766\n",
      "37 Batch accuracy: 1.0 Val accuracy: 0.9774\n",
      "38 Batch accuracy: 1.0 Val accuracy: 0.9774\n",
      "39 Batch accuracy: 1.0 Val accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/my_model_final.ckpt\") # or better, use save_path\n",
    "    #X_new_scaled = X_test[:20]\n",
    "    X_new_scaled = X_test\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted classes:\", y_pred[:20])\n",
    "print(\"Actual classes:   \", y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.9345539761428904&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0714285746216774\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;dnn/hidden1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;dnn/hidden1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;dnn/hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/add&quot;\\n  op: &quot;AddV2&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;dnn/hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.1154700517654419\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;dnn/hidden2/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;dnn/hidden2/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;dnn/hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/add&quot;\\n  op: &quot;AddV2&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;dnn/hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;dnn/outputs/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;dnn/outputs/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;dnn/outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/add&quot;\\n  op: &quot;AddV2&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;dnn/outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/outputs/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/outputs/kernel/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2&quot;\\n  op: &quot;InTopKV2&quot;\\n  input: &quot;dnn/outputs/add&quot;\\n  input: &quot;y&quot;\\n  input: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/in_top_k/InTopKV2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^dnn/hidden1/bias/Assign&quot;\\n  input: &quot;^dnn/hidden1/kernel/Assign&quot;\\n  input: &quot;^dnn/hidden2/bias/Assign&quot;\\n  input: &quot;^dnn/hidden2/kernel/Assign&quot;\\n  input: &quot;^dnn/outputs/bias/Assign&quot;\\n  input: &quot;^dnn/outputs/kernel/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/filename/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/filename&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/bias&quot;\\n        string_val: &quot;dnn/hidden1/kernel&quot;\\n        string_val: &quot;dnn/hidden2/bias&quot;\\n        string_val: &quot;dnn/hidden2/kernel&quot;\\n        string_val: &quot;dnn/outputs/bias&quot;\\n        string_val: &quot;dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/bias&quot;\\n        string_val: &quot;dnn/hidden1/kernel&quot;\\n        string_val: &quot;dnn/hidden2/bias&quot;\\n        string_val: &quot;dnn/hidden2/kernel&quot;\\n        string_val: &quot;dnn/outputs/bias&quot;\\n        string_val: &quot;dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;save/RestoreV2:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;save/RestoreV2:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;save/RestoreV2:5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.9345539761428904&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 使用了命名空间来保持名字的清晰。另外，logits是经过softmax激活函数之前神经网络的输出：基于优化的考虑，将在稍后处理softmax计算。\n",
    "\n",
    "TensorFlow提供了很多便利的函数来创建标准神经网络层，所以通常无须定义自己的`neuron_layer()`函数。比如TensorFlow的`fully_connected()`函数会创建全连接层，其中所有输入都连接到该层中的所有神经元。这个函数会创建权重和偏差变量，使用合适的初始化策略，使用ReLU激活函数（可以通过activation_fn参数来修改）。它还支持规则化和归一化参数。用`fully_connected()`[新版本使用`dense()`]函数来替换自己写的`neuron_layer()`函数，只需要导入函数并替换掉DNN的构造即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-7a15087f755c>:2: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    #logits = tf.keras.layers.Dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> tensorflow.contrib包里包含了很多有用的函数，不过其中很多代码都是实验性质的，还没有被正式收录到TensorFlow的API中。fully_connected（）（以及其他很多contrib包中的代码）函数将来可能会变更。\n",
    "\n",
    "已经有了神经网络模型，现在需要定义成本函数用以训练它。正如第4章做的Softmax回归，这里会使用交叉熵。之前讨论过，交叉熵会处罚那些估计目标类的概率较低的模型。TensorFlow提供了很多函数来计算交叉熵，这里用`spare_soft_max_cross_entropy_with_logits()`：它会根据“logits”来计算交叉熵（比如，在通过softmax激活函数之前网络的输出），并且期望以0到分类个数减1的整数形式标记（例子中是从0到9）。这会计算出一个包含每个实例的交叉熵的一维张量。可以使用TensorFlow的`reduce_mean()`函数来计算所有实例的平均交叉熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 函数`sparse_softmax_cross_entropy_with_logits()`与先应用softmax函数再计算交叉熵的效果是一样的，不过它更高效一些，另外它会处理一些边界值如logits等于0的情况。这也是为什么之前没有使用softmax激活函数的原因。此外还有一个`softmax_cross_entropy_with_logits()`函数，它以one-hot的形式获取标签（而不是从0到分类数量减1）。\n",
    "\n",
    "现在有了神经网络模型，有了成本函数，是时候来定义一个`梯度下降优化器`（`GradientDescentOptimizer`）了，这个优化器会调整模型的参数来使得成本函数的值最小化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建期的最后一个重要步骤是指定如何对模型求值。简单地将精度用作性能指标。首先，对于每个实例，通过检查最高logit值是否对应于目标类来确定神经网络的预测是否正确。这里可以使用`in_top_k()`函数，这个函数会返回一个一维的张量，其值为布尔类型，因此需要将值强制装换成浮点型然后计算平均值，这会得出网络的总体精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与往常一样，创建节点初始化变量，创建Saver将训练后的模型保存到磁盘："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了！构建期终于结束了。一共不到40行代码，不过很清晰：1. 创建了用于输入和目标值占位符节点，2. 创建了用以创建神经网络的函数，使用它创建DNN，3. 定义了成本函数，4. 创建了一个优化器，5. 最后还定义了性能度量。现在我们进入执行期。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行阶段\n",
    "\n",
    "这部分会短很多，也简单很多。首先，加载MNIST数据集。可以像上一章一样用Scikit-Learn，不过TensorFlow提供了自己的助手函数来加载数据，缩放（从0到1），打乱，还提供了一个简单函数每次加载一个小批次。这里用TensorFlow提供的函数：\n",
    "\n",
    "然后定义需要运行的epoch数量，以及小批次大小："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "n_batches = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在就可以训练模型了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.96 Validation accuracy: 0.9032\n",
      "1 Batch accuracy: 0.96 Validation accuracy: 0.9232\n",
      "2 Batch accuracy: 0.96 Validation accuracy: 0.9348\n",
      "3 Batch accuracy: 0.98 Validation accuracy: 0.9394\n",
      "4 Batch accuracy: 0.98 Validation accuracy: 0.945\n",
      "5 Batch accuracy: 0.92 Validation accuracy: 0.9488\n",
      "6 Batch accuracy: 0.98 Validation accuracy: 0.954\n",
      "7 Batch accuracy: 0.96 Validation accuracy: 0.9586\n",
      "8 Batch accuracy: 0.96 Validation accuracy: 0.96\n",
      "9 Batch accuracy: 0.92 Validation accuracy: 0.9616\n",
      "10 Batch accuracy: 0.94 Validation accuracy: 0.9642\n",
      "11 Batch accuracy: 0.94 Validation accuracy: 0.9654\n",
      "12 Batch accuracy: 0.96 Validation accuracy: 0.9668\n",
      "13 Batch accuracy: 0.96 Validation accuracy: 0.9676\n",
      "14 Batch accuracy: 0.98 Validation accuracy: 0.9686\n",
      "15 Batch accuracy: 0.98 Validation accuracy: 0.9694\n",
      "16 Batch accuracy: 0.96 Validation accuracy: 0.9712\n",
      "17 Batch accuracy: 0.96 Validation accuracy: 0.9716\n",
      "18 Batch accuracy: 1.0 Validation accuracy: 0.9718\n",
      "19 Batch accuracy: 0.98 Validation accuracy: 0.9736\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码先打开了一个TensorFlow的会话，运行初始化代码来初始化所有的变量。运行主训练循环：在每一个周期（epoch）中，迭代一组和训练集大小相对应的批次，每一个小批次通过`next_batch()`方法来获得，然后执行训练操作，将当前小批次的输入数据和目标传入。接下来，在每个周期结束的时候，代码会用上一个小批次以及全量的训练集来评估模型，并打印结果。最后，将模型的参数保存到硬盘。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用神经网络\n",
    "\n",
    "现在神经网络已经被训练好了，可以用它来做预测了。保留构建器的代码，修改执行期的代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./models/my_model_final.ckpt\") # or better, use save_path\n",
    "    #X_new_scaled = X_test[:20]\n",
    "    X_new_scaled = X_test\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[20:40]\n",
    "y_test[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码首先从硬盘上加载模型参数，然后加载需要被分类的新图片。记住应用与训练数据相同的特征缩放（这里是从0到1）。然后评估logits节点。如果想知道所有分类的概率，可以给logits使用`softmax()`函数，如果只是想预测一个分类，只需要选出那个有最大logit值的即可（可以使用`argmax()`函数完成）。\n",
    "\n",
    "[1] 使用截断的正态分布而不是常规的正态分布，保证这里不存在任何减慢训练的大权重。\n",
    "\n",
    "[2] 例如，如果将所有的权重设置为0，然后所有的神经元输出为0，对于给定隐藏层的所有神经元，误差梯度也是相同的。然后梯度下降步骤在每一层以相同的方式更新所有神经元的权重，因此它们将保持相等。换句话说，尽管每层有数百个神经元，但是模型的每层就好像只有一个神经元一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调神经网络的超参数\n",
    "\n",
    "神经网络的灵活性也恰好是它的一个主要的短板：有太多的超参数需要调整。不仅仅是可以使用任何的网络拓扑（神经元是如何彼此连接的），即使是简单的MLP，也有很多可以调整的参数：可以修改层数，每层的神经元数，每层用的激活函数类型，初始化逻辑的权重，等等。怎么才能知道超参数的何种组合适合你呢？\n",
    "\n",
    "当然，正如上一章展示的，可以使用具有交叉验证的网格搜索来查找正确的超参数。不过有如此多的超参数需要调整，另外，在一个大的数据集上训练神经网络会很耗时，在有限的时间内，只可能探索很小一部分超参数。不过用我们在第2章提到的随机搜索法（ https://goo.gl/QFjMKu ）会好很多。另外一个选项是使用像Oscar（ http://oscar.calldesk.ai/ ）这样的工具，它实现了更复杂的算法，可以更快地找出超参数集。\n",
    "\n",
    "对于缩小搜索空间来说，了解每个超参数的合理取值会很有帮助。从隐藏层的个数开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隐藏层的个数\n",
    "\n",
    "对很多问题，可以从单一的隐藏层开始，而且通常可以获得很好的效果。事实上人们发现只要神经元足够多，仅有一个隐藏层的MLP都可以建模大部分复杂的函数。很长一段时间里，研究者们都认为无须进一步研究更深的神经网络。不过他们忽视了深层网络比浅层网络有更高的参数效率：深层网络可以用非常少的神经元来建模复杂函数，因此训练起来更加快速。\n",
    "\n",
    "要理解为什么会这样，设想你被要求用一个绘图软件画一片森林，但是不允许拷贝粘贴。只能依次画每一棵树，每一个枝干，每一片叶子。如果可以先画一片叶子，然后拷贝粘贴成一个枝干，再拷贝粘贴成一棵树，最后再拷贝粘贴整棵树形成森林，那速度将会大大提高。现实世界的数据往往会按照层次结构组织，而DNN天生的就很擅长处理这种数据：低级隐藏层用以建模低层结构（比如，各种形状和方向的线段），中级隐藏层组合这些低层结构来建模中层结构（比如，正方形、圆形等），高级隐藏层和输出层组合这些中层结构来建模高层结构（比如，人脸）。\n",
    "\n",
    "分层的架构不但可以帮助DNN更快地归纳出好方案，还可以提高对于新数据集的泛化能力。比如，已经训练出了一个可以识别人脸的模型，现在想要训练一个新的模型来识别发型，可以完全重用第一个模型中的低层神经网络。不必随机初始化新的网络中低层的权重和偏差，可以直接用第一个网络的低层神经网络。这样新网络无须从头在图片中学习所有低层的结构，而只需要从高层结构学习即可（比如发型）。\n",
    "\n",
    "总之，对于大多数问题来说，都只需要一个或者两个隐藏层来处理（对于MINST数据集，一个拥有数百个神经元的隐藏层就可以达到97%的精度，而用同样数量神经元构建的两层隐藏层就可以获得超过98%的精度，而且训练时间基本相同）。对于更复杂的问题，可以逐渐增减隐藏层的层次，直到在训练集上产生过度拟合。非常复杂的问题，比如大图片的分类，或者语音识别，通常需要数十层的隐藏层（甚至数百层，非全连接的层，将在第13章讨论），当然它们需要超大的训练数据集。不过，很少会从头构建这样的网络：更常见的是重用别人训练好的用来处理类似任务的网络。这样训练就会快很多，而且需要的数据量也会少很多（在第11章讨论）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每个隐藏层中的神经元数\n",
    "\n",
    "显然，输入输出层中的神经元数由任务要求的输入输出类型决定。比如，MNIST任务需要28×28=784个输入神经元和10个输出神经元。对于隐藏层来说，一个常用的实践是以漏斗型来定义其尺寸，每层的神经元数依次减少：原因是许多低级功能可以合并成数量更少的高级功能。比如，一个典型的MINST的神经网络有两个隐藏层，第一层有300个神经元，而第二层有100个神经元。不过，这种实践现在也不那么常用了，可以将所有层次定义为同一尺寸，每个隐藏层各150个神经元：这只是一个超参数调整。与层次的数量一样，你可以逐步添加神经元的数量，直到出现过度拟合。通常来说，通过增加每层的神经元数量比增加层数会产生更多的消耗。不幸的是，找到完美的神经元数量仍然是黑科技。\n",
    "\n",
    "一个更简单的做法是使用（比实际所需）更多的层次和神经元，然后提前结束训练来避免过度拟合（以及其他的正则化技术，特别是dropout，我们将在第11章讨论）。这被称为“弹力裤”方法。 [1] 无须花费时间找刚好适合你的裤子，随便挑弹力裤，它会缩小到合适的尺寸。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "大多数情况下，可以在隐藏层中使用ReLU激活函数（或者其变种，会在第11章看到）。它比其他激活函数要快一些，因为梯度下降对于大输入值没有上限，会导致它无法终止（与逻辑函数或者双曲正切函数刚好相反，它们会在1处饱和）。\n",
    "\n",
    "对于输出层，softmax激活函数对于分类任务（如果分类是互斥的）来说是一个很不错的选择。对于回归任务，完全可以不使用激活函数。\n",
    "\n",
    "人工神经网络的介绍就到此为止了。在接下来的章节中，会讨论如何训练深度网络，将训练过程分布到多个服务器和GPU上。还会探索一些其他的神经网络架构：卷积神经网络、复发神经网络和自动编码器。 [2]\n",
    "\n",
    "[1] Vincent Vanhoucke在Udacity.com上的深度学习课程（https://goo.gl/Y5TFqz）。\n",
    "\n",
    "[2] 其他更多的ANN架构详见附录E。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1.用原生人造神经元绘制一个计算$A \\oplus B$（代表异或操作）的ANN（见图10-3）。提示：$A \\oplus B = (A \\land \\neg B) \\lor (\\neg A \\land B)$。\n",
    "\n",
    "2.为什么通常更倾向用逻辑回归分类器而不是经典的感知器（比如，使用感知器训练算法训练的单层线性阈值单元）？如何调整一个感知器，让它与逻辑回归分类器等价？\n",
    "\n",
    "不可微；更改激活函数\n",
    "\n",
    "标准答案：\n",
    "经典的感知器只有在数据集是线性可分的情况下才会收敛，并且不能估计分类的概率。作为对比，逻辑回归分类器即使在数据集不是线性可分的情况下也可以很好地收敛，而且还能输出分类的概率。如果你将感知器的激活函数修改为逻辑激活函数（或者如果有多个神经元的时候，采用softmax激活函数），然后训练其使用梯度下降（或者使成本函数最小化的一些其他优化算法，通常是交叉熵法），那么它就会变为一个逻辑回归分类器了。\n",
    "\n",
    "3.为什么逻辑激活函数是训练第一个MLP的关键因素？\n",
    "\n",
    "标准答案：\n",
    "逻辑激活函数是训练第一个MLP的关键因素，因为它的导数总是非零的，所以梯度下降总是可以持续的。当激活功能是一个阶梯函数时，渐变下降就不能再持续了，因为这时候根本没有斜率。\n",
    "\n",
    "4.说出3种流行的激活函数，你能画出它们的图形吗？\n",
    "ReLU\n",
    "Sigmoid\n",
    "Softmax\n",
    "\n",
    "标准答案：\n",
    "阶梯函数、逻辑函数、双曲正切、线性整流函数，如图10-8所示。有关其他示例，请参阅第11章，例如ELU和ReLU的其他变体。\n",
    "\n",
    "5.假设你有一个MLP包含：由一个有10个透传神经元组成的输入层，及一个有50个人工神经元的隐藏层，以及一个有3个神经元的输出层。所有的神经元都用ReLU激活函数。那么：\n",
    "\n",
    "* 输入矩阵X的形状是什么？\n",
    "* 隐藏层权重向量$W_h$ ，偏移向量$b_h$ 的形状呢？\n",
    "* 输出层权重向量$W_o$ ，偏移向量$b_o$ 的形状呢？\n",
    "* 输出矩阵$Y$的形状是什么？\n",
    "* 写出计算网络输出矩阵Y对应X、W h 、b h 、W o 和b o 的方程式。\n",
    "\n",
    "`m*10`；`10*50`,`1*50`;`50*3`,`1*3`;`m*3`\n",
    "$$\n",
    "Y = (X\\cdot W_h+b_h)\\cdot W_o+b_0\n",
    "$$\n",
    "\n",
    "\n",
    "6.要区分邮件是不是垃圾邮件，输出层需要多少个神经元？输出层应该选择哪种激活函数？如果要处理MNIST，输出层又需要多少个神经元？使用哪种激活函数？回答与第2章同样的问题。让这个网络预测房价。\n",
    "\n",
    "2个；\n",
    "10个；\n",
    "\n",
    "标准答案：\n",
    "要将电子邮件分类为垃圾邮件和正常邮件，只需要在神经网络的输出层中使用一个神经元，例如，指出电子邮件是垃圾邮件的概率。估算概率时，通常会在输出层使用`逻辑激活函数`。\n",
    "\n",
    "如果要解决MNIST问题，则需要输出层中有10个神经元，并且必须用可以处理`多个分类的softmax激活函数`替换逻辑函数，为每个分类输出一个概率。\n",
    "\n",
    "如果想让神经网络预测房价，那么需要一个输出神经元，而在输出层则无须使用激活函数。\n",
    "\n",
    "7.什么是反向传播，它是如何工作的？反向传播与反式自动微分有何区别？\n",
    "\n",
    "反向传播是一种用于训练人工神经网络的技术。它首先计算关于每个模型参数（所有的权重和偏差）的成本函数的梯度，然后使用这些梯度执行梯度下降。这种反向传播步骤通常执行数千次或数百万次，并需要多个训练批次，直到模型参数收敛到最小化成本函数的值为止。为了计算梯度，反向传播使用反向模式autodiff（尽管在反向传播被发明的时候还不叫autodiff，事实上autodiff的概念已经被重新发明了多次）。反向模式的autodiff会先在计算图上正向执行一次，计算当前训练批次的每个节点的值，然后反向执行一次，一次性计算所有梯度（详见附录D）。那和反向传播有什么区别呢？反向传播是指使用多个反向传播步骤来训练人工神经网络的全部过程，每个步骤计算梯度并使用它们执行梯度下降过程。相反，反向模式autodiff只是一种简单的计算梯度的技术，只是恰好被反向传播使用了而已。\n",
    "\n",
    "8.你能列出可以被调整的所有的MLP的超参数吗？如果MLP对于数据集过度拟合了，你会如何调整这些超参数来解决？\n",
    "\n",
    "标准答案：\n",
    "这里列出了所有可以在基本MLP中调整的超参数：隐藏层的数量，每个隐藏层中神经元的数量，以及每个隐藏层和输出层中使用的激活函数。 [4] 一般情况下，ReLU激活函数是隐藏层的一个很好的默认值。\n",
    "\n",
    "对于输出层，通常需要二分分类的逻辑激活函数，多类分类的softmax激活函数，在做回归时则无须任何激活函数。\n",
    "\n",
    "如果MLP对训练数据有过度拟合，可以尝试减少隐藏层的数量，并减少每个隐藏层的神经元数量。\n",
    "\n",
    "9.在MNIST数据集上训练一个深度MLP，看看预测准确度能不能超过98%。就像第9章结束前的那个练习一样，尝试添加一些额外的功能（保存检查点，中断后从检查点恢复，添加汇总，用TensorBoard绘制学习曲线等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    loss_summary = tf.summary.scalar('log_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory to write the TensorBoard logs to\n",
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = log_dir(\"mnist_dnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training was interrupted. Continuing at epoch 121\n",
      "INFO:tensorflow:Restoring parameters from /tmp/my_deep_mnist_model.ckpt\n",
      "Epoch: 125 \tValidation accuracy: 98.260% \tLoss: 0.07412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./models/my_deep_mnist_model'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130 \tValidation accuracy: 98.280% \tLoss: 0.07507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135 \tValidation accuracy: 98.240% \tLoss: 0.07528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 \tValidation accuracy: 98.300% \tLoss: 0.07521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145 \tValidation accuracy: 98.280% \tLoss: 0.07545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150 \tValidation accuracy: 98.320% \tLoss: 0.07570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155 \tValidation accuracy: 98.300% \tLoss: 0.07641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 \tValidation accuracy: 98.300% \tLoss: 0.07671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165 \tValidation accuracy: 98.300% \tLoss: 0.07692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170 \tValidation accuracy: 98.280% \tLoss: 0.07779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175 \tValidation accuracy: 98.300% \tLoss: 0.07782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 \tValidation accuracy: 98.300% \tLoss: 0.07822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/my_deep_mnist_model.ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./models/my_deep_mnist_model\"\n",
    "\n",
    "best_loss = np.infty\n",
    "epochs_without_progress = 0\n",
    "max_epochs_without_progress = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
    "        file_writer.add_summary(accuracy_summary_str, epoch)\n",
    "        file_writer.add_summary(loss_summary_str, epoch)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch:\", epoch,\n",
    "                  \"\\tValidation accuracy: {:.3f}%\".format(accuracy_val * 100),\n",
    "                  \"\\tLoss: {:.5f}\".format(loss_val))\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "            if loss_val < best_loss:\n",
    "                saver.save(sess, final_model_path)\n",
    "                best_loss = loss_val\n",
    "            else:\n",
    "                epochs_without_progress += 5\n",
    "                if epochs_without_progress > max_epochs_without_progress:\n",
    "                    print(\"Early stopping\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_deep_mnist_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, final_model_path)\n",
    "    accuracy_val = accuracy.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
