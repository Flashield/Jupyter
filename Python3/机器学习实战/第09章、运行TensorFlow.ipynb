{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow是一个用于数值计算的强大开源软件库，非常适合大型机器学习。它背后的原理很简单：首先在Python中定义一个用来计算的图（见图9-1），然后TensorFlow就会使用这个图，并用优化过的C++代码来执行计算。\n",
    "\n",
    "![图9-1：一个简单的计算图](images/VNote/20201202104105073_12738.png)\n",
    "\n",
    "图9-1：一个简单的计算图\n",
    "\n",
    "最重要的是，TensorFlow可以将一个计算图划分成多个子图，然后并行地在多个CPU或者GPU上执行（见图9-2）。TensorFlow还支持分布式计算，这样可以在合理的时间内，通过在数百台服务器上分割计算，在庞大的训练集上训练巨大的神经网络（详见第12章）。TensorFlow可以在由数十亿个实例组成的训练集上训练具有数百万个参数的神经网络，每个实例具有数百万个特征。这些其实也都不足为奇，毕竟TensorFlow是由Google Brain小组开发的，而且Google众多的大型服务（比如Google Cloud Speech、Google Photos、Google Search等）背后都有TensorFlow的支持。\n",
    "\n",
    "在TensorFlow从2015年11月宣布开源的时候，深度学习领域已经存在众多流行的开源库（表9-1中列出了一些）。不过，TensorFlow凭借自己清晰的设计、扩展性、灵活性 [1] 和完善的文档（更别提Google的名字了）很快就排在了这个列表的顶端。简而言之，TensorFlow兼具灵活性和扩展性，可直接供生产系统使用，其他已有的框架仅仅能做到这三者中的两个。以下是TensorFlow的一些亮点：\n",
    "\n",
    "![图9-2：多CPU/GPU/服务器上的并行计算](images/VNote/20201202104149601_32595.png)\n",
    "\n",
    "图9-2：多CPU/GPU/服务器上的并行计算\n",
    "\n",
    "* 它可以运行在Windows、Linux、macOS和移动设备上，包括iOS和Android。\n",
    "\n",
    "* 它提供了一个非常简单的名叫TF.Learn [2] （tensorflow.contrib.learn）的Python API来兼容Scikit-Learn。只需要几行代码，就可以用它来训练各种类型的神经网络。这个库的前身是一个独立的项目，叫作Scikit-Flow（或者简称skflow）。\n",
    "\n",
    "* 它还提供另一个叫作TF-Slim（tensorflow.contrib.slim）的简单API来简化神经网络的构建、训练和评估。\n",
    "\n",
    "* 在TensorFlow之上，独立构建了一些高级的API，比如Keras（ http://keras.io ）和Pretty Tensor（ https://github.com/google/prettytensor/ ）。\n",
    "\n",
    "* 它的Python API提供了很多灵活的方式（代价是很高的复杂性）来创建所有类型的计算，包括所有能想到的神经网络架构。\n",
    "\n",
    "* 它包含了很多非常高效的、用C++实现的机器学习操作，特别是用来构建神经网络的操作。另外，通过它的API，还可以用C++来实现自己的高性能操作。\n",
    "\n",
    "* 它为搜索最小化成本函数的参数提供了很多高度优化的节点。TensorFlow会自动计算成本函数的梯度，所以用起来会非常容易，这称为自动微分（或者autodiff）。\n",
    "\n",
    "* 它还提供一个非常强大的叫作TensorBoard的可视化工具，可以用来浏览计算图，查看学习曲线等。\n",
    "\n",
    "* Google还启动了一个运行TensorFlow计算图（ https://cloud.google.com/ml ）的云服务。\n",
    "\n",
    "* 最后，它有一个热情且乐于助人的开发团队和一个不断增长、持续改进它的社区。它是GitHub上最受欢迎的开源项目之一，有越来越多的项目都是构建于其上的（参见源代码 https://www.tensorflow.org/ 或 https://github.com/jtoy/awesome-tensorflow ）。如果遇到了具体的技术问题，可以在 http://stackoverflow.com/ 提问，并将问题标记为\"tensorflow\"。可以在GitHub上记录bug或者发起特性请求。对于普通的讨论，请加入Google讨论组（ http://goo.gl/N7kRF9 ）。\n",
    "\n",
    "这一章会讲解TensorFlow的基础知识，从安装，到创建，执行，保存，可视化简单的计算图。掌握这些基础知识对于构建自己的第一个神经网络（我们会在下一章讨论）来说非常重要。\n",
    "\n",
    "\n",
    "|       库        |      API所用语言      |               操作系统               |\n",
    "| -------------- | -------------------- | ----------------------------------- |\n",
    "| Caffe          | Python、C++、Matlab  | Linux、macOS、Windows               |\n",
    "| Deeplearning4j | Java、Scala、Clojure | Linux、macOS、Windows、Android      |\n",
    "| H2O            | Python、R            | Linux、macOS、Windows               |\n",
    "| MXNet          | Python、C++、others  | Linux、macOS、Windows、iOS、Android |\n",
    "| TensorFlow     | Python、C++          | Linux、macOS、Windows、iOS、Android |\n",
    "| Theano         | Python               | Linux、macOS、iOS                   |\n",
    "| Torch          | C++、Lua             | Linux、macOS、iOS、Android          |\n",
    "\n",
    "表9-1：开源的深度学习库（这不是一个详尽的清单）\n",
    "\n",
    "\n",
    "\n",
    "[1] TensorFlow不局限在神经网络或者机器学习，甚至可以用它来运行量子物理仿真。\n",
    "\n",
    "[2] 不要与TFLearn库混淆，TFLearn库是一个独立的项目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装\n",
    "\n",
    "那就开始吧。假设已经按照第2章里的步骤安装了Jupyter和Scikit-Learn，这样就可以简单地用pip安装TensorFlow了。如果已经用virtualenv创建了独立的环境，那么首先得激活它："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ cd $ML_PATH               # Your ML working directory (e.g., $HOME/ml)\n",
    "\n",
    "$ source env/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，安装TensorFlow："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ pip3 install --upgrade tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 要启动GPU支持，需要安装tensorflow-gpu，而不是tensorflow，详见第12章。\n",
    "\n",
    "用下面这条命令来检查是否安装成功。如果安装成功，这条命令的输出应该是："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ python3 -c 'import tensorflow; print(tensorflow.__version__)'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个计算图并在会话中执行\n",
    "\n",
    "下面这段代码会创建图9-1中描述的图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=55):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zhuangbin/pyenv/jupyter/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# 使用tensorflow v1\n",
    "# import tensorflow as tf \n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "# 这个也要加上，否则两个版本的处理方式不同\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就这么简单！重要的是，要理解这段代码其实并没有执行任何的计算，尽管看起来有点像（特别是最后一行），它仅仅是创建了一个计算图而已。事实上，它连变量都还没有初始化。要执行这个图，需要打开一个TensorFlow的会话，然后用它来初始化变量并求值f。一个TensorFlow的会话会将计算分发到诸如CPU和GPU设备上并执行，它还持有所有变量的值 [1] 。下面的代码创建一个会话，初始化所有变量，然后求值，最后f关闭整个会话（释放占用的资源）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次都重复`sess.run`看起来有些笨拙，好在有更好的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在with块中，会有一个默认会话。调用`x.initializer.run`等价于调用`tf.get_default_session().run(x.initializer)`，同样，`f.eval`等价于`tf.get_default_session().run(f)`。这种写法不仅可以增加可读性，还可使会话在块中的代码执行结束后自动关闭。\n",
    "\n",
    "除了手工为每个变量调用初始化器之外，还可以使用`global_variables_initializer()`函数来完成同样的动作。注意，这个操作并不会立刻做初始化，它只是在图中创建了一个节点，这个节点会在会话执行时初始化所有变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables \n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Jupyter或者在Python shell中，可以创建一个InteractiveSession。它和常规会话的不同之处在于InteractiveSession在创建时会将自己设置为默认会话，因此无须使用with块（不过需要在结束之后手工关闭会话）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# 这种写法无需with\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个TensorFlow程序通常可以分成两部分：\n",
    "1. 第一部分用来构建一个计算图（称为构建阶段）;\n",
    "2. 第二部分来执行这个图（称为执行阶段）。\n",
    "\n",
    "构建阶段通常会构建一个计算图，这个图用来展现ML模型和训练所需的计算。执行阶段则重复地执行每一步训练动作（比如每个小批量执行一步），并逐步提升模型的参数。\n",
    "\n",
    "[1] 在分布式TensorFlow中，变量的值存储在服务器而不是会话中，详情参见第12章。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理图\n",
    "\n",
    "创建的所有节点都会自动添加到默认图上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大部分情况下，这都不是问题，不过有时候你可能想要管理多个互不依赖的图。可以创建一个新的图，然后用with块临时将它设置为默认图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在Jupyter中（或者Python shell中），做实验时你经常会多次执行同一条命令。这样可能会在同一个图上添加了很多重复节点。一种做法是重启Jupyter内核（或者Python shell），更方便的做法是通过tf.reset_default_graph（）来重置默认图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 节点值的生命周期\n",
    "\n",
    "当求值一个节点时，TensorFlow会自动检测该节点依赖的节点，并先对这些节点求值，比如在下面这个例子中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = y * 3\n",
    "with tf.Session() as sess:\n",
    "    print(w.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，这段代码定义了一个非常简单的计算图。然后，它启动一个会话，并开始执行计算图，求值y：TensorFlow自动检测到y依赖于w，因为x依赖于w，所以它会先求值w，然后是x，然后是y，并返回y的值。最后，这段代码执行到对z求值的时候。TensorFlow发现需要先求值w和y。需要注意的是，TensorFlow不会复用上一步求值的w和x的结果。简而言之，w和x的值会计算两次。\n",
    "\n",
    "在图的每次执行间，所有节点值都会被丢弃，但是变量的值不会，因为变量的值是由会话维护的（队列和阅读器也会维护一些状态，详见第12章）。变量的生命周期从初始化器的执行开始，到关闭会话才结束。\n",
    "\n",
    "对于上述代码，如果不希望对y和z重复求值，那么必须告诉TensorFlow在一次图的执行中就完成y和z的求值，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 30\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val, z_val)  # 10, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在单进程的TensorFlow中，即使它们共享同一个计算图，多个会话之间仍然互相隔离，不共享任何状态（每个会话对每个变量都有自己的拷贝）。对于分布式TensorFlow（见第12章），变量值保存在每个服务器上，而不是会话中，所以多个会话可以共享同一变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow中的线性回归\n",
    "\n",
    "TensorFlow中的操作（简称op）可以接受任意数量的输入，也可以产生任意数量的输出。举个例子，加法和乘法操作都接受两个输入，并产生一个输出。常量和变量（称为源操作）则没有输入。输入和输出都是多维数组，叫作`张量`（这也是TensorFlow名字的来源）。就像NumPy中的数组一样，张量也有类型和形状。事实上，在Python API中，张量可以用NumPy中的ndarrays来表示。通常它们会用来保存浮点型数据，不过也可以用它来存储字符串（任意的字节数组）。\n",
    "\n",
    "目前看到的例子中，张量都只包含了单个标量值，但可以对任意形状的数组进行计算。比如，下面的代码展示了如何操作二维的数组来计算加州的住房数据的线性回归（在第2章中有介绍）。首先，获取数据。然后，对所有训练实例都添加一个额外的偏移（$x_0 =1$）（由于使用了Numpy，所以这是立刻执行的）。接下来，创建两个TensorFlow的常量节点，X和y以及目标 [1] ，代码中还使用了TensorFlow提供的矩阵操作来定义theta。这些矩阵相关函数`transpose()`、`matmul()`和`matrix_inverse()`都是自解释的，与以往一样，它们不会立即执行，现在只是定义了图中的节点，具体计算要等到图运行时才会发生。可能已经看出来了，theta的定义用的是正规方程（Normal Equation）$\\hat \\theta = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$。最后，代码创建会话并对theta求值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 ms, sys: 10.9 ms, total: 43.6 ms\n",
      "Wall time: 36.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.6655663e+01],\n",
       "       [ 4.3743783e-01],\n",
       "       [ 9.4843078e-03],\n",
       "       [-1.0814029e-01],\n",
       "       [ 6.4832175e-01],\n",
       "       [-3.8346388e-06],\n",
       "       [-3.7944992e-03],\n",
       "       [-4.1838482e-01],\n",
       "       [-4.3125460e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与直接用NumPy来计算正规方程相比，上述代码的最大好处是如果有GPU，TensorFlow会把计算自动分发到GPU上去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 纯numpy方法\n",
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn方法\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 注意`housing.target`是个一维数组，需要将它变成一个列向量来计算theta。Numpy的reshape()函数接受-1（表示未指定）作为参数：该维度将根据数组的长度和剩余维度进行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现梯度下降\n",
    "\n",
    "来试一下批量梯度下降法（在第4章中有介绍）。首先手工计算梯度，然后使用TensorFlow的自动微分特性来自动计算梯度，最后学习TensorFlow内置的众多优化器。\n",
    "\n",
    "> 当使用梯度下降法时，要先对输入的特征向量做归一化，否则训练过程会非常慢。可以用TensorFlow、NumPy、Scikit-Learn的StandardScaler，或者其他的方法。下面这段代码假设已经做过了归一化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手工计算梯度\n",
    "\n",
    "下面的代码基本上都是自解释的了，除了这些新的点之外：\n",
    "\n",
    "* 函数`random_uniform()`会在图中创建一个节点，这个节点会生成一个张量。函数会根据传入的形状和值域来生成随机值来填充这个张量，这和NumPy的`rand()`函数很相似。\n",
    "\n",
    "* 函数`assign()`创建一个为变量赋值的节点。这里，它实现了批量梯度下降step $\\theta^{next\\_step} = \\theta - \\eta \\nabla_\\theta MSE(\\theta)$。\n",
    "\n",
    "* 主循环部分不断执行训练步骤（共`n_epochs`次），每经过100次迭代，它会打印当前的均方误差（Mean Squared Error）。这个值应该是不断降低的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , MSE = 6.835376\n",
      "Epoch 100 , MSE = 0.6663593\n",
      "Epoch 200 , MSE = 0.5608896\n",
      "Epoch 300 , MSE = 0.551602\n",
      "Epoch 400 , MSE = 0.5458059\n",
      "Epoch 500 , MSE = 0.54134893\n",
      "Epoch 600 , MSE = 0.53787977\n",
      "Epoch 700 , MSE = 0.53516465\n",
      "Epoch 800 , MSE = 0.53302884\n",
      "Epoch 900 , MSE = 0.53134054\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \", MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用自动微分\n",
    "\n",
    "上面的代码可以很好地工作，但是需要用数学的方式来从成本函数（MSE）中算出梯度。对于线性回归来说，这是很简单的，但是如果要处理深度神经网络就很头疼了：过程会琐碎而且容易出错。可以用符号微分法来自动求出偏导方程，不过代码就不一定那么高效了。\n",
    "\n",
    "为了理解其中的原因，想象函数$f(x)=\\exp(\\exp(\\exp(x)))$。如果懂微积分，计算出它的导数是$f'(x)=\\exp(x) \\times \\exp(\\exp(x)) \\times \\exp(\\exp(\\exp(x)))$。如果在代码中也这样做，那肯定是低效的。更高效的方式是写一个函数先计算$\\exp(x)$，然后再计算$\\exp(\\exp(x))$，最后计算$\\exp(\\exp(\\exp(x)))$，之后返回三个值。这样可以直接计算出$f(x)$，如果要计算导数，只需要将这三个值相乘。如果用原生的方法，需要调用exp函数9次来计算$f(x)$和$f'(x)$。后面这种方式只需要3次。\n",
    "\n",
    "如果函数由更复杂的代码定义，情况会变更糟。能求出下面这个函数的偏导方程吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754914"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "幸运的是，TensorFlow的`autodiff`功能可以帮你解决：它可以自动而且高效地算出梯度。只需要把上述例子中的对gradients的赋值的语句换成下面的代码即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.835376\n",
      "Epoch 100 MSE = 0.6663594\n",
      "Epoch 200 MSE = 0.5608896\n",
      "Epoch 300 MSE = 0.55160195\n",
      "Epoch 400 MSE = 0.5458059\n",
      "Epoch 500 MSE = 0.54134893\n",
      "Epoch 600 MSE = 0.53787977\n",
      "Epoch 700 MSE = 0.53516465\n",
      "Epoch 800 MSE = 0.53302884\n",
      "Epoch 900 MSE = 0.5313405\n",
      "Best theta: \n",
      " [[ 2.0685525 ]\n",
      " [ 0.8867773 ]\n",
      " [ 0.14236812]\n",
      " [-0.3493901 ]\n",
      " [ 0.36443284]\n",
      " [ 0.00334622]\n",
      " [-0.04254271]\n",
      " [-0.6740523 ]\n",
      " [-0.650193  ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta: \\n\",best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gradients()`函数接受一个操作符（这里是mse）和一个参数列表（这里是theta）作为参数，然后它会创建一个操作符的列表来计算每个变量的梯度。所以梯度节点将计算MSE相对于theta的梯度向量。\n",
    "\n",
    "四种自动计算梯度的主要方法见表9-2。TensorFlow使用了反向的`autodiff`算法，它非常适用于有多个输入和少量输出的场景（高效而精确），在神经网络中这种场景非常常见。它只需要$n_{outputs}+1$次遍历，就可以求出所有输出相对于输入的偏导。\n",
    "\n",
    "|    方法     | 计算所有梯度所需遍历次数 | 精确度 | 是否支持任意代码 |\n",
    "| ----------- | --------------------- | ----- | -------------- |\n",
    "| 数值微分    |                      | 低     | 是             |\n",
    "| 符号微分     |                      | 高     | 否             |\n",
    "| 前向自动微分 |                      | 高     | 是             |\n",
    "| 反向自动微分 |                      | 高     | 是             |\n",
    "\n",
    "表9-2：自动计算梯度的主要方法\n",
    "\n",
    "如果对其背后原理感兴趣，请参见附录D。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用优化器\n",
    "\n",
    "TensorFlow会计算梯度，不过它还提供更容易的方法：它内置了很多的优化器，其中就包括梯度下降优化器。只需要把上面对`gradients=`和`training_op=`赋值的语句修改成下面的代码即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.835376\n",
      "Epoch 100 MSE = 0.6663594\n",
      "Epoch 200 MSE = 0.5608896\n",
      "Epoch 300 MSE = 0.55160195\n",
      "Epoch 400 MSE = 0.5458059\n",
      "Epoch 500 MSE = 0.54134893\n",
      "Epoch 600 MSE = 0.53787977\n",
      "Epoch 700 MSE = 0.53516465\n",
      "Epoch 800 MSE = 0.53302884\n",
      "Epoch 900 MSE = 0.5313405\n",
      "Best theta: \n",
      " [[ 2.0685525 ]\n",
      " [ 0.8867773 ]\n",
      " [ 0.14236812]\n",
      " [-0.3493901 ]\n",
      " [ 0.36443284]\n",
      " [ 0.00334622]\n",
      " [-0.04254271]\n",
      " [-0.6740523 ]\n",
      " [-0.650193  ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta: \\n\", best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想使用其他类型的优化器，只需要修改一行代码。例如，如果要使用动量优化器（momentum optimizer）（比梯度下降优化器的收敛速度快很多，见第11章），可以这样定义优化器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.835376\n",
      "Epoch 100 MSE = 0.5299696\n",
      "Epoch 200 MSE = 0.52495897\n",
      "Epoch 300 MSE = 0.52440417\n",
      "Epoch 400 MSE = 0.52433205\n",
      "Epoch 500 MSE = 0.5243224\n",
      "Epoch 600 MSE = 0.52432126\n",
      "Epoch 700 MSE = 0.524321\n",
      "Epoch 800 MSE = 0.52432096\n",
      "Epoch 900 MSE = 0.524321\n",
      "Best theta: \n",
      " [[ 2.0685577 ]\n",
      " [ 0.8296283 ]\n",
      " [ 0.1187533 ]\n",
      " [-0.2655439 ]\n",
      " [ 0.30571038]\n",
      " [-0.00450253]\n",
      " [-0.0393266 ]\n",
      " [-0.89986515]\n",
      " [-0.8705216 ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta: \\n\", best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 给训练算法提供数据\n",
    "\n",
    "下面把上面的代码改成小批次梯度下降（Mini-batch Gradient Descent）。为此，需要一种在每次迭代时用下一个小批量替换$X$和$y$的方法。最简单的方法是用占位符节点。占位符节点非常特别，它们不进行任何实际的计算，而只是在运行时输出需要它输出的值。一般它用来在训练过程中将值传给TensorFlow。如果运行时不为占位符指定一个值，就会得到一个异常。\n",
    "\n",
    "要创建一个占位符节点，需要调用`placeholder()`函数并指定输出张量的数据类型。另外，如果想强制张量的形状，也可以在此指定。如果给维度设置None值，则表示“任意尺寸”。比如，下面的代码创建了一个占位符节点A，同时创建节点B，节点B=A+5。当对B求值时，给`eval()`方法传一个`feed_dict`，并指定A的值。注意，A必须是2阶的（比如，一个二维数组）而且必须有3列（否则会抛异常），不过可以有任意多行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.]]\n",
      "[[ 69.]\n",
      " [105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "k = tf.constant(np.array([2,4,6]).reshape(3, -1), dtype=tf.float32, name='k')\n",
    "B = tf.matmul(A, k)+ 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4,5,6],[7,8,9]]})\n",
    "\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 实际上，可以输入任何操作的输出，而不仅仅是占位符。这时TensorFlow不会求值这些操作，它会用传给它的值。\n",
    "\n",
    "要实现小批次梯度下降，只需要对既有代码做一点微小的调整。首先在构造阶段把$X$和$y$定义为占位符节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后定义批次的大小并计算批次的总数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，在执行阶段，逐个获取小批次，然后在评估依赖于它们的节点时，通过`feed_dict`参数提供$X$和$y$的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta: \n",
      " [[ 2.0698106 ]\n",
      " [ 0.7968277 ]\n",
      " [ 0.11595044]\n",
      " [-0.17811511]\n",
      " [ 0.26683366]\n",
      " [ 0.0036989 ]\n",
      " [-0.01120376]\n",
      " [-0.94976294]\n",
      " [-0.90927356]]\n"
     ]
    }
   ],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print(\"Best theta: \\n\", best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在求值theta时无须给$X$和$y$传值，因为theta不依赖于它们中的任意一个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复模型\n",
    "\n",
    "一旦训练好了模型，就需要将模型的参数保存到硬盘上，这样可以在任何时刻使用这些参数，可以在其他程序中使用，与其他模型做比较，等等。另外，可能希望在训练过程中定期将`检查点`（checkpoint）保存起来，这样当电脑崩溃时，可以从最近一个检查点恢复，而不是从头再来。\n",
    "\n",
    "在TensorFlow中，存取模型都非常容易。在构造期末尾（在所有变量节点都创建之后）创建一个Saver节点，然后在执行期，调用`save()`方法，并传入一个会话和检查点文件的路径即可保存模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.835376\n",
      "Epoch 100 MSE = 0.6663594\n",
      "Epoch 200 MSE = 0.5608896\n",
      "Epoch 300 MSE = 0.55160195\n",
      "Epoch 400 MSE = 0.5458059\n",
      "Epoch 500 MSE = 0.54134893\n",
      "Epoch 600 MSE = 0.53787977\n",
      "Epoch 700 MSE = 0.53516465\n",
      "Epoch 800 MSE = 0.53302884\n",
      "Epoch 900 MSE = 0.5313405\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                                       # not shown in the book\n",
    "learning_rate = 0.01                                                                  # not shown\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # not shown\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # not shown\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # not shown\n",
    "error = y_pred - y                                                                    # not shown\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # not shown\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # not shown\n",
    "training_op = optimizer.minimize(mse)                                                 # not shown\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
    "            save_path = saver.save(sess, \"models/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8867773 ],\n",
       "       [ 0.14236812],\n",
       "       [-0.3493901 ],\n",
       "       [ 0.36443284],\n",
       "       [ 0.00334622],\n",
       "       [-0.04254271],\n",
       "       [-0.6740523 ],\n",
       "       [-0.650193  ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恢复模型同样简单：与之前一样，在构造期末尾创建一个Saver节点，不过在执行期开始的时候，不是用init节点来初始化变量，而是调用`Saver`对象上的`restore()`方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() # not shown in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8867773 ],\n",
       "       [ 0.14236812],\n",
       "       [-0.3493901 ],\n",
       "       [ 0.36443284],\n",
       "       [ 0.00334622],\n",
       "       [-0.04254271],\n",
       "       [-0.6740523 ],\n",
       "       [-0.650193  ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认地，Saver会按照变量名来保存和恢复变量，不过如果想做更多的控制，也可以在保存和恢复时自己指定名称。比如，在下面的代码中，`Saver`只会保存theta，并将其命名为weights："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "# notice that we start with an empty graph.\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"models/my_model_final.ckpt.meta\")  # this loads the graph structure\n",
    "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\") # not shown in the book\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/my_model_final.ckpt\")  # this restores the graph's state\n",
    "    best_theta_restored = theta.eval() # not shown in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用TensorBoard来可视化图和训练曲线\n",
    "\n",
    "现在有一个可以用小批量梯度下降法训练线性回归模型的计算图了，而且可以周期性地将检查点保存起来。听起来很不错，不是吗？不过，现在还是依赖`print()`函数来可视化训练的进度。有一个更好的方法：使用`TensorBoard`。给它一些训练状态，它可以在浏览器中将这些状态以交互的方式展现出来（比如学习曲线）。还可以将图的定义提供给它，然后通过浏览器来进行查看。这种方式对识别图中的错误，发现图的瓶颈等非常有用。\n",
    "\n",
    "首先要对程序稍做修改，这样它可以将图的定义和训练状态，比如，训练误差（MSE），写入到一个TensorBoard会读取的日志文件夹中。每次运行程序时，都需要指定一个不同的目录，否则TensorBoard会将这些状态信息合并起来，这会导致可视化结果变成一团糟。最简单的方式是用时间戳来命名日志文件夹。把下面这些代码放在程序的开始部分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.093108286671858&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 9\\n          }\\n        }\\n        tensor_content: &quot;<stripped 743040 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        tensor_content: &quot;<stripped 82560 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 55\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 20640.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;gradients/Square_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/Square_grad/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Square_grad/Mul_1&quot;\\n  input: &quot;^gradients/sub_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Square_grad/Mul_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Square_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_theta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_theta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/filename/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/filename&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.093108286671858&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，把下面的代码放在构造期的最后一行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一行在图中创建了一个节点，这个节点用来求MSE的值，并将其写入与TensorBoard称为汇总（summary）的二进制日志字符串中。第二行创建了一个用来将汇总写入到日志目录的FileWriter。第一个参数指定了日志目录的路径（在这里如tf_logs/run-20160906091959，相对于当前目录）。第二个参数（可选）指定了想要可视化的计算图。创建之后，如果目录不存在，FileWriter会创建日志目录（如果父目录不存在，也会自动创建），并将图的定义写入一个叫作事件文件的二进制日志文件中。\n",
    "\n",
    "接下来，在执行期中，需要在训练时定期地求值mse_summary节点（比如，每10个小批量）。这会将汇总信息输出，然后通过`file_writer`来将其写入事件文件中，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()                                                     # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 要避免在每一步都记录状态信息，因为这会严重拖慢训练速度。\n",
    "\n",
    "最后，需要在程序结束时关闭FileWriter："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0698106 ],\n",
       "       [ 0.7968277 ],\n",
       "       [ 0.11595044],\n",
       "       [-0.17811511],\n",
       "       [ 0.26683366],\n",
       "       [ 0.0036989 ],\n",
       "       [-0.01120376],\n",
       "       [-0.94976294],\n",
       "       [-0.90927356]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在执行这个程序：它会创建一个日志目录，并在该目录中创建一个事件文件，事件文件中包含了图的定义和MSE的值。打开命令行，切换到工作目录，然后输入ls-l tf_logs/run*来列出该目录中的所有文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_logs/run-20201204061636:\n",
      "total 72\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec  4 14:18 events.out.tfevents.1607062601.esxvm1606\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 43372 Dec  4 14:39 events.out.tfevents.1607063964.esxvm1606\n",
      "\n",
      "tf_logs/run-20201221083619:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27451 Dec 21 16:54 events.out.tfevents.1608540655.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224073620:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec 24 15:36 events.out.tfevents.1608795404.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224073658:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27451 Dec 24 15:37 events.out.tfevents.1608795420.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224074416:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec 24 15:44 events.out.tfevents.1608795857.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224074418:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27451 Dec 24 15:44 events.out.tfevents.1608795858.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224074947:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec 24 15:49 events.out.tfevents.1608796187.esxvm1606\n"
     ]
    }
   ],
   "source": [
    "!ls -l tf_logs/run*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次运行该程序时，会在tf_logs/中看到第二个目录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_logs/run-20201204061636:\n",
      "total 72\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec  4 14:18 events.out.tfevents.1607062601.esxvm1606\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 43372 Dec  4 14:39 events.out.tfevents.1607063964.esxvm1606\n",
      "\n",
      "tf_logs/run-20201221083619:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27451 Dec 21 16:54 events.out.tfevents.1608540655.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224073620:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec 24 15:36 events.out.tfevents.1608795404.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224073658:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27451 Dec 24 15:37 events.out.tfevents.1608795420.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224074416:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec 24 15:44 events.out.tfevents.1608795857.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224074418:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27451 Dec 24 15:44 events.out.tfevents.1608795858.esxvm1606\n",
      "\n",
      "tf_logs/run-20201224074947:\n",
      "total 28\n",
      "-rw-rw-r-- 1 zhuangbin zhuangbin 27089 Dec 24 15:49 events.out.tfevents.1608796187.esxvm1606\n"
     ]
    }
   ],
   "source": [
    "!ls -l tf_logs/run*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好！现在是时候启动TensorBoard服务器了。如果创建了virtualenv，需要先激活它，然后用tensorboard命令来启动服务器，使它指向日志的根目录。这会启动TensorBoard的Web服务器，并在端口6006上监听（6006正是“goog”倒过来）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "source env/bin/activate\n",
    "tensorboard --logdir tf_logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在浏览器中输入 http://0.0.0.0:6006/ （或者 http://localhost:6006/ ），就可以看到TensorBoard的界面了！在事件页签，应该可以看到右侧的MSE，如图9-3所示。点击它可以看到两次训练过程中MSE的图表。可以选择展示哪一次的图表，可以放大或者缩小，鼠标移上去查看详情，等等。\n",
    "\n",
    "![图9-3：用TensorBoard可视化训练状态](images/VNote/20201221150807264_19623.png)\n",
    "\n",
    "图9-3：用TensorBoard可视化训练状态\n",
    "\n",
    "点击Graphs页签，应该可以看到图9-4中展示的图表。\n",
    "\n",
    "为了减轻页面上的杂乱感，有多条边的节点单独放在右侧的辅助区域（可以通过右键单击来切换节点在主图和辅助区域的展示）。图的一些部分默认地会折叠起来。比如，把鼠标指针挪至梯度节点，然后点击⊕图标就可以展开它的子图。接着在子图中，再试试展开mse_grad子图。\n",
    "\n",
    "> 如果你想在Jupyter中直接看一眼图的结构，可以用本章的笔记本中的函数`show_graph()`。这个函数最早由A.Mordvintsev在他的deepdream笔记本（ http://goo.gl/EtCWUc ）中开发。还可以安装E.Jang’s的包含了Jypyter扩展的TensorFlow调试工具（ https://github.com/ericjang/tdb ）来对图做可视化。\n",
    "\n",
    "![图9-4：用TensorBoard可视化计算图](images/VNote/20201221151005633_10253.png)\n",
    "\n",
    "图9-4：用TensorBoard可视化计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名作用域\n",
    "\n",
    "在处理诸如神经网络等复杂模型时，图很容易就变得杂乱而庞大。为了避免这种情况，可以创建命名作用域来将相关的节点分组。比如，可以修改上面的例子，将error（误差）和mse ops（MSE操作）定义到一个叫作“loss”的命名作用域中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.0703275 ]\n",
      " [ 0.86243355]\n",
      " [ 0.12225007]\n",
      " [-0.3099036 ]\n",
      " [ 0.38333285]\n",
      " [ 0.00425775]\n",
      " [-0.01224578]\n",
      " [-0.83737737]\n",
      " [-0.80648667]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个作用域中定义的每个操作现在都有一个“loss/”前缀："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在TensorBoard中，mse和error节点现在都显示在“loss”命名空间中，并且该命名空间默认是收起来的（见图9-5）。\n",
    "\n",
    "![图9-5：一个收起来的命名作用域](images/VNote/20201221170431025_2490.png)\n",
    "\n",
    "![](images/VNote/20201221170507301_16329.png)\n",
    "\n",
    "图9-5：一个收起来的命名作用域"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模块化\n",
    "\n",
    "假设想要创建一个计算两个修正线性单元（ReLU）之和的图。修正线性单元会计算输入的线性函数，如果值是正数，则输出其值，如果是负数，则返回0，如公式9-1所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h_{w,b}(X) = \\max(X \\cdot w +b , 0) \\tag{9-1} \\label{9-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式9-1：修正线性单元\n",
    "\n",
    "下面的代码可以完成这个工作，不过有点冗余："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "#relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
    "relu2 = tf.maximum(z2, 0., name=\"relu2\")\n",
    "\n",
    "output = tf.add(relu1, relu2, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种重复代码很难维护，也容易出错（事实上，这段代码包含了一个cut-and-paste的错误，你能看出来吗？）。当要添加多个ReLU时，情况会变得更糟。幸运的是，TensorFlow会让你保持DRY（Don’t Repeat Yourself，不要重复自己）原则：用一个函数来构建ReLU。下面的代码创建了5个ReLU，并且输出了它们的和（注意，`add_n()`创建了一个会计算一个张量列表的和的操作）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu1\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当创建一个节点时，TensorFlow会检查这个名字是否已经存在，如果已经存在了，它会为其添加一个下划线和一个索引以保证唯一性。第一个ReLU包含了名字为\"weights\"\"bias\"\"z\"和\"relu\"（以及一些有自己默认名字的节点，比如\"MatMul\"）的节点；第二个ReLU包含的节点即为：\"weights_1\"\"bias_1\"等；第三个ReLU会包含\"weights_2\"\"bias_2\"等节点，TensorBoard会发现这种规律，并将其归类到一组以避免界面的混乱（见图9-6）。\n",
    "\n",
    "![图9-6：收起的节点序列](images/VNote/20201221180913582_10312.png)\n",
    "\n",
    "图9-6：收起的节点序列\n",
    "\n",
    "使用命名作用域，可以让图更加清晰。只需要将`relu()`函数的内容放进一个命名作用域即可。图9-7展示了结果图。注意，TensorFlow还通过加`_1`、`_2`等后缀的方式为命名作用域提供了唯一的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                          # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                             # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      # not shown\n",
    "        return tf.maximum(z, 0., name=\"max\")                          # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图9-7：带有命名作用域的更加清晰的图](images/VNote/20201221181218686_15091.png)\n",
    "\n",
    "图9-7：带有命名作用域的更加清晰的图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享变量\n",
    "\n",
    "如果想在图的不同组件中共享变量，最简单的做法是先创建，然后将其作为参数传递给需要它的函数。比如想通过一个共享的阈值变量来控制所有ReLU的阈值（当前是硬编码为0的）。可以先创建这个变量，然后传给`relu()`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是可行的：已经可以通过threshold变量来控制所有ReLU的阈值了。不过，如果有太多类似的共享参数，那么一直将其作为参数来到处传递就会变得很痛苦。有些人创建了一个包含模型所需要的所有变量的字典，然后传递给每一个函数。也有人为每个模块都创建一个类（例如，一个ReLU类用类变量来持有共享参数）。别一个选项是在第一次调用时将共享变量设置为`relu()`函数的一个属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, \"threshold\"):\n",
    "            relu.threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, relu.threshold, name=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow提供另外一个选择，可以让代码更加清晰，也更加模块化。 [1] 这种方式一开始理解起来会有点困难，不过它会在TensorFlow中频繁使用，还是值得详细讨论的。如果共享变量不存在，该方法先通过`get_variable()`函数创建共享变量；如果已经存在了，就复用该共享变量。期望的行为通过当前`variable_scope()`的一个属性来控制（创建或者复用）。比如，下面的代码会创建一个名为\"relu/threshold\"的变量（因为`shape=()`，所以结果是一个标量，并且以0.0为初始值）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，如果这个变量之前已经被`get_variable()`调用创建过，这里会抛出一个异常。这种机制避免由于误操作而复用变量。如果要复用一个变量，需要通过设置变量作用域的`reuse`属性为True来显式地实现（在这里，不必指定形状或初始化器）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\", reuse=True):\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码会获取既有的\"relu/threshold\"变量，如果该变量不存在，或者在调用`get_variable()`时没有创建成功，那么会抛出一个异常。另一种方式是，在调用作用域的`reuse_variables()`方法块中设置reuse属性为True："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\") as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 一旦reuse属性设置为True之后，在该块中就不能再设置为False了。另外，如果在块中定义了另外的变量作用域，它们会自动继承`resue=True`。最后，只有通过`get_variable()`创建的变量才可以用这种方式来进行复用。\n",
    "\n",
    "现在已经看到了所有能让`relu()`函数无须通过传入参数就访问threshold变量的方法了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # not shown\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu6\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码首先定义了`relu()`函数，然后创建了relu/threshold变量（作为一个标量，会被初始化为0.0）并通过调用`relu()`函数构建了5个ReLU。`relu()`函数复用了relu/threshold变量，并创建其他的ReLU节点。\n",
    "\n",
    "> 通过`get_variable()`创建的变量总是以它们的`variable_scope`作为前缀来命名的（比如\"relu/threshold\"），对于其他节点（包括通过`tf.Variable()`创建的变量）变量作用域的行为就好像是一个新的作用域。具体来说，如果一个命名作用域有一个已经创建了的变量名，那么就会加上一个后缀以保证其唯一性。比如，上面例子中的所有变量（除了threshold变量）都有一个“relu_1”到“relu_5”的前缀，见图9-8。\n",
    "\n",
    "![图9-8：5个共享阈值变量的ReLU](images/VNote/20201223155932252_6679.png)\n",
    "\n",
    "图9-8：5个共享阈值变量的ReLU\n",
    "\n",
    "遗憾的是，threshold变量必须定义在`relu()`函数之外，其他所有的ReLU代码都在内部。要解决这个问题，下面的代码在`relu()`函数第一次调用时创建了threshold变量，并在后续的调用中复用。现在`relu()`函数无须关注命名作用域或者变量共享问题，它只需要调用`get_variable()`，来创建或者复用threshold变量（无须关心到底是创建还是复用）。剩下的代码调用了`relu()`5次，确保第一次调用时将reuse设置为False，后续的调用将reuse设置为True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "    b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果图跟之前的略有不同，因为共享变量在第一个ReLU中（见图9-9）。\n",
    "\n",
    "![图9-9：5个共享threshold变量的ReLU](images/VNote/20201223160538149_22655.png)\n",
    "\n",
    "图9-9：5个共享threshold变量的ReLU\n",
    "\n",
    "TensorFlow的介绍就到此为止了。后续的章节将讨论更多的高级主题，特别是与深度神经网络、卷积神经网络、复发神经网络相关的操作，以及如何通过多线程、队列、多GPU、多服务器等对TensorFlow进行扩容。\n",
    "\n",
    "[1] 理论上来说，创建一个ReLU类是最清晰的做法，不过非常重量级。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习\n",
    "\n",
    "1.相比直接执行计算，创建计算图的最大优点是什么？最大的缺点呢？\n",
    "\n",
    "标准答案：\n",
    "* 主要优点：\n",
    "- TensorFlow可以自动计算梯度（通过反向的autodiff）。\n",
    "- TensorFlow负责在不同的线程中并行执行各个操作。\n",
    "- 它可以更容易地在多设备上运行同一个模型。\n",
    "- 它简化了查看，比如，在TensorBoard上查看模型。\n",
    "\n",
    "* 主要缺点：\n",
    "- 学习曲线陡峭。\n",
    "- 逐步的调试比较困难。\n",
    "\n",
    "2.语句a_val=a.eval（session=sess）和a_val=sess.run（a）等价吗？\n",
    "\n",
    "等价\n",
    "\n",
    "3.语句a_val，b_val=a.eval（session=sess），b.eval（session=sess）和a_val，b_val=sess.run（[a，b]）等价吗？\n",
    "\n",
    "标准答案：\n",
    "语句a_val，b_val=a.eval（session=sess），b.eval（ses sion=sess）不等于a_val，b_val=sess.run（[a，b]）。第一条语句会运行两次（第一次计算a，第二次计算b），而第二条语句只运行一次。如果这些操作（或者它们依赖的操作）中的任意一个具有副作用（比如，修改一个变量，向队列中插入一条记录，或者读取一个文件等），那么效果就会不同。如果操作没有副作用，那么语句会返回同样的结果，不过第二条语句会比第一条快。\n",
    "\n",
    "4.你可以在同一个会话中运行两个图吗？\n",
    "不可以。需要合并两个图\n",
    "\n",
    "5.假设你创建了一个包含变量w的图，然后在两个线程中分别启动一个会话，两个线程都使用了图g，每个会话会有自己对w变量的拷贝，还是会共享变量？\n",
    "\n",
    "标准答案：\n",
    "在本地TensorFlow中，会话用来管理变量的值，如果创建了一个包含变量w的图g，然后启动两个线程，并在每个线程中打开一个本地的会话，这两个线程使用同一个图g，那么每个会话会拥有自己的w的拷贝。如果在分布式的TensorFlow中，变量的值则存储在由集群管理的容器中，如果两个会话连接了同一个集群，并使用同一个容器，那么它们会共享变量w。\n",
    "\n",
    "6.变量何时被初始化，又在何时被销毁？\n",
    "\n",
    "标准答案：\n",
    "变量在调用其初始化器的时候被初始化，在会话结束的时候被销毁。在分布式TensorFlow中，变量存活于集群上的容器中，所以关闭一个会话不会销毁变量。要销毁一个变量，需要清空它所在的容器。\n",
    "\n",
    "7.占位符(placeholder)和变量的区别是什么？\n",
    "\n",
    "标准答案：\n",
    "变量和占位符完全不同：\n",
    "\n",
    "* 变量是包含一个值的操作。执行一个变量，它会返回对应的值。在执行之前，需要初始化变量。可以修改变量的值（比如，通过使用赋值操作）。变量有状态：在连续运行图时，变量保持相同的值。通常它被用作保存模型的参数，不过也可以用作其他用途（比如，对全局训练的步数进行计数）。\n",
    "\n",
    "* 占位符则只能做很少的事儿：它们只有其所代表的张量的类型和形状的信息，但没有值。事实上，如果要对一个依赖于占位符的操作进行求值，必须先为其传值（通过feed_dict），否则会得到一个异常。占位符通常在被用作在执行期为训练或者测试数据传值。在将值传递给赋值节点以更改变量的值时（例如，模型的权重），占位符也很有用。\n",
    "\n",
    "8.如果对一个依赖于占位符的操作求值，但是又没有为其传值，会发生什么？如果这个操作不依赖于占位符呢？\n",
    "\n",
    "如果运行计算图来求值一个依赖于占位符的操作，但不提供值，则会发生异常。如果操作不依赖于占位符，则不会引发异常。\n",
    "\n",
    "9.运行一个图时，可以为任意操作输出值，还是只能输出占位符的值？\n",
    "\n",
    "为任意操作输出值。\n",
    "\n",
    "标准答案：可以提供任何操作的输出值，而不仅仅是占位符的值。在实践中，这种情况很少见（有时候会是有用的，比如你要缓存冷冻层的输出时，详见第11章）。\n",
    "\n",
    "10.在执行期，你如何为一个变量设置任意的值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43695855\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "x = tf.Variable(tf.random_uniform(shape=(), minval=0.0, maxval=1.0, seed=55))\n",
    "x_new_val = tf.placeholder(shape=(), dtype=tf.float32)\n",
    "x_assign = tf.assign(x, x_new_val)\n",
    "\n",
    "with tf.Session():\n",
    "    x.initializer.run() # random number is sampled *now*\n",
    "    print(x.eval()) # 0.43695855 (some random number)\n",
    "    x_assign.eval(feed_dict={x_new_val: 5.0})\n",
    "    print(x.eval()) # 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.反向模式autodiff需要多少次遍历图形才能计算10个变量的成本函数的梯度？正向模式autodiff怎么样？符号微分呢？\n",
    "\n",
    "标准答案：\n",
    "要计算任意数量变量的成本函数的梯度，反向模式的autodiff算法（由TensorFlow实现）只需要遍历两次图。作为对比，正向模式的autodiff算法需要为每个变量运行一次（如果需要10个不同变量的梯度，那么就需要执行10次）。对于符号微分，它会建立一个不同的图来计算梯度，所以根本不会遍历原来的图（除了在建立新的梯度图时）。一个高度优化的符号微分系统可能只需要运行一次新的梯度图来计算和所有变量相关的梯度，但与原始图相比，新的图可能是非常复杂和低效的。\n",
    "\n",
    "12.用小批量梯度下降法来实现逻辑回归。用月亮数据集来训练和评估（数据见第5章）。尝试下面这些任务：\n",
    "\n",
    "·在函数logistic_regression（）中定义可以被复用的图。\n",
    "\n",
    "·在训练过程中，定期地通过Saver将检查点保存起来，并将最后的模型保存起来。\n",
    "\n",
    "·如果训练被终止了，恢复之前保存的模型。\n",
    "\n",
    "·用合理的作用域来定义图，使得其在TensorBoard上看起来比较漂亮。\n",
    "\n",
    "·添加汇总信息以在TensorBoard中可视化学习曲线。\n",
    "\n",
    "·调整诸如学习速率和批次大小等超参数，并查看学习曲线的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label=\"Positive\")\n",
    "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.04041541,  0.2593172 ],\n",
       "       [ 1.        , -0.87690781,  0.71716305],\n",
       "       [ 1.        , -0.05176601,  0.17144429],\n",
       "       [ 1.        ,  1.77017809, -0.11691548],\n",
       "       [ 1.        ,  0.13624349,  1.03418265]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moons_with_bias[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m * test_ratio)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.56662761,  0.61405463],\n",
       "       [ 1.        , -0.88745633,  0.52356176],\n",
       "       [ 1.        , -0.09593897,  0.98536308],\n",
       "       [ 1.        , -0.54951966,  0.72140468],\n",
       "       [ 1.        , -1.03773679,  0.02002096]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = random_batch(X_train, y_train, 5)\n",
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=55), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name=\"logits\")\n",
    "y_proba = 1 / (1 + tf.exp(-logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7  # to avoid an overflow when computing the log\n",
    "loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * tf.log(1 - y_proba + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.log_loss(y, y_proba)  # uses epsilon = 1e-7 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.7139546\n",
      "Epoch: 100 \tLoss: 0.35528415\n",
      "Epoch: 200 \tLoss: 0.3090748\n",
      "Epoch: 300 \tLoss: 0.28753236\n",
      "Epoch: 400 \tLoss: 0.27620205\n",
      "Epoch: 500 \tLoss: 0.26895764\n",
      "Epoch: 600 \tLoss: 0.26432994\n",
      "Epoch: 700 \tLoss: 0.26093873\n",
      "Epoch: 800 \tLoss: 0.25875986\n",
      "Epoch: 900 \tLoss: 0.2570105\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6278026 ],\n",
       "       [0.1208533 ],\n",
       "       [0.8089659 ],\n",
       "       [0.03510776],\n",
       "       [0.98115313]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_proba_val >= 0.5)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8529411764705882"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877551020408163"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enhanced = np.c_[X_train,\n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 7)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enhanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=55, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
    "            theta = tf.Variable(initializer, name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2 + 4\n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 1.0210636\n",
      "Epoch: 500 \tLoss: 0.16051973\n",
      "Epoch: 1000 \tLoss: 0.112247065\n",
      "Epoch: 1500 \tLoss: 0.0890018\n",
      "Epoch: 2000 \tLoss: 0.07484798\n",
      "Epoch: 2500 \tLoss: 0.06549355\n",
      "Epoch: 3000 \tLoss: 0.05846446\n",
      "Epoch: 3500 \tLoss: 0.053244147\n",
      "Epoch: 4000 \tLoss: 0.04919156\n",
      "Epoch: 4500 \tLoss: 0.045878693\n",
      "Epoch: 5000 \tLoss: 0.042978708\n",
      "Epoch: 5500 \tLoss: 0.04073383\n",
      "Epoch: 6000 \tLoss: 0.038682833\n",
      "Epoch: 6500 \tLoss: 0.036881603\n",
      "Epoch: 7000 \tLoss: 0.03536608\n",
      "Epoch: 7500 \tLoss: 0.03405993\n",
      "Epoch: 8000 \tLoss: 0.032896604\n",
      "Epoch: 8500 \tLoss: 0.031772044\n",
      "Epoch: 9000 \tLoss: 0.030746384\n",
      "Epoch: 9500 \tLoss: 0.029842796\n",
      "Epoch: 10000 \tLoss: 0.029036965\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./models/my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98989898989899"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949238578680203"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "  logdir: tf_logs/logreg-run-20201224075228/\n",
      "  batch size: 80\n",
      "  learning_rate: 0.004430375245218265\n",
      "  training: .....................\n",
      "  precision: 0.98\n",
      "  recall: 1.0\n",
      "Iteration 1\n",
      "  logdir: tf_logs/logreg-run-20201224075404/\n",
      "  batch size: 67\n",
      "  learning_rate: 0.0017826497151386947\n",
      "  training: .....................\n",
      "  precision: 0.9607843137254902\n",
      "  recall: 1.0\n",
      "Iteration 2\n",
      "  logdir: tf_logs/logreg-run-20201224075552/\n",
      "  batch size: 40\n",
      "  learning_rate: 0.00203228544324115\n",
      "  training: .....................\n",
      "  precision: 0.98\n",
      "  recall: 1.0\n",
      "Iteration 3\n",
      "  logdir: tf_logs/logreg-run-20201224075843/\n",
      "  batch size: 80\n",
      "  learning_rate: 0.004491523825137997\n",
      "  training: .....................\n",
      "  precision: 0.98\n",
      "  recall: 1.0\n",
      "Iteration 4\n",
      "  logdir: tf_logs/logreg-run-20201224080018/\n",
      "  batch size: 67\n",
      "  learning_rate: 0.07963234721775589\n",
      "  training: .....................\n",
      "  precision: 1.0\n",
      "  recall: 1.0\n",
      "Iteration 5\n",
      "  logdir: tf_logs/logreg-run-20201224080206/\n",
      "  batch size: 40\n",
      "  learning_rate: 0.0004634250583294876\n",
      "  training: .....................\n",
      "  precision: 0.9393939393939394\n",
      "  recall: 0.9489795918367347\n",
      "Iteration 6\n",
      "  logdir: tf_logs/logreg-run-20201224080458/\n",
      "  batch size: 80\n",
      "  learning_rate: 0.047706818419354494\n",
      "  training: .....................\n",
      "  precision: 1.0\n",
      "  recall: 1.0\n",
      "Iteration 7\n",
      "  logdir: tf_logs/logreg-run-20201224080634/\n",
      "  batch size: 67\n",
      "  learning_rate: 0.0001694044709524274\n",
      "  training: .....................\n",
      "  precision: 0.8446601941747572\n",
      "  recall: 0.8877551020408163\n",
      "Iteration 8\n",
      "  logdir: tf_logs/logreg-run-20201224080823/\n",
      "  batch size: 40\n",
      "  learning_rate: 0.04171461199412461\n",
      "  training: .....................\n",
      "  precision: 1.0\n",
      "  recall: 1.0\n",
      "Iteration 9\n",
      "  logdir: tf_logs/logreg-run-20201224081115/\n",
      "  batch size: 80\n",
      "  learning_rate: 0.00010742922968438615\n",
      "  training: .....................\n",
      "  precision: 0.8217821782178217\n",
      "  recall: 0.8469387755102041\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "\n",
    "n_search_iterations = 10\n",
    "\n",
    "for search_iteration in range(n_search_iterations):\n",
    "    batch_size = np.random.randint(1, 100)\n",
    "    learning_rate = reciprocal(0.0001, 0.1).rvs(random_state=search_iteration)\n",
    "\n",
    "    n_inputs = 2 + 4\n",
    "    logdir = log_dir(\"logreg\")\n",
    "    \n",
    "    print(\"Iteration\", search_iteration)\n",
    "    print(\"  logdir:\", logdir)\n",
    "    print(\"  batch size:\", batch_size)\n",
    "    print(\"  learning_rate:\", learning_rate)\n",
    "    print(\"  training: \", end=\"\")\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(\n",
    "        X, y, learning_rate=learning_rate)\n",
    "\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "    n_epochs = 10001\n",
    "    n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "    final_model_path = \"./models/my_logreg_model_%d\" % search_iteration\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_index in range(n_batches):\n",
    "                X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "            if epoch % 500 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "\n",
    "        saver.save(sess, final_model_path)\n",
    "\n",
    "        print()\n",
    "        y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        y_pred = (y_proba_val >= 0.5)\n",
    "        \n",
    "        print(\"  precision:\", precision_score(y_test, y_pred))\n",
    "        print(\"  recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
